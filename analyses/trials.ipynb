{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "192eb123",
   "metadata": {},
   "source": [
    "These should work on kaggle server with Brain-to-text '25 as input.\n",
    "\n",
    "You have to save the output files manually since they will be destroyed once the kaggle session is finished!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "\n",
    "Probably if you want to test other models that return the same format as the baseline, you can change the evaluate_model.py script and the arguments in cmd1 or cmd2 below (remember that you have to push the changed evaluate_model.py file to github first)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc573e59",
   "metadata": {},
   "source": [
    "1. Run this to test the model and create a submission file and detailed description file(groud truth not available):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba03bb2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,632 B]\n",
      "Get:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n",
      "Get:3 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]      \n",
      "Get:4 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]           \n",
      "0% [Waiting for headers] [3 InRelease 14.2 kB/129 kB 11%] [Waiting for headers]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get:5 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ Packages [83.6 kB]\n",
      "Hit:6 http://archive.ubuntu.com/ubuntu jammy InRelease                         \n",
      "Get:7 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [2,225 kB]\n",
      "Get:8 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]        \n",
      "Get:9 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [9,572 kB]  \n",
      "Get:10 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease [18.1 kB]\n",
      "Hit:11 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
      "Hit:12 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease   \n",
      "Get:13 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [6,205 kB]\n",
      "Get:14 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,860 kB]\n",
      "Get:15 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 Packages [38.5 kB]\n",
      "Get:16 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]     \n",
      "Get:17 http://archive.ubuntu.com/ubuntu jammy-updates/multiverse amd64 Packages [69.2 kB]\n",
      "Get:18 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,287 kB]\n",
      "Get:19 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [3,633 kB]\n",
      "Get:20 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,598 kB]\n",
      "Get:21 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [6,411 kB]\n",
      "Get:22 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [3,966 kB]\n",
      "Get:23 http://archive.ubuntu.com/ubuntu jammy-backports/main amd64 Packages [83.9 kB]\n",
      "Get:24 http://archive.ubuntu.com/ubuntu jammy-backports/universe amd64 Packages [37.2 kB]\n",
      "Fetched 38.5 MB in 3s (13.6 MB/s)                            \n",
      "Reading package lists... Done\n",
      "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
      "Reading package lists... Done\n",
      "Building dependency tree... Done\n",
      "Reading state information... Done\n",
      "The following additional packages will be installed:\n",
      "  libjemalloc2 liblua5.1-0 liblzf1 lua-bitop lua-cjson redis-tools\n",
      "Suggested packages:\n",
      "  ruby-redis\n",
      "The following NEW packages will be installed:\n",
      "  libjemalloc2 liblua5.1-0 liblzf1 lua-bitop lua-cjson redis-server\n",
      "  redis-tools\n",
      "0 upgraded, 7 newly installed, 0 to remove and 191 not upgraded.\n",
      "Need to get 1,273 kB of archives.\n",
      "After this operation, 5,725 kB of additional disk space will be used.\n",
      "Get:1 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libjemalloc2 amd64 5.2.1-4ubuntu1 [240 kB]\n",
      "Get:2 http://archive.ubuntu.com/ubuntu jammy/universe amd64 liblua5.1-0 amd64 5.1.5-8.1build4 [99.9 kB]\n",
      "Get:3 http://archive.ubuntu.com/ubuntu jammy/universe amd64 liblzf1 amd64 3.6-3 [7,444 B]\n",
      "Get:4 http://archive.ubuntu.com/ubuntu jammy/universe amd64 lua-bitop amd64 1.0.2-5 [6,680 B]\n",
      "Get:5 http://archive.ubuntu.com/ubuntu jammy/universe amd64 lua-cjson amd64 2.1.0+dfsg-2.1 [17.4 kB]\n",
      "Get:6 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 redis-tools amd64 5:6.0.16-1ubuntu1.1 [856 kB]\n",
      "Get:7 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 redis-server amd64 5:6.0.16-1ubuntu1.1 [45.9 kB]\n",
      "Fetched 1,273 kB in 0s (5,252 kB/s)     \n",
      "Selecting previously unselected package libjemalloc2:amd64.\n",
      "(Reading database ... 128639 files and directories currently installed.)\n",
      "Preparing to unpack .../0-libjemalloc2_5.2.1-4ubuntu1_amd64.deb ...\n",
      "Unpacking libjemalloc2:amd64 (5.2.1-4ubuntu1) ...\n",
      "Selecting previously unselected package liblua5.1-0:amd64.\n",
      "Preparing to unpack .../1-liblua5.1-0_5.1.5-8.1build4_amd64.deb ...\n",
      "Unpacking liblua5.1-0:amd64 (5.1.5-8.1build4) ...\n",
      "Selecting previously unselected package liblzf1:amd64.\n",
      "Preparing to unpack .../2-liblzf1_3.6-3_amd64.deb ...\n",
      "Unpacking liblzf1:amd64 (3.6-3) ...\n",
      "Selecting previously unselected package lua-bitop:amd64.\n",
      "Preparing to unpack .../3-lua-bitop_1.0.2-5_amd64.deb ...\n",
      "Unpacking lua-bitop:amd64 (1.0.2-5) ...\n",
      "Selecting previously unselected package lua-cjson:amd64.\n",
      "Preparing to unpack .../4-lua-cjson_2.1.0+dfsg-2.1_amd64.deb ...\n",
      "Unpacking lua-cjson:amd64 (2.1.0+dfsg-2.1) ...\n",
      "Selecting previously unselected package redis-tools.\n",
      "Preparing to unpack .../5-redis-tools_5%3a6.0.16-1ubuntu1.1_amd64.deb ...\n",
      "Unpacking redis-tools (5:6.0.16-1ubuntu1.1) ...\n",
      "Selecting previously unselected package redis-server.\n",
      "Preparing to unpack .../6-redis-server_5%3a6.0.16-1ubuntu1.1_amd64.deb ...\n",
      "Unpacking redis-server (5:6.0.16-1ubuntu1.1) ...\n",
      "Setting up libjemalloc2:amd64 (5.2.1-4ubuntu1) ...\n",
      "Setting up lua-cjson:amd64 (2.1.0+dfsg-2.1) ...\n",
      "Setting up liblzf1:amd64 (3.6-3) ...\n",
      "Setting up lua-bitop:amd64 (1.0.2-5) ...\n",
      "Setting up liblua5.1-0:amd64 (5.1.5-8.1build4) ...\n",
      "Setting up redis-tools (5:6.0.16-1ubuntu1.1) ...\n",
      "Setting up redis-server (5:6.0.16-1ubuntu1.1) ...\n",
      "invoke-rc.d: could not determine current runlevel\n",
      "invoke-rc.d: policy-rc.d denied execution of start.\n",
      "Created symlink /etc/systemd/system/redis.service → /lib/systemd/system/redis-server.service.\n",
      "Created symlink /etc/systemd/system/multi-user.target.wants/redis-server.service → /lib/systemd/system/redis-server.service.\n",
      "Processing triggers for man-db (2.10.2-1) ...\n",
      "Processing triggers for libc-bin (2.35-0ubuntu3.8) ...\n",
      "/sbin/ldconfig.real: /usr/local/lib/libumf.so.0 is not a symbolic link\n",
      "\n",
      "/sbin/ldconfig.real: /usr/local/lib/libtcm_debug.so.1 is not a symbolic link\n",
      "\n",
      "/sbin/ldconfig.real: /usr/local/lib/libtcm.so.1 is not a symbolic link\n",
      "\n",
      "/sbin/ldconfig.real: /usr/local/lib/libhwloc.so.15 is not a symbolic link\n",
      "\n",
      "/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n",
      "\n",
      "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n",
      "\n",
      "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n",
      "\n",
      "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
      "\n",
      "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
      "\n",
      "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
      "\n",
      "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
      "\n",
      "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
      "\n",
      "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
      "\n",
      "--2025-12-24 07:26:05--  https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh\n",
      "Resolving repo.anaconda.com (repo.anaconda.com)... 104.16.32.241, 104.16.191.158, 2606:4700::6810:20f1, ...\n",
      "Connecting to repo.anaconda.com (repo.anaconda.com)|104.16.32.241|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 156772981 (150M) [application/octet-stream]\n",
      "Saving to: ‘/root/miniconda3/miniconda.sh’\n",
      "\n",
      "/root/miniconda3/mi 100%[===================>] 149.51M   150MB/s    in 1.0s    \n",
      "\n",
      "2025-12-24 07:26:06 (150 MB/s) - ‘/root/miniconda3/miniconda.sh’ saved [156772981/156772981]\n",
      "\n",
      "PREFIX=/root/miniconda3\n",
      "Unpacking bootstrapper...\n",
      "Unpacking payload...\n",
      "\n",
      "Installing base environment...\n",
      "\n",
      "Preparing transaction: ...working... done\n",
      "Executing transaction: ...working... done\n",
      "installation finished.\n",
      "WARNING:\n",
      "    You currently have a PYTHONPATH environment variable set. This may cause\n",
      "    unexpected behavior when running the Python interpreter in Miniconda3.\n",
      "    For best results, please verify that your PYTHONPATH only points to\n",
      "    directories of packages that are compatible with the Python interpreter\n",
      "    in Miniconda3: /root/miniconda3\n",
      "accepted Terms of Service for \u001b[4;94mhttps://repo.anaconda.com/pkgs/main\u001b[0m\n",
      "accepted Terms of Service for \u001b[4;94mhttps://repo.anaconda.com/pkgs/r\u001b[0m\n",
      "rm: cannot remove './Brain-To-Text-MOA': No such file or directory\n",
      "Cloning into 'Brain-To-Text-MOA'...\n",
      "remote: Enumerating objects: 2974, done.\u001b[K\n",
      "remote: Counting objects: 100% (35/35), done.\u001b[K\n",
      "remote: Compressing objects: 100% (27/27), done.\u001b[K\n",
      "remote: Total 2974 (delta 14), reused 23 (delta 7), pack-reused 2939 (from 3)\u001b[K\n",
      "Receiving objects: 100% (2974/2974), 82.12 MiB | 44.78 MiB/s, done.\n",
      "Resolving deltas: 100% (390/390), done.\n",
      "/kaggle/working/Brain-To-Text-MOA\n",
      "\u001b[35mcmd2:\u001b[0m Sleeping for 15 minutes...\n",
      "\u001b[95mcmd1:\u001b[0m Jupyter detected...\n",
      "\u001b[95mcmd1:\u001b[0m 2 channel Terms of Service accepted\n",
      "\u001b[95mcmd1:\u001b[0m Retrieving notices: done\n",
      "\u001b[95mcmd1:\u001b[0m Channels:\n",
      "\u001b[95mcmd1:\u001b[0m  - defaults\n",
      "\u001b[95mcmd1:\u001b[0m Platform: linux-64\n",
      "\u001b[95mcmd1:\u001b[0m Collecting package metadata (repodata.json): done\n",
      "\u001b[95mcmd1:\u001b[0m Solving environment: done\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[95mcmd1:\u001b[0m ## Package Plan ##\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[95mcmd1:\u001b[0m   environment location: /root/miniconda3/envs/b2txt25_lm\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[95mcmd1:\u001b[0m   added / updated specs:\n",
      "\u001b[95mcmd1:\u001b[0m     - python=3.9\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[95mcmd1:\u001b[0m The following packages will be downloaded:\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[95mcmd1:\u001b[0m     package                    |            build\n",
      "\u001b[95mcmd1:\u001b[0m     ---------------------------|-----------------\n",
      "\u001b[95mcmd1:\u001b[0m     libnsl-2.0.0               |       h5eee18b_0          31 KB\n",
      "\u001b[95mcmd1:\u001b[0m     python-3.9.25              |       h0dcde21_1        23.0 MB\n",
      "\u001b[95mcmd1:\u001b[0m     setuptools-80.9.0          |   py39h06a4308_0         1.4 MB\n",
      "\u001b[95mcmd1:\u001b[0m     wheel-0.45.1               |   py39h06a4308_0         114 KB\n",
      "\u001b[95mcmd1:\u001b[0m     ------------------------------------------------------------\n",
      "\u001b[95mcmd1:\u001b[0m                                            Total:        24.6 MB\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[95mcmd1:\u001b[0m The following NEW packages will be INSTALLED:\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[95mcmd1:\u001b[0m   _libgcc_mutex      pkgs/main/linux-64::_libgcc_mutex-0.1-main \n",
      "\u001b[95mcmd1:\u001b[0m   _openmp_mutex      pkgs/main/linux-64::_openmp_mutex-5.1-1_gnu \n",
      "\u001b[95mcmd1:\u001b[0m   bzip2              pkgs/main/linux-64::bzip2-1.0.8-h5eee18b_6 \n",
      "\u001b[95mcmd1:\u001b[0m   ca-certificates    pkgs/main/linux-64::ca-certificates-2025.12.2-h06a4308_0 \n",
      "\u001b[95mcmd1:\u001b[0m   expat              pkgs/main/linux-64::expat-2.7.3-h7354ed3_4 \n",
      "\u001b[95mcmd1:\u001b[0m   ld_impl_linux-64   pkgs/main/linux-64::ld_impl_linux-64-2.44-h153f514_2 \n",
      "\u001b[95mcmd1:\u001b[0m   libexpat           pkgs/main/linux-64::libexpat-2.7.3-h7354ed3_4 \n",
      "\u001b[95mcmd1:\u001b[0m   libffi             pkgs/main/linux-64::libffi-3.4.4-h6a678d5_1 \n",
      "\u001b[95mcmd1:\u001b[0m   libgcc             pkgs/main/linux-64::libgcc-15.2.0-h69a1729_7 \n",
      "\u001b[95mcmd1:\u001b[0m   libgcc-ng          pkgs/main/linux-64::libgcc-ng-15.2.0-h166f726_7 \n",
      "\u001b[95mcmd1:\u001b[0m   libgomp            pkgs/main/linux-64::libgomp-15.2.0-h4751f2c_7 \n",
      "\u001b[95mcmd1:\u001b[0m   libnsl             pkgs/main/linux-64::libnsl-2.0.0-h5eee18b_0 \n",
      "\u001b[95mcmd1:\u001b[0m   libstdcxx          pkgs/main/linux-64::libstdcxx-15.2.0-h39759b7_7 \n",
      "\u001b[95mcmd1:\u001b[0m   libstdcxx-ng       pkgs/main/linux-64::libstdcxx-ng-15.2.0-hc03a8fd_7 \n",
      "\u001b[95mcmd1:\u001b[0m   libuuid            pkgs/main/linux-64::libuuid-1.41.5-h5eee18b_0 \n",
      "\u001b[95mcmd1:\u001b[0m   libxcb             pkgs/main/linux-64::libxcb-1.17.0-h9b100fa_0 \n",
      "\u001b[95mcmd1:\u001b[0m   libzlib            pkgs/main/linux-64::libzlib-1.3.1-hb25bd0a_0 \n",
      "\u001b[95mcmd1:\u001b[0m   ncurses            pkgs/main/linux-64::ncurses-6.5-h7934f7d_0 \n",
      "\u001b[95mcmd1:\u001b[0m   openssl            pkgs/main/linux-64::openssl-3.0.18-hd6dcaed_0 \n",
      "\u001b[95mcmd1:\u001b[0m   pip                pkgs/main/noarch::pip-25.3-pyhc872135_0 \n",
      "\u001b[95mcmd1:\u001b[0m   pthread-stubs      pkgs/main/linux-64::pthread-stubs-0.3-h0ce48e5_1 \n",
      "\u001b[95mcmd1:\u001b[0m   python             pkgs/main/linux-64::python-3.9.25-h0dcde21_1 \n",
      "\u001b[95mcmd1:\u001b[0m   readline           pkgs/main/linux-64::readline-8.3-hc2a1206_0 \n",
      "\u001b[95mcmd1:\u001b[0m   setuptools         pkgs/main/linux-64::setuptools-80.9.0-py39h06a4308_0 \n",
      "\u001b[95mcmd1:\u001b[0m   sqlite             pkgs/main/linux-64::sqlite-3.51.0-h2a70700_0 \n",
      "\u001b[95mcmd1:\u001b[0m   tk                 pkgs/main/linux-64::tk-8.6.15-h54e0aa7_0 \n",
      "\u001b[95mcmd1:\u001b[0m   tzdata             pkgs/main/noarch::tzdata-2025b-h04d1e81_0 \n",
      "\u001b[95mcmd1:\u001b[0m   wheel              pkgs/main/linux-64::wheel-0.45.1-py39h06a4308_0 \n",
      "\u001b[95mcmd1:\u001b[0m   xorg-libx11        pkgs/main/linux-64::xorg-libx11-1.8.12-h9b100fa_1 \n",
      "\u001b[95mcmd1:\u001b[0m   xorg-libxau        pkgs/main/linux-64::xorg-libxau-1.0.12-h9b100fa_0 \n",
      "\u001b[95mcmd1:\u001b[0m   xorg-libxdmcp      pkgs/main/linux-64::xorg-libxdmcp-1.1.5-h9b100fa_0 \n",
      "\u001b[95mcmd1:\u001b[0m   xorg-xorgproto     pkgs/main/linux-64::xorg-xorgproto-2024.1-h5eee18b_1 \n",
      "\u001b[95mcmd1:\u001b[0m   xz                 pkgs/main/linux-64::xz-5.6.4-h5eee18b_1 \n",
      "\u001b[95mcmd1:\u001b[0m   zlib               pkgs/main/linux-64::zlib-1.3.1-hb25bd0a_0 \n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[95mcmd1:\u001b[0m Downloading and Extracting Packages: ...working...\n",
      "\u001b[95mcmd1:\u001b[0m python-3.9.25        | 23.0 MB   |            |   0% \n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[95mcmd1:\u001b[0m setuptools-80.9.0    | 1.4 MB    |            |   0% \u001b[A\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[95mcmd1:\u001b[0m wheel-0.45.1         | 114 KB    |            |   0% \u001b[A\u001b[A\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[95mcmd1:\u001b[0m libnsl-2.0.0         | 31 KB     |            |   0% \u001b[A\u001b[A\u001b[A\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[95mcmd1:\u001b[0m setuptools-80.9.0    | 1.4 MB    | 1          |   1% \u001b[A\n",
      "\u001b[95mcmd1:\u001b[0m python-3.9.25        | 23.0 MB   |            |   0% \n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[95mcmd1:\u001b[0m libnsl-2.0.0         | 31 KB     | #####1     |  52% \u001b[A\u001b[A\u001b[A\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[95mcmd1:\u001b[0m libnsl-2.0.0         | 31 KB     | ########## | 100% \u001b[A\u001b[A\u001b[A\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[95mcmd1:\u001b[0m wheel-0.45.1         | 114 KB    | #4         |  14% \u001b[A\u001b[A\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[95mcmd1:\u001b[0m libnsl-2.0.0         | 31 KB     | ########## | 100% \u001b[A\u001b[A\u001b[A\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[95mcmd1:\u001b[0m wheel-0.45.1         | 114 KB    | ########## | 100% \u001b[A\u001b[A\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[95mcmd1:\u001b[0m setuptools-80.9.0    | 1.4 MB    | ########## | 100% \u001b[A\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[95mcmd1:\u001b[0m wheel-0.45.1         | 114 KB    | ########## | 100% \u001b[A\u001b[A\n",
      "\u001b[95mcmd1:\u001b[0m python-3.9.25        | 23.0 MB   | ##1        |  21% \n",
      "\u001b[95mcmd1:\u001b[0m python-3.9.25        | 23.0 MB   | #######8   |  78% \n",
      "\u001b[95mcmd1:\u001b[0m python-3.9.25        | 23.0 MB   | ########## | 100% \n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[95mcmd1:\u001b[0m setuptools-80.9.0    | 1.4 MB    | ########## | 100% \u001b[A\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[95mcmd1:\u001b[0m setuptools-80.9.0    | 1.4 MB    | ########## | 100% \u001b[A\n",
      "\u001b[95mcmd1:\u001b[0m python-3.9.25        | 23.0 MB   | ########## | 100% \n",
      "\u001b[95mcmd1:\u001b[0m                                                      \n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[95mcmd1:\u001b[0m                                                      \u001b[A\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[95mcmd1:\u001b[0m                                                      \u001b[A\u001b[A\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[95mcmd1:\u001b[0m                                                      \u001b[A\u001b[A\u001b[A done\n",
      "\u001b[95mcmd1:\u001b[0m Preparing transaction: done\n",
      "\u001b[95mcmd1:\u001b[0m Verifying transaction: done\n",
      "\u001b[95mcmd1:\u001b[0m Executing transaction: done\n",
      "\u001b[95mcmd1:\u001b[0m #\n",
      "\u001b[95mcmd1:\u001b[0m # To activate this environment, use\n",
      "\u001b[95mcmd1:\u001b[0m #\n",
      "\u001b[95mcmd1:\u001b[0m #     $ conda activate b2txt25_lm\n",
      "\u001b[95mcmd1:\u001b[0m #\n",
      "\u001b[95mcmd1:\u001b[0m # To deactivate an active environment, use\n",
      "\u001b[95mcmd1:\u001b[0m #\n",
      "\u001b[95mcmd1:\u001b[0m #     $ conda deactivate\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[95mcmd1:\u001b[0m Requirement already satisfied: pip in /root/miniconda3/envs/b2txt25_lm/lib/python3.9/site-packages (25.3)\n",
      "\u001b[95mcmd1:\u001b[0m Collecting torch==1.13.1\n",
      "\u001b[95mcmd1:\u001b[0m   Downloading torch-1.13.1-cp39-cp39-manylinux1_x86_64.whl.metadata (24 kB)\n",
      "\u001b[95mcmd1:\u001b[0m Collecting redis==5.0.6\n",
      "\u001b[95mcmd1:\u001b[0m   Downloading redis-5.0.6-py3-none-any.whl.metadata (9.3 kB)\n",
      "\u001b[95mcmd1:\u001b[0m Collecting jupyter==1.1.1\n",
      "\u001b[95mcmd1:\u001b[0m   Downloading jupyter-1.1.1-py2.py3-none-any.whl.metadata (2.0 kB)\n",
      "\u001b[95mcmd1:\u001b[0m Collecting numpy==1.24.4\n",
      "\u001b[95mcmd1:\u001b[0m   Downloading numpy-1.24.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.6 kB)\n",
      "\u001b[95mcmd1:\u001b[0m Collecting matplotlib==3.9.0\n",
      "\u001b[95mcmd1:\u001b[0m   Downloading matplotlib-3.9.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
      "\u001b[95mcmd1:\u001b[0m Collecting scipy==1.11.1\n",
      "\u001b[95mcmd1:\u001b[0m   Downloading scipy-1.11.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (59 kB)\n",
      "\u001b[95mcmd1:\u001b[0m Collecting scikit-learn==1.6.1\n",
      "\u001b[95mcmd1:\u001b[0m   Downloading scikit_learn-1.6.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
      "\u001b[95mcmd1:\u001b[0m Collecting tqdm==4.66.4\n",
      "\u001b[95mcmd1:\u001b[0m   Downloading tqdm-4.66.4-py3-none-any.whl.metadata (57 kB)\n",
      "\u001b[95mcmd1:\u001b[0m Collecting g2p_en==2.1.0\n",
      "\u001b[95mcmd1:\u001b[0m   Downloading g2p_en-2.1.0-py3-none-any.whl.metadata (4.5 kB)\n",
      "\u001b[95mcmd1:\u001b[0m Collecting omegaconf==2.3.0\n",
      "\u001b[95mcmd1:\u001b[0m   Downloading omegaconf-2.3.0-py3-none-any.whl.metadata (3.9 kB)\n",
      "\u001b[95mcmd1:\u001b[0m Collecting huggingface-hub==0.23.4\n",
      "\u001b[95mcmd1:\u001b[0m   Downloading huggingface_hub-0.23.4-py3-none-any.whl.metadata (12 kB)\n",
      "\u001b[95mcmd1:\u001b[0m Collecting transformers==4.40.0\n",
      "\u001b[95mcmd1:\u001b[0m   Downloading transformers-4.40.0-py3-none-any.whl.metadata (137 kB)\n",
      "\u001b[95mcmd1:\u001b[0m Collecting tokenizers==0.19.1\n",
      "\u001b[95mcmd1:\u001b[0m   Downloading tokenizers-0.19.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "\u001b[95mcmd1:\u001b[0m Collecting accelerate==0.33.0\n",
      "\u001b[95mcmd1:\u001b[0m   Downloading accelerate-0.33.0-py3-none-any.whl.metadata (18 kB)\n",
      "\u001b[95mcmd1:\u001b[0m Collecting bitsandbytes==0.41.1\n",
      "\u001b[95mcmd1:\u001b[0m   Downloading bitsandbytes-0.41.1-py3-none-any.whl.metadata (9.8 kB)\n",
      "\u001b[95mcmd1:\u001b[0m Collecting typing-extensions (from torch==1.13.1)\n",
      "\u001b[95mcmd1:\u001b[0m   Downloading typing_extensions-4.15.0-py3-none-any.whl.metadata (3.3 kB)\n",
      "\u001b[95mcmd1:\u001b[0m Collecting nvidia-cuda-runtime-cu11==11.7.99 (from torch==1.13.1)\n",
      "\u001b[95mcmd1:\u001b[0m   Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "\u001b[95mcmd1:\u001b[0m Collecting nvidia-cudnn-cu11==8.5.0.96 (from torch==1.13.1)\n",
      "\u001b[95mcmd1:\u001b[0m   Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "\u001b[95mcmd1:\u001b[0m Collecting nvidia-cublas-cu11==11.10.3.66 (from torch==1.13.1)\n",
      "\u001b[95mcmd1:\u001b[0m   Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "\u001b[95mcmd1:\u001b[0m Collecting nvidia-cuda-nvrtc-cu11==11.7.99 (from torch==1.13.1)\n",
      "\u001b[95mcmd1:\u001b[0m   Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "\u001b[95mcmd1:\u001b[0m Collecting async-timeout>=4.0.3 (from redis==5.0.6)\n",
      "\u001b[95mcmd1:\u001b[0m   Downloading async_timeout-5.0.1-py3-none-any.whl.metadata (5.1 kB)\n",
      "\u001b[95mcmd1:\u001b[0m Collecting notebook (from jupyter==1.1.1)\n",
      "\u001b[95mcmd1:\u001b[0m   Downloading notebook-7.5.1-py3-none-any.whl.metadata (10 kB)\n",
      "\u001b[95mcmd1:\u001b[0m Collecting jupyter-console (from jupyter==1.1.1)\n",
      "\u001b[95mcmd1:\u001b[0m   Downloading jupyter_console-6.6.3-py3-none-any.whl.metadata (5.8 kB)\n",
      "\u001b[95mcmd1:\u001b[0m Collecting nbconvert (from jupyter==1.1.1)\n",
      "\u001b[95mcmd1:\u001b[0m   Downloading nbconvert-7.16.6-py3-none-any.whl.metadata (8.5 kB)\n",
      "\u001b[95mcmd1:\u001b[0m Collecting ipykernel (from jupyter==1.1.1)\n",
      "\u001b[95mcmd1:\u001b[0m   Downloading ipykernel-6.31.0-py3-none-any.whl.metadata (4.5 kB)\n",
      "\u001b[95mcmd1:\u001b[0m Collecting ipywidgets (from jupyter==1.1.1)\n",
      "\u001b[95mcmd1:\u001b[0m   Downloading ipywidgets-8.1.8-py3-none-any.whl.metadata (2.4 kB)\n",
      "\u001b[95mcmd1:\u001b[0m Collecting jupyterlab (from jupyter==1.1.1)\n",
      "\u001b[95mcmd1:\u001b[0m   Downloading jupyterlab-4.5.1-py3-none-any.whl.metadata (16 kB)\n",
      "\u001b[95mcmd1:\u001b[0m Collecting contourpy>=1.0.1 (from matplotlib==3.9.0)\n",
      "\u001b[95mcmd1:\u001b[0m   Downloading contourpy-1.3.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.4 kB)\n",
      "\u001b[95mcmd1:\u001b[0m Collecting cycler>=0.10 (from matplotlib==3.9.0)\n",
      "\u001b[95mcmd1:\u001b[0m   Downloading cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "\u001b[95mcmd1:\u001b[0m Collecting fonttools>=4.22.0 (from matplotlib==3.9.0)\n",
      "\u001b[95mcmd1:\u001b[0m   Downloading fonttools-4.60.2-cp39-cp39-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (113 kB)\n",
      "\u001b[95mcmd1:\u001b[0m Collecting kiwisolver>=1.3.1 (from matplotlib==3.9.0)\n",
      "\u001b[95mcmd1:\u001b[0m   Downloading kiwisolver-1.4.7-cp39-cp39-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (6.3 kB)\n",
      "\u001b[95mcmd1:\u001b[0m Collecting packaging>=20.0 (from matplotlib==3.9.0)\n",
      "\u001b[95mcmd1:\u001b[0m   Downloading packaging-25.0-py3-none-any.whl.metadata (3.3 kB)\n",
      "\u001b[95mcmd1:\u001b[0m Collecting pillow>=8 (from matplotlib==3.9.0)\n",
      "\u001b[95mcmd1:\u001b[0m   Downloading pillow-11.3.0-cp39-cp39-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (9.0 kB)\n",
      "\u001b[95mcmd1:\u001b[0m Collecting pyparsing>=2.3.1 (from matplotlib==3.9.0)\n",
      "\u001b[95mcmd1:\u001b[0m   Downloading pyparsing-3.3.1-py3-none-any.whl.metadata (5.6 kB)\n",
      "\u001b[95mcmd1:\u001b[0m Collecting python-dateutil>=2.7 (from matplotlib==3.9.0)\n",
      "\u001b[95mcmd1:\u001b[0m   Downloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl.metadata (8.4 kB)\n",
      "\u001b[95mcmd1:\u001b[0m Collecting importlib-resources>=3.2.0 (from matplotlib==3.9.0)\n",
      "\u001b[95mcmd1:\u001b[0m   Downloading importlib_resources-6.5.2-py3-none-any.whl.metadata (3.9 kB)\n",
      "\u001b[95mcmd1:\u001b[0m Collecting joblib>=1.2.0 (from scikit-learn==1.6.1)\n",
      "\u001b[95mcmd1:\u001b[0m   Downloading joblib-1.5.3-py3-none-any.whl.metadata (5.5 kB)\n",
      "\u001b[95mcmd1:\u001b[0m Collecting threadpoolctl>=3.1.0 (from scikit-learn==1.6.1)\n",
      "\u001b[95mcmd1:\u001b[0m   Downloading threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "\u001b[95mcmd1:\u001b[0m Collecting nltk>=3.2.4 (from g2p_en==2.1.0)\n",
      "\u001b[95mcmd1:\u001b[0m   Downloading nltk-3.9.2-py3-none-any.whl.metadata (3.2 kB)\n",
      "\u001b[95mcmd1:\u001b[0m Collecting inflect>=0.3.1 (from g2p_en==2.1.0)\n",
      "\u001b[95mcmd1:\u001b[0m   Downloading inflect-7.5.0-py3-none-any.whl.metadata (24 kB)\n",
      "\u001b[95mcmd1:\u001b[0m Collecting distance>=0.1.3 (from g2p_en==2.1.0)\n",
      "\u001b[95mcmd1:\u001b[0m   Downloading Distance-0.1.3.tar.gz (180 kB)\n",
      "\u001b[95mcmd1:\u001b[0m   Installing build dependencies: started\n",
      "\u001b[95mcmd1:\u001b[0m   Installing build dependencies: finished with status 'done'\n",
      "\u001b[95mcmd1:\u001b[0m   Getting requirements to build wheel: started\n",
      "\u001b[95mcmd1:\u001b[0m   Getting requirements to build wheel: finished with status 'done'\n",
      "\u001b[95mcmd1:\u001b[0m   Preparing metadata (pyproject.toml): started\n",
      "\u001b[95mcmd1:\u001b[0m   Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "\u001b[95mcmd1:\u001b[0m Collecting antlr4-python3-runtime==4.9.* (from omegaconf==2.3.0)\n",
      "\u001b[95mcmd1:\u001b[0m   Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n",
      "\u001b[95mcmd1:\u001b[0m   Installing build dependencies: started\n",
      "\u001b[95mcmd1:\u001b[0m   Installing build dependencies: finished with status 'done'\n",
      "\u001b[95mcmd1:\u001b[0m   Getting requirements to build wheel: started\n",
      "\u001b[95mcmd1:\u001b[0m   Getting requirements to build wheel: finished with status 'done'\n",
      "\u001b[95mcmd1:\u001b[0m   Preparing metadata (pyproject.toml): started\n",
      "\u001b[95mcmd1:\u001b[0m   Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "\u001b[95mcmd1:\u001b[0m Collecting PyYAML>=5.1.0 (from omegaconf==2.3.0)\n",
      "\u001b[95mcmd1:\u001b[0m   Downloading pyyaml-6.0.3-cp39-cp39-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (2.4 kB)\n",
      "\u001b[95mcmd1:\u001b[0m Collecting filelock (from huggingface-hub==0.23.4)\n",
      "\u001b[95mcmd1:\u001b[0m   Downloading filelock-3.19.1-py3-none-any.whl.metadata (2.1 kB)\n",
      "\u001b[95mcmd1:\u001b[0m Collecting fsspec>=2023.5.0 (from huggingface-hub==0.23.4)\n",
      "\u001b[95mcmd1:\u001b[0m   Downloading fsspec-2025.10.0-py3-none-any.whl.metadata (10 kB)\n",
      "\u001b[95mcmd1:\u001b[0m Collecting requests (from huggingface-hub==0.23.4)\n",
      "\u001b[95mcmd1:\u001b[0m   Downloading requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
      "\u001b[95mcmd1:\u001b[0m Collecting regex!=2019.12.17 (from transformers==4.40.0)\n",
      "\u001b[95mcmd1:\u001b[0m   Downloading regex-2025.11.3-cp39-cp39-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (40 kB)\n",
      "\u001b[95mcmd1:\u001b[0m Collecting safetensors>=0.4.1 (from transformers==4.40.0)\n",
      "\u001b[95mcmd1:\u001b[0m   Downloading safetensors-0.7.0-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
      "\u001b[95mcmd1:\u001b[0m Collecting psutil (from accelerate==0.33.0)\n",
      "\u001b[95mcmd1:\u001b[0m   Downloading psutil-7.2.0-cp36-abi3-manylinux2010_x86_64.manylinux_2_12_x86_64.manylinux_2_28_x86_64.whl.metadata (22 kB)\n",
      "\u001b[95mcmd1:\u001b[0m Requirement already satisfied: setuptools in /root/miniconda3/envs/b2txt25_lm/lib/python3.9/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch==1.13.1) (80.9.0)\n",
      "\u001b[95mcmd1:\u001b[0m Requirement already satisfied: wheel in /root/miniconda3/envs/b2txt25_lm/lib/python3.9/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch==1.13.1) (0.45.1)\n",
      "\u001b[95mcmd1:\u001b[0m Collecting zipp>=3.1.0 (from importlib-resources>=3.2.0->matplotlib==3.9.0)\n",
      "\u001b[95mcmd1:\u001b[0m   Downloading zipp-3.23.0-py3-none-any.whl.metadata (3.6 kB)\n",
      "\u001b[95mcmd1:\u001b[0m Collecting more_itertools>=8.5.0 (from inflect>=0.3.1->g2p_en==2.1.0)\n",
      "\u001b[95mcmd1:\u001b[0m   Downloading more_itertools-10.8.0-py3-none-any.whl.metadata (39 kB)\n",
      "\u001b[95mcmd1:\u001b[0m Collecting typeguard>=4.0.1 (from inflect>=0.3.1->g2p_en==2.1.0)\n",
      "\u001b[95mcmd1:\u001b[0m   Downloading typeguard-4.4.4-py3-none-any.whl.metadata (3.3 kB)\n",
      "\u001b[95mcmd1:\u001b[0m Collecting click (from nltk>=3.2.4->g2p_en==2.1.0)\n",
      "\u001b[95mcmd1:\u001b[0m   Downloading click-8.1.8-py3-none-any.whl.metadata (2.3 kB)\n",
      "\u001b[95mcmd1:\u001b[0m Collecting six>=1.5 (from python-dateutil>=2.7->matplotlib==3.9.0)\n",
      "\u001b[95mcmd1:\u001b[0m   Downloading six-1.17.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
      "\u001b[95mcmd1:\u001b[0m Collecting importlib_metadata>=3.6 (from typeguard>=4.0.1->inflect>=0.3.1->g2p_en==2.1.0)\n",
      "\u001b[95mcmd1:\u001b[0m   Downloading importlib_metadata-8.7.1-py3-none-any.whl.metadata (4.7 kB)\n",
      "\u001b[95mcmd1:\u001b[0m Collecting comm>=0.1.1 (from ipykernel->jupyter==1.1.1)\n",
      "\u001b[95mcmd1:\u001b[0m   Downloading comm-0.2.3-py3-none-any.whl.metadata (3.7 kB)\n",
      "\u001b[95mcmd1:\u001b[0m Collecting debugpy>=1.6.5 (from ipykernel->jupyter==1.1.1)\n",
      "\u001b[95mcmd1:\u001b[0m   Downloading debugpy-1.8.19-cp39-cp39-manylinux_2_34_x86_64.whl.metadata (1.4 kB)\n",
      "\u001b[95mcmd1:\u001b[0m Collecting ipython>=7.23.1 (from ipykernel->jupyter==1.1.1)\n",
      "\u001b[95mcmd1:\u001b[0m   Downloading ipython-8.18.1-py3-none-any.whl.metadata (6.0 kB)\n",
      "\u001b[95mcmd1:\u001b[0m Collecting jupyter-client>=8.0.0 (from ipykernel->jupyter==1.1.1)\n",
      "\u001b[95mcmd1:\u001b[0m   Downloading jupyter_client-8.6.3-py3-none-any.whl.metadata (8.3 kB)\n",
      "\u001b[95mcmd1:\u001b[0m Collecting jupyter-core!=5.0.*,>=4.12 (from ipykernel->jupyter==1.1.1)\n",
      "\u001b[95mcmd1:\u001b[0m   Downloading jupyter_core-5.8.1-py3-none-any.whl.metadata (1.6 kB)\n",
      "\u001b[95mcmd1:\u001b[0m Collecting matplotlib-inline>=0.1 (from ipykernel->jupyter==1.1.1)\n",
      "\u001b[95mcmd1:\u001b[0m   Downloading matplotlib_inline-0.2.1-py3-none-any.whl.metadata (2.3 kB)\n",
      "\u001b[95mcmd1:\u001b[0m Collecting nest-asyncio>=1.4 (from ipykernel->jupyter==1.1.1)\n",
      "\u001b[95mcmd1:\u001b[0m   Downloading nest_asyncio-1.6.0-py3-none-any.whl.metadata (2.8 kB)\n",
      "\u001b[95mcmd1:\u001b[0m Collecting pyzmq>=25 (from ipykernel->jupyter==1.1.1)\n",
      "\u001b[95mcmd1:\u001b[0m   Downloading pyzmq-27.1.0-cp39-cp39-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (6.0 kB)\n",
      "\u001b[95mcmd1:\u001b[0m Collecting tornado>=6.2 (from ipykernel->jupyter==1.1.1)\n",
      "\u001b[95mcmd1:\u001b[0m   Downloading tornado-6.5.4-cp39-abi3-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.8 kB)\n",
      "\u001b[95mcmd1:\u001b[0m Collecting traitlets>=5.4.0 (from ipykernel->jupyter==1.1.1)\n",
      "\u001b[95mcmd1:\u001b[0m   Downloading traitlets-5.14.3-py3-none-any.whl.metadata (10 kB)\n",
      "\u001b[95mcmd1:\u001b[0m Collecting decorator (from ipython>=7.23.1->ipykernel->jupyter==1.1.1)\n",
      "\u001b[95mcmd1:\u001b[0m   Downloading decorator-5.2.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "\u001b[95mcmd1:\u001b[0m Collecting jedi>=0.16 (from ipython>=7.23.1->ipykernel->jupyter==1.1.1)\n",
      "\u001b[95mcmd1:\u001b[0m   Downloading jedi-0.19.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "\u001b[95mcmd1:\u001b[0m Collecting prompt-toolkit<3.1.0,>=3.0.41 (from ipython>=7.23.1->ipykernel->jupyter==1.1.1)\n",
      "\u001b[95mcmd1:\u001b[0m   Downloading prompt_toolkit-3.0.52-py3-none-any.whl.metadata (6.4 kB)\n",
      "\u001b[95mcmd1:\u001b[0m Collecting pygments>=2.4.0 (from ipython>=7.23.1->ipykernel->jupyter==1.1.1)\n",
      "\u001b[95mcmd1:\u001b[0m   Downloading pygments-2.19.2-py3-none-any.whl.metadata (2.5 kB)\n",
      "\u001b[95mcmd1:\u001b[0m Collecting stack-data (from ipython>=7.23.1->ipykernel->jupyter==1.1.1)\n",
      "\u001b[95mcmd1:\u001b[0m   Downloading stack_data-0.6.3-py3-none-any.whl.metadata (18 kB)\n",
      "\u001b[95mcmd1:\u001b[0m Collecting exceptiongroup (from ipython>=7.23.1->ipykernel->jupyter==1.1.1)\n",
      "\u001b[95mcmd1:\u001b[0m   Downloading exceptiongroup-1.3.1-py3-none-any.whl.metadata (6.7 kB)\n",
      "\u001b[95mcmd1:\u001b[0m Collecting pexpect>4.3 (from ipython>=7.23.1->ipykernel->jupyter==1.1.1)\n",
      "\u001b[95mcmd1:\u001b[0m   Downloading pexpect-4.9.0-py2.py3-none-any.whl.metadata (2.5 kB)\n",
      "\u001b[95mcmd1:\u001b[0m Collecting wcwidth (from prompt-toolkit<3.1.0,>=3.0.41->ipython>=7.23.1->ipykernel->jupyter==1.1.1)\n",
      "\u001b[95mcmd1:\u001b[0m   Downloading wcwidth-0.2.14-py2.py3-none-any.whl.metadata (15 kB)\n",
      "\u001b[95mcmd1:\u001b[0m Collecting parso<0.9.0,>=0.8.4 (from jedi>=0.16->ipython>=7.23.1->ipykernel->jupyter==1.1.1)\n",
      "\u001b[95mcmd1:\u001b[0m   Downloading parso-0.8.5-py2.py3-none-any.whl.metadata (8.3 kB)\n",
      "\u001b[95mcmd1:\u001b[0m Collecting platformdirs>=2.5 (from jupyter-core!=5.0.*,>=4.12->ipykernel->jupyter==1.1.1)\n",
      "\u001b[95mcmd1:\u001b[0m   Downloading platformdirs-4.4.0-py3-none-any.whl.metadata (12 kB)\n",
      "\u001b[95mcmd1:\u001b[0m Collecting ptyprocess>=0.5 (from pexpect>4.3->ipython>=7.23.1->ipykernel->jupyter==1.1.1)\n",
      "\u001b[95mcmd1:\u001b[0m   Downloading ptyprocess-0.7.0-py2.py3-none-any.whl.metadata (1.3 kB)\n",
      "\u001b[95mcmd1:\u001b[0m Collecting widgetsnbextension~=4.0.14 (from ipywidgets->jupyter==1.1.1)\n",
      "\u001b[95mcmd1:\u001b[0m   Downloading widgetsnbextension-4.0.15-py3-none-any.whl.metadata (1.6 kB)\n",
      "\u001b[95mcmd1:\u001b[0m Collecting jupyterlab_widgets~=3.0.15 (from ipywidgets->jupyter==1.1.1)\n",
      "\u001b[95mcmd1:\u001b[0m   Downloading jupyterlab_widgets-3.0.16-py3-none-any.whl.metadata (20 kB)\n",
      "\u001b[95mcmd1:\u001b[0m Collecting async-lru>=1.0.0 (from jupyterlab->jupyter==1.1.1)\n",
      "\u001b[95mcmd1:\u001b[0m   Downloading async_lru-2.0.5-py3-none-any.whl.metadata (4.5 kB)\n",
      "\u001b[95mcmd1:\u001b[0m Collecting httpx<1,>=0.25.0 (from jupyterlab->jupyter==1.1.1)\n",
      "\u001b[95mcmd1:\u001b[0m   Downloading httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "\u001b[95mcmd1:\u001b[0m Collecting jinja2>=3.0.3 (from jupyterlab->jupyter==1.1.1)\n",
      "\u001b[95mcmd1:\u001b[0m   Downloading jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
      "\u001b[95mcmd1:\u001b[0m Collecting jupyter-lsp>=2.0.0 (from jupyterlab->jupyter==1.1.1)\n",
      "\u001b[95mcmd1:\u001b[0m   Downloading jupyter_lsp-2.3.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "\u001b[95mcmd1:\u001b[0m Collecting jupyter-server<3,>=2.4.0 (from jupyterlab->jupyter==1.1.1)\n",
      "\u001b[95mcmd1:\u001b[0m   Downloading jupyter_server-2.17.0-py3-none-any.whl.metadata (8.5 kB)\n",
      "\u001b[95mcmd1:\u001b[0m Collecting jupyterlab-server<3,>=2.28.0 (from jupyterlab->jupyter==1.1.1)\n",
      "\u001b[95mcmd1:\u001b[0m   Downloading jupyterlab_server-2.28.0-py3-none-any.whl.metadata (5.9 kB)\n",
      "\u001b[95mcmd1:\u001b[0m Collecting notebook-shim>=0.2 (from jupyterlab->jupyter==1.1.1)\n",
      "\u001b[95mcmd1:\u001b[0m   Downloading notebook_shim-0.2.4-py3-none-any.whl.metadata (4.0 kB)\n",
      "\u001b[95mcmd1:\u001b[0m Collecting tomli>=1.2.2 (from jupyterlab->jupyter==1.1.1)\n",
      "\u001b[95mcmd1:\u001b[0m   Downloading tomli-2.3.0-py3-none-any.whl.metadata (10 kB)\n",
      "\u001b[95mcmd1:\u001b[0m Collecting anyio (from httpx<1,>=0.25.0->jupyterlab->jupyter==1.1.1)\n",
      "\u001b[95mcmd1:\u001b[0m   Downloading anyio-4.12.0-py3-none-any.whl.metadata (4.3 kB)\n",
      "\u001b[95mcmd1:\u001b[0m Collecting certifi (from httpx<1,>=0.25.0->jupyterlab->jupyter==1.1.1)\n",
      "\u001b[95mcmd1:\u001b[0m   Downloading certifi-2025.11.12-py3-none-any.whl.metadata (2.5 kB)\n",
      "\u001b[95mcmd1:\u001b[0m Collecting httpcore==1.* (from httpx<1,>=0.25.0->jupyterlab->jupyter==1.1.1)\n",
      "\u001b[95mcmd1:\u001b[0m   Downloading httpcore-1.0.9-py3-none-any.whl.metadata (21 kB)\n",
      "\u001b[95mcmd1:\u001b[0m Collecting idna (from httpx<1,>=0.25.0->jupyterlab->jupyter==1.1.1)\n",
      "\u001b[95mcmd1:\u001b[0m   Downloading idna-3.11-py3-none-any.whl.metadata (8.4 kB)\n",
      "\u001b[95mcmd1:\u001b[0m Collecting h11>=0.16 (from httpcore==1.*->httpx<1,>=0.25.0->jupyterlab->jupyter==1.1.1)\n",
      "\u001b[95mcmd1:\u001b[0m   Downloading h11-0.16.0-py3-none-any.whl.metadata (8.3 kB)\n",
      "\u001b[95mcmd1:\u001b[0m Collecting argon2-cffi>=21.1 (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter==1.1.1)\n",
      "\u001b[95mcmd1:\u001b[0m   Downloading argon2_cffi-25.1.0-py3-none-any.whl.metadata (4.1 kB)\n",
      "\u001b[95mcmd1:\u001b[0m Collecting jupyter-events>=0.11.0 (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter==1.1.1)\n",
      "\u001b[95mcmd1:\u001b[0m   Downloading jupyter_events-0.12.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "\u001b[95mcmd1:\u001b[0m Collecting jupyter-server-terminals>=0.4.4 (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter==1.1.1)\n",
      "\u001b[95mcmd1:\u001b[0m   Downloading jupyter_server_terminals-0.5.3-py3-none-any.whl.metadata (5.6 kB)\n",
      "\u001b[95mcmd1:\u001b[0m Collecting nbformat>=5.3.0 (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter==1.1.1)\n",
      "\u001b[95mcmd1:\u001b[0m   Downloading nbformat-5.10.4-py3-none-any.whl.metadata (3.6 kB)\n",
      "\u001b[95mcmd1:\u001b[0m Collecting overrides>=5.0 (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter==1.1.1)\n",
      "\u001b[95mcmd1:\u001b[0m   Downloading overrides-7.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "\u001b[95mcmd1:\u001b[0m Collecting prometheus-client>=0.9 (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter==1.1.1)\n",
      "\u001b[95mcmd1:\u001b[0m   Downloading prometheus_client-0.23.1-py3-none-any.whl.metadata (1.9 kB)\n",
      "\u001b[95mcmd1:\u001b[0m Collecting send2trash>=1.8.2 (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter==1.1.1)\n",
      "\u001b[95mcmd1:\u001b[0m   Downloading Send2Trash-1.8.3-py3-none-any.whl.metadata (4.0 kB)\n",
      "\u001b[95mcmd1:\u001b[0m Collecting terminado>=0.8.3 (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter==1.1.1)\n",
      "\u001b[95mcmd1:\u001b[0m   Downloading terminado-0.18.1-py3-none-any.whl.metadata (5.8 kB)\n",
      "\u001b[95mcmd1:\u001b[0m Collecting websocket-client>=1.7 (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter==1.1.1)\n",
      "\u001b[95mcmd1:\u001b[0m   Downloading websocket_client-1.9.0-py3-none-any.whl.metadata (8.3 kB)\n",
      "\u001b[95mcmd1:\u001b[0m Collecting babel>=2.10 (from jupyterlab-server<3,>=2.28.0->jupyterlab->jupyter==1.1.1)\n",
      "\u001b[95mcmd1:\u001b[0m   Downloading babel-2.17.0-py3-none-any.whl.metadata (2.0 kB)\n",
      "\u001b[95mcmd1:\u001b[0m Collecting json5>=0.9.0 (from jupyterlab-server<3,>=2.28.0->jupyterlab->jupyter==1.1.1)\n",
      "\u001b[95mcmd1:\u001b[0m   Downloading json5-0.12.1-py3-none-any.whl.metadata (36 kB)\n",
      "\u001b[95mcmd1:\u001b[0m Collecting jsonschema>=4.18.0 (from jupyterlab-server<3,>=2.28.0->jupyterlab->jupyter==1.1.1)\n",
      "\u001b[95mcmd1:\u001b[0m   Downloading jsonschema-4.25.1-py3-none-any.whl.metadata (7.6 kB)\n",
      "\u001b[95mcmd1:\u001b[0m Collecting argon2-cffi-bindings (from argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab->jupyter==1.1.1)\n",
      "\u001b[95mcmd1:\u001b[0m   Downloading argon2_cffi_bindings-25.1.0-cp39-abi3-manylinux_2_26_x86_64.manylinux_2_28_x86_64.whl.metadata (7.4 kB)\n",
      "\u001b[95mcmd1:\u001b[0m Collecting MarkupSafe>=2.0 (from jinja2>=3.0.3->jupyterlab->jupyter==1.1.1)\n",
      "\u001b[95mcmd1:\u001b[0m   Downloading markupsafe-3.0.3-cp39-cp39-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (2.7 kB)\n",
      "\u001b[95mcmd1:\u001b[0m Collecting attrs>=22.2.0 (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.28.0->jupyterlab->jupyter==1.1.1)\n",
      "\u001b[95mcmd1:\u001b[0m   Downloading attrs-25.4.0-py3-none-any.whl.metadata (10 kB)\n",
      "\u001b[95mcmd1:\u001b[0m Collecting jsonschema-specifications>=2023.03.6 (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.28.0->jupyterlab->jupyter==1.1.1)\n",
      "\u001b[95mcmd1:\u001b[0m   Downloading jsonschema_specifications-2025.9.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "\u001b[95mcmd1:\u001b[0m Collecting referencing>=0.28.4 (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.28.0->jupyterlab->jupyter==1.1.1)\n",
      "\u001b[95mcmd1:\u001b[0m   Downloading referencing-0.36.2-py3-none-any.whl.metadata (2.8 kB)\n",
      "\u001b[95mcmd1:\u001b[0m Collecting rpds-py>=0.7.1 (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.28.0->jupyterlab->jupyter==1.1.1)\n",
      "\u001b[95mcmd1:\u001b[0m   Downloading rpds_py-0.27.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\n",
      "\u001b[95mcmd1:\u001b[0m Collecting python-json-logger>=2.0.4 (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter==1.1.1)\n",
      "\u001b[95mcmd1:\u001b[0m   Downloading python_json_logger-4.0.0-py3-none-any.whl.metadata (4.0 kB)\n",
      "\u001b[95mcmd1:\u001b[0m Collecting rfc3339-validator (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter==1.1.1)\n",
      "\u001b[95mcmd1:\u001b[0m   Downloading rfc3339_validator-0.1.4-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "\u001b[95mcmd1:\u001b[0m Collecting rfc3986-validator>=0.1.1 (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter==1.1.1)\n",
      "\u001b[95mcmd1:\u001b[0m   Downloading rfc3986_validator-0.1.1-py2.py3-none-any.whl.metadata (1.7 kB)\n",
      "\u001b[95mcmd1:\u001b[0m Collecting fqdn (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter==1.1.1)\n",
      "\u001b[95mcmd1:\u001b[0m   Downloading fqdn-1.5.1-py3-none-any.whl.metadata (1.4 kB)\n",
      "\u001b[95mcmd1:\u001b[0m Collecting isoduration (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter==1.1.1)\n",
      "\u001b[95mcmd1:\u001b[0m   Downloading isoduration-20.11.0-py3-none-any.whl.metadata (5.7 kB)\n",
      "\u001b[95mcmd1:\u001b[0m Collecting jsonpointer>1.13 (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter==1.1.1)\n",
      "\u001b[95mcmd1:\u001b[0m   Downloading jsonpointer-3.0.0-py2.py3-none-any.whl.metadata (2.3 kB)\n",
      "\u001b[95mcmd1:\u001b[0m Collecting rfc3987-syntax>=1.1.0 (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter==1.1.1)\n",
      "\u001b[95mcmd1:\u001b[0m   Downloading rfc3987_syntax-1.1.0-py3-none-any.whl.metadata (7.7 kB)\n",
      "\u001b[95mcmd1:\u001b[0m Collecting uri-template (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter==1.1.1)\n",
      "\u001b[95mcmd1:\u001b[0m   Downloading uri_template-1.3.0-py3-none-any.whl.metadata (8.8 kB)\n",
      "\u001b[95mcmd1:\u001b[0m Collecting webcolors>=24.6.0 (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter==1.1.1)\n",
      "\u001b[95mcmd1:\u001b[0m   Downloading webcolors-24.11.1-py3-none-any.whl.metadata (2.2 kB)\n",
      "\u001b[95mcmd1:\u001b[0m Collecting beautifulsoup4 (from nbconvert->jupyter==1.1.1)\n",
      "\u001b[95mcmd1:\u001b[0m   Downloading beautifulsoup4-4.14.3-py3-none-any.whl.metadata (3.8 kB)\n",
      "\u001b[95mcmd1:\u001b[0m Collecting bleach!=5.0.0 (from bleach[css]!=5.0.0->nbconvert->jupyter==1.1.1)\n",
      "\u001b[95mcmd1:\u001b[0m   Downloading bleach-6.2.0-py3-none-any.whl.metadata (30 kB)\n",
      "\u001b[95mcmd1:\u001b[0m Collecting defusedxml (from nbconvert->jupyter==1.1.1)\n",
      "\u001b[95mcmd1:\u001b[0m   Downloading defusedxml-0.7.1-py2.py3-none-any.whl.metadata (32 kB)\n",
      "\u001b[95mcmd1:\u001b[0m Collecting jupyterlab-pygments (from nbconvert->jupyter==1.1.1)\n",
      "\u001b[95mcmd1:\u001b[0m   Downloading jupyterlab_pygments-0.3.0-py3-none-any.whl.metadata (4.4 kB)\n",
      "\u001b[95mcmd1:\u001b[0m Collecting mistune<4,>=2.0.3 (from nbconvert->jupyter==1.1.1)\n",
      "\u001b[95mcmd1:\u001b[0m   Downloading mistune-3.2.0-py3-none-any.whl.metadata (1.9 kB)\n",
      "\u001b[95mcmd1:\u001b[0m Collecting nbclient>=0.5.0 (from nbconvert->jupyter==1.1.1)\n",
      "\u001b[95mcmd1:\u001b[0m   Downloading nbclient-0.10.2-py3-none-any.whl.metadata (8.3 kB)\n",
      "\u001b[95mcmd1:\u001b[0m Collecting pandocfilters>=1.4.1 (from nbconvert->jupyter==1.1.1)\n",
      "\u001b[95mcmd1:\u001b[0m   Downloading pandocfilters-1.5.1-py2.py3-none-any.whl.metadata (9.0 kB)\n",
      "\u001b[95mcmd1:\u001b[0m Collecting webencodings (from bleach!=5.0.0->bleach[css]!=5.0.0->nbconvert->jupyter==1.1.1)\n",
      "\u001b[95mcmd1:\u001b[0m   Downloading webencodings-0.5.1-py2.py3-none-any.whl.metadata (2.1 kB)\n",
      "\u001b[95mcmd1:\u001b[0m Collecting tinycss2<1.5,>=1.1.0 (from bleach[css]!=5.0.0->nbconvert->jupyter==1.1.1)\n",
      "\u001b[95mcmd1:\u001b[0m   Downloading tinycss2-1.4.0-py3-none-any.whl.metadata (3.0 kB)\n",
      "\u001b[95mcmd1:\u001b[0m Collecting fastjsonschema>=2.15 (from nbformat>=5.3.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter==1.1.1)\n",
      "\u001b[95mcmd1:\u001b[0m   Downloading fastjsonschema-2.21.2-py3-none-any.whl.metadata (2.3 kB)\n",
      "\u001b[95mcmd1:\u001b[0m Collecting charset_normalizer<4,>=2 (from requests->huggingface-hub==0.23.4)\n",
      "\u001b[95mcmd1:\u001b[0m   Downloading charset_normalizer-3.4.4-cp39-cp39-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (37 kB)\n",
      "\u001b[95mcmd1:\u001b[0m Collecting urllib3<3,>=1.21.1 (from requests->huggingface-hub==0.23.4)\n",
      "\u001b[95mcmd1:\u001b[0m   Downloading urllib3-2.6.2-py3-none-any.whl.metadata (6.6 kB)\n",
      "\u001b[95mcmd1:\u001b[0m Collecting lark>=1.2.2 (from rfc3987-syntax>=1.1.0->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter==1.1.1)\n",
      "\u001b[95mcmd1:\u001b[0m   Downloading lark-1.3.1-py3-none-any.whl.metadata (1.8 kB)\n",
      "\u001b[95mcmd1:\u001b[0m Collecting cffi>=1.0.1 (from argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab->jupyter==1.1.1)\n",
      "\u001b[95mcmd1:\u001b[0m   Downloading cffi-2.0.0-cp39-cp39-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.6 kB)\n",
      "\u001b[95mcmd1:\u001b[0m Collecting pycparser (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab->jupyter==1.1.1)\n",
      "\u001b[95mcmd1:\u001b[0m   Downloading pycparser-2.23-py3-none-any.whl.metadata (993 bytes)\n",
      "\u001b[95mcmd1:\u001b[0m Collecting soupsieve>=1.6.1 (from beautifulsoup4->nbconvert->jupyter==1.1.1)\n",
      "\u001b[95mcmd1:\u001b[0m   Downloading soupsieve-2.8.1-py3-none-any.whl.metadata (4.6 kB)\n",
      "\u001b[95mcmd1:\u001b[0m Collecting arrow>=0.15.0 (from isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter==1.1.1)\n",
      "\u001b[95mcmd1:\u001b[0m   Downloading arrow-1.4.0-py3-none-any.whl.metadata (7.7 kB)\n",
      "\u001b[95mcmd1:\u001b[0m Collecting tzdata (from arrow>=0.15.0->isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter==1.1.1)\n",
      "\u001b[95mcmd1:\u001b[0m   Downloading tzdata-2025.3-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "\u001b[95mcmd1:\u001b[0m Collecting executing>=1.2.0 (from stack-data->ipython>=7.23.1->ipykernel->jupyter==1.1.1)\n",
      "\u001b[95mcmd1:\u001b[0m   Downloading executing-2.2.1-py2.py3-none-any.whl.metadata (8.9 kB)\n",
      "\u001b[95mcmd1:\u001b[0m Collecting asttokens>=2.1.0 (from stack-data->ipython>=7.23.1->ipykernel->jupyter==1.1.1)\n",
      "\u001b[95mcmd1:\u001b[0m   Downloading asttokens-3.0.1-py3-none-any.whl.metadata (4.9 kB)\n",
      "\u001b[95mcmd1:\u001b[0m Collecting pure-eval (from stack-data->ipython>=7.23.1->ipykernel->jupyter==1.1.1)\n",
      "\u001b[95mcmd1:\u001b[0m   Downloading pure_eval-0.2.3-py3-none-any.whl.metadata (6.3 kB)\n",
      "\u001b[95mcmd1:\u001b[0m Downloading torch-1.13.1-cp39-cp39-manylinux1_x86_64.whl (887.4 MB)\n",
      "\u001b[95mcmd1:\u001b[0m    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 887.4/887.4 MB 39.6 MB/s  0:00:10\n",
      "\u001b[95mcmd1:\u001b[0m Downloading redis-5.0.6-py3-none-any.whl (252 kB)\n",
      "\u001b[95mcmd1:\u001b[0m Downloading jupyter-1.1.1-py2.py3-none-any.whl (2.7 kB)\n",
      "\u001b[95mcmd1:\u001b[0m Downloading numpy-1.24.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\n",
      "\u001b[95mcmd1:\u001b[0m    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 17.3/17.3 MB 134.0 MB/s  0:00:00\n",
      "\u001b[95mcmd1:\u001b[0m Downloading matplotlib-3.9.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.3 MB)\n",
      "\u001b[95mcmd1:\u001b[0m    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 8.3/8.3 MB 127.4 MB/s  0:00:00\n",
      "\u001b[95mcmd1:\u001b[0m Downloading scipy-1.11.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (36.5 MB)\n",
      "\u001b[95mcmd1:\u001b[0m    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 36.5/36.5 MB 148.0 MB/s  0:00:00\n",
      "\u001b[95mcmd1:\u001b[0m Downloading scikit_learn-1.6.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.5 MB)\n",
      "\u001b[95mcmd1:\u001b[0m    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 13.5/13.5 MB 132.6 MB/s  0:00:00\n",
      "\u001b[95mcmd1:\u001b[0m Downloading tqdm-4.66.4-py3-none-any.whl (78 kB)\n",
      "\u001b[95mcmd1:\u001b[0m Downloading g2p_en-2.1.0-py3-none-any.whl (3.1 MB)\n",
      "\u001b[95mcmd1:\u001b[0m    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.1/3.1 MB 102.1 MB/s  0:00:00\n",
      "\u001b[95mcmd1:\u001b[0m Downloading omegaconf-2.3.0-py3-none-any.whl (79 kB)\n",
      "\u001b[95mcmd1:\u001b[0m Downloading huggingface_hub-0.23.4-py3-none-any.whl (402 kB)\n",
      "\u001b[95mcmd1:\u001b[0m Downloading transformers-4.40.0-py3-none-any.whl (9.0 MB)\n",
      "\u001b[95mcmd1:\u001b[0m    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 9.0/9.0 MB 120.2 MB/s  0:00:00\n",
      "\u001b[95mcmd1:\u001b[0m Downloading tokenizers-0.19.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
      "\u001b[95mcmd1:\u001b[0m    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.6/3.6 MB 112.9 MB/s  0:00:00\n",
      "\u001b[95mcmd1:\u001b[0m Downloading accelerate-0.33.0-py3-none-any.whl (315 kB)\n",
      "\u001b[95mcmd1:\u001b[0m Downloading bitsandbytes-0.41.1-py3-none-any.whl (92.6 MB)\n",
      "\u001b[95mcmd1:\u001b[0m    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 92.6/92.6 MB 96.6 MB/s  0:00:00\n",
      "\u001b[95mcmd1:\u001b[0m Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n",
      "\u001b[95mcmd1:\u001b[0m    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 317.1/317.1 MB 99.5 MB/s  0:00:02\n",
      "\u001b[95mcmd1:\u001b[0m Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n",
      "\u001b[95mcmd1:\u001b[0m    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 21.0/21.0 MB 12.8 MB/s  0:00:01\n",
      "\u001b[95mcmd1:\u001b[0m Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n",
      "\u001b[95mcmd1:\u001b[0m    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 849.3/849.3 kB 723.7 kB/s  0:00:00\n",
      "\u001b[95mcmd1:\u001b[0m Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n",
      "\u001b[95mcmd1:\u001b[0m    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 557.1/557.1 MB 53.0 MB/s  0:00:05\n",
      "\u001b[95mcmd1:\u001b[0m Downloading async_timeout-5.0.1-py3-none-any.whl (6.2 kB)\n",
      "\u001b[95mcmd1:\u001b[0m Downloading contourpy-1.3.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (321 kB)\n",
      "\u001b[95mcmd1:\u001b[0m Downloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "\u001b[95mcmd1:\u001b[0m Downloading fonttools-4.60.2-cp39-cp39-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (4.8 MB)\n",
      "\u001b[95mcmd1:\u001b[0m    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 4.8/4.8 MB 123.6 MB/s  0:00:00\n",
      "\u001b[95mcmd1:\u001b[0m Downloading fsspec-2025.10.0-py3-none-any.whl (200 kB)\n",
      "\u001b[95mcmd1:\u001b[0m Downloading importlib_resources-6.5.2-py3-none-any.whl (37 kB)\n",
      "\u001b[95mcmd1:\u001b[0m Downloading inflect-7.5.0-py3-none-any.whl (35 kB)\n",
      "\u001b[95mcmd1:\u001b[0m Downloading joblib-1.5.3-py3-none-any.whl (309 kB)\n",
      "\u001b[95mcmd1:\u001b[0m Downloading kiwisolver-1.4.7-cp39-cp39-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.6 MB)\n",
      "\u001b[95mcmd1:\u001b[0m    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.6/1.6 MB 76.8 MB/s  0:00:00\n",
      "\u001b[95mcmd1:\u001b[0m Downloading more_itertools-10.8.0-py3-none-any.whl (69 kB)\n",
      "\u001b[95mcmd1:\u001b[0m Downloading nltk-3.9.2-py3-none-any.whl (1.5 MB)\n",
      "\u001b[95mcmd1:\u001b[0m    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.5/1.5 MB 74.5 MB/s  0:00:00\n",
      "\u001b[95mcmd1:\u001b[0m Downloading packaging-25.0-py3-none-any.whl (66 kB)\n",
      "\u001b[95mcmd1:\u001b[0m Downloading pillow-11.3.0-cp39-cp39-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (6.6 MB)\n",
      "\u001b[95mcmd1:\u001b[0m    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 6.6/6.6 MB 128.2 MB/s  0:00:00\n",
      "\u001b[95mcmd1:\u001b[0m Downloading pyparsing-3.3.1-py3-none-any.whl (121 kB)\n",
      "\u001b[95mcmd1:\u001b[0m Downloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)\n",
      "\u001b[95mcmd1:\u001b[0m Downloading pyyaml-6.0.3-cp39-cp39-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (750 kB)\n",
      "\u001b[95mcmd1:\u001b[0m    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 750.8/750.8 kB 36.8 MB/s  0:00:00\n",
      "\u001b[95mcmd1:\u001b[0m Downloading regex-2025.11.3-cp39-cp39-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (791 kB)\n",
      "\u001b[95mcmd1:\u001b[0m    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 791.2/791.2 kB 36.9 MB/s  0:00:00\n",
      "\u001b[95mcmd1:\u001b[0m Downloading safetensors-0.7.0-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (507 kB)\n",
      "\u001b[95mcmd1:\u001b[0m Downloading six-1.17.0-py2.py3-none-any.whl (11 kB)\n",
      "\u001b[95mcmd1:\u001b[0m Downloading threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "\u001b[95mcmd1:\u001b[0m Downloading typeguard-4.4.4-py3-none-any.whl (34 kB)\n",
      "\u001b[95mcmd1:\u001b[0m Downloading importlib_metadata-8.7.1-py3-none-any.whl (27 kB)\n",
      "\u001b[95mcmd1:\u001b[0m Downloading typing_extensions-4.15.0-py3-none-any.whl (44 kB)\n",
      "\u001b[95mcmd1:\u001b[0m Downloading zipp-3.23.0-py3-none-any.whl (10 kB)\n",
      "\u001b[95mcmd1:\u001b[0m Downloading click-8.1.8-py3-none-any.whl (98 kB)\n",
      "\u001b[95mcmd1:\u001b[0m Downloading filelock-3.19.1-py3-none-any.whl (15 kB)\n",
      "\u001b[95mcmd1:\u001b[0m Downloading ipykernel-6.31.0-py3-none-any.whl (117 kB)\n",
      "\u001b[95mcmd1:\u001b[0m Downloading comm-0.2.3-py3-none-any.whl (7.3 kB)\n",
      "\u001b[95mcmd1:\u001b[0m Downloading debugpy-1.8.19-cp39-cp39-manylinux_2_34_x86_64.whl (3.1 MB)\n",
      "\u001b[95mcmd1:\u001b[0m    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.1/3.1 MB 122.5 MB/s  0:00:00\n",
      "\u001b[95mcmd1:\u001b[0m Downloading ipython-8.18.1-py3-none-any.whl (808 kB)\n",
      "\u001b[95mcmd1:\u001b[0m    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 808.2/808.2 kB 41.7 MB/s  0:00:00\n",
      "\u001b[95mcmd1:\u001b[0m Downloading prompt_toolkit-3.0.52-py3-none-any.whl (391 kB)\n",
      "\u001b[95mcmd1:\u001b[0m Downloading jedi-0.19.2-py2.py3-none-any.whl (1.6 MB)\n",
      "\u001b[95mcmd1:\u001b[0m    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.6/1.6 MB 74.5 MB/s  0:00:00\n",
      "\u001b[95mcmd1:\u001b[0m Downloading parso-0.8.5-py2.py3-none-any.whl (106 kB)\n",
      "\u001b[95mcmd1:\u001b[0m Downloading jupyter_client-8.6.3-py3-none-any.whl (106 kB)\n",
      "\u001b[95mcmd1:\u001b[0m Downloading jupyter_core-5.8.1-py3-none-any.whl (28 kB)\n",
      "\u001b[95mcmd1:\u001b[0m Downloading matplotlib_inline-0.2.1-py3-none-any.whl (9.5 kB)\n",
      "\u001b[95mcmd1:\u001b[0m Downloading nest_asyncio-1.6.0-py3-none-any.whl (5.2 kB)\n",
      "\u001b[95mcmd1:\u001b[0m Downloading pexpect-4.9.0-py2.py3-none-any.whl (63 kB)\n",
      "\u001b[95mcmd1:\u001b[0m Downloading platformdirs-4.4.0-py3-none-any.whl (18 kB)\n",
      "\u001b[95mcmd1:\u001b[0m Downloading psutil-7.2.0-cp36-abi3-manylinux2010_x86_64.manylinux_2_12_x86_64.manylinux_2_28_x86_64.whl (154 kB)\n",
      "\u001b[95mcmd1:\u001b[0m Downloading ptyprocess-0.7.0-py2.py3-none-any.whl (13 kB)\n",
      "\u001b[95mcmd1:\u001b[0m Downloading pygments-2.19.2-py3-none-any.whl (1.2 MB)\n",
      "\u001b[95mcmd1:\u001b[0m    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.2/1.2 MB 64.4 MB/s  0:00:00\n",
      "\u001b[95mcmd1:\u001b[0m Downloading pyzmq-27.1.0-cp39-cp39-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (863 kB)\n",
      "\u001b[95mcmd1:\u001b[0m    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 863.8/863.8 kB 36.1 MB/s  0:00:00\n",
      "\u001b[95mcmd1:\u001b[0m Downloading tornado-6.5.4-cp39-abi3-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (445 kB)\n",
      "\u001b[95mcmd1:\u001b[0m Downloading traitlets-5.14.3-py3-none-any.whl (85 kB)\n",
      "\u001b[95mcmd1:\u001b[0m Downloading decorator-5.2.1-py3-none-any.whl (9.2 kB)\n",
      "\u001b[95mcmd1:\u001b[0m Downloading exceptiongroup-1.3.1-py3-none-any.whl (16 kB)\n",
      "\u001b[95mcmd1:\u001b[0m Downloading ipywidgets-8.1.8-py3-none-any.whl (139 kB)\n",
      "\u001b[95mcmd1:\u001b[0m Downloading jupyterlab_widgets-3.0.16-py3-none-any.whl (914 kB)\n",
      "\u001b[95mcmd1:\u001b[0m    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 914.9/914.9 kB 43.8 MB/s  0:00:00\n",
      "\u001b[95mcmd1:\u001b[0m Downloading widgetsnbextension-4.0.15-py3-none-any.whl (2.2 MB)\n",
      "\u001b[95mcmd1:\u001b[0m    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.2/2.2 MB 93.5 MB/s  0:00:00\n",
      "\u001b[95mcmd1:\u001b[0m Downloading jupyter_console-6.6.3-py3-none-any.whl (24 kB)\n",
      "\u001b[95mcmd1:\u001b[0m Downloading jupyterlab-4.5.1-py3-none-any.whl (12.4 MB)\n",
      "\u001b[95mcmd1:\u001b[0m    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 12.4/12.4 MB 132.9 MB/s  0:00:00\n",
      "\u001b[95mcmd1:\u001b[0m Downloading httpx-0.28.1-py3-none-any.whl (73 kB)\n",
      "\u001b[95mcmd1:\u001b[0m Downloading httpcore-1.0.9-py3-none-any.whl (78 kB)\n",
      "\u001b[95mcmd1:\u001b[0m Downloading jupyter_server-2.17.0-py3-none-any.whl (388 kB)\n",
      "\u001b[95mcmd1:\u001b[0m Downloading jupyterlab_server-2.28.0-py3-none-any.whl (59 kB)\n",
      "\u001b[95mcmd1:\u001b[0m Downloading anyio-4.12.0-py3-none-any.whl (113 kB)\n",
      "\u001b[95mcmd1:\u001b[0m Downloading argon2_cffi-25.1.0-py3-none-any.whl (14 kB)\n",
      "\u001b[95mcmd1:\u001b[0m Downloading async_lru-2.0.5-py3-none-any.whl (6.1 kB)\n",
      "\u001b[95mcmd1:\u001b[0m Downloading babel-2.17.0-py3-none-any.whl (10.2 MB)\n",
      "\u001b[95mcmd1:\u001b[0m    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 10.2/10.2 MB 124.4 MB/s  0:00:00\n",
      "\u001b[95mcmd1:\u001b[0m Downloading h11-0.16.0-py3-none-any.whl (37 kB)\n",
      "\u001b[95mcmd1:\u001b[0m Downloading idna-3.11-py3-none-any.whl (71 kB)\n",
      "\u001b[95mcmd1:\u001b[0m Downloading jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
      "\u001b[95mcmd1:\u001b[0m Downloading json5-0.12.1-py3-none-any.whl (36 kB)\n",
      "\u001b[95mcmd1:\u001b[0m Downloading jsonschema-4.25.1-py3-none-any.whl (90 kB)\n",
      "\u001b[95mcmd1:\u001b[0m Downloading attrs-25.4.0-py3-none-any.whl (67 kB)\n",
      "\u001b[95mcmd1:\u001b[0m Downloading jsonschema_specifications-2025.9.1-py3-none-any.whl (18 kB)\n",
      "\u001b[95mcmd1:\u001b[0m Downloading jupyter_events-0.12.0-py3-none-any.whl (19 kB)\n",
      "\u001b[95mcmd1:\u001b[0m Downloading jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
      "\u001b[95mcmd1:\u001b[0m Downloading jupyter_lsp-2.3.0-py3-none-any.whl (76 kB)\n",
      "\u001b[95mcmd1:\u001b[0m Downloading jupyter_server_terminals-0.5.3-py3-none-any.whl (13 kB)\n",
      "\u001b[95mcmd1:\u001b[0m Downloading markupsafe-3.0.3-cp39-cp39-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (20 kB)\n",
      "\u001b[95mcmd1:\u001b[0m Downloading nbconvert-7.16.6-py3-none-any.whl (258 kB)\n",
      "\u001b[95mcmd1:\u001b[0m Downloading mistune-3.2.0-py3-none-any.whl (53 kB)\n",
      "\u001b[95mcmd1:\u001b[0m Downloading bleach-6.2.0-py3-none-any.whl (163 kB)\n",
      "\u001b[95mcmd1:\u001b[0m Downloading tinycss2-1.4.0-py3-none-any.whl (26 kB)\n",
      "\u001b[95mcmd1:\u001b[0m Downloading nbclient-0.10.2-py3-none-any.whl (25 kB)\n",
      "\u001b[95mcmd1:\u001b[0m Downloading nbformat-5.10.4-py3-none-any.whl (78 kB)\n",
      "\u001b[95mcmd1:\u001b[0m Downloading fastjsonschema-2.21.2-py3-none-any.whl (24 kB)\n",
      "\u001b[95mcmd1:\u001b[0m Downloading notebook_shim-0.2.4-py3-none-any.whl (13 kB)\n",
      "\u001b[95mcmd1:\u001b[0m Downloading overrides-7.7.0-py3-none-any.whl (17 kB)\n",
      "\u001b[95mcmd1:\u001b[0m Downloading pandocfilters-1.5.1-py2.py3-none-any.whl (8.7 kB)\n",
      "\u001b[95mcmd1:\u001b[0m Downloading prometheus_client-0.23.1-py3-none-any.whl (61 kB)\n",
      "\u001b[95mcmd1:\u001b[0m Downloading python_json_logger-4.0.0-py3-none-any.whl (15 kB)\n",
      "\u001b[95mcmd1:\u001b[0m Downloading referencing-0.36.2-py3-none-any.whl (26 kB)\n",
      "\u001b[95mcmd1:\u001b[0m Downloading requests-2.32.5-py3-none-any.whl (64 kB)\n",
      "\u001b[95mcmd1:\u001b[0m Downloading charset_normalizer-3.4.4-cp39-cp39-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (153 kB)\n",
      "\u001b[95mcmd1:\u001b[0m Downloading urllib3-2.6.2-py3-none-any.whl (131 kB)\n",
      "\u001b[95mcmd1:\u001b[0m Downloading certifi-2025.11.12-py3-none-any.whl (159 kB)\n",
      "\u001b[95mcmd1:\u001b[0m Downloading rfc3986_validator-0.1.1-py2.py3-none-any.whl (4.2 kB)\n",
      "\u001b[95mcmd1:\u001b[0m Downloading rfc3987_syntax-1.1.0-py3-none-any.whl (8.0 kB)\n",
      "\u001b[95mcmd1:\u001b[0m Downloading lark-1.3.1-py3-none-any.whl (113 kB)\n",
      "\u001b[95mcmd1:\u001b[0m Downloading rpds_py-0.27.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (384 kB)\n",
      "\u001b[95mcmd1:\u001b[0m Downloading Send2Trash-1.8.3-py3-none-any.whl (18 kB)\n",
      "\u001b[95mcmd1:\u001b[0m Downloading terminado-0.18.1-py3-none-any.whl (14 kB)\n",
      "\u001b[95mcmd1:\u001b[0m Downloading tomli-2.3.0-py3-none-any.whl (14 kB)\n",
      "\u001b[95mcmd1:\u001b[0m Downloading webcolors-24.11.1-py3-none-any.whl (14 kB)\n",
      "\u001b[95mcmd1:\u001b[0m Downloading webencodings-0.5.1-py2.py3-none-any.whl (11 kB)\n",
      "\u001b[95mcmd1:\u001b[0m Downloading websocket_client-1.9.0-py3-none-any.whl (82 kB)\n",
      "\u001b[95mcmd1:\u001b[0m Downloading argon2_cffi_bindings-25.1.0-cp39-abi3-manylinux_2_26_x86_64.manylinux_2_28_x86_64.whl (87 kB)\n",
      "\u001b[95mcmd1:\u001b[0m Downloading cffi-2.0.0-cp39-cp39-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (216 kB)\n",
      "\u001b[95mcmd1:\u001b[0m Downloading beautifulsoup4-4.14.3-py3-none-any.whl (107 kB)\n",
      "\u001b[95mcmd1:\u001b[0m Downloading soupsieve-2.8.1-py3-none-any.whl (36 kB)\n",
      "\u001b[95mcmd1:\u001b[0m Downloading defusedxml-0.7.1-py2.py3-none-any.whl (25 kB)\n",
      "\u001b[95mcmd1:\u001b[0m Downloading fqdn-1.5.1-py3-none-any.whl (9.1 kB)\n",
      "\u001b[95mcmd1:\u001b[0m Downloading isoduration-20.11.0-py3-none-any.whl (11 kB)\n",
      "\u001b[95mcmd1:\u001b[0m Downloading arrow-1.4.0-py3-none-any.whl (68 kB)\n",
      "\u001b[95mcmd1:\u001b[0m Downloading jupyterlab_pygments-0.3.0-py3-none-any.whl (15 kB)\n",
      "\u001b[95mcmd1:\u001b[0m Downloading notebook-7.5.1-py3-none-any.whl (14.5 MB)\n",
      "\u001b[95mcmd1:\u001b[0m    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 14.5/14.5 MB 137.1 MB/s  0:00:00\n",
      "\u001b[95mcmd1:\u001b[0m Downloading pycparser-2.23-py3-none-any.whl (118 kB)\n",
      "\u001b[95mcmd1:\u001b[0m Downloading rfc3339_validator-0.1.4-py2.py3-none-any.whl (3.5 kB)\n",
      "\u001b[95mcmd1:\u001b[0m Downloading stack_data-0.6.3-py3-none-any.whl (24 kB)\n",
      "\u001b[95mcmd1:\u001b[0m Downloading asttokens-3.0.1-py3-none-any.whl (27 kB)\n",
      "\u001b[95mcmd1:\u001b[0m Downloading executing-2.2.1-py2.py3-none-any.whl (28 kB)\n",
      "\u001b[95mcmd1:\u001b[0m Downloading pure_eval-0.2.3-py3-none-any.whl (11 kB)\n",
      "\u001b[95mcmd1:\u001b[0m Downloading tzdata-2025.3-py2.py3-none-any.whl (348 kB)\n",
      "\u001b[95mcmd1:\u001b[0m Downloading uri_template-1.3.0-py3-none-any.whl (11 kB)\n",
      "\u001b[95mcmd1:\u001b[0m Downloading wcwidth-0.2.14-py2.py3-none-any.whl (37 kB)\n",
      "\u001b[95mcmd1:\u001b[0m Building wheels for collected packages: antlr4-python3-runtime, distance\n",
      "\u001b[95mcmd1:\u001b[0m   Building wheel for antlr4-python3-runtime (pyproject.toml): started\n",
      "\u001b[95mcmd1:\u001b[0m   Building wheel for antlr4-python3-runtime (pyproject.toml): finished with status 'done'\n",
      "\u001b[95mcmd1:\u001b[0m   Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144591 sha256=9059479d67c77b4a3d1ae203c5b447e448b5829b5a2f092f24d0ff09e58ef556\n",
      "\u001b[95mcmd1:\u001b[0m   Stored in directory: /root/.cache/pip/wheels/23/cf/80/f3efa822e6ab23277902ee9165fe772eeb1dfb8014f359020a\n",
      "\u001b[95mcmd1:\u001b[0m   Building wheel for distance (pyproject.toml): started\n",
      "\u001b[95mcmd1:\u001b[0m   Building wheel for distance (pyproject.toml): finished with status 'done'\n",
      "\u001b[95mcmd1:\u001b[0m   Created wheel for distance: filename=distance-0.1.3-py3-none-any.whl size=16321 sha256=b6d1de6e9cc2d29104dacb5faef78aed8be1e4174f349b0829a59b50b7544aac\n",
      "\u001b[95mcmd1:\u001b[0m   Stored in directory: /root/.cache/pip/wheels/fb/b3/aa/04241cced6d1722b132273b1d6aafba317887ec004f48b853a\n",
      "\u001b[95mcmd1:\u001b[0m Successfully built antlr4-python3-runtime distance\n",
      "\u001b[95mcmd1:\u001b[0m Installing collected packages: webencodings, pure-eval, ptyprocess, fastjsonschema, distance, bitsandbytes, antlr4-python3-runtime, zipp, widgetsnbextension, websocket-client, webcolors, wcwidth, urllib3, uri-template, tzdata, typing-extensions, traitlets, tqdm, tornado, tomli, tinycss2, threadpoolctl, soupsieve, six, send2trash, safetensors, rpds-py, rfc3986-validator, regex, pyzmq, PyYAML, pyparsing, pygments, pycparser, psutil, prometheus-client, platformdirs, pillow, pexpect, parso, pandocfilters, packaging, overrides, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cublas-cu11, numpy, nest-asyncio, more_itertools, MarkupSafe, lark, kiwisolver, jupyterlab_widgets, jupyterlab-pygments, jsonpointer, json5, joblib, idna, h11, fsspec, fqdn, fonttools, filelock, executing, defusedxml, decorator, debugpy, cycler, comm, click, charset_normalizer, certifi, bleach, babel, attrs, async-timeout, asttokens, terminado, stack-data, scipy, rfc3987-syntax, rfc3339-validator, requests, referencing, redis, python-json-logger, python-dateutil, prompt-toolkit, omegaconf, nvidia-cudnn-cu11, nltk, mistune, matplotlib-inline, jupyter-core, jinja2, jedi, importlib-resources, importlib_metadata, httpcore, exceptiongroup, contourpy, cffi, beautifulsoup4, async-lru, typeguard, torch, scikit-learn, matplotlib, jupyter-server-terminals, jupyter-client, jsonschema-specifications, ipython, huggingface-hub, arrow, argon2-cffi-bindings, anyio, tokenizers, jsonschema, isoduration, ipywidgets, ipykernel, inflect, httpx, argon2-cffi, accelerate, transformers, nbformat, jupyter-console, g2p_en, nbclient, jupyter-events, nbconvert, jupyter-server, notebook-shim, jupyterlab-server, jupyter-lsp, jupyterlab, notebook, jupyter\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[95mcmd1:\u001b[0m Successfully installed MarkupSafe-3.0.3 PyYAML-6.0.3 accelerate-0.33.0 antlr4-python3-runtime-4.9.3 anyio-4.12.0 argon2-cffi-25.1.0 argon2-cffi-bindings-25.1.0 arrow-1.4.0 asttokens-3.0.1 async-lru-2.0.5 async-timeout-5.0.1 attrs-25.4.0 babel-2.17.0 beautifulsoup4-4.14.3 bitsandbytes-0.41.1 bleach-6.2.0 certifi-2025.11.12 cffi-2.0.0 charset_normalizer-3.4.4 click-8.1.8 comm-0.2.3 contourpy-1.3.0 cycler-0.12.1 debugpy-1.8.19 decorator-5.2.1 defusedxml-0.7.1 distance-0.1.3 exceptiongroup-1.3.1 executing-2.2.1 fastjsonschema-2.21.2 filelock-3.19.1 fonttools-4.60.2 fqdn-1.5.1 fsspec-2025.10.0 g2p_en-2.1.0 h11-0.16.0 httpcore-1.0.9 httpx-0.28.1 huggingface-hub-0.23.4 idna-3.11 importlib-resources-6.5.2 importlib_metadata-8.7.1 inflect-7.5.0 ipykernel-6.31.0 ipython-8.18.1 ipywidgets-8.1.8 isoduration-20.11.0 jedi-0.19.2 jinja2-3.1.6 joblib-1.5.3 json5-0.12.1 jsonpointer-3.0.0 jsonschema-4.25.1 jsonschema-specifications-2025.9.1 jupyter-1.1.1 jupyter-client-8.6.3 jupyter-console-6.6.3 jupyter-core-5.8.1 jupyter-events-0.12.0 jupyter-lsp-2.3.0 jupyter-server-2.17.0 jupyter-server-terminals-0.5.3 jupyterlab-4.5.1 jupyterlab-pygments-0.3.0 jupyterlab-server-2.28.0 jupyterlab_widgets-3.0.16 kiwisolver-1.4.7 lark-1.3.1 matplotlib-3.9.0 matplotlib-inline-0.2.1 mistune-3.2.0 more_itertools-10.8.0 nbclient-0.10.2 nbconvert-7.16.6 nbformat-5.10.4 nest-asyncio-1.6.0 nltk-3.9.2 notebook-7.5.1 notebook-shim-0.2.4 numpy-1.24.4 nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 omegaconf-2.3.0 overrides-7.7.0 packaging-25.0 pandocfilters-1.5.1 parso-0.8.5 pexpect-4.9.0 pillow-11.3.0 platformdirs-4.4.0 prometheus-client-0.23.1 prompt-toolkit-3.0.52 psutil-7.2.0 ptyprocess-0.7.0 pure-eval-0.2.3 pycparser-2.23 pygments-2.19.2 pyparsing-3.3.1 python-dateutil-2.9.0.post0 python-json-logger-4.0.0 pyzmq-27.1.0 redis-5.0.6 referencing-0.36.2 regex-2025.11.3 requests-2.32.5 rfc3339-validator-0.1.4 rfc3986-validator-0.1.1 rfc3987-syntax-1.1.0 rpds-py-0.27.1 safetensors-0.7.0 scikit-learn-1.6.1 scipy-1.11.1 send2trash-1.8.3 six-1.17.0 soupsieve-2.8.1 stack-data-0.6.3 terminado-0.18.1 threadpoolctl-3.6.0 tinycss2-1.4.0 tokenizers-0.19.1 tomli-2.3.0 torch-1.13.1 tornado-6.5.4 tqdm-4.66.4 traitlets-5.14.3 transformers-4.40.0 typeguard-4.4.4 typing-extensions-4.15.0 tzdata-2025.3 uri-template-1.3.0 urllib3-2.6.2 wcwidth-0.2.14 webcolors-24.11.1 webencodings-0.5.1 websocket-client-1.9.0 widgetsnbextension-4.0.15 zipp-3.23.0\n",
      "\u001b[95mcmd1:\u001b[0m running install\n",
      "\u001b[95mcmd1:\u001b[0m /root/miniconda3/envs/b2txt25_lm/lib/python3.9/site-packages/setuptools/_distutils/cmd.py:90: SetuptoolsDeprecationWarning: setup.py install is deprecated.\n",
      "\u001b[95mcmd1:\u001b[0m !!\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[95mcmd1:\u001b[0m         ********************************************************************************\n",
      "\u001b[95mcmd1:\u001b[0m         Please avoid running ``setup.py`` directly.\n",
      "\u001b[95mcmd1:\u001b[0m         Instead, use pypa/build, pypa/installer or other\n",
      "\u001b[95mcmd1:\u001b[0m         standards-based tools.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[95mcmd1:\u001b[0m         This deprecation is overdue, please update your project and remove deprecated\n",
      "\u001b[95mcmd1:\u001b[0m         calls to avoid build errors in the future.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[95mcmd1:\u001b[0m         See https://blog.ganssle.io/articles/2021/10/setup-py-deprecated.html for details.\n",
      "\u001b[95mcmd1:\u001b[0m         ********************************************************************************\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[95mcmd1:\u001b[0m !!\n",
      "\u001b[95mcmd1:\u001b[0m   self.initialize_options()\n",
      "\u001b[95mcmd1:\u001b[0m running build\n",
      "\u001b[95mcmd1:\u001b[0m running build_ext\n",
      "\u001b[95mcmd1:\u001b[0m -- The C compiler identification is GNU 11.4.0\n",
      "\u001b[95mcmd1:\u001b[0m -- The CXX compiler identification is GNU 11.4.0\n",
      "\u001b[95mcmd1:\u001b[0m -- Detecting C compiler ABI info\n",
      "\u001b[95mcmd1:\u001b[0m -- Detecting C compiler ABI info - done\n",
      "\u001b[95mcmd1:\u001b[0m -- Check for working C compiler: /usr/bin/cc - skipped\n",
      "\u001b[95mcmd1:\u001b[0m -- Detecting C compile features\n",
      "\u001b[95mcmd1:\u001b[0m -- Detecting C compile features - done\n",
      "\u001b[95mcmd1:\u001b[0m -- Detecting CXX compiler ABI info\n",
      "\u001b[95mcmd1:\u001b[0m -- Detecting CXX compiler ABI info - done\n",
      "\u001b[95mcmd1:\u001b[0m -- Check for working CXX compiler: /usr/bin/c++ - skipped\n",
      "\u001b[95mcmd1:\u001b[0m -- Detecting CXX compile features\n",
      "\u001b[95mcmd1:\u001b[0m -- Detecting CXX compile features - done\n",
      "\u001b[95mcmd1:\u001b[0m CMake Warning (dev) at /usr/local/lib/python3.11/dist-packages/cmake/data/share/cmake-3.31/Modules/FetchContent.cmake:1373 (message):\n",
      "\u001b[95mcmd1:\u001b[0m   The DOWNLOAD_EXTRACT_TIMESTAMP option was not given and policy CMP0135 is\n",
      "\u001b[95mcmd1:\u001b[0m   not set.  The policy's OLD behavior will be used.  When using a URL\n",
      "\u001b[95mcmd1:\u001b[0m   download, the timestamps of extracted files should preferably be that of\n",
      "\u001b[95mcmd1:\u001b[0m   the time of extraction, otherwise code that depends on the extracted\n",
      "\u001b[95mcmd1:\u001b[0m   contents might not be rebuilt if the URL changes.  The OLD behavior\n",
      "\u001b[95mcmd1:\u001b[0m   preserves the timestamps from the archive instead, but this is usually not\n",
      "\u001b[95mcmd1:\u001b[0m   what you want.  Update your project to the NEW behavior or specify the\n",
      "\u001b[95mcmd1:\u001b[0m   DOWNLOAD_EXTRACT_TIMESTAMP option with a value of true to avoid this\n",
      "\u001b[95mcmd1:\u001b[0m   robustness issue.\n",
      "\u001b[95mcmd1:\u001b[0m Call Stack (most recent call first):\n",
      "\u001b[95mcmd1:\u001b[0m   CMakeLists.txt:33 (FetchContent_Declare)\n",
      "\u001b[95mcmd1:\u001b[0m This warning is for project developers.  Use -Wno-dev to suppress it.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[95mcmd1:\u001b[0m -- Populating gflags\n",
      "\u001b[95mcmd1:\u001b[0m -- Configuring done (0.0s)\n",
      "\u001b[95mcmd1:\u001b[0m -- Generating done (0.0s)\n",
      "\u001b[95mcmd1:\u001b[0m -- Build files have been written to: /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-subbuild\n",
      "\u001b[95mcmd1:\u001b[0m [ 11%] Creating directories for 'gflags-populate'\n",
      "\u001b[95mcmd1:\u001b[0m [ 22%] Performing download step (download, verify and extract) for 'gflags-populate'\n",
      "\u001b[95mcmd1:\u001b[0m -- Downloading...\n",
      "\u001b[95mcmd1:\u001b[0m    dst='/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-subbuild/gflags-populate-prefix/src/v2.2.1.zip'\n",
      "\u001b[95mcmd1:\u001b[0m    timeout='none'\n",
      "\u001b[95mcmd1:\u001b[0m    inactivity timeout='none'\n",
      "\u001b[95mcmd1:\u001b[0m -- Using src='https://github.com/gflags/gflags/archive/v2.2.1.zip'\n",
      "\u001b[95mcmd1:\u001b[0m -- verifying file...\n",
      "\u001b[95mcmd1:\u001b[0m        file='/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-subbuild/gflags-populate-prefix/src/v2.2.1.zip'\n",
      "\u001b[95mcmd1:\u001b[0m -- Downloading... done\n",
      "\u001b[95mcmd1:\u001b[0m -- extracting...\n",
      "\u001b[95mcmd1:\u001b[0m      src='/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-subbuild/gflags-populate-prefix/src/v2.2.1.zip'\n",
      "\u001b[95mcmd1:\u001b[0m      dst='/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-src'\n",
      "\u001b[95mcmd1:\u001b[0m -- extracting... [tar xfz]\n",
      "\u001b[95mcmd1:\u001b[0m -- extracting... [analysis]\n",
      "\u001b[95mcmd1:\u001b[0m -- extracting... [rename]\n",
      "\u001b[95mcmd1:\u001b[0m -- extracting... [clean up]\n",
      "\u001b[95mcmd1:\u001b[0m -- extracting... done\n",
      "\u001b[95mcmd1:\u001b[0m [ 33%] No update step for 'gflags-populate'\n",
      "\u001b[95mcmd1:\u001b[0m [ 44%] No patch step for 'gflags-populate'\n",
      "\u001b[95mcmd1:\u001b[0m [ 55%] No configure step for 'gflags-populate'\n",
      "\u001b[95mcmd1:\u001b[0m [ 66%] No build step for 'gflags-populate'\n",
      "\u001b[95mcmd1:\u001b[0m [ 77%] No install step for 'gflags-populate'\n",
      "\u001b[95mcmd1:\u001b[0m [ 88%] No test step for 'gflags-populate'\n",
      "\u001b[95mcmd1:\u001b[0m [100%] Completed 'gflags-populate'\n",
      "\u001b[95mcmd1:\u001b[0m [100%] Built target gflags-populate\n",
      "\u001b[95mcmd1:\u001b[0m CMake Deprecation Warning at fc_base/gflags-src/CMakeLists.txt:73 (cmake_minimum_required):\n",
      "\u001b[95mcmd1:\u001b[0m   Compatibility with CMake < 3.10 will be removed from a future version of\n",
      "\u001b[95mcmd1:\u001b[0m   CMake.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[95mcmd1:\u001b[0m   Update the VERSION argument <min> value.  Or, use the <min>...<max> syntax\n",
      "\u001b[95mcmd1:\u001b[0m   to tell CMake that the project requires at least <min> but has been updated\n",
      "\u001b[95mcmd1:\u001b[0m   to work with policies introduced by <max> or earlier.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[95mcmd1:\u001b[0m CMake Warning (dev) at fc_base/gflags-src/CMakeLists.txt:93 (project):\n",
      "\u001b[95mcmd1:\u001b[0m   Policy CMP0048 is not set: project() command manages VERSION variables.\n",
      "\u001b[95mcmd1:\u001b[0m   Run \"cmake --help-policy CMP0048\" for policy details.  Use the cmake_policy\n",
      "\u001b[95mcmd1:\u001b[0m   command to set the policy and suppress this warning.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[95mcmd1:\u001b[0m   The following variable(s) would be set to empty:\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[95mcmd1:\u001b[0m     PROJECT_VERSION\n",
      "\u001b[95mcmd1:\u001b[0m     PROJECT_VERSION_MAJOR\n",
      "\u001b[95mcmd1:\u001b[0m     PROJECT_VERSION_MINOR\n",
      "\u001b[95mcmd1:\u001b[0m This warning is for project developers.  Use -Wno-dev to suppress it.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[95mcmd1:\u001b[0m -- Looking for C++ include unistd.h\n",
      "\u001b[95mcmd1:\u001b[0m -- Looking for C++ include unistd.h - found\n",
      "\u001b[95mcmd1:\u001b[0m -- Looking for C++ include stdint.h\n",
      "\u001b[95mcmd1:\u001b[0m -- Looking for C++ include stdint.h - found\n",
      "\u001b[95mcmd1:\u001b[0m -- Looking for C++ include inttypes.h\n",
      "\u001b[95mcmd1:\u001b[0m -- Looking for C++ include inttypes.h - found\n",
      "\u001b[95mcmd1:\u001b[0m -- Looking for C++ include sys/types.h\n",
      "\u001b[95mcmd1:\u001b[0m -- Looking for C++ include sys/types.h - found\n",
      "\u001b[95mcmd1:\u001b[0m -- Looking for C++ include sys/stat.h\n",
      "\u001b[95mcmd1:\u001b[0m -- Looking for C++ include sys/stat.h - found\n",
      "\u001b[95mcmd1:\u001b[0m -- Looking for C++ include fnmatch.h\n",
      "\u001b[95mcmd1:\u001b[0m -- Looking for C++ include fnmatch.h - found\n",
      "\u001b[95mcmd1:\u001b[0m -- Looking for C++ include stddef.h\n",
      "\u001b[95mcmd1:\u001b[0m -- Looking for C++ include stddef.h - found\n",
      "\u001b[95mcmd1:\u001b[0m -- Check size of uint32_t\n",
      "\u001b[95mcmd1:\u001b[0m -- Check size of uint32_t - done\n",
      "\u001b[95mcmd1:\u001b[0m -- Looking for strtoll\n",
      "\u001b[95mcmd1:\u001b[0m -- Looking for strtoll - found\n",
      "\u001b[95mcmd1:\u001b[0m CMake Warning (dev) at /usr/local/lib/python3.11/dist-packages/cmake/data/share/cmake-3.31/Modules/FetchContent.cmake:1373 (message):\n",
      "\u001b[95mcmd1:\u001b[0m   The DOWNLOAD_EXTRACT_TIMESTAMP option was not given and policy CMP0135 is\n",
      "\u001b[95mcmd1:\u001b[0m   not set.  The policy's OLD behavior will be used.  When using a URL\n",
      "\u001b[95mcmd1:\u001b[0m   download, the timestamps of extracted files should preferably be that of\n",
      "\u001b[95mcmd1:\u001b[0m   the time of extraction, otherwise code that depends on the extracted\n",
      "\u001b[95mcmd1:\u001b[0m   contents might not be rebuilt if the URL changes.  The OLD behavior\n",
      "\u001b[95mcmd1:\u001b[0m   preserves the timestamps from the archive instead, but this is usually not\n",
      "\u001b[95mcmd1:\u001b[0m   what you want.  Update your project to the NEW behavior or specify the\n",
      "\u001b[95mcmd1:\u001b[0m   DOWNLOAD_EXTRACT_TIMESTAMP option with a value of true to avoid this\n",
      "\u001b[95mcmd1:\u001b[0m   robustness issue.\n",
      "\u001b[95mcmd1:\u001b[0m Call Stack (most recent call first):\n",
      "\u001b[95mcmd1:\u001b[0m   CMakeLists.txt:41 (FetchContent_Declare)\n",
      "\u001b[95mcmd1:\u001b[0m This warning is for project developers.  Use -Wno-dev to suppress it.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[95mcmd1:\u001b[0m -- Populating glog\n",
      "\u001b[95mcmd1:\u001b[0m -- Configuring done (0.0s)\n",
      "\u001b[95mcmd1:\u001b[0m -- Generating done (0.0s)\n",
      "\u001b[95mcmd1:\u001b[0m -- Build files have been written to: /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-subbuild\n",
      "\u001b[95mcmd1:\u001b[0m [ 11%] Creating directories for 'glog-populate'\n",
      "\u001b[95mcmd1:\u001b[0m [ 22%] Performing download step (download, verify and extract) for 'glog-populate'\n",
      "\u001b[95mcmd1:\u001b[0m -- Downloading...\n",
      "\u001b[95mcmd1:\u001b[0m    dst='/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-subbuild/glog-populate-prefix/src/v0.4.0.zip'\n",
      "\u001b[95mcmd1:\u001b[0m    timeout='none'\n",
      "\u001b[95mcmd1:\u001b[0m    inactivity timeout='none'\n",
      "\u001b[95mcmd1:\u001b[0m -- Using src='https://github.com/google/glog/archive/v0.4.0.zip'\n",
      "\u001b[95mcmd1:\u001b[0m -- verifying file...\n",
      "\u001b[95mcmd1:\u001b[0m        file='/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-subbuild/glog-populate-prefix/src/v0.4.0.zip'\n",
      "\u001b[95mcmd1:\u001b[0m -- Downloading... done\n",
      "\u001b[95mcmd1:\u001b[0m -- extracting...\n",
      "\u001b[95mcmd1:\u001b[0m      src='/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-subbuild/glog-populate-prefix/src/v0.4.0.zip'\n",
      "\u001b[95mcmd1:\u001b[0m      dst='/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src'\n",
      "\u001b[95mcmd1:\u001b[0m -- extracting... [tar xfz]\n",
      "\u001b[95mcmd1:\u001b[0m -- extracting... [analysis]\n",
      "\u001b[95mcmd1:\u001b[0m -- extracting... [rename]\n",
      "\u001b[95mcmd1:\u001b[0m -- extracting... [clean up]\n",
      "\u001b[95mcmd1:\u001b[0m -- extracting... done\n",
      "\u001b[95mcmd1:\u001b[0m [ 33%] No update step for 'glog-populate'\n",
      "\u001b[95mcmd1:\u001b[0m [ 44%] No patch step for 'glog-populate'\n",
      "\u001b[95mcmd1:\u001b[0m [ 55%] No configure step for 'glog-populate'\n",
      "\u001b[95mcmd1:\u001b[0m [ 66%] No build step for 'glog-populate'\n",
      "\u001b[95mcmd1:\u001b[0m [ 77%] No install step for 'glog-populate'\n",
      "\u001b[95mcmd1:\u001b[0m [ 88%] No test step for 'glog-populate'\n",
      "\u001b[95mcmd1:\u001b[0m [100%] Completed 'glog-populate'\n",
      "\u001b[95mcmd1:\u001b[0m [100%] Built target glog-populate\n",
      "\u001b[95mcmd1:\u001b[0m CMake Deprecation Warning at fc_base/glog-src/CMakeLists.txt:1 (cmake_minimum_required):\n",
      "\u001b[95mcmd1:\u001b[0m   Compatibility with CMake < 3.10 will be removed from a future version of\n",
      "\u001b[95mcmd1:\u001b[0m   CMake.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[95mcmd1:\u001b[0m   Update the VERSION argument <min> value.  Or, use the <min>...<max> syntax\n",
      "\u001b[95mcmd1:\u001b[0m   to tell CMake that the project requires at least <min> but has been updated\n",
      "\u001b[95mcmd1:\u001b[0m   to work with policies introduced by <max> or earlier.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[95mcmd1:\u001b[0m CMake Warning at fc_base/glog-src/CMakeLists.txt:51 (find_package):\n",
      "\u001b[95mcmd1:\u001b[0m   By not providing \"Findgflags.cmake\" in CMAKE_MODULE_PATH this project has\n",
      "\u001b[95mcmd1:\u001b[0m   asked CMake to find a package configuration file provided by \"gflags\", but\n",
      "\u001b[95mcmd1:\u001b[0m   CMake did not find one.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[95mcmd1:\u001b[0m   Could not find a package configuration file provided by \"gflags\" (requested\n",
      "\u001b[95mcmd1:\u001b[0m   version 2.2.0) with any of the following names:\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[95mcmd1:\u001b[0m     gflagsConfig.cmake\n",
      "\u001b[95mcmd1:\u001b[0m     gflags-config.cmake\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[95mcmd1:\u001b[0m   Add the installation prefix of \"gflags\" to CMAKE_PREFIX_PATH or set\n",
      "\u001b[95mcmd1:\u001b[0m   \"gflags_DIR\" to a directory containing one of the above files.  If \"gflags\"\n",
      "\u001b[95mcmd1:\u001b[0m   provides a separate development package or SDK, be sure it has been\n",
      "\u001b[95mcmd1:\u001b[0m   installed.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[95mcmd1:\u001b[0m -- Performing Test CMAKE_HAVE_LIBC_PTHREAD\n",
      "\u001b[95mcmd1:\u001b[0m -- Performing Test CMAKE_HAVE_LIBC_PTHREAD - Success\n",
      "\u001b[95mcmd1:\u001b[0m -- Found Threads: TRUE\n",
      "\u001b[95mcmd1:\u001b[0m -- Looking for dlfcn.h\n",
      "\u001b[95mcmd1:\u001b[0m -- Looking for dlfcn.h - found\n",
      "\u001b[95mcmd1:\u001b[0m -- Looking for execinfo.h\n",
      "\u001b[95mcmd1:\u001b[0m -- Looking for execinfo.h - found\n",
      "\u001b[95mcmd1:\u001b[0m -- Looking for glob.h\n",
      "\u001b[95mcmd1:\u001b[0m -- Looking for glob.h - found\n",
      "\u001b[95mcmd1:\u001b[0m -- Looking for libunwind.h\n",
      "\u001b[95mcmd1:\u001b[0m -- Looking for libunwind.h - not found\n",
      "\u001b[95mcmd1:\u001b[0m -- Looking for memory.h\n",
      "\u001b[95mcmd1:\u001b[0m -- Looking for memory.h - found\n",
      "\u001b[95mcmd1:\u001b[0m -- Looking for pwd.h\n",
      "\u001b[95mcmd1:\u001b[0m -- Looking for pwd.h - found\n",
      "\u001b[95mcmd1:\u001b[0m -- Looking for stdlib.h\n",
      "\u001b[95mcmd1:\u001b[0m -- Looking for stdlib.h - found\n",
      "\u001b[95mcmd1:\u001b[0m -- Looking for string.h\n",
      "\u001b[95mcmd1:\u001b[0m -- Looking for string.h - found\n",
      "\u001b[95mcmd1:\u001b[0m -- Looking for strings.h\n",
      "\u001b[95mcmd1:\u001b[0m -- Looking for strings.h - found\n",
      "\u001b[95mcmd1:\u001b[0m -- Looking for sys/syscall.h\n",
      "\u001b[95mcmd1:\u001b[0m -- Looking for sys/syscall.h - found\n",
      "\u001b[95mcmd1:\u001b[0m -- Looking for sys/time.h\n",
      "\u001b[95mcmd1:\u001b[0m -- Looking for sys/time.h - found\n",
      "\u001b[95mcmd1:\u001b[0m -- Looking for sys/utsname.h\n",
      "\u001b[95mcmd1:\u001b[0m -- Looking for sys/utsname.h - found\n",
      "\u001b[95mcmd1:\u001b[0m -- Looking for syscall.h\n",
      "\u001b[95mcmd1:\u001b[0m -- Looking for syscall.h - found\n",
      "\u001b[95mcmd1:\u001b[0m -- Looking for syslog.h\n",
      "\u001b[95mcmd1:\u001b[0m -- Looking for syslog.h - found\n",
      "\u001b[95mcmd1:\u001b[0m -- Looking for ucontext.h\n",
      "\u001b[95mcmd1:\u001b[0m -- Looking for ucontext.h - found\n",
      "\u001b[95mcmd1:\u001b[0m -- Looking for unwind.h\n",
      "\u001b[95mcmd1:\u001b[0m -- Looking for unwind.h - found\n",
      "\u001b[95mcmd1:\u001b[0m -- Looking for C++ include ext/hash_map\n",
      "\u001b[95mcmd1:\u001b[0m -- Looking for C++ include ext/hash_map - found\n",
      "\u001b[95mcmd1:\u001b[0m -- Looking for C++ include ext/hash_set\n",
      "\u001b[95mcmd1:\u001b[0m -- Looking for C++ include ext/hash_set - found\n",
      "\u001b[95mcmd1:\u001b[0m -- Looking for C++ include ext/slist\n",
      "\u001b[95mcmd1:\u001b[0m -- Looking for C++ include ext/slist - found\n",
      "\u001b[95mcmd1:\u001b[0m -- Looking for C++ include tr1/unordered_map\n",
      "\u001b[95mcmd1:\u001b[0m -- Looking for C++ include tr1/unordered_map - found\n",
      "\u001b[95mcmd1:\u001b[0m -- Looking for C++ include tr1/unordered_set\n",
      "\u001b[95mcmd1:\u001b[0m -- Looking for C++ include tr1/unordered_set - found\n",
      "\u001b[95mcmd1:\u001b[0m -- Looking for C++ include unordered_map\n",
      "\u001b[95mcmd1:\u001b[0m -- Looking for C++ include unordered_map - found\n",
      "\u001b[95mcmd1:\u001b[0m -- Looking for C++ include unordered_set\n",
      "\u001b[95mcmd1:\u001b[0m -- Looking for C++ include unordered_set - found\n",
      "\u001b[95mcmd1:\u001b[0m -- Check size of unsigned __int16\n",
      "\u001b[95mcmd1:\u001b[0m -- Check size of unsigned __int16 - failed\n",
      "\u001b[95mcmd1:\u001b[0m -- Check size of u_int16_t\n",
      "\u001b[95mcmd1:\u001b[0m -- Check size of u_int16_t - done\n",
      "\u001b[95mcmd1:\u001b[0m -- Check size of uint16_t\n",
      "\u001b[95mcmd1:\u001b[0m -- Check size of uint16_t - done\n",
      "\u001b[95mcmd1:\u001b[0m -- Looking for dladdr\n",
      "\u001b[95mcmd1:\u001b[0m -- Looking for dladdr - found\n",
      "\u001b[95mcmd1:\u001b[0m -- Looking for fcntl\n",
      "\u001b[95mcmd1:\u001b[0m -- Looking for fcntl - found\n",
      "\u001b[95mcmd1:\u001b[0m -- Looking for pread\n",
      "\u001b[95mcmd1:\u001b[0m -- Looking for pread - found\n",
      "\u001b[95mcmd1:\u001b[0m -- Looking for pwrite\n",
      "\u001b[95mcmd1:\u001b[0m -- Looking for pwrite - found\n",
      "\u001b[95mcmd1:\u001b[0m -- Looking for sigaction\n",
      "\u001b[95mcmd1:\u001b[0m -- Looking for sigaction - found\n",
      "\u001b[95mcmd1:\u001b[0m -- Looking for sigaltstack\n",
      "\u001b[95mcmd1:\u001b[0m -- Looking for sigaltstack - found\n",
      "\u001b[95mcmd1:\u001b[0m -- Performing Test HAVE_NO_DEPRECATED\n",
      "\u001b[95mcmd1:\u001b[0m -- Performing Test HAVE_NO_DEPRECATED - Success\n",
      "\u001b[95mcmd1:\u001b[0m -- Performing Test HAVE_NO_UNNAMED_TYPE_TEMPLATE_ARGS\n",
      "\u001b[95mcmd1:\u001b[0m -- Performing Test HAVE_NO_UNNAMED_TYPE_TEMPLATE_ARGS - Failed\n",
      "\u001b[95mcmd1:\u001b[0m -- Looking for snprintf\n",
      "\u001b[95mcmd1:\u001b[0m -- Looking for snprintf - found\n",
      "\u001b[95mcmd1:\u001b[0m -- Looking for get_static_proc_name in unwind\n",
      "\u001b[95mcmd1:\u001b[0m -- Looking for get_static_proc_name in unwind - not found\n",
      "\u001b[95mcmd1:\u001b[0m -- Looking for UnDecorateSymbolName in dbghelp\n",
      "\u001b[95mcmd1:\u001b[0m -- Looking for UnDecorateSymbolName in dbghelp - not found\n",
      "\u001b[95mcmd1:\u001b[0m -- Performing Test HAVE___ATTRIBUTE__\n",
      "\u001b[95mcmd1:\u001b[0m -- Performing Test HAVE___ATTRIBUTE__ - Success\n",
      "\u001b[95mcmd1:\u001b[0m -- Performing Test HAVE___ATTRIBUTE__VISIBILITY_DEFAULT\n",
      "\u001b[95mcmd1:\u001b[0m -- Performing Test HAVE___ATTRIBUTE__VISIBILITY_DEFAULT - Success\n",
      "\u001b[95mcmd1:\u001b[0m -- Performing Test HAVE___ATTRIBUTE__VISIBILITY_HIDDEN\n",
      "\u001b[95mcmd1:\u001b[0m -- Performing Test HAVE___ATTRIBUTE__VISIBILITY_HIDDEN - Success\n",
      "\u001b[95mcmd1:\u001b[0m -- Performing Test HAVE___BUILTIN_EXPECT\n",
      "\u001b[95mcmd1:\u001b[0m -- Performing Test HAVE___BUILTIN_EXPECT - Success\n",
      "\u001b[95mcmd1:\u001b[0m -- Performing Test HAVE___SYNC_VAL_COMPARE_AND_SWAP\n",
      "\u001b[95mcmd1:\u001b[0m -- Performing Test HAVE___SYNC_VAL_COMPARE_AND_SWAP - Success\n",
      "\u001b[95mcmd1:\u001b[0m -- Performing Test HAVE_RWLOCK\n",
      "\u001b[95mcmd1:\u001b[0m -- Performing Test HAVE_RWLOCK - Success\n",
      "\u001b[95mcmd1:\u001b[0m -- Performing Test HAVE___DECLSPEC\n",
      "\u001b[95mcmd1:\u001b[0m -- Performing Test HAVE___DECLSPEC - Failed\n",
      "\u001b[95mcmd1:\u001b[0m -- Performing Test STL_NO_NAMESPACE\n",
      "\u001b[95mcmd1:\u001b[0m -- Performing Test STL_NO_NAMESPACE - Failed\n",
      "\u001b[95mcmd1:\u001b[0m -- Performing Test STL_STD_NAMESPACE\n",
      "\u001b[95mcmd1:\u001b[0m -- Performing Test STL_STD_NAMESPACE - Success\n",
      "\u001b[95mcmd1:\u001b[0m -- Performing Test HAVE_USING_OPERATOR\n",
      "\u001b[95mcmd1:\u001b[0m -- Performing Test HAVE_USING_OPERATOR - Success\n",
      "\u001b[95mcmd1:\u001b[0m -- Performing Test HAVE_NAMESPACES\n",
      "\u001b[95mcmd1:\u001b[0m -- Performing Test HAVE_NAMESPACES - Success\n",
      "\u001b[95mcmd1:\u001b[0m -- Performing Test HAVE_GCC_TLS\n",
      "\u001b[95mcmd1:\u001b[0m -- Performing Test HAVE_GCC_TLS - Success\n",
      "\u001b[95mcmd1:\u001b[0m -- Performing Test HAVE_MSVC_TLS\n",
      "\u001b[95mcmd1:\u001b[0m -- Performing Test HAVE_MSVC_TLS - Failed\n",
      "\u001b[95mcmd1:\u001b[0m -- Performing Test HAVE_CXX11_TLS\n",
      "\u001b[95mcmd1:\u001b[0m -- Performing Test HAVE_CXX11_TLS - Success\n",
      "\u001b[95mcmd1:\u001b[0m -- Performing Test HAVE_ALIGNED_STORAGE\n",
      "\u001b[95mcmd1:\u001b[0m -- Performing Test HAVE_ALIGNED_STORAGE - Success\n",
      "\u001b[95mcmd1:\u001b[0m -- Performing Test HAVE_LOCALTIME_R\n",
      "\u001b[95mcmd1:\u001b[0m -- Performing Test HAVE_LOCALTIME_R - Success\n",
      "\u001b[95mcmd1:\u001b[0m CMake Warning (dev) at /usr/local/lib/python3.11/dist-packages/cmake/data/share/cmake-3.31/Modules/FetchContent.cmake:1373 (message):\n",
      "\u001b[95mcmd1:\u001b[0m   The DOWNLOAD_EXTRACT_TIMESTAMP option was not given and policy CMP0135 is\n",
      "\u001b[95mcmd1:\u001b[0m   not set.  The policy's OLD behavior will be used.  When using a URL\n",
      "\u001b[95mcmd1:\u001b[0m   download, the timestamps of extracted files should preferably be that of\n",
      "\u001b[95mcmd1:\u001b[0m   the time of extraction, otherwise code that depends on the extracted\n",
      "\u001b[95mcmd1:\u001b[0m   contents might not be rebuilt if the URL changes.  The OLD behavior\n",
      "\u001b[95mcmd1:\u001b[0m   preserves the timestamps from the archive instead, but this is usually not\n",
      "\u001b[95mcmd1:\u001b[0m   what you want.  Update your project to the NEW behavior or specify the\n",
      "\u001b[95mcmd1:\u001b[0m   DOWNLOAD_EXTRACT_TIMESTAMP option with a value of true to avoid this\n",
      "\u001b[95mcmd1:\u001b[0m   robustness issue.\n",
      "\u001b[95mcmd1:\u001b[0m Call Stack (most recent call first):\n",
      "\u001b[95mcmd1:\u001b[0m   CMakeLists.txt:49 (FetchContent_Declare)\n",
      "\u001b[95mcmd1:\u001b[0m This warning is for project developers.  Use -Wno-dev to suppress it.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[95mcmd1:\u001b[0m -- Populating googletest\n",
      "\u001b[95mcmd1:\u001b[0m -- Configuring done (0.0s)\n",
      "\u001b[95mcmd1:\u001b[0m -- Generating done (0.0s)\n",
      "\u001b[95mcmd1:\u001b[0m -- Build files have been written to: /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/googletest-subbuild\n",
      "\u001b[95mcmd1:\u001b[0m [ 11%] Creating directories for 'googletest-populate'\n",
      "\u001b[95mcmd1:\u001b[0m [ 22%] Performing download step (download, verify and extract) for 'googletest-populate'\n",
      "\u001b[95mcmd1:\u001b[0m -- Downloading...\n",
      "\u001b[95mcmd1:\u001b[0m    dst='/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/googletest-subbuild/googletest-populate-prefix/src/release-1.10.0.zip'\n",
      "\u001b[95mcmd1:\u001b[0m    timeout='none'\n",
      "\u001b[95mcmd1:\u001b[0m    inactivity timeout='none'\n",
      "\u001b[95mcmd1:\u001b[0m -- Using src='https://github.com/google/googletest/archive/release-1.10.0.zip'\n",
      "\u001b[95mcmd1:\u001b[0m -- [download 1% complete]\n",
      "\u001b[95mcmd1:\u001b[0m -- [download 3% complete]\n",
      "\u001b[95mcmd1:\u001b[0m -- [download 4% complete]\n",
      "\u001b[95mcmd1:\u001b[0m -- [download 5% complete]\n",
      "\u001b[95mcmd1:\u001b[0m -- [download 7% complete]\n",
      "\u001b[95mcmd1:\u001b[0m -- [download 8% complete]\n",
      "\u001b[95mcmd1:\u001b[0m -- [download 10% complete]\n",
      "\u001b[95mcmd1:\u001b[0m -- [download 11% complete]\n",
      "\u001b[95mcmd1:\u001b[0m -- [download 13% complete]\n",
      "\u001b[95mcmd1:\u001b[0m -- [download 14% complete]\n",
      "\u001b[95mcmd1:\u001b[0m -- [download 16% complete]\n",
      "\u001b[95mcmd1:\u001b[0m -- [download 17% complete]\n",
      "\u001b[95mcmd1:\u001b[0m -- [download 18% complete]\n",
      "\u001b[95mcmd1:\u001b[0m -- [download 20% complete]\n",
      "\u001b[95mcmd1:\u001b[0m -- [download 21% complete]\n",
      "\u001b[95mcmd1:\u001b[0m -- [download 22% complete]\n",
      "\u001b[95mcmd1:\u001b[0m -- [download 24% complete]\n",
      "\u001b[95mcmd1:\u001b[0m -- [download 25% complete]\n",
      "\u001b[95mcmd1:\u001b[0m -- [download 27% complete]\n",
      "\u001b[95mcmd1:\u001b[0m -- [download 28% complete]\n",
      "\u001b[95mcmd1:\u001b[0m -- [download 30% complete]\n",
      "\u001b[95mcmd1:\u001b[0m -- [download 32% complete]\n",
      "\u001b[95mcmd1:\u001b[0m -- [download 34% complete]\n",
      "\u001b[95mcmd1:\u001b[0m -- [download 35% complete]\n",
      "\u001b[95mcmd1:\u001b[0m -- [download 36% complete]\n",
      "\u001b[95mcmd1:\u001b[0m -- [download 38% complete]\n",
      "\u001b[95mcmd1:\u001b[0m -- [download 39% complete]\n",
      "\u001b[95mcmd1:\u001b[0m -- [download 41% complete]\n",
      "\u001b[95mcmd1:\u001b[0m -- [download 42% complete]\n",
      "\u001b[95mcmd1:\u001b[0m -- [download 44% complete]\n",
      "\u001b[95mcmd1:\u001b[0m -- [download 45% complete]\n",
      "\u001b[95mcmd1:\u001b[0m -- [download 46% complete]\n",
      "\u001b[95mcmd1:\u001b[0m -- [download 48% complete]\n",
      "\u001b[95mcmd1:\u001b[0m -- [download 49% complete]\n",
      "\u001b[95mcmd1:\u001b[0m -- [download 51% complete]\n",
      "\u001b[95mcmd1:\u001b[0m -- [download 52% complete]\n",
      "\u001b[95mcmd1:\u001b[0m -- [download 54% complete]\n",
      "\u001b[95mcmd1:\u001b[0m -- [download 55% complete]\n",
      "\u001b[95mcmd1:\u001b[0m -- [download 57% complete]\n",
      "\u001b[95mcmd1:\u001b[0m -- [download 58% complete]\n",
      "\u001b[95mcmd1:\u001b[0m -- [download 59% complete]\n",
      "\u001b[95mcmd1:\u001b[0m -- [download 61% complete]\n",
      "\u001b[95mcmd1:\u001b[0m -- [download 62% complete]\n",
      "\u001b[95mcmd1:\u001b[0m -- [download 64% complete]\n",
      "\u001b[95mcmd1:\u001b[0m -- [download 65% complete]\n",
      "\u001b[95mcmd1:\u001b[0m -- [download 67% complete]\n",
      "\u001b[95mcmd1:\u001b[0m -- [download 68% complete]\n",
      "\u001b[95mcmd1:\u001b[0m -- [download 69% complete]\n",
      "\u001b[95mcmd1:\u001b[0m -- [download 71% complete]\n",
      "\u001b[95mcmd1:\u001b[0m -- [download 72% complete]\n",
      "\u001b[95mcmd1:\u001b[0m -- [download 74% complete]\n",
      "\u001b[95mcmd1:\u001b[0m -- [download 75% complete]\n",
      "\u001b[95mcmd1:\u001b[0m -- [download 77% complete]\n",
      "\u001b[95mcmd1:\u001b[0m -- [download 78% complete]\n",
      "\u001b[95mcmd1:\u001b[0m -- [download 79% complete]\n",
      "\u001b[95mcmd1:\u001b[0m -- [download 81% complete]\n",
      "\u001b[95mcmd1:\u001b[0m -- [download 82% complete]\n",
      "\u001b[95mcmd1:\u001b[0m -- [download 84% complete]\n",
      "\u001b[95mcmd1:\u001b[0m -- [download 85% complete]\n",
      "\u001b[95mcmd1:\u001b[0m -- [download 87% complete]\n",
      "\u001b[95mcmd1:\u001b[0m -- [download 88% complete]\n",
      "\u001b[95mcmd1:\u001b[0m -- [download 90% complete]\n",
      "\u001b[95mcmd1:\u001b[0m -- [download 91% complete]\n",
      "\u001b[95mcmd1:\u001b[0m -- [download 92% complete]\n",
      "\u001b[95mcmd1:\u001b[0m -- [download 94% complete]\n",
      "\u001b[95mcmd1:\u001b[0m -- [download 95% complete]\n",
      "\u001b[95mcmd1:\u001b[0m -- [download 97% complete]\n",
      "\u001b[95mcmd1:\u001b[0m -- [download 98% complete]\n",
      "\u001b[95mcmd1:\u001b[0m -- [download 100% complete]\n",
      "\u001b[95mcmd1:\u001b[0m -- verifying file...\n",
      "\u001b[95mcmd1:\u001b[0m        file='/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/googletest-subbuild/googletest-populate-prefix/src/release-1.10.0.zip'\n",
      "\u001b[95mcmd1:\u001b[0m -- Downloading... done\n",
      "\u001b[95mcmd1:\u001b[0m -- extracting...\n",
      "\u001b[95mcmd1:\u001b[0m      src='/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/googletest-subbuild/googletest-populate-prefix/src/release-1.10.0.zip'\n",
      "\u001b[95mcmd1:\u001b[0m      dst='/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/googletest-src'\n",
      "\u001b[95mcmd1:\u001b[0m -- extracting... [tar xfz]\n",
      "\u001b[95mcmd1:\u001b[0m -- extracting... [analysis]\n",
      "\u001b[95mcmd1:\u001b[0m -- extracting... [rename]\n",
      "\u001b[95mcmd1:\u001b[0m -- extracting... [clean up]\n",
      "\u001b[95mcmd1:\u001b[0m -- extracting... done\n",
      "\u001b[95mcmd1:\u001b[0m [ 33%] No update step for 'googletest-populate'\n",
      "\u001b[95mcmd1:\u001b[0m [ 44%] No patch step for 'googletest-populate'\n",
      "\u001b[95mcmd1:\u001b[0m [ 55%] No configure step for 'googletest-populate'\n",
      "\u001b[95mcmd1:\u001b[0m [ 66%] No build step for 'googletest-populate'\n",
      "\u001b[95mcmd1:\u001b[0m [ 77%] No install step for 'googletest-populate'\n",
      "\u001b[95mcmd1:\u001b[0m [ 88%] No test step for 'googletest-populate'\n",
      "\u001b[95mcmd1:\u001b[0m [100%] Completed 'googletest-populate'\n",
      "\u001b[95mcmd1:\u001b[0m [100%] Built target googletest-populate\n",
      "\u001b[95mcmd1:\u001b[0m CMake Deprecation Warning at fc_base/googletest-src/CMakeLists.txt:4 (cmake_minimum_required):\n",
      "\u001b[95mcmd1:\u001b[0m   Compatibility with CMake < 3.10 will be removed from a future version of\n",
      "\u001b[95mcmd1:\u001b[0m   CMake.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[95mcmd1:\u001b[0m   Update the VERSION argument <min> value.  Or, use the <min>...<max> syntax\n",
      "\u001b[95mcmd1:\u001b[0m   to tell CMake that the project requires at least <min> but has been updated\n",
      "\u001b[95mcmd1:\u001b[0m   to work with policies introduced by <max> or earlier.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[95mcmd1:\u001b[0m CMake Deprecation Warning at fc_base/googletest-src/googlemock/CMakeLists.txt:45 (cmake_minimum_required):\n",
      "\u001b[95mcmd1:\u001b[0m   Compatibility with CMake < 3.10 will be removed from a future version of\n",
      "\u001b[95mcmd1:\u001b[0m   CMake.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[95mcmd1:\u001b[0m   Update the VERSION argument <min> value.  Or, use the <min>...<max> syntax\n",
      "\u001b[95mcmd1:\u001b[0m   to tell CMake that the project requires at least <min> but has been updated\n",
      "\u001b[95mcmd1:\u001b[0m   to work with policies introduced by <max> or earlier.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[95mcmd1:\u001b[0m CMake Deprecation Warning at fc_base/googletest-src/googletest/CMakeLists.txt:56 (cmake_minimum_required):\n",
      "\u001b[95mcmd1:\u001b[0m   Compatibility with CMake < 3.10 will be removed from a future version of\n",
      "\u001b[95mcmd1:\u001b[0m   CMake.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[95mcmd1:\u001b[0m   Update the VERSION argument <min> value.  Or, use the <min>...<max> syntax\n",
      "\u001b[95mcmd1:\u001b[0m   to tell CMake that the project requires at least <min> but has been updated\n",
      "\u001b[95mcmd1:\u001b[0m   to work with policies introduced by <max> or earlier.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[95mcmd1:\u001b[0m CMake Warning (dev) at fc_base/googletest-src/googletest/cmake/internal_utils.cmake:243 (find_package):\n",
      "\u001b[95mcmd1:\u001b[0m   Policy CMP0148 is not set: The FindPythonInterp and FindPythonLibs modules\n",
      "\u001b[95mcmd1:\u001b[0m   are removed.  Run \"cmake --help-policy CMP0148\" for policy details.  Use\n",
      "\u001b[95mcmd1:\u001b[0m   the cmake_policy command to set the policy and suppress this warning.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[95mcmd1:\u001b[0m Call Stack (most recent call first):\n",
      "\u001b[95mcmd1:\u001b[0m   fc_base/googletest-src/googletest/CMakeLists.txt:91 (include)\n",
      "\u001b[95mcmd1:\u001b[0m This warning is for project developers.  Use -Wno-dev to suppress it.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[95mcmd1:\u001b[0m -- Found PythonInterp: /root/miniconda3/envs/b2txt25_lm/bin/python (found version \"3.9.25\")\n",
      "\u001b[95mcmd1:\u001b[0m CMake Warning (dev) at /usr/local/lib/python3.11/dist-packages/cmake/data/share/cmake-3.31/Modules/FetchContent.cmake:1373 (message):\n",
      "\u001b[95mcmd1:\u001b[0m   The DOWNLOAD_EXTRACT_TIMESTAMP option was not given and policy CMP0135 is\n",
      "\u001b[95mcmd1:\u001b[0m   not set.  The policy's OLD behavior will be used.  When using a URL\n",
      "\u001b[95mcmd1:\u001b[0m   download, the timestamps of extracted files should preferably be that of\n",
      "\u001b[95mcmd1:\u001b[0m   the time of extraction, otherwise code that depends on the extracted\n",
      "\u001b[95mcmd1:\u001b[0m   contents might not be rebuilt if the URL changes.  The OLD behavior\n",
      "\u001b[95mcmd1:\u001b[0m   preserves the timestamps from the archive instead, but this is usually not\n",
      "\u001b[95mcmd1:\u001b[0m   what you want.  Update your project to the NEW behavior or specify the\n",
      "\u001b[95mcmd1:\u001b[0m   DOWNLOAD_EXTRACT_TIMESTAMP option with a value of true to avoid this\n",
      "\u001b[95mcmd1:\u001b[0m   robustness issue.\n",
      "\u001b[95mcmd1:\u001b[0m Call Stack (most recent call first):\n",
      "\u001b[95mcmd1:\u001b[0m   CMakeLists.txt:56 (FetchContent_Declare)\n",
      "\u001b[95mcmd1:\u001b[0m This warning is for project developers.  Use -Wno-dev to suppress it.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[95mcmd1:\u001b[0m -- Populating boost\n",
      "\u001b[95mcmd1:\u001b[0m -- Configuring done (0.0s)\n",
      "\u001b[95mcmd1:\u001b[0m -- Generating done (0.0s)\n",
      "\u001b[95mcmd1:\u001b[0m -- Build files have been written to: /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/boost-subbuild\n",
      "\u001b[95mcmd1:\u001b[0m [ 11%] Creating directories for 'boost-populate'\n",
      "\u001b[95mcmd1:\u001b[0m [ 22%] Performing download step (download, verify and extract) for 'boost-populate'\n",
      "\u001b[95mcmd1:\u001b[0m -- Downloading...\n",
      "\u001b[95mcmd1:\u001b[0m    dst='/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/boost-subbuild/boost-populate-prefix/src/boost_1_75_0.tar.gz'\n",
      "\u001b[95mcmd1:\u001b[0m    timeout='none'\n",
      "\u001b[95mcmd1:\u001b[0m    inactivity timeout='none'\n",
      "\u001b[95mcmd1:\u001b[0m -- Using src='https://archives.boost.io/release/1.75.0/source/boost_1_75_0.tar.gz'\n",
      "\u001b[95mcmd1:\u001b[0m -- [download 0% complete]\n",
      "\u001b[95mcmd1:\u001b[0m -- [download 1% complete]\n",
      "\u001b[95mcmd1:\u001b[0m -- [download 2% complete]\n",
      "\u001b[95mcmd1:\u001b[0m -- [download 3% complete]\n",
      "\u001b[95mcmd1:\u001b[0m -- [download 4% complete]\n",
      "\u001b[95mcmd1:\u001b[0m -- [download 5% complete]\n",
      "\u001b[95mcmd1:\u001b[0m -- [download 6% complete]\n",
      "\u001b[95mcmd1:\u001b[0m -- [download 7% complete]\n",
      "\u001b[95mcmd1:\u001b[0m -- [download 8% complete]\n",
      "\u001b[95mcmd1:\u001b[0m -- [download 9% complete]\n",
      "\u001b[95mcmd1:\u001b[0m -- [download 10% complete]\n",
      "\u001b[95mcmd1:\u001b[0m -- [download 11% complete]\n",
      "\u001b[95mcmd1:\u001b[0m -- [download 12% complete]\n",
      "\u001b[95mcmd1:\u001b[0m -- [download 13% complete]\n",
      "\u001b[95mcmd1:\u001b[0m -- [download 14% complete]\n",
      "\u001b[95mcmd1:\u001b[0m -- [download 15% complete]\n",
      "\u001b[95mcmd1:\u001b[0m -- [download 16% complete]\n",
      "\u001b[95mcmd1:\u001b[0m -- [download 17% complete]\n",
      "\u001b[95mcmd1:\u001b[0m -- [download 18% complete]\n",
      "\u001b[95mcmd1:\u001b[0m -- [download 19% complete]\n",
      "\u001b[95mcmd1:\u001b[0m -- [download 20% complete]\n",
      "\u001b[95mcmd1:\u001b[0m -- [download 21% complete]\n",
      "\u001b[95mcmd1:\u001b[0m -- [download 22% complete]\n",
      "\u001b[95mcmd1:\u001b[0m -- [download 23% complete]\n",
      "\u001b[95mcmd1:\u001b[0m -- [download 24% complete]\n",
      "\u001b[95mcmd1:\u001b[0m -- [download 25% complete]\n",
      "\u001b[95mcmd1:\u001b[0m -- [download 26% complete]\n",
      "\u001b[95mcmd1:\u001b[0m -- [download 27% complete]\n",
      "\u001b[95mcmd1:\u001b[0m -- [download 28% complete]\n",
      "\u001b[95mcmd1:\u001b[0m -- [download 29% complete]\n",
      "\u001b[95mcmd1:\u001b[0m -- [download 30% complete]\n",
      "\u001b[95mcmd1:\u001b[0m -- [download 31% complete]\n",
      "\u001b[95mcmd1:\u001b[0m -- [download 32% complete]\n",
      "\u001b[95mcmd1:\u001b[0m -- [download 33% complete]\n",
      "\u001b[95mcmd1:\u001b[0m -- [download 34% complete]\n",
      "\u001b[95mcmd1:\u001b[0m -- [download 35% complete]\n",
      "\u001b[95mcmd1:\u001b[0m -- [download 36% complete]\n",
      "\u001b[95mcmd1:\u001b[0m -- [download 37% complete]\n",
      "\u001b[95mcmd1:\u001b[0m -- [download 38% complete]\n",
      "\u001b[95mcmd1:\u001b[0m -- [download 39% complete]\n",
      "\u001b[95mcmd1:\u001b[0m -- [download 40% complete]\n",
      "\u001b[95mcmd1:\u001b[0m -- [download 41% complete]\n",
      "\u001b[95mcmd1:\u001b[0m -- [download 42% complete]\n",
      "\u001b[95mcmd1:\u001b[0m -- [download 43% complete]\n",
      "\u001b[95mcmd1:\u001b[0m -- [download 44% complete]\n",
      "\u001b[95mcmd1:\u001b[0m -- [download 45% complete]\n",
      "\u001b[95mcmd1:\u001b[0m -- [download 46% complete]\n",
      "\u001b[95mcmd1:\u001b[0m -- [download 47% complete]\n",
      "\u001b[95mcmd1:\u001b[0m -- [download 48% complete]\n",
      "\u001b[95mcmd1:\u001b[0m -- [download 49% complete]\n",
      "\u001b[95mcmd1:\u001b[0m -- [download 50% complete]\n",
      "\u001b[95mcmd1:\u001b[0m -- [download 51% complete]\n",
      "\u001b[95mcmd1:\u001b[0m -- [download 52% complete]\n",
      "\u001b[95mcmd1:\u001b[0m -- [download 53% complete]\n",
      "\u001b[95mcmd1:\u001b[0m -- [download 54% complete]\n",
      "\u001b[95mcmd1:\u001b[0m -- [download 55% complete]\n",
      "\u001b[95mcmd1:\u001b[0m -- [download 56% complete]\n",
      "\u001b[95mcmd1:\u001b[0m -- [download 57% complete]\n",
      "\u001b[95mcmd1:\u001b[0m -- [download 58% complete]\n",
      "\u001b[95mcmd1:\u001b[0m -- [download 59% complete]\n",
      "\u001b[95mcmd1:\u001b[0m -- [download 60% complete]\n",
      "\u001b[95mcmd1:\u001b[0m -- [download 61% complete]\n",
      "\u001b[95mcmd1:\u001b[0m -- [download 62% complete]\n",
      "\u001b[95mcmd1:\u001b[0m -- [download 63% complete]\n",
      "\u001b[95mcmd1:\u001b[0m -- [download 64% complete]\n",
      "\u001b[95mcmd1:\u001b[0m -- [download 65% complete]\n",
      "\u001b[95mcmd1:\u001b[0m -- [download 66% complete]\n",
      "\u001b[95mcmd1:\u001b[0m -- [download 67% complete]\n",
      "\u001b[95mcmd1:\u001b[0m -- [download 68% complete]\n",
      "\u001b[95mcmd1:\u001b[0m -- [download 69% complete]\n",
      "\u001b[95mcmd1:\u001b[0m -- [download 70% complete]\n",
      "\u001b[95mcmd1:\u001b[0m -- [download 71% complete]\n",
      "\u001b[95mcmd1:\u001b[0m -- [download 72% complete]\n",
      "\u001b[95mcmd1:\u001b[0m -- [download 73% complete]\n",
      "\u001b[95mcmd1:\u001b[0m -- [download 74% complete]\n",
      "\u001b[95mcmd1:\u001b[0m -- [download 75% complete]\n",
      "\u001b[95mcmd1:\u001b[0m -- [download 76% complete]\n",
      "\u001b[95mcmd1:\u001b[0m -- [download 77% complete]\n",
      "\u001b[95mcmd1:\u001b[0m -- [download 78% complete]\n",
      "\u001b[95mcmd1:\u001b[0m -- [download 79% complete]\n",
      "\u001b[95mcmd1:\u001b[0m -- [download 80% complete]\n",
      "\u001b[95mcmd1:\u001b[0m -- [download 81% complete]\n",
      "\u001b[95mcmd1:\u001b[0m -- [download 82% complete]\n",
      "\u001b[95mcmd1:\u001b[0m -- [download 83% complete]\n",
      "\u001b[95mcmd1:\u001b[0m -- [download 84% complete]\n",
      "\u001b[95mcmd1:\u001b[0m -- [download 85% complete]\n",
      "\u001b[95mcmd1:\u001b[0m -- [download 86% complete]\n",
      "\u001b[95mcmd1:\u001b[0m -- [download 87% complete]\n",
      "\u001b[95mcmd1:\u001b[0m -- [download 88% complete]\n",
      "\u001b[95mcmd1:\u001b[0m -- [download 89% complete]\n",
      "\u001b[95mcmd1:\u001b[0m -- [download 90% complete]\n",
      "\u001b[95mcmd1:\u001b[0m -- [download 91% complete]\n",
      "\u001b[95mcmd1:\u001b[0m -- [download 92% complete]\n",
      "\u001b[95mcmd1:\u001b[0m -- [download 93% complete]\n",
      "\u001b[95mcmd1:\u001b[0m -- [download 94% complete]\n",
      "\u001b[95mcmd1:\u001b[0m -- [download 95% complete]\n",
      "\u001b[95mcmd1:\u001b[0m -- [download 96% complete]\n",
      "\u001b[95mcmd1:\u001b[0m -- [download 97% complete]\n",
      "\u001b[95mcmd1:\u001b[0m -- [download 98% complete]\n",
      "\u001b[95mcmd1:\u001b[0m -- [download 99% complete]\n",
      "\u001b[95mcmd1:\u001b[0m -- [download 100% complete]\n",
      "\u001b[95mcmd1:\u001b[0m -- verifying file...\n",
      "\u001b[95mcmd1:\u001b[0m        file='/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/boost-subbuild/boost-populate-prefix/src/boost_1_75_0.tar.gz'\n",
      "\u001b[95mcmd1:\u001b[0m -- Downloading... done\n",
      "\u001b[95mcmd1:\u001b[0m -- extracting...\n",
      "\u001b[95mcmd1:\u001b[0m      src='/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/boost-subbuild/boost-populate-prefix/src/boost_1_75_0.tar.gz'\n",
      "\u001b[95mcmd1:\u001b[0m      dst='/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/boost-src'\n",
      "\u001b[95mcmd1:\u001b[0m -- extracting... [tar xfz]\n",
      "\u001b[95mcmd1:\u001b[0m -- extracting... [analysis]\n",
      "\u001b[95mcmd1:\u001b[0m -- extracting... [rename]\n",
      "\u001b[95mcmd1:\u001b[0m -- extracting... [clean up]\n",
      "\u001b[95mcmd1:\u001b[0m -- extracting... done\n",
      "\u001b[95mcmd1:\u001b[0m [ 33%] No update step for 'boost-populate'\n",
      "\u001b[95mcmd1:\u001b[0m [ 44%] No patch step for 'boost-populate'\n",
      "\u001b[95mcmd1:\u001b[0m [ 55%] No configure step for 'boost-populate'\n",
      "\u001b[95mcmd1:\u001b[0m [ 66%] No build step for 'boost-populate'\n",
      "\u001b[95mcmd1:\u001b[0m [ 77%] No install step for 'boost-populate'\n",
      "\u001b[95mcmd1:\u001b[0m [ 88%] No test step for 'boost-populate'\n",
      "\u001b[95mcmd1:\u001b[0m [100%] Completed 'boost-populate'\n",
      "\u001b[95mcmd1:\u001b[0m [100%] Built target boost-populate\n",
      "\u001b[95mcmd1:\u001b[0m CMake Warning (dev) at /usr/local/lib/python3.11/dist-packages/cmake/data/share/cmake-3.31/Modules/FetchContent.cmake:1373 (message):\n",
      "\u001b[95mcmd1:\u001b[0m   The DOWNLOAD_EXTRACT_TIMESTAMP option was not given and policy CMP0135 is\n",
      "\u001b[95mcmd1:\u001b[0m   not set.  The policy's OLD behavior will be used.  When using a URL\n",
      "\u001b[95mcmd1:\u001b[0m   download, the timestamps of extracted files should preferably be that of\n",
      "\u001b[95mcmd1:\u001b[0m   the time of extraction, otherwise code that depends on the extracted\n",
      "\u001b[95mcmd1:\u001b[0m   contents might not be rebuilt if the URL changes.  The OLD behavior\n",
      "\u001b[95mcmd1:\u001b[0m   preserves the timestamps from the archive instead, but this is usually not\n",
      "\u001b[95mcmd1:\u001b[0m   what you want.  Update your project to the NEW behavior or specify the\n",
      "\u001b[95mcmd1:\u001b[0m   DOWNLOAD_EXTRACT_TIMESTAMP option with a value of true to avoid this\n",
      "\u001b[95mcmd1:\u001b[0m   robustness issue.\n",
      "\u001b[95mcmd1:\u001b[0m Call Stack (most recent call first):\n",
      "\u001b[95mcmd1:\u001b[0m   CMakeLists.txt:64 (FetchContent_Declare)\n",
      "\u001b[95mcmd1:\u001b[0m This warning is for project developers.  Use -Wno-dev to suppress it.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[95mcmd1:\u001b[0m -- Populating cnpy\n",
      "\u001b[95mcmd1:\u001b[0m -- Configuring done (0.0s)\n",
      "\u001b[95mcmd1:\u001b[0m -- Generating done (0.0s)\n",
      "\u001b[95mcmd1:\u001b[0m -- Build files have been written to: /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/cnpy-subbuild\n",
      "\u001b[95mcmd1:\u001b[0m [ 11%] Creating directories for 'cnpy-populate'\n",
      "\u001b[95mcmd1:\u001b[0m [ 22%] Performing download step (download, verify and extract) for 'cnpy-populate'\n",
      "\u001b[95mcmd1:\u001b[0m -- Downloading...\n",
      "\u001b[95mcmd1:\u001b[0m    dst='/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/cnpy-subbuild/cnpy-populate-prefix/src/master.zip'\n",
      "\u001b[95mcmd1:\u001b[0m    timeout='none'\n",
      "\u001b[95mcmd1:\u001b[0m    inactivity timeout='none'\n",
      "\u001b[95mcmd1:\u001b[0m -- Using src='https://github.com/rogersce/cnpy/archive/refs/heads/master.zip'\n",
      "\u001b[95mcmd1:\u001b[0m -- verifying file...\n",
      "\u001b[95mcmd1:\u001b[0m        file='/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/cnpy-subbuild/cnpy-populate-prefix/src/master.zip'\n",
      "\u001b[95mcmd1:\u001b[0m -- Downloading... done\n",
      "\u001b[95mcmd1:\u001b[0m -- extracting...\n",
      "\u001b[95mcmd1:\u001b[0m      src='/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/cnpy-subbuild/cnpy-populate-prefix/src/master.zip'\n",
      "\u001b[95mcmd1:\u001b[0m      dst='/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/cnpy-src'\n",
      "\u001b[95mcmd1:\u001b[0m -- extracting... [tar xfz]\n",
      "\u001b[95mcmd1:\u001b[0m -- extracting... [analysis]\n",
      "\u001b[95mcmd1:\u001b[0m -- extracting... [rename]\n",
      "\u001b[95mcmd1:\u001b[0m -- extracting... [clean up]\n",
      "\u001b[95mcmd1:\u001b[0m -- extracting... done\n",
      "\u001b[95mcmd1:\u001b[0m [ 33%] No update step for 'cnpy-populate'\n",
      "\u001b[95mcmd1:\u001b[0m [ 44%] No patch step for 'cnpy-populate'\n",
      "\u001b[95mcmd1:\u001b[0m [ 55%] No configure step for 'cnpy-populate'\n",
      "\u001b[95mcmd1:\u001b[0m [ 66%] No build step for 'cnpy-populate'\n",
      "\u001b[95mcmd1:\u001b[0m [ 77%] No install step for 'cnpy-populate'\n",
      "\u001b[95mcmd1:\u001b[0m [ 88%] No test step for 'cnpy-populate'\n",
      "\u001b[95mcmd1:\u001b[0m [100%] Completed 'cnpy-populate'\n",
      "\u001b[95mcmd1:\u001b[0m [100%] Built target cnpy-populate\n",
      "\u001b[95mcmd1:\u001b[0m CMake Deprecation Warning at fc_base/cnpy-src/CMakeLists.txt:1 (CMAKE_MINIMUM_REQUIRED):\n",
      "\u001b[95mcmd1:\u001b[0m   Compatibility with CMake < 3.10 will be removed from a future version of\n",
      "\u001b[95mcmd1:\u001b[0m   CMake.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[95mcmd1:\u001b[0m   Update the VERSION argument <min> value.  Or, use the <min>...<max> syntax\n",
      "\u001b[95mcmd1:\u001b[0m   to tell CMake that the project requires at least <min> but has been updated\n",
      "\u001b[95mcmd1:\u001b[0m   to work with policies introduced by <max> or earlier.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[95mcmd1:\u001b[0m -- Found ZLIB: /usr/lib/x86_64-linux-gnu/libz.so (found version \"1.2.11\")\n",
      "\u001b[95mcmd1:\u001b[0m CMake Deprecation Warning at third_party/hiredis/CMakeLists.txt:1 (CMAKE_MINIMUM_REQUIRED):\n",
      "\u001b[95mcmd1:\u001b[0m   Compatibility with CMake < 3.10 will be removed from a future version of\n",
      "\u001b[95mcmd1:\u001b[0m   CMake.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[95mcmd1:\u001b[0m   Update the VERSION argument <min> value.  Or, use the <min>...<max> syntax\n",
      "\u001b[95mcmd1:\u001b[0m   to tell CMake that the project requires at least <min> but has been updated\n",
      "\u001b[95mcmd1:\u001b[0m   to work with policies introduced by <max> or earlier.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[95mcmd1:\u001b[0m Detected version: 1.0.1\n",
      "\u001b[95mcmd1:\u001b[0m CMake Deprecation Warning at third_party/redis-plus-plus/CMakeLists.txt:1 (cmake_minimum_required):\n",
      "\u001b[95mcmd1:\u001b[0m   Compatibility with CMake < 3.10 will be removed from a future version of\n",
      "\u001b[95mcmd1:\u001b[0m   CMake.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[95mcmd1:\u001b[0m   Update the VERSION argument <min> value.  Or, use the <min>...<max> syntax\n",
      "\u001b[95mcmd1:\u001b[0m   to tell CMake that the project requires at least <min> but has been updated\n",
      "\u001b[95mcmd1:\u001b[0m   to work with policies introduced by <max> or earlier.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[95mcmd1:\u001b[0m -- redis-plus-plus version: 1.3.1\n",
      "\u001b[95mcmd1:\u001b[0m -- redis-plus-plus build type: Release\n",
      "\u001b[95mcmd1:\u001b[0m -- redis-plus-plus build with CXX standard: c++14\n",
      "\u001b[95mcmd1:\u001b[0m -- redis-plus-plus TLS support: OFF\n",
      "\u001b[95mcmd1:\u001b[0m -- redis-plus-plus build static library: ON\n",
      "\u001b[95mcmd1:\u001b[0m -- redis-plus-plus build static library with position independent code: ON\n",
      "\u001b[95mcmd1:\u001b[0m -- redis-plus-plus build shared library: ON\n",
      "\u001b[95mcmd1:\u001b[0m -- redis-plus-plus build test: ON\n",
      "\u001b[95mcmd1:\u001b[0m CMake Deprecation Warning at third_party/redis-plus-plus/test/CMakeLists.txt:3 (cmake_minimum_required):\n",
      "\u001b[95mcmd1:\u001b[0m   Compatibility with CMake < 3.10 will be removed from a future version of\n",
      "\u001b[95mcmd1:\u001b[0m   CMake.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[95mcmd1:\u001b[0m   Update the VERSION argument <min> value.  Or, use the <min>...<max> syntax\n",
      "\u001b[95mcmd1:\u001b[0m   to tell CMake that the project requires at least <min> but has been updated\n",
      "\u001b[95mcmd1:\u001b[0m   to work with policies introduced by <max> or earlier.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[95mcmd1:\u001b[0m -- Debian package name: .deb\n",
      "\u001b[95mcmd1:\u001b[0m CMake Warning (dev) at /usr/local/lib/python3.11/dist-packages/cmake/data/share/cmake-3.31/Modules/FetchContent.cmake:1373 (message):\n",
      "\u001b[95mcmd1:\u001b[0m   The DOWNLOAD_EXTRACT_TIMESTAMP option was not given and policy CMP0135 is\n",
      "\u001b[95mcmd1:\u001b[0m   not set.  The policy's OLD behavior will be used.  When using a URL\n",
      "\u001b[95mcmd1:\u001b[0m   download, the timestamps of extracted files should preferably be that of\n",
      "\u001b[95mcmd1:\u001b[0m   the time of extraction, otherwise code that depends on the extracted\n",
      "\u001b[95mcmd1:\u001b[0m   contents might not be rebuilt if the URL changes.  The OLD behavior\n",
      "\u001b[95mcmd1:\u001b[0m   preserves the timestamps from the archive instead, but this is usually not\n",
      "\u001b[95mcmd1:\u001b[0m   what you want.  Update your project to the NEW behavior or specify the\n",
      "\u001b[95mcmd1:\u001b[0m   DOWNLOAD_EXTRACT_TIMESTAMP option with a value of true to avoid this\n",
      "\u001b[95mcmd1:\u001b[0m   robustness issue.\n",
      "\u001b[95mcmd1:\u001b[0m Call Stack (most recent call first):\n",
      "\u001b[95mcmd1:\u001b[0m   CMakeLists.txt:88 (FetchContent_Declare)\n",
      "\u001b[95mcmd1:\u001b[0m This warning is for project developers.  Use -Wno-dev to suppress it.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[95mcmd1:\u001b[0m -- Populating libtorch\n",
      "\u001b[95mcmd1:\u001b[0m -- Configuring done (0.0s)\n",
      "\u001b[95mcmd1:\u001b[0m -- Generating done (0.0s)\n",
      "\u001b[95mcmd1:\u001b[0m -- Build files have been written to: /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/libtorch-subbuild\n",
      "\u001b[95mcmd1:\u001b[0m [ 11%] Creating directories for 'libtorch-populate'\n",
      "\u001b[95mcmd1:\u001b[0m [ 22%] Performing download step (download, verify and extract) for 'libtorch-populate'\n",
      "\u001b[95mcmd1:\u001b[0m -- Downloading...\n",
      "\u001b[95mcmd1:\u001b[0m    dst='/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/libtorch-subbuild/libtorch-populate-prefix/src/libtorch-shared-with-deps-1.13.1%2Bcpu.zip'\n",
      "\u001b[95mcmd1:\u001b[0m    timeout='none'\n",
      "\u001b[95mcmd1:\u001b[0m    inactivity timeout='none'\n",
      "\u001b[95mcmd1:\u001b[0m -- Using src='https://download.pytorch.org/libtorch/cpu/libtorch-shared-with-deps-1.13.1%2Bcpu.zip'\n",
      "\u001b[95mcmd1:\u001b[0m -- [download 0% complete]\n",
      "\u001b[95mcmd1:\u001b[0m -- [download 1% complete]\n",
      "\u001b[95mcmd1:\u001b[0m -- [download 2% complete]\n",
      "\u001b[95mcmd1:\u001b[0m -- [download 3% complete]\n",
      "\u001b[95mcmd1:\u001b[0m -- [download 4% complete]\n",
      "\u001b[95mcmd1:\u001b[0m -- [download 5% complete]\n",
      "\u001b[95mcmd1:\u001b[0m -- [download 6% complete]\n",
      "\u001b[95mcmd1:\u001b[0m -- [download 7% complete]\n",
      "\u001b[95mcmd1:\u001b[0m -- [download 8% complete]\n",
      "\u001b[95mcmd1:\u001b[0m -- [download 9% complete]\n",
      "\u001b[95mcmd1:\u001b[0m -- [download 10% complete]\n",
      "\u001b[95mcmd1:\u001b[0m -- [download 11% complete]\n",
      "\u001b[95mcmd1:\u001b[0m -- [download 12% complete]\n",
      "\u001b[95mcmd1:\u001b[0m -- [download 13% complete]\n",
      "\u001b[95mcmd1:\u001b[0m -- [download 14% complete]\n",
      "\u001b[95mcmd1:\u001b[0m -- [download 15% complete]\n",
      "\u001b[95mcmd1:\u001b[0m -- [download 16% complete]\n",
      "\u001b[95mcmd1:\u001b[0m -- [download 17% complete]\n",
      "\u001b[95mcmd1:\u001b[0m -- [download 18% complete]\n",
      "\u001b[95mcmd1:\u001b[0m -- [download 19% complete]\n",
      "\u001b[95mcmd1:\u001b[0m -- [download 20% complete]\n",
      "\u001b[95mcmd1:\u001b[0m -- [download 21% complete]\n",
      "\u001b[95mcmd1:\u001b[0m -- [download 22% complete]\n",
      "\u001b[95mcmd1:\u001b[0m -- [download 23% complete]\n",
      "\u001b[95mcmd1:\u001b[0m -- [download 24% complete]\n",
      "\u001b[95mcmd1:\u001b[0m -- [download 25% complete]\n",
      "\u001b[95mcmd1:\u001b[0m -- [download 26% complete]\n",
      "\u001b[95mcmd1:\u001b[0m -- [download 27% complete]\n",
      "\u001b[95mcmd1:\u001b[0m -- [download 28% complete]\n",
      "\u001b[95mcmd1:\u001b[0m -- [download 29% complete]\n",
      "\u001b[95mcmd1:\u001b[0m -- [download 30% complete]\n",
      "\u001b[95mcmd1:\u001b[0m -- [download 31% complete]\n",
      "\u001b[95mcmd1:\u001b[0m -- [download 32% complete]\n",
      "\u001b[95mcmd1:\u001b[0m -- [download 33% complete]\n",
      "\u001b[95mcmd1:\u001b[0m -- [download 34% complete]\n",
      "\u001b[95mcmd1:\u001b[0m -- [download 35% complete]\n",
      "\u001b[95mcmd1:\u001b[0m -- [download 36% complete]\n",
      "\u001b[95mcmd1:\u001b[0m -- [download 37% complete]\n",
      "\u001b[95mcmd1:\u001b[0m -- [download 38% complete]\n",
      "\u001b[95mcmd1:\u001b[0m -- [download 39% complete]\n",
      "\u001b[95mcmd1:\u001b[0m -- [download 40% complete]\n",
      "\u001b[95mcmd1:\u001b[0m -- [download 41% complete]\n",
      "\u001b[95mcmd1:\u001b[0m -- [download 42% complete]\n",
      "\u001b[95mcmd1:\u001b[0m -- [download 43% complete]\n",
      "\u001b[95mcmd1:\u001b[0m -- [download 44% complete]\n",
      "\u001b[95mcmd1:\u001b[0m -- [download 45% complete]\n",
      "\u001b[95mcmd1:\u001b[0m -- [download 46% complete]\n",
      "\u001b[95mcmd1:\u001b[0m -- [download 47% complete]\n",
      "\u001b[95mcmd1:\u001b[0m -- [download 48% complete]\n",
      "\u001b[95mcmd1:\u001b[0m -- [download 49% complete]\n",
      "\u001b[95mcmd1:\u001b[0m -- [download 50% complete]\n",
      "\u001b[95mcmd1:\u001b[0m -- [download 51% complete]\n",
      "\u001b[95mcmd1:\u001b[0m -- [download 52% complete]\n",
      "\u001b[95mcmd1:\u001b[0m -- [download 53% complete]\n",
      "\u001b[95mcmd1:\u001b[0m -- [download 54% complete]\n",
      "\u001b[95mcmd1:\u001b[0m -- [download 55% complete]\n",
      "\u001b[95mcmd1:\u001b[0m -- [download 56% complete]\n",
      "\u001b[95mcmd1:\u001b[0m -- [download 57% complete]\n",
      "\u001b[95mcmd1:\u001b[0m -- [download 58% complete]\n",
      "\u001b[95mcmd1:\u001b[0m -- [download 59% complete]\n",
      "\u001b[95mcmd1:\u001b[0m -- [download 60% complete]\n",
      "\u001b[95mcmd1:\u001b[0m -- [download 61% complete]\n",
      "\u001b[95mcmd1:\u001b[0m -- [download 62% complete]\n",
      "\u001b[95mcmd1:\u001b[0m -- [download 63% complete]\n",
      "\u001b[95mcmd1:\u001b[0m -- [download 64% complete]\n",
      "\u001b[95mcmd1:\u001b[0m -- [download 65% complete]\n",
      "\u001b[95mcmd1:\u001b[0m -- [download 66% complete]\n",
      "\u001b[95mcmd1:\u001b[0m -- [download 67% complete]\n",
      "\u001b[95mcmd1:\u001b[0m -- [download 68% complete]\n",
      "\u001b[95mcmd1:\u001b[0m -- [download 69% complete]\n",
      "\u001b[95mcmd1:\u001b[0m -- [download 70% complete]\n",
      "\u001b[95mcmd1:\u001b[0m -- [download 71% complete]\n",
      "\u001b[95mcmd1:\u001b[0m -- [download 72% complete]\n",
      "\u001b[95mcmd1:\u001b[0m -- [download 73% complete]\n",
      "\u001b[95mcmd1:\u001b[0m -- [download 74% complete]\n",
      "\u001b[95mcmd1:\u001b[0m -- [download 75% complete]\n",
      "\u001b[95mcmd1:\u001b[0m -- [download 76% complete]\n",
      "\u001b[95mcmd1:\u001b[0m -- [download 77% complete]\n",
      "\u001b[95mcmd1:\u001b[0m -- [download 78% complete]\n",
      "\u001b[95mcmd1:\u001b[0m -- [download 79% complete]\n",
      "\u001b[95mcmd1:\u001b[0m -- [download 80% complete]\n",
      "\u001b[95mcmd1:\u001b[0m -- [download 81% complete]\n",
      "\u001b[95mcmd1:\u001b[0m -- [download 82% complete]\n",
      "\u001b[95mcmd1:\u001b[0m -- [download 83% complete]\n",
      "\u001b[95mcmd1:\u001b[0m -- [download 84% complete]\n",
      "\u001b[95mcmd1:\u001b[0m -- [download 85% complete]\n",
      "\u001b[95mcmd1:\u001b[0m -- [download 86% complete]\n",
      "\u001b[95mcmd1:\u001b[0m -- [download 87% complete]\n",
      "\u001b[95mcmd1:\u001b[0m -- [download 88% complete]\n",
      "\u001b[95mcmd1:\u001b[0m -- [download 89% complete]\n",
      "\u001b[95mcmd1:\u001b[0m -- [download 90% complete]\n",
      "\u001b[95mcmd1:\u001b[0m -- [download 91% complete]\n",
      "\u001b[95mcmd1:\u001b[0m -- [download 92% complete]\n",
      "\u001b[95mcmd1:\u001b[0m -- [download 93% complete]\n",
      "\u001b[95mcmd1:\u001b[0m -- [download 94% complete]\n",
      "\u001b[95mcmd1:\u001b[0m -- [download 95% complete]\n",
      "\u001b[95mcmd1:\u001b[0m -- [download 96% complete]\n",
      "\u001b[95mcmd1:\u001b[0m -- [download 97% complete]\n",
      "\u001b[95mcmd1:\u001b[0m -- [download 98% complete]\n",
      "\u001b[95mcmd1:\u001b[0m -- [download 99% complete]\n",
      "\u001b[95mcmd1:\u001b[0m -- [download 100% complete]\n",
      "\u001b[95mcmd1:\u001b[0m -- verifying file...\n",
      "\u001b[95mcmd1:\u001b[0m        file='/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/libtorch-subbuild/libtorch-populate-prefix/src/libtorch-shared-with-deps-1.13.1%2Bcpu.zip'\n",
      "\u001b[95mcmd1:\u001b[0m -- Downloading... done\n",
      "\u001b[95mcmd1:\u001b[0m -- extracting...\n",
      "\u001b[95mcmd1:\u001b[0m      src='/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/libtorch-subbuild/libtorch-populate-prefix/src/libtorch-shared-with-deps-1.13.1%2Bcpu.zip'\n",
      "\u001b[95mcmd1:\u001b[0m      dst='/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/libtorch-src'\n",
      "\u001b[95mcmd1:\u001b[0m -- extracting... [tar xfz]\n",
      "\u001b[95mcmd1:\u001b[0m -- extracting... [analysis]\n",
      "\u001b[95mcmd1:\u001b[0m -- extracting... [rename]\n",
      "\u001b[95mcmd1:\u001b[0m -- extracting... [clean up]\n",
      "\u001b[95mcmd1:\u001b[0m -- extracting... done\n",
      "\u001b[95mcmd1:\u001b[0m [ 33%] No update step for 'libtorch-populate'\n",
      "\u001b[95mcmd1:\u001b[0m [ 44%] No patch step for 'libtorch-populate'\n",
      "\u001b[95mcmd1:\u001b[0m [ 55%] No configure step for 'libtorch-populate'\n",
      "\u001b[95mcmd1:\u001b[0m [ 66%] No build step for 'libtorch-populate'\n",
      "\u001b[95mcmd1:\u001b[0m [ 77%] No install step for 'libtorch-populate'\n",
      "\u001b[95mcmd1:\u001b[0m [ 88%] No test step for 'libtorch-populate'\n",
      "\u001b[95mcmd1:\u001b[0m [100%] Completed 'libtorch-populate'\n",
      "\u001b[95mcmd1:\u001b[0m [100%] Built target libtorch-populate\n",
      "\u001b[95mcmd1:\u001b[0m -- Found Torch: /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/libtorch-src/lib/libtorch.so\n",
      "\u001b[95mcmd1:\u001b[0m CMake Warning (dev) at /usr/local/lib/python3.11/dist-packages/cmake/data/share/cmake-3.31/Modules/ExternalProject/shared_internal_commands.cmake:1276 (message):\n",
      "\u001b[95mcmd1:\u001b[0m   The DOWNLOAD_EXTRACT_TIMESTAMP option was not given and policy CMP0135 is\n",
      "\u001b[95mcmd1:\u001b[0m   not set.  The policy's OLD behavior will be used.  When using a URL\n",
      "\u001b[95mcmd1:\u001b[0m   download, the timestamps of extracted files should preferably be that of\n",
      "\u001b[95mcmd1:\u001b[0m   the time of extraction, otherwise code that depends on the extracted\n",
      "\u001b[95mcmd1:\u001b[0m   contents might not be rebuilt if the URL changes.  The OLD behavior\n",
      "\u001b[95mcmd1:\u001b[0m   preserves the timestamps from the archive instead, but this is usually not\n",
      "\u001b[95mcmd1:\u001b[0m   what you want.  Update your project to the NEW behavior or specify the\n",
      "\u001b[95mcmd1:\u001b[0m   DOWNLOAD_EXTRACT_TIMESTAMP option with a value of true to avoid this\n",
      "\u001b[95mcmd1:\u001b[0m   robustness issue.\n",
      "\u001b[95mcmd1:\u001b[0m Call Stack (most recent call first):\n",
      "\u001b[95mcmd1:\u001b[0m   /usr/local/lib/python3.11/dist-packages/cmake/data/share/cmake-3.31/Modules/ExternalProject.cmake:3041 (_ep_add_download_command)\n",
      "\u001b[95mcmd1:\u001b[0m   CMakeLists.txt:111 (ExternalProject_Add)\n",
      "\u001b[95mcmd1:\u001b[0m This warning is for project developers.  Use -Wno-dev to suppress it.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[95mcmd1:\u001b[0m CMake Deprecation Warning at pybind11/CMakeLists.txt:8 (cmake_minimum_required):\n",
      "\u001b[95mcmd1:\u001b[0m   Compatibility with CMake < 3.10 will be removed from a future version of\n",
      "\u001b[95mcmd1:\u001b[0m   CMake.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[95mcmd1:\u001b[0m   Update the VERSION argument <min> value.  Or, use the <min>...<max> syntax\n",
      "\u001b[95mcmd1:\u001b[0m   to tell CMake that the project requires at least <min> but has been updated\n",
      "\u001b[95mcmd1:\u001b[0m   to work with policies introduced by <max> or earlier.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[95mcmd1:\u001b[0m -- pybind11 v2.9.0 dev1\n",
      "\u001b[95mcmd1:\u001b[0m CMake Warning (dev) at pybind11/tools/FindPythonLibsNew.cmake:98 (find_package):\n",
      "\u001b[95mcmd1:\u001b[0m   Policy CMP0148 is not set: The FindPythonInterp and FindPythonLibs modules\n",
      "\u001b[95mcmd1:\u001b[0m   are removed.  Run \"cmake --help-policy CMP0148\" for policy details.  Use\n",
      "\u001b[95mcmd1:\u001b[0m   the cmake_policy command to set the policy and suppress this warning.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[95mcmd1:\u001b[0m Call Stack (most recent call first):\n",
      "\u001b[95mcmd1:\u001b[0m   pybind11/tools/pybind11Tools.cmake:50 (find_package)\n",
      "\u001b[95mcmd1:\u001b[0m   pybind11/tools/pybind11Common.cmake:206 (include)\n",
      "\u001b[95mcmd1:\u001b[0m   pybind11/CMakeLists.txt:198 (include)\n",
      "\u001b[95mcmd1:\u001b[0m This warning is for project developers.  Use -Wno-dev to suppress it.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[95mcmd1:\u001b[0m -- Found PythonLibs: /root/miniconda3/envs/b2txt25_lm/lib/libpython3.9.so\n",
      "\u001b[95mcmd1:\u001b[0m -- Performing Test HAS_FLTO\n",
      "\u001b[95mcmd1:\u001b[0m -- Performing Test HAS_FLTO - Success\n",
      "\u001b[95mcmd1:\u001b[0m -- Configuring done (26.8s)\n",
      "\u001b[95mcmd1:\u001b[0m -- Generating done (0.1s)\n",
      "\u001b[95mcmd1:\u001b[0m CMake Warning:\n",
      "\u001b[95mcmd1:\u001b[0m   Manually-specified variables were not used by the project:\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[95mcmd1:\u001b[0m     EXAMPLE_VERSION_INFO\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[95mcmd1:\u001b[0m -- Build files have been written to: /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/build/temp.linux-x86_64-cpython-39\n",
      "\u001b[95mcmd1:\u001b[0m /usr/local/lib/python3.11/dist-packages/cmake/data/bin/cmake -S/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86 -B/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/build/temp.linux-x86_64-cpython-39 --check-build-system CMakeFiles/Makefile.cmake 0\n",
      "\u001b[95mcmd1:\u001b[0m /usr/bin/gmake  -f CMakeFiles/Makefile2 lm_decoder\n",
      "\u001b[95mcmd1:\u001b[0m gmake[1]: Entering directory '/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/build/temp.linux-x86_64-cpython-39'\n",
      "\u001b[95mcmd1:\u001b[0m /usr/local/lib/python3.11/dist-packages/cmake/data/bin/cmake -S/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86 -B/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/build/temp.linux-x86_64-cpython-39 --check-build-system CMakeFiles/Makefile.cmake 0\n",
      "\u001b[95mcmd1:\u001b[0m /usr/local/lib/python3.11/dist-packages/cmake/data/bin/cmake -E cmake_progress_start /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/build/temp.linux-x86_64-cpython-39/CMakeFiles 33\n",
      "\u001b[95mcmd1:\u001b[0m /usr/bin/gmake  -f CMakeFiles/Makefile2 CMakeFiles/lm_decoder.dir/all\n",
      "\u001b[95mcmd1:\u001b[0m gmake[2]: Entering directory '/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/build/temp.linux-x86_64-cpython-39'\n",
      "\u001b[95mcmd1:\u001b[0m /usr/bin/gmake  -f /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/CMakeFiles/gflags_nothreads_static.dir/build.make /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/CMakeFiles/gflags_nothreads_static.dir/depend\n",
      "\u001b[95mcmd1:\u001b[0m gmake[3]: Entering directory '/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/build/temp.linux-x86_64-cpython-39'\n",
      "\u001b[95mcmd1:\u001b[0m cd /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/build/temp.linux-x86_64-cpython-39 && /usr/local/lib/python3.11/dist-packages/cmake/data/bin/cmake -E cmake_depends \"Unix Makefiles\" /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86 /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-src /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/build/temp.linux-x86_64-cpython-39 /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/CMakeFiles/gflags_nothreads_static.dir/DependInfo.cmake \"--color=\"\n",
      "\u001b[95mcmd1:\u001b[0m gmake[3]: Leaving directory '/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/build/temp.linux-x86_64-cpython-39'\n",
      "\u001b[95mcmd1:\u001b[0m /usr/bin/gmake  -f /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/CMakeFiles/gflags_nothreads_static.dir/build.make /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/CMakeFiles/gflags_nothreads_static.dir/build\n",
      "\u001b[95mcmd1:\u001b[0m gmake[3]: Entering directory '/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/build/temp.linux-x86_64-cpython-39'\n",
      "\u001b[95mcmd1:\u001b[0m [  0%] Building CXX object /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/CMakeFiles/gflags_nothreads_static.dir/src/gflags.cc.o\n",
      "\u001b[95mcmd1:\u001b[0m cd /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build && /usr/bin/c++ -DGFLAGS_IS_A_DLL=0 -DNO_THREADS -D_GLIBCXX_USE_CXX11_ABI=0 -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86 -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/kaldi -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include/gflags -std=c++14 -pthread -fPIC -O3 -DNDEBUG -MD -MT /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/CMakeFiles/gflags_nothreads_static.dir/src/gflags.cc.o -MF CMakeFiles/gflags_nothreads_static.dir/src/gflags.cc.o.d -o CMakeFiles/gflags_nothreads_static.dir/src/gflags.cc.o -c /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-src/src/gflags.cc\n",
      "\u001b[95mcmd1:\u001b[0m [  3%] Building CXX object /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/CMakeFiles/gflags_nothreads_static.dir/src/gflags_reporting.cc.o\n",
      "\u001b[95mcmd1:\u001b[0m cd /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build && /usr/bin/c++ -DGFLAGS_IS_A_DLL=0 -DNO_THREADS -D_GLIBCXX_USE_CXX11_ABI=0 -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86 -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/kaldi -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include/gflags -std=c++14 -pthread -fPIC -O3 -DNDEBUG -MD -MT /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/CMakeFiles/gflags_nothreads_static.dir/src/gflags_reporting.cc.o -MF CMakeFiles/gflags_nothreads_static.dir/src/gflags_reporting.cc.o.d -o CMakeFiles/gflags_nothreads_static.dir/src/gflags_reporting.cc.o -c /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-src/src/gflags_reporting.cc\n",
      "\u001b[95mcmd1:\u001b[0m [  6%] Building CXX object /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/CMakeFiles/gflags_nothreads_static.dir/src/gflags_completions.cc.o\n",
      "\u001b[95mcmd1:\u001b[0m cd /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build && /usr/bin/c++ -DGFLAGS_IS_A_DLL=0 -DNO_THREADS -D_GLIBCXX_USE_CXX11_ABI=0 -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86 -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/kaldi -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include/gflags -std=c++14 -pthread -fPIC -O3 -DNDEBUG -MD -MT /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/CMakeFiles/gflags_nothreads_static.dir/src/gflags_completions.cc.o -MF CMakeFiles/gflags_nothreads_static.dir/src/gflags_completions.cc.o.d -o CMakeFiles/gflags_nothreads_static.dir/src/gflags_completions.cc.o -c /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-src/src/gflags_completions.cc\n",
      "\u001b[95mcmd1:\u001b[0m [  6%] Linking CXX static library libgflags_nothreads.a\n",
      "\u001b[95mcmd1:\u001b[0m cd /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build && /usr/local/lib/python3.11/dist-packages/cmake/data/bin/cmake -P CMakeFiles/gflags_nothreads_static.dir/cmake_clean_target.cmake\n",
      "\u001b[95mcmd1:\u001b[0m cd /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build && /usr/local/lib/python3.11/dist-packages/cmake/data/bin/cmake -E cmake_link_script CMakeFiles/gflags_nothreads_static.dir/link.txt --verbose=1\n",
      "\u001b[95mcmd1:\u001b[0m /usr/bin/ar qc libgflags_nothreads.a CMakeFiles/gflags_nothreads_static.dir/src/gflags.cc.o CMakeFiles/gflags_nothreads_static.dir/src/gflags_reporting.cc.o CMakeFiles/gflags_nothreads_static.dir/src/gflags_completions.cc.o\n",
      "\u001b[95mcmd1:\u001b[0m /usr/bin/ranlib libgflags_nothreads.a\n",
      "\u001b[95mcmd1:\u001b[0m gmake[3]: Leaving directory '/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/build/temp.linux-x86_64-cpython-39'\n",
      "\u001b[95mcmd1:\u001b[0m [  6%] Built target gflags_nothreads_static\n",
      "\u001b[95mcmd1:\u001b[0m /usr/bin/gmake  -f /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build/CMakeFiles/glog.dir/build.make /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build/CMakeFiles/glog.dir/depend\n",
      "\u001b[95mcmd1:\u001b[0m gmake[3]: Entering directory '/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/build/temp.linux-x86_64-cpython-39'\n",
      "\u001b[95mcmd1:\u001b[0m cd /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/build/temp.linux-x86_64-cpython-39 && /usr/local/lib/python3.11/dist-packages/cmake/data/bin/cmake -E cmake_depends \"Unix Makefiles\" /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86 /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/build/temp.linux-x86_64-cpython-39 /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build/CMakeFiles/glog.dir/DependInfo.cmake \"--color=\"\n",
      "\u001b[95mcmd1:\u001b[0m gmake[3]: Leaving directory '/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/build/temp.linux-x86_64-cpython-39'\n",
      "\u001b[95mcmd1:\u001b[0m /usr/bin/gmake  -f /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build/CMakeFiles/glog.dir/build.make /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build/CMakeFiles/glog.dir/build\n",
      "\u001b[95mcmd1:\u001b[0m gmake[3]: Entering directory '/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/build/temp.linux-x86_64-cpython-39'\n",
      "\u001b[95mcmd1:\u001b[0m [  9%] Building CXX object /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build/CMakeFiles/glog.dir/src/demangle.cc.o\n",
      "\u001b[95mcmd1:\u001b[0m cd /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build && /usr/bin/c++ -DGOOGLE_GLOG_DLL_DECL=\"\" -D_GLIBCXX_USE_CXX11_ABI=0 -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86 -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/kaldi -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -std=c++14 -pthread -fPIC -O3 -DNDEBUG -fPIC -fvisibility=default -fvisibility-inlines-hidden -MD -MT /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build/CMakeFiles/glog.dir/src/demangle.cc.o -MF CMakeFiles/glog.dir/src/demangle.cc.o.d -o CMakeFiles/glog.dir/src/demangle.cc.o -c /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src/demangle.cc\n",
      "\u001b[95mcmd1:\u001b[0m [ 12%] Building CXX object /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build/CMakeFiles/glog.dir/src/logging.cc.o\n",
      "\u001b[95mcmd1:\u001b[0m cd /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build && /usr/bin/c++ -DGOOGLE_GLOG_DLL_DECL=\"\" -D_GLIBCXX_USE_CXX11_ABI=0 -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86 -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/kaldi -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -std=c++14 -pthread -fPIC -O3 -DNDEBUG -fPIC -fvisibility=default -fvisibility-inlines-hidden -MD -MT /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build/CMakeFiles/glog.dir/src/logging.cc.o -MF CMakeFiles/glog.dir/src/logging.cc.o.d -o CMakeFiles/glog.dir/src/logging.cc.o -c /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src/logging.cc\n",
      "\u001b[95mcmd1:\u001b[0m [ 12%] Building CXX object /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build/CMakeFiles/glog.dir/src/raw_logging.cc.o\n",
      "\u001b[95mcmd1:\u001b[0m cd /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build && /usr/bin/c++ -DGOOGLE_GLOG_DLL_DECL=\"\" -D_GLIBCXX_USE_CXX11_ABI=0 -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86 -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/kaldi -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -std=c++14 -pthread -fPIC -O3 -DNDEBUG -fPIC -fvisibility=default -fvisibility-inlines-hidden -MD -MT /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build/CMakeFiles/glog.dir/src/raw_logging.cc.o -MF CMakeFiles/glog.dir/src/raw_logging.cc.o.d -o CMakeFiles/glog.dir/src/raw_logging.cc.o -c /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src/raw_logging.cc\n",
      "\u001b[95mcmd1:\u001b[0m [ 15%] Building CXX object /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build/CMakeFiles/glog.dir/src/symbolize.cc.o\n",
      "\u001b[95mcmd1:\u001b[0m cd /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build && /usr/bin/c++ -DGOOGLE_GLOG_DLL_DECL=\"\" -D_GLIBCXX_USE_CXX11_ABI=0 -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86 -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/kaldi -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -std=c++14 -pthread -fPIC -O3 -DNDEBUG -fPIC -fvisibility=default -fvisibility-inlines-hidden -MD -MT /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build/CMakeFiles/glog.dir/src/symbolize.cc.o -MF CMakeFiles/glog.dir/src/symbolize.cc.o.d -o CMakeFiles/glog.dir/src/symbolize.cc.o -c /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src/symbolize.cc\n",
      "\u001b[95mcmd1:\u001b[0m [ 18%] Building CXX object /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build/CMakeFiles/glog.dir/src/utilities.cc.o\n",
      "\u001b[95mcmd1:\u001b[0m cd /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build && /usr/bin/c++ -DGOOGLE_GLOG_DLL_DECL=\"\" -D_GLIBCXX_USE_CXX11_ABI=0 -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86 -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/kaldi -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -std=c++14 -pthread -fPIC -O3 -DNDEBUG -fPIC -fvisibility=default -fvisibility-inlines-hidden -MD -MT /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build/CMakeFiles/glog.dir/src/utilities.cc.o -MF CMakeFiles/glog.dir/src/utilities.cc.o.d -o CMakeFiles/glog.dir/src/utilities.cc.o -c /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src/utilities.cc\n",
      "\u001b[95mcmd1:\u001b[0m [ 21%] Building CXX object /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build/CMakeFiles/glog.dir/src/vlog_is_on.cc.o\n",
      "\u001b[95mcmd1:\u001b[0m cd /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build && /usr/bin/c++ -DGOOGLE_GLOG_DLL_DECL=\"\" -D_GLIBCXX_USE_CXX11_ABI=0 -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86 -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/kaldi -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -std=c++14 -pthread -fPIC -O3 -DNDEBUG -fPIC -fvisibility=default -fvisibility-inlines-hidden -MD -MT /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build/CMakeFiles/glog.dir/src/vlog_is_on.cc.o -MF CMakeFiles/glog.dir/src/vlog_is_on.cc.o.d -o CMakeFiles/glog.dir/src/vlog_is_on.cc.o -c /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src/vlog_is_on.cc\n",
      "\u001b[95mcmd1:\u001b[0m [ 21%] Building CXX object /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build/CMakeFiles/glog.dir/src/signalhandler.cc.o\n",
      "\u001b[95mcmd1:\u001b[0m cd /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build && /usr/bin/c++ -DGOOGLE_GLOG_DLL_DECL=\"\" -D_GLIBCXX_USE_CXX11_ABI=0 -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86 -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/kaldi -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -std=c++14 -pthread -fPIC -O3 -DNDEBUG -fPIC -fvisibility=default -fvisibility-inlines-hidden -MD -MT /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build/CMakeFiles/glog.dir/src/signalhandler.cc.o -MF CMakeFiles/glog.dir/src/signalhandler.cc.o.d -o CMakeFiles/glog.dir/src/signalhandler.cc.o -c /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src/signalhandler.cc\n",
      "\u001b[95mcmd1:\u001b[0m [ 24%] Linking CXX static library libglog.a\n",
      "\u001b[95mcmd1:\u001b[0m cd /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build && /usr/local/lib/python3.11/dist-packages/cmake/data/bin/cmake -P CMakeFiles/glog.dir/cmake_clean_target.cmake\n",
      "\u001b[95mcmd1:\u001b[0m cd /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build && /usr/local/lib/python3.11/dist-packages/cmake/data/bin/cmake -E cmake_link_script CMakeFiles/glog.dir/link.txt --verbose=1\n",
      "\u001b[95mcmd1:\u001b[0m /usr/bin/ar qc libglog.a CMakeFiles/glog.dir/src/demangle.cc.o CMakeFiles/glog.dir/src/logging.cc.o CMakeFiles/glog.dir/src/raw_logging.cc.o CMakeFiles/glog.dir/src/symbolize.cc.o CMakeFiles/glog.dir/src/utilities.cc.o CMakeFiles/glog.dir/src/vlog_is_on.cc.o CMakeFiles/glog.dir/src/signalhandler.cc.o\n",
      "\u001b[95mcmd1:\u001b[0m /usr/bin/ranlib libglog.a\n",
      "\u001b[95mcmd1:\u001b[0m gmake[3]: Leaving directory '/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/build/temp.linux-x86_64-cpython-39'\n",
      "\u001b[95mcmd1:\u001b[0m [ 24%] Built target glog\n",
      "\u001b[95mcmd1:\u001b[0m /usr/bin/gmake  -f CMakeFiles/openfst.dir/build.make CMakeFiles/openfst.dir/depend\n",
      "\u001b[95mcmd1:\u001b[0m gmake[3]: Entering directory '/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/build/temp.linux-x86_64-cpython-39'\n",
      "\u001b[95mcmd1:\u001b[0m cd /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/build/temp.linux-x86_64-cpython-39 && /usr/local/lib/python3.11/dist-packages/cmake/data/bin/cmake -E cmake_depends \"Unix Makefiles\" /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86 /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86 /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/build/temp.linux-x86_64-cpython-39 /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/build/temp.linux-x86_64-cpython-39 /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/build/temp.linux-x86_64-cpython-39/CMakeFiles/openfst.dir/DependInfo.cmake \"--color=\"\n",
      "\u001b[95mcmd1:\u001b[0m gmake[3]: Leaving directory '/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/build/temp.linux-x86_64-cpython-39'\n",
      "\u001b[95mcmd1:\u001b[0m /usr/bin/gmake  -f CMakeFiles/openfst.dir/build.make CMakeFiles/openfst.dir/build\n",
      "\u001b[95mcmd1:\u001b[0m gmake[3]: Entering directory '/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/build/temp.linux-x86_64-cpython-39'\n",
      "\u001b[95mcmd1:\u001b[0m [ 24%] Creating directories for 'openfst'\n",
      "\u001b[95mcmd1:\u001b[0m /usr/local/lib/python3.11/dist-packages/cmake/data/bin/cmake -Dcfgdir= -P /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/build/temp.linux-x86_64-cpython-39/openfst-prefix/tmp/openfst-mkdirs.cmake\n",
      "\u001b[95mcmd1:\u001b[0m /usr/local/lib/python3.11/dist-packages/cmake/data/bin/cmake -E touch /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/build/temp.linux-x86_64-cpython-39/openfst-prefix/src/openfst-stamp/openfst-mkdir\n",
      "\u001b[95mcmd1:\u001b[0m [ 27%] Performing download step (download, verify and extract) for 'openfst'\n",
      "\u001b[95mcmd1:\u001b[0m cd /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base && /usr/local/lib/python3.11/dist-packages/cmake/data/bin/cmake -DCMAKE_MESSAGE_LOG_LEVEL=VERBOSE -P /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/build/temp.linux-x86_64-cpython-39/openfst-prefix/src/openfst-stamp/download-openfst.cmake\n",
      "\u001b[95mcmd1:\u001b[0m -- Downloading...\n",
      "\u001b[95mcmd1:\u001b[0m    dst='/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/build/temp.linux-x86_64-cpython-39/openfst-prefix/src/1.6.5.zip'\n",
      "\u001b[95mcmd1:\u001b[0m    timeout='none'\n",
      "\u001b[95mcmd1:\u001b[0m    inactivity timeout='none'\n",
      "\u001b[95mcmd1:\u001b[0m -- Using src='https://github.com/mjansche/openfst/archive/1.6.5.zip'\n",
      "\u001b[95mcmd1:\u001b[0m -- verifying file...\n",
      "\u001b[95mcmd1:\u001b[0m        file='/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/build/temp.linux-x86_64-cpython-39/openfst-prefix/src/1.6.5.zip'\n",
      "\u001b[95mcmd1:\u001b[0m -- Downloading... done\n",
      "\u001b[95mcmd1:\u001b[0m cd /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base && /usr/local/lib/python3.11/dist-packages/cmake/data/bin/cmake -DCMAKE_MESSAGE_LOG_LEVEL=VERBOSE -P /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/build/temp.linux-x86_64-cpython-39/openfst-prefix/src/openfst-stamp/verify-openfst.cmake\n",
      "\u001b[95mcmd1:\u001b[0m cd /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base && /usr/local/lib/python3.11/dist-packages/cmake/data/bin/cmake -DCMAKE_MESSAGE_LOG_LEVEL=VERBOSE -P /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/build/temp.linux-x86_64-cpython-39/openfst-prefix/src/openfst-stamp/extract-openfst.cmake\n",
      "\u001b[95mcmd1:\u001b[0m -- extracting...\n",
      "\u001b[95mcmd1:\u001b[0m      src='/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/build/temp.linux-x86_64-cpython-39/openfst-prefix/src/1.6.5.zip'\n",
      "\u001b[95mcmd1:\u001b[0m      dst='/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src'\n",
      "\u001b[95mcmd1:\u001b[0m -- extracting... [tar xfz]\n",
      "\u001b[95mcmd1:\u001b[0m -- extracting... [analysis]\n",
      "\u001b[95mcmd1:\u001b[0m -- extracting... [rename]\n",
      "\u001b[95mcmd1:\u001b[0m -- extracting... [clean up]\n",
      "\u001b[95mcmd1:\u001b[0m -- extracting... done\n",
      "\u001b[95mcmd1:\u001b[0m cd /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base && /usr/local/lib/python3.11/dist-packages/cmake/data/bin/cmake -E touch /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/build/temp.linux-x86_64-cpython-39/openfst-prefix/src/openfst-stamp/openfst-download\n",
      "\u001b[95mcmd1:\u001b[0m [ 30%] No update step for 'openfst'\n",
      "\u001b[95mcmd1:\u001b[0m /usr/local/lib/python3.11/dist-packages/cmake/data/bin/cmake -E echo_append\n",
      "\u001b[95mcmd1:\u001b[0m /usr/local/lib/python3.11/dist-packages/cmake/data/bin/cmake -E touch /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/build/temp.linux-x86_64-cpython-39/openfst-prefix/src/openfst-stamp/openfst-update\n",
      "\u001b[95mcmd1:\u001b[0m [ 33%] No patch step for 'openfst'\n",
      "\u001b[95mcmd1:\u001b[0m /usr/local/lib/python3.11/dist-packages/cmake/data/bin/cmake -E echo_append\n",
      "\u001b[95mcmd1:\u001b[0m /usr/local/lib/python3.11/dist-packages/cmake/data/bin/cmake -E touch /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/build/temp.linux-x86_64-cpython-39/openfst-prefix/src/openfst-stamp/openfst-patch\n",
      "\u001b[95mcmd1:\u001b[0m [ 33%] Performing configure step for 'openfst'\n",
      "\u001b[95mcmd1:\u001b[0m cd /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-build && /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/configure --prefix=/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-subbuild/openfst-populate-prefix \"CPPFLAGS=-I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0\" \"LDFLAGS=-L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build\" \"LIBS=-lgflags_nothreads -lglog -lpthread\"\n",
      "\u001b[95mcmd1:\u001b[0m checking for a BSD-compatible install... /usr/bin/install -c\n",
      "\u001b[95mcmd1:\u001b[0m checking whether build environment is sane... yes\n",
      "\u001b[95mcmd1:\u001b[0m checking for a thread-safe mkdir -p... /usr/bin/mkdir -p\n",
      "\u001b[95mcmd1:\u001b[0m checking for gawk... no\n",
      "\u001b[95mcmd1:\u001b[0m checking for mawk... mawk\n",
      "\u001b[95mcmd1:\u001b[0m checking whether make sets $(MAKE)... yes\n",
      "\u001b[95mcmd1:\u001b[0m checking whether make supports nested variables... yes\n",
      "\u001b[95mcmd1:\u001b[0m checking for style of include used by make... GNU\n",
      "\u001b[95mcmd1:\u001b[0m checking for gcc... gcc\n",
      "\u001b[95mcmd1:\u001b[0m checking whether the C compiler works... yes\n",
      "\u001b[95mcmd1:\u001b[0m checking for C compiler default output file name... a.out\n",
      "\u001b[95mcmd1:\u001b[0m checking for suffix of executables... \n",
      "\u001b[95mcmd1:\u001b[0m checking whether we are cross compiling... no\n",
      "\u001b[95mcmd1:\u001b[0m checking for suffix of object files... o\n",
      "\u001b[95mcmd1:\u001b[0m checking whether we are using the GNU C compiler... yes\n",
      "\u001b[95mcmd1:\u001b[0m checking whether gcc accepts -g... yes\n",
      "\u001b[95mcmd1:\u001b[0m checking for gcc option to accept ISO C89... none needed\n",
      "\u001b[95mcmd1:\u001b[0m checking whether gcc understands -c and -o together... yes\n",
      "\u001b[95mcmd1:\u001b[0m checking dependency style of gcc... gcc3\n",
      "\u001b[95mcmd1:\u001b[0m checking for ar... ar\n",
      "\u001b[95mcmd1:\u001b[0m checking the archiver (ar) interface... ar\n",
      "\u001b[95mcmd1:\u001b[0m checking for g++... g++\n",
      "\u001b[95mcmd1:\u001b[0m checking whether we are using the GNU C++ compiler... yes\n",
      "\u001b[95mcmd1:\u001b[0m checking whether g++ accepts -g... yes\n",
      "\u001b[95mcmd1:\u001b[0m checking dependency style of g++... gcc3\n",
      "\u001b[95mcmd1:\u001b[0m checking build system type... x86_64-unknown-linux-gnu\n",
      "\u001b[95mcmd1:\u001b[0m checking host system type... x86_64-unknown-linux-gnu\n",
      "\u001b[95mcmd1:\u001b[0m checking how to print strings... printf\n",
      "\u001b[95mcmd1:\u001b[0m checking for a sed that does not truncate output... /usr/bin/sed\n",
      "\u001b[95mcmd1:\u001b[0m checking for grep that handles long lines and -e... /usr/bin/grep\n",
      "\u001b[95mcmd1:\u001b[0m checking for egrep... /usr/bin/grep -E\n",
      "\u001b[95mcmd1:\u001b[0m checking for fgrep... /usr/bin/grep -F\n",
      "\u001b[95mcmd1:\u001b[0m checking for ld used by gcc... /usr/bin/ld\n",
      "\u001b[95mcmd1:\u001b[0m checking if the linker (/usr/bin/ld) is GNU ld... yes\n",
      "\u001b[95mcmd1:\u001b[0m checking for BSD- or MS-compatible name lister (nm)... /usr/bin/nm -B\n",
      "\u001b[95mcmd1:\u001b[0m checking the name lister (/usr/bin/nm -B) interface... BSD nm\n",
      "\u001b[95mcmd1:\u001b[0m checking whether ln -s works... yes\n",
      "\u001b[95mcmd1:\u001b[0m checking the maximum length of command line arguments... 1572864\n",
      "\u001b[95mcmd1:\u001b[0m checking whether the shell understands some XSI constructs... yes\n",
      "\u001b[95mcmd1:\u001b[0m checking whether the shell understands \"+=\"... yes\n",
      "\u001b[95mcmd1:\u001b[0m checking how to convert x86_64-unknown-linux-gnu file names to x86_64-unknown-linux-gnu format... func_convert_file_noop\n",
      "\u001b[95mcmd1:\u001b[0m checking how to convert x86_64-unknown-linux-gnu file names to toolchain format... func_convert_file_noop\n",
      "\u001b[95mcmd1:\u001b[0m checking for /usr/bin/ld option to reload object files... -r\n",
      "\u001b[95mcmd1:\u001b[0m checking for objdump... objdump\n",
      "\u001b[95mcmd1:\u001b[0m checking how to recognize dependent libraries... pass_all\n",
      "\u001b[95mcmd1:\u001b[0m checking for dlltool... no\n",
      "\u001b[95mcmd1:\u001b[0m checking how to associate runtime and link libraries... printf %s\\n\n",
      "\u001b[95mcmd1:\u001b[0m checking for archiver @FILE support... @\n",
      "\u001b[95mcmd1:\u001b[0m checking for strip... strip\n",
      "\u001b[95mcmd1:\u001b[0m checking for ranlib... ranlib\n",
      "\u001b[95mcmd1:\u001b[0m checking command to parse /usr/bin/nm -B output from gcc object... ok\n",
      "\u001b[95mcmd1:\u001b[0m checking for sysroot... no\n",
      "\u001b[95mcmd1:\u001b[0m checking for mt... no\n",
      "\u001b[95mcmd1:\u001b[0m checking if : is a manifest tool... no\n",
      "\u001b[95mcmd1:\u001b[0m checking how to run the C preprocessor... gcc -E\n",
      "\u001b[95mcmd1:\u001b[0m checking for ANSI C header files... yes\n",
      "\u001b[95mcmd1:\u001b[0m checking for sys/types.h... yes\n",
      "\u001b[95mcmd1:\u001b[0m checking for sys/stat.h... yes\n",
      "\u001b[95mcmd1:\u001b[0m checking for stdlib.h... yes\n",
      "\u001b[95mcmd1:\u001b[0m checking for string.h... yes\n",
      "\u001b[95mcmd1:\u001b[0m checking for memory.h... yes\n",
      "\u001b[95mcmd1:\u001b[0m checking for strings.h... yes\n",
      "\u001b[95mcmd1:\u001b[0m checking for inttypes.h... yes\n",
      "\u001b[95mcmd1:\u001b[0m checking for stdint.h... yes\n",
      "\u001b[95mcmd1:\u001b[0m checking for unistd.h... yes\n",
      "\u001b[95mcmd1:\u001b[0m checking for dlfcn.h... yes\n",
      "\u001b[95mcmd1:\u001b[0m checking for objdir... .libs\n",
      "\u001b[95mcmd1:\u001b[0m checking if gcc supports -fno-rtti -fno-exceptions... no\n",
      "\u001b[95mcmd1:\u001b[0m checking for gcc option to produce PIC... -fPIC -DPIC\n",
      "\u001b[95mcmd1:\u001b[0m checking if gcc PIC flag -fPIC -DPIC works... yes\n",
      "\u001b[95mcmd1:\u001b[0m checking if gcc static flag -static works... yes\n",
      "\u001b[95mcmd1:\u001b[0m checking if gcc supports -c -o file.o... yes\n",
      "\u001b[95mcmd1:\u001b[0m checking if gcc supports -c -o file.o... (cached) yes\n",
      "\u001b[95mcmd1:\u001b[0m checking whether the gcc linker (/usr/bin/ld -m elf_x86_64) supports shared libraries... yes\n",
      "\u001b[95mcmd1:\u001b[0m checking whether -lc should be explicitly linked in... no\n",
      "\u001b[95mcmd1:\u001b[0m checking dynamic linker characteristics... GNU/Linux ld.so\n",
      "\u001b[95mcmd1:\u001b[0m checking how to hardcode library paths into programs... immediate\n",
      "\u001b[95mcmd1:\u001b[0m checking whether stripping libraries is possible... yes\n",
      "\u001b[95mcmd1:\u001b[0m checking if libtool supports shared libraries... yes\n",
      "\u001b[95mcmd1:\u001b[0m checking whether to build shared libraries... yes\n",
      "\u001b[95mcmd1:\u001b[0m checking whether to build static libraries... no\n",
      "\u001b[95mcmd1:\u001b[0m checking how to run the C++ preprocessor... g++ -E\n",
      "\u001b[95mcmd1:\u001b[0m checking for ld used by g++... /usr/bin/ld -m elf_x86_64\n",
      "\u001b[95mcmd1:\u001b[0m checking if the linker (/usr/bin/ld -m elf_x86_64) is GNU ld... yes\n",
      "\u001b[95mcmd1:\u001b[0m checking whether the g++ linker (/usr/bin/ld -m elf_x86_64) supports shared libraries... yes\n",
      "\u001b[95mcmd1:\u001b[0m checking for g++ option to produce PIC... -fPIC -DPIC\n",
      "\u001b[95mcmd1:\u001b[0m checking if g++ PIC flag -fPIC -DPIC works... yes\n",
      "\u001b[95mcmd1:\u001b[0m checking if g++ static flag -static works... yes\n",
      "\u001b[95mcmd1:\u001b[0m checking if g++ supports -c -o file.o... yes\n",
      "\u001b[95mcmd1:\u001b[0m checking if g++ supports -c -o file.o... (cached) yes\n",
      "\u001b[95mcmd1:\u001b[0m checking whether the g++ linker (/usr/bin/ld -m elf_x86_64) supports shared libraries... yes\n",
      "\u001b[95mcmd1:\u001b[0m checking dynamic linker characteristics... (cached) GNU/Linux ld.so\n",
      "\u001b[95mcmd1:\u001b[0m checking how to hardcode library paths into programs... immediate\n",
      "\u001b[95mcmd1:\u001b[0m checking for dlopen in -ldl... yes\n",
      "\u001b[95mcmd1:\u001b[0m checking that generated files are newer than configure... done\n",
      "\u001b[95mcmd1:\u001b[0m configure: creating ./config.status\n",
      "\u001b[95mcmd1:\u001b[0m config.status: creating Makefile\n",
      "\u001b[95mcmd1:\u001b[0m config.status: creating src/Makefile\n",
      "\u001b[95mcmd1:\u001b[0m config.status: creating src/include/Makefile\n",
      "\u001b[95mcmd1:\u001b[0m config.status: creating src/lib/Makefile\n",
      "\u001b[95mcmd1:\u001b[0m config.status: creating src/bin/Makefile\n",
      "\u001b[95mcmd1:\u001b[0m config.status: creating src/test/Makefile\n",
      "\u001b[95mcmd1:\u001b[0m config.status: creating src/extensions/Makefile\n",
      "\u001b[95mcmd1:\u001b[0m config.status: creating src/extensions/compact/Makefile\n",
      "\u001b[95mcmd1:\u001b[0m config.status: creating src/extensions/compress/Makefile\n",
      "\u001b[95mcmd1:\u001b[0m config.status: creating src/extensions/const/Makefile\n",
      "\u001b[95mcmd1:\u001b[0m config.status: creating src/extensions/far/Makefile\n",
      "\u001b[95mcmd1:\u001b[0m config.status: creating src/extensions/linear/Makefile\n",
      "\u001b[95mcmd1:\u001b[0m config.status: creating src/extensions/lookahead/Makefile\n",
      "\u001b[95mcmd1:\u001b[0m config.status: creating src/extensions/mpdt/Makefile\n",
      "\u001b[95mcmd1:\u001b[0m config.status: creating src/extensions/ngram/Makefile\n",
      "\u001b[95mcmd1:\u001b[0m config.status: creating src/extensions/pdt/Makefile\n",
      "\u001b[95mcmd1:\u001b[0m config.status: creating src/extensions/python/Makefile\n",
      "\u001b[95mcmd1:\u001b[0m config.status: creating src/extensions/special/Makefile\n",
      "\u001b[95mcmd1:\u001b[0m config.status: creating src/script/Makefile\n",
      "\u001b[95mcmd1:\u001b[0m config.status: creating config.h\n",
      "\u001b[95mcmd1:\u001b[0m config.status: creating src/include/fst/config.h\n",
      "\u001b[95mcmd1:\u001b[0m config.status: executing depfiles commands\n",
      "\u001b[95mcmd1:\u001b[0m config.status: executing libtool commands\n",
      "\u001b[95mcmd1:\u001b[0m cd /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-build && /usr/local/lib/python3.11/dist-packages/cmake/data/bin/cmake -E copy_directory /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/patch/openfst /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src\n",
      "\u001b[95mcmd1:\u001b[0m cd /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-build && /usr/local/lib/python3.11/dist-packages/cmake/data/bin/cmake -E touch /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/build/temp.linux-x86_64-cpython-39/openfst-prefix/src/openfst-stamp/openfst-configure\n",
      "\u001b[95mcmd1:\u001b[0m [ 36%] Performing build step for 'openfst'\n",
      "\u001b[95mcmd1:\u001b[0m cd /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-build && make -j 4\n",
      "\u001b[95mcmd1:\u001b[0m make[4]: Entering directory '/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-build'\n",
      "\u001b[95mcmd1:\u001b[0m make  all-recursive\n",
      "\u001b[95mcmd1:\u001b[0m make[5]: Entering directory '/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-build'\n",
      "\u001b[95mcmd1:\u001b[0m Making all in src\n",
      "\u001b[95mcmd1:\u001b[0m make[6]: Entering directory '/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-build/src'\n",
      "\u001b[95mcmd1:\u001b[0m Making all in include\n",
      "\u001b[95mcmd1:\u001b[0m make[7]: Entering directory '/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-build/src/include'\n",
      "\u001b[95mcmd1:\u001b[0m make[7]: Nothing to be done for 'all'.\n",
      "\u001b[95mcmd1:\u001b[0m make[7]: Leaving directory '/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-build/src/include'\n",
      "\u001b[95mcmd1:\u001b[0m Making all in lib\n",
      "\u001b[95mcmd1:\u001b[0m make[7]: Entering directory '/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-build/src/lib'\n",
      "\u001b[95mcmd1:\u001b[0m depbase=`echo compat.lo | sed 's|[^/]*$|.deps/&|;s|\\.lo$||'`;\\\n",
      "\u001b[95mcmd1:\u001b[0m /bin/bash ../../libtool  --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H   -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/lib/../include  -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char  -std=c++11 -MT compat.lo -MD -MP -MF $depbase.Tpo -c -o compat.lo /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/lib/compat.cc &&\\\n",
      "\u001b[95mcmd1:\u001b[0m mv -f $depbase.Tpo $depbase.Plo\n",
      "\u001b[95mcmd1:\u001b[0m depbase=`echo flags.lo | sed 's|[^/]*$|.deps/&|;s|\\.lo$||'`;\\\n",
      "\u001b[95mcmd1:\u001b[0m /bin/bash ../../libtool  --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H   -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/lib/../include  -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char  -std=c++11 -MT flags.lo -MD -MP -MF $depbase.Tpo -c -o flags.lo /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/lib/flags.cc &&\\\n",
      "\u001b[95mcmd1:\u001b[0m mv -f $depbase.Tpo $depbase.Plo\n",
      "\u001b[95mcmd1:\u001b[0m depbase=`echo fst.lo | sed 's|[^/]*$|.deps/&|;s|\\.lo$||'`;\\\n",
      "\u001b[95mcmd1:\u001b[0m /bin/bash ../../libtool  --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H   -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/lib/../include  -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char  -std=c++11 -MT fst.lo -MD -MP -MF $depbase.Tpo -c -o fst.lo /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/lib/fst.cc &&\\\n",
      "\u001b[95mcmd1:\u001b[0m mv -f $depbase.Tpo $depbase.Plo\n",
      "\u001b[95mcmd1:\u001b[0m depbase=`echo mapped-file.lo | sed 's|[^/]*$|.deps/&|;s|\\.lo$||'`;\\\n",
      "\u001b[95mcmd1:\u001b[0m /bin/bash ../../libtool  --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H   -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/lib/../include  -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char  -std=c++11 -MT mapped-file.lo -MD -MP -MF $depbase.Tpo -c -o mapped-file.lo /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/lib/mapped-file.cc &&\\\n",
      "\u001b[95mcmd1:\u001b[0m mv -f $depbase.Tpo $depbase.Plo\n",
      "\u001b[95mcmd1:\u001b[0m libtool: compile:  g++ -DHAVE_CONFIG_H -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/lib/../include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char -std=c++11 -MT compat.lo -MD -MP -MF .deps/compat.Tpo -c /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/lib/compat.cc  -fPIC -DPIC -o .libs/compat.o\n",
      "\u001b[95mcmd1:\u001b[0m libtool: compile:  g++ -DHAVE_CONFIG_H -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/lib/../include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char -std=c++11 -MT flags.lo -MD -MP -MF .deps/flags.Tpo -c /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/lib/flags.cc  -fPIC -DPIC -o .libs/flags.o\n",
      "\u001b[95mcmd1:\u001b[0m libtool: compile:  g++ -DHAVE_CONFIG_H -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/lib/../include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char -std=c++11 -MT fst.lo -MD -MP -MF .deps/fst.Tpo -c /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/lib/fst.cc  -fPIC -DPIC -o .libs/fst.o\n",
      "\u001b[95mcmd1:\u001b[0m libtool: compile:  g++ -DHAVE_CONFIG_H -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/lib/../include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char -std=c++11 -MT mapped-file.lo -MD -MP -MF .deps/mapped-file.Tpo -c /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/lib/mapped-file.cc  -fPIC -DPIC -o .libs/mapped-file.o\n",
      "\u001b[95mcmd1:\u001b[0m depbase=`echo properties.lo | sed 's|[^/]*$|.deps/&|;s|\\.lo$||'`;\\\n",
      "\u001b[95mcmd1:\u001b[0m /bin/bash ../../libtool  --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H   -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/lib/../include  -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char  -std=c++11 -MT properties.lo -MD -MP -MF $depbase.Tpo -c -o properties.lo /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/lib/properties.cc &&\\\n",
      "\u001b[95mcmd1:\u001b[0m mv -f $depbase.Tpo $depbase.Plo\n",
      "\u001b[95mcmd1:\u001b[0m libtool: compile:  g++ -DHAVE_CONFIG_H -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/lib/../include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char -std=c++11 -MT properties.lo -MD -MP -MF .deps/properties.Tpo -c /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/lib/properties.cc  -fPIC -DPIC -o .libs/properties.o\n",
      "\u001b[95mcmd1:\u001b[0m depbase=`echo symbol-table.lo | sed 's|[^/]*$|.deps/&|;s|\\.lo$||'`;\\\n",
      "\u001b[95mcmd1:\u001b[0m /bin/bash ../../libtool  --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H   -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/lib/../include  -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char  -std=c++11 -MT symbol-table.lo -MD -MP -MF $depbase.Tpo -c -o symbol-table.lo /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/lib/symbol-table.cc &&\\\n",
      "\u001b[95mcmd1:\u001b[0m mv -f $depbase.Tpo $depbase.Plo\n",
      "\u001b[95mcmd1:\u001b[0m libtool: compile:  g++ -DHAVE_CONFIG_H -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/lib/../include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char -std=c++11 -MT symbol-table.lo -MD -MP -MF .deps/symbol-table.Tpo -c /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/lib/symbol-table.cc  -fPIC -DPIC -o .libs/symbol-table.o\n",
      "\u001b[95mcmd1:\u001b[0m depbase=`echo symbol-table-ops.lo | sed 's|[^/]*$|.deps/&|;s|\\.lo$||'`;\\\n",
      "\u001b[95mcmd1:\u001b[0m /bin/bash ../../libtool  --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H   -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/lib/../include  -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char  -std=c++11 -MT symbol-table-ops.lo -MD -MP -MF $depbase.Tpo -c -o symbol-table-ops.lo /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/lib/symbol-table-ops.cc &&\\\n",
      "\u001b[95mcmd1:\u001b[0m mv -f $depbase.Tpo $depbase.Plo\n",
      "\u001b[95mcmd1:\u001b[0m libtool: compile:  g++ -DHAVE_CONFIG_H -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/lib/../include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char -std=c++11 -MT symbol-table-ops.lo -MD -MP -MF .deps/symbol-table-ops.Tpo -c /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/lib/symbol-table-ops.cc  -fPIC -DPIC -o .libs/symbol-table-ops.o\n",
      "\u001b[95mcmd1:\u001b[0m depbase=`echo weight.lo | sed 's|[^/]*$|.deps/&|;s|\\.lo$||'`;\\\n",
      "\u001b[95mcmd1:\u001b[0m /bin/bash ../../libtool  --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H   -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/lib/../include  -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char  -std=c++11 -MT weight.lo -MD -MP -MF $depbase.Tpo -c -o weight.lo /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/lib/weight.cc &&\\\n",
      "\u001b[95mcmd1:\u001b[0m mv -f $depbase.Tpo $depbase.Plo\n",
      "\u001b[95mcmd1:\u001b[0m libtool: compile:  g++ -DHAVE_CONFIG_H -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/lib/../include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char -std=c++11 -MT weight.lo -MD -MP -MF .deps/weight.Tpo -c /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/lib/weight.cc  -fPIC -DPIC -o .libs/weight.o\n",
      "\u001b[95mcmd1:\u001b[0m depbase=`echo util.lo | sed 's|[^/]*$|.deps/&|;s|\\.lo$||'`;\\\n",
      "\u001b[95mcmd1:\u001b[0m /bin/bash ../../libtool  --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H   -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/lib/../include  -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char  -std=c++11 -MT util.lo -MD -MP -MF $depbase.Tpo -c -o util.lo /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/lib/util.cc &&\\\n",
      "\u001b[95mcmd1:\u001b[0m mv -f $depbase.Tpo $depbase.Plo\n",
      "\u001b[95mcmd1:\u001b[0m libtool: compile:  g++ -DHAVE_CONFIG_H -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/lib/../include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char -std=c++11 -MT util.lo -MD -MP -MF .deps/util.Tpo -c /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/lib/util.cc  -fPIC -DPIC -o .libs/util.o\n",
      "\u001b[95mcmd1:\u001b[0m /bin/bash ../../libtool  --tag=CXX   --mode=link g++  -std=c++11 -version-info 8:0:0 -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -o libfst.la -rpath /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-subbuild/openfst-populate-prefix/lib compat.lo flags.lo fst.lo mapped-file.lo properties.lo symbol-table.lo symbol-table-ops.lo weight.lo util.lo -ldl -lgflags_nothreads -lglog -lpthread\n",
      "\u001b[95mcmd1:\u001b[0m libtool: link: g++  -fPIC -DPIC -shared -nostdlib /usr/lib/gcc/x86_64-linux-gnu/11/../../../x86_64-linux-gnu/crti.o /usr/lib/gcc/x86_64-linux-gnu/11/crtbeginS.o  .libs/compat.o .libs/flags.o .libs/fst.o .libs/mapped-file.o .libs/properties.o .libs/symbol-table.o .libs/symbol-table-ops.o .libs/weight.o .libs/util.o   -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -ldl -lgflags_nothreads -lglog -lpthread -L/usr/lib/gcc/x86_64-linux-gnu/11 -L/usr/lib/gcc/x86_64-linux-gnu/11/../../../x86_64-linux-gnu -L/usr/lib/gcc/x86_64-linux-gnu/11/../../../../lib -L/lib/x86_64-linux-gnu -L/lib/../lib -L/usr/lib/x86_64-linux-gnu -L/usr/lib/../lib -L/usr/local/cuda/lib64/stubs -L/usr/lib/gcc/x86_64-linux-gnu/11/../../.. -lstdc++ -lm -lc -lgcc_s /usr/lib/gcc/x86_64-linux-gnu/11/crtendS.o /usr/lib/gcc/x86_64-linux-gnu/11/../../../x86_64-linux-gnu/crtn.o    -Wl,-soname -Wl,libfst.so.8 -o .libs/libfst.so.8.0.0\n",
      "\u001b[95mcmd1:\u001b[0m libtool: link: (cd \".libs\" && rm -f \"libfst.so.8\" && ln -s \"libfst.so.8.0.0\" \"libfst.so.8\")\n",
      "\u001b[95mcmd1:\u001b[0m libtool: link: (cd \".libs\" && rm -f \"libfst.so\" && ln -s \"libfst.so.8.0.0\" \"libfst.so\")\n",
      "\u001b[95mcmd1:\u001b[0m libtool: link: ( cd \".libs\" && rm -f \"libfst.la\" && ln -s \"../libfst.la\" \"libfst.la\" )\n",
      "\u001b[95mcmd1:\u001b[0m make[7]: Leaving directory '/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-build/src/lib'\n",
      "\u001b[95mcmd1:\u001b[0m Making all in script\n",
      "\u001b[95mcmd1:\u001b[0m make[7]: Entering directory '/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-build/src/script'\n",
      "\u001b[95mcmd1:\u001b[0m depbase=`echo arciterator-class.lo | sed 's|[^/]*$|.deps/&|;s|\\.lo$||'`;\\\n",
      "\u001b[95mcmd1:\u001b[0m /bin/bash ../../libtool  --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H   -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/../include  -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char  -std=c++11 -MT arciterator-class.lo -MD -MP -MF $depbase.Tpo -c -o arciterator-class.lo /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/arciterator-class.cc &&\\\n",
      "\u001b[95mcmd1:\u001b[0m mv -f $depbase.Tpo $depbase.Plo\n",
      "\u001b[95mcmd1:\u001b[0m depbase=`echo arcsort.lo | sed 's|[^/]*$|.deps/&|;s|\\.lo$||'`;\\\n",
      "\u001b[95mcmd1:\u001b[0m /bin/bash ../../libtool  --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H   -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/../include  -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char  -std=c++11 -MT arcsort.lo -MD -MP -MF $depbase.Tpo -c -o arcsort.lo /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/arcsort.cc &&\\\n",
      "\u001b[95mcmd1:\u001b[0m mv -f $depbase.Tpo $depbase.Plo\n",
      "\u001b[95mcmd1:\u001b[0m depbase=`echo closure.lo | sed 's|[^/]*$|.deps/&|;s|\\.lo$||'`;\\\n",
      "\u001b[95mcmd1:\u001b[0m /bin/bash ../../libtool  --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H   -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/../include  -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char  -std=c++11 -MT closure.lo -MD -MP -MF $depbase.Tpo -c -o closure.lo /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/closure.cc &&\\\n",
      "\u001b[95mcmd1:\u001b[0m mv -f $depbase.Tpo $depbase.Plo\n",
      "\u001b[95mcmd1:\u001b[0m depbase=`echo compile.lo | sed 's|[^/]*$|.deps/&|;s|\\.lo$||'`;\\\n",
      "\u001b[95mcmd1:\u001b[0m /bin/bash ../../libtool  --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H   -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/../include  -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char  -std=c++11 -MT compile.lo -MD -MP -MF $depbase.Tpo -c -o compile.lo /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/compile.cc &&\\\n",
      "\u001b[95mcmd1:\u001b[0m mv -f $depbase.Tpo $depbase.Plo\n",
      "\u001b[95mcmd1:\u001b[0m libtool: compile:  g++ -DHAVE_CONFIG_H -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/../include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char -std=c++11 -MT arciterator-class.lo -MD -MP -MF .deps/arciterator-class.Tpo -c /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/arciterator-class.cc  -fPIC -DPIC -o .libs/arciterator-class.o\n",
      "\u001b[95mcmd1:\u001b[0m libtool: compile:  g++ -DHAVE_CONFIG_H -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/../include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char -std=c++11 -MT arcsort.lo -MD -MP -MF .deps/arcsort.Tpo -c /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/arcsort.cc  -fPIC -DPIC -o .libs/arcsort.o\n",
      "\u001b[95mcmd1:\u001b[0m libtool: compile:  g++ -DHAVE_CONFIG_H -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/../include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char -std=c++11 -MT closure.lo -MD -MP -MF .deps/closure.Tpo -c /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/closure.cc  -fPIC -DPIC -o .libs/closure.o\n",
      "\u001b[95mcmd1:\u001b[0m libtool: compile:  g++ -DHAVE_CONFIG_H -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/../include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char -std=c++11 -MT compile.lo -MD -MP -MF .deps/compile.Tpo -c /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/compile.cc  -fPIC -DPIC -o .libs/compile.o\n",
      "\u001b[95mcmd1:\u001b[0m depbase=`echo compose.lo | sed 's|[^/]*$|.deps/&|;s|\\.lo$||'`;\\\n",
      "\u001b[95mcmd1:\u001b[0m /bin/bash ../../libtool  --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H   -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/../include  -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char  -std=c++11 -MT compose.lo -MD -MP -MF $depbase.Tpo -c -o compose.lo /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/compose.cc &&\\\n",
      "\u001b[95mcmd1:\u001b[0m mv -f $depbase.Tpo $depbase.Plo\n",
      "\u001b[95mcmd1:\u001b[0m libtool: compile:  g++ -DHAVE_CONFIG_H -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/../include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char -std=c++11 -MT compose.lo -MD -MP -MF .deps/compose.Tpo -c /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/compose.cc  -fPIC -DPIC -o .libs/compose.o\n",
      "\u001b[95mcmd1:\u001b[0m depbase=`echo concat.lo | sed 's|[^/]*$|.deps/&|;s|\\.lo$||'`;\\\n",
      "\u001b[95mcmd1:\u001b[0m /bin/bash ../../libtool  --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H   -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/../include  -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char  -std=c++11 -MT concat.lo -MD -MP -MF $depbase.Tpo -c -o concat.lo /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/concat.cc &&\\\n",
      "\u001b[95mcmd1:\u001b[0m mv -f $depbase.Tpo $depbase.Plo\n",
      "\u001b[95mcmd1:\u001b[0m libtool: compile:  g++ -DHAVE_CONFIG_H -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/../include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char -std=c++11 -MT concat.lo -MD -MP -MF .deps/concat.Tpo -c /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/concat.cc  -fPIC -DPIC -o .libs/concat.o\n",
      "\u001b[95mcmd1:\u001b[0m depbase=`echo connect.lo | sed 's|[^/]*$|.deps/&|;s|\\.lo$||'`;\\\n",
      "\u001b[95mcmd1:\u001b[0m /bin/bash ../../libtool  --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H   -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/../include  -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char  -std=c++11 -MT connect.lo -MD -MP -MF $depbase.Tpo -c -o connect.lo /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/connect.cc &&\\\n",
      "\u001b[95mcmd1:\u001b[0m mv -f $depbase.Tpo $depbase.Plo\n",
      "\u001b[95mcmd1:\u001b[0m libtool: compile:  g++ -DHAVE_CONFIG_H -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/../include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char -std=c++11 -MT connect.lo -MD -MP -MF .deps/connect.Tpo -c /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/connect.cc  -fPIC -DPIC -o .libs/connect.o\n",
      "\u001b[95mcmd1:\u001b[0m depbase=`echo convert.lo | sed 's|[^/]*$|.deps/&|;s|\\.lo$||'`;\\\n",
      "\u001b[95mcmd1:\u001b[0m /bin/bash ../../libtool  --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H   -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/../include  -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char  -std=c++11 -MT convert.lo -MD -MP -MF $depbase.Tpo -c -o convert.lo /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/convert.cc &&\\\n",
      "\u001b[95mcmd1:\u001b[0m mv -f $depbase.Tpo $depbase.Plo\n",
      "\u001b[95mcmd1:\u001b[0m libtool: compile:  g++ -DHAVE_CONFIG_H -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/../include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char -std=c++11 -MT convert.lo -MD -MP -MF .deps/convert.Tpo -c /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/convert.cc  -fPIC -DPIC -o .libs/convert.o\n",
      "\u001b[95mcmd1:\u001b[0m depbase=`echo decode.lo | sed 's|[^/]*$|.deps/&|;s|\\.lo$||'`;\\\n",
      "\u001b[95mcmd1:\u001b[0m /bin/bash ../../libtool  --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H   -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/../include  -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char  -std=c++11 -MT decode.lo -MD -MP -MF $depbase.Tpo -c -o decode.lo /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/decode.cc &&\\\n",
      "\u001b[95mcmd1:\u001b[0m mv -f $depbase.Tpo $depbase.Plo\n",
      "\u001b[95mcmd1:\u001b[0m depbase=`echo determinize.lo | sed 's|[^/]*$|.deps/&|;s|\\.lo$||'`;\\\n",
      "\u001b[95mcmd1:\u001b[0m /bin/bash ../../libtool  --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H   -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/../include  -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char  -std=c++11 -MT determinize.lo -MD -MP -MF $depbase.Tpo -c -o determinize.lo /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/determinize.cc &&\\\n",
      "\u001b[95mcmd1:\u001b[0m mv -f $depbase.Tpo $depbase.Plo\n",
      "\u001b[95mcmd1:\u001b[0m libtool: compile:  g++ -DHAVE_CONFIG_H -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/../include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char -std=c++11 -MT decode.lo -MD -MP -MF .deps/decode.Tpo -c /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/decode.cc  -fPIC -DPIC -o .libs/decode.o\n",
      "\u001b[95mcmd1:\u001b[0m libtool: compile:  g++ -DHAVE_CONFIG_H -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/../include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char -std=c++11 -MT determinize.lo -MD -MP -MF .deps/determinize.Tpo -c /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/determinize.cc  -fPIC -DPIC -o .libs/determinize.o\n",
      "\u001b[95mcmd1:\u001b[0m depbase=`echo difference.lo | sed 's|[^/]*$|.deps/&|;s|\\.lo$||'`;\\\n",
      "\u001b[95mcmd1:\u001b[0m /bin/bash ../../libtool  --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H   -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/../include  -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char  -std=c++11 -MT difference.lo -MD -MP -MF $depbase.Tpo -c -o difference.lo /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/difference.cc &&\\\n",
      "\u001b[95mcmd1:\u001b[0m mv -f $depbase.Tpo $depbase.Plo\n",
      "\u001b[95mcmd1:\u001b[0m libtool: compile:  g++ -DHAVE_CONFIG_H -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/../include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char -std=c++11 -MT difference.lo -MD -MP -MF .deps/difference.Tpo -c /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/difference.cc  -fPIC -DPIC -o .libs/difference.o\n",
      "\u001b[95mcmd1:\u001b[0m depbase=`echo disambiguate.lo | sed 's|[^/]*$|.deps/&|;s|\\.lo$||'`;\\\n",
      "\u001b[95mcmd1:\u001b[0m /bin/bash ../../libtool  --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H   -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/../include  -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char  -std=c++11 -MT disambiguate.lo -MD -MP -MF $depbase.Tpo -c -o disambiguate.lo /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/disambiguate.cc &&\\\n",
      "\u001b[95mcmd1:\u001b[0m mv -f $depbase.Tpo $depbase.Plo\n",
      "\u001b[95mcmd1:\u001b[0m libtool: compile:  g++ -DHAVE_CONFIG_H -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/../include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char -std=c++11 -MT disambiguate.lo -MD -MP -MF .deps/disambiguate.Tpo -c /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/disambiguate.cc  -fPIC -DPIC -o .libs/disambiguate.o\n",
      "\u001b[95mcmd1:\u001b[0m depbase=`echo draw.lo | sed 's|[^/]*$|.deps/&|;s|\\.lo$||'`;\\\n",
      "\u001b[95mcmd1:\u001b[0m /bin/bash ../../libtool  --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H   -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/../include  -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char  -std=c++11 -MT draw.lo -MD -MP -MF $depbase.Tpo -c -o draw.lo /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/draw.cc &&\\\n",
      "\u001b[95mcmd1:\u001b[0m mv -f $depbase.Tpo $depbase.Plo\n",
      "\u001b[95mcmd1:\u001b[0m libtool: compile:  g++ -DHAVE_CONFIG_H -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/../include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char -std=c++11 -MT draw.lo -MD -MP -MF .deps/draw.Tpo -c /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/draw.cc  -fPIC -DPIC -o .libs/draw.o\n",
      "\u001b[95mcmd1:\u001b[0m depbase=`echo encode.lo | sed 's|[^/]*$|.deps/&|;s|\\.lo$||'`;\\\n",
      "\u001b[95mcmd1:\u001b[0m /bin/bash ../../libtool  --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H   -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/../include  -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char  -std=c++11 -MT encode.lo -MD -MP -MF $depbase.Tpo -c -o encode.lo /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/encode.cc &&\\\n",
      "\u001b[95mcmd1:\u001b[0m mv -f $depbase.Tpo $depbase.Plo\n",
      "\u001b[95mcmd1:\u001b[0m libtool: compile:  g++ -DHAVE_CONFIG_H -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/../include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char -std=c++11 -MT encode.lo -MD -MP -MF .deps/encode.Tpo -c /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/encode.cc  -fPIC -DPIC -o .libs/encode.o\n",
      "\u001b[95mcmd1:\u001b[0m depbase=`echo encodemapper-class.lo | sed 's|[^/]*$|.deps/&|;s|\\.lo$||'`;\\\n",
      "\u001b[95mcmd1:\u001b[0m /bin/bash ../../libtool  --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H   -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/../include  -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char  -std=c++11 -MT encodemapper-class.lo -MD -MP -MF $depbase.Tpo -c -o encodemapper-class.lo /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/encodemapper-class.cc &&\\\n",
      "\u001b[95mcmd1:\u001b[0m mv -f $depbase.Tpo $depbase.Plo\n",
      "\u001b[95mcmd1:\u001b[0m libtool: compile:  g++ -DHAVE_CONFIG_H -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/../include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char -std=c++11 -MT encodemapper-class.lo -MD -MP -MF .deps/encodemapper-class.Tpo -c /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/encodemapper-class.cc  -fPIC -DPIC -o .libs/encodemapper-class.o\n",
      "\u001b[95mcmd1:\u001b[0m depbase=`echo epsnormalize.lo | sed 's|[^/]*$|.deps/&|;s|\\.lo$||'`;\\\n",
      "\u001b[95mcmd1:\u001b[0m /bin/bash ../../libtool  --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H   -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/../include  -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char  -std=c++11 -MT epsnormalize.lo -MD -MP -MF $depbase.Tpo -c -o epsnormalize.lo /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/epsnormalize.cc &&\\\n",
      "\u001b[95mcmd1:\u001b[0m mv -f $depbase.Tpo $depbase.Plo\n",
      "\u001b[95mcmd1:\u001b[0m libtool: compile:  g++ -DHAVE_CONFIG_H -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/../include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char -std=c++11 -MT epsnormalize.lo -MD -MP -MF .deps/epsnormalize.Tpo -c /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/epsnormalize.cc  -fPIC -DPIC -o .libs/epsnormalize.o\n",
      "\u001b[95mcmd1:\u001b[0m depbase=`echo equal.lo | sed 's|[^/]*$|.deps/&|;s|\\.lo$||'`;\\\n",
      "\u001b[95mcmd1:\u001b[0m /bin/bash ../../libtool  --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H   -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/../include  -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char  -std=c++11 -MT equal.lo -MD -MP -MF $depbase.Tpo -c -o equal.lo /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/equal.cc &&\\\n",
      "\u001b[95mcmd1:\u001b[0m mv -f $depbase.Tpo $depbase.Plo\n",
      "\u001b[95mcmd1:\u001b[0m libtool: compile:  g++ -DHAVE_CONFIG_H -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/../include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char -std=c++11 -MT equal.lo -MD -MP -MF .deps/equal.Tpo -c /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/equal.cc  -fPIC -DPIC -o .libs/equal.o\n",
      "\u001b[95mcmd1:\u001b[0m depbase=`echo equivalent.lo | sed 's|[^/]*$|.deps/&|;s|\\.lo$||'`;\\\n",
      "\u001b[95mcmd1:\u001b[0m /bin/bash ../../libtool  --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H   -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/../include  -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char  -std=c++11 -MT equivalent.lo -MD -MP -MF $depbase.Tpo -c -o equivalent.lo /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/equivalent.cc &&\\\n",
      "\u001b[95mcmd1:\u001b[0m mv -f $depbase.Tpo $depbase.Plo\n",
      "\u001b[95mcmd1:\u001b[0m libtool: compile:  g++ -DHAVE_CONFIG_H -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/../include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char -std=c++11 -MT equivalent.lo -MD -MP -MF .deps/equivalent.Tpo -c /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/equivalent.cc  -fPIC -DPIC -o .libs/equivalent.o\n",
      "\u001b[95mcmd1:\u001b[0m depbase=`echo fst-class.lo | sed 's|[^/]*$|.deps/&|;s|\\.lo$||'`;\\\n",
      "\u001b[95mcmd1:\u001b[0m /bin/bash ../../libtool  --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H   -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/../include  -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char  -std=c++11 -MT fst-class.lo -MD -MP -MF $depbase.Tpo -c -o fst-class.lo /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/fst-class.cc &&\\\n",
      "\u001b[95mcmd1:\u001b[0m mv -f $depbase.Tpo $depbase.Plo\n",
      "\u001b[95mcmd1:\u001b[0m libtool: compile:  g++ -DHAVE_CONFIG_H -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/../include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char -std=c++11 -MT fst-class.lo -MD -MP -MF .deps/fst-class.Tpo -c /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/fst-class.cc  -fPIC -DPIC -o .libs/fst-class.o\n",
      "\u001b[95mcmd1:\u001b[0m depbase=`echo getters.lo | sed 's|[^/]*$|.deps/&|;s|\\.lo$||'`;\\\n",
      "\u001b[95mcmd1:\u001b[0m /bin/bash ../../libtool  --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H   -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/../include  -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char  -std=c++11 -MT getters.lo -MD -MP -MF $depbase.Tpo -c -o getters.lo /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/getters.cc &&\\\n",
      "\u001b[95mcmd1:\u001b[0m mv -f $depbase.Tpo $depbase.Plo\n",
      "\u001b[95mcmd1:\u001b[0m libtool: compile:  g++ -DHAVE_CONFIG_H -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/../include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char -std=c++11 -MT getters.lo -MD -MP -MF .deps/getters.Tpo -c /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/getters.cc  -fPIC -DPIC -o .libs/getters.o\n",
      "\u001b[95mcmd1:\u001b[0m depbase=`echo info-impl.lo | sed 's|[^/]*$|.deps/&|;s|\\.lo$||'`;\\\n",
      "\u001b[95mcmd1:\u001b[0m /bin/bash ../../libtool  --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H   -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/../include  -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char  -std=c++11 -MT info-impl.lo -MD -MP -MF $depbase.Tpo -c -o info-impl.lo /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/info-impl.cc &&\\\n",
      "\u001b[95mcmd1:\u001b[0m mv -f $depbase.Tpo $depbase.Plo\n",
      "\u001b[95mcmd1:\u001b[0m libtool: compile:  g++ -DHAVE_CONFIG_H -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/../include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char -std=c++11 -MT info-impl.lo -MD -MP -MF .deps/info-impl.Tpo -c /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/info-impl.cc  -fPIC -DPIC -o .libs/info-impl.o\n",
      "\u001b[95mcmd1:\u001b[0m depbase=`echo info.lo | sed 's|[^/]*$|.deps/&|;s|\\.lo$||'`;\\\n",
      "\u001b[95mcmd1:\u001b[0m /bin/bash ../../libtool  --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H   -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/../include  -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char  -std=c++11 -MT info.lo -MD -MP -MF $depbase.Tpo -c -o info.lo /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/info.cc &&\\\n",
      "\u001b[95mcmd1:\u001b[0m mv -f $depbase.Tpo $depbase.Plo\n",
      "\u001b[95mcmd1:\u001b[0m libtool: compile:  g++ -DHAVE_CONFIG_H -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/../include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char -std=c++11 -MT info.lo -MD -MP -MF .deps/info.Tpo -c /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/info.cc  -fPIC -DPIC -o .libs/info.o\n",
      "\u001b[95mcmd1:\u001b[0m depbase=`echo intersect.lo | sed 's|[^/]*$|.deps/&|;s|\\.lo$||'`;\\\n",
      "\u001b[95mcmd1:\u001b[0m /bin/bash ../../libtool  --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H   -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/../include  -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char  -std=c++11 -MT intersect.lo -MD -MP -MF $depbase.Tpo -c -o intersect.lo /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/intersect.cc &&\\\n",
      "\u001b[95mcmd1:\u001b[0m mv -f $depbase.Tpo $depbase.Plo\n",
      "\u001b[95mcmd1:\u001b[0m libtool: compile:  g++ -DHAVE_CONFIG_H -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/../include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char -std=c++11 -MT intersect.lo -MD -MP -MF .deps/intersect.Tpo -c /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/intersect.cc  -fPIC -DPIC -o .libs/intersect.o\n",
      "\u001b[95mcmd1:\u001b[0m depbase=`echo invert.lo | sed 's|[^/]*$|.deps/&|;s|\\.lo$||'`;\\\n",
      "\u001b[95mcmd1:\u001b[0m /bin/bash ../../libtool  --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H   -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/../include  -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char  -std=c++11 -MT invert.lo -MD -MP -MF $depbase.Tpo -c -o invert.lo /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/invert.cc &&\\\n",
      "\u001b[95mcmd1:\u001b[0m mv -f $depbase.Tpo $depbase.Plo\n",
      "\u001b[95mcmd1:\u001b[0m libtool: compile:  g++ -DHAVE_CONFIG_H -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/../include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char -std=c++11 -MT invert.lo -MD -MP -MF .deps/invert.Tpo -c /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/invert.cc  -fPIC -DPIC -o .libs/invert.o\n",
      "\u001b[95mcmd1:\u001b[0m depbase=`echo isomorphic.lo | sed 's|[^/]*$|.deps/&|;s|\\.lo$||'`;\\\n",
      "\u001b[95mcmd1:\u001b[0m /bin/bash ../../libtool  --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H   -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/../include  -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char  -std=c++11 -MT isomorphic.lo -MD -MP -MF $depbase.Tpo -c -o isomorphic.lo /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/isomorphic.cc &&\\\n",
      "\u001b[95mcmd1:\u001b[0m mv -f $depbase.Tpo $depbase.Plo\n",
      "\u001b[95mcmd1:\u001b[0m libtool: compile:  g++ -DHAVE_CONFIG_H -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/../include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char -std=c++11 -MT isomorphic.lo -MD -MP -MF .deps/isomorphic.Tpo -c /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/isomorphic.cc  -fPIC -DPIC -o .libs/isomorphic.o\n",
      "\u001b[95mcmd1:\u001b[0m depbase=`echo map.lo | sed 's|[^/]*$|.deps/&|;s|\\.lo$||'`;\\\n",
      "\u001b[95mcmd1:\u001b[0m /bin/bash ../../libtool  --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H   -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/../include  -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char  -std=c++11 -MT map.lo -MD -MP -MF $depbase.Tpo -c -o map.lo /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/map.cc &&\\\n",
      "\u001b[95mcmd1:\u001b[0m mv -f $depbase.Tpo $depbase.Plo\n",
      "\u001b[95mcmd1:\u001b[0m libtool: compile:  g++ -DHAVE_CONFIG_H -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/../include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char -std=c++11 -MT map.lo -MD -MP -MF .deps/map.Tpo -c /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/map.cc  -fPIC -DPIC -o .libs/map.o\n",
      "\u001b[95mcmd1:\u001b[0m depbase=`echo minimize.lo | sed 's|[^/]*$|.deps/&|;s|\\.lo$||'`;\\\n",
      "\u001b[95mcmd1:\u001b[0m /bin/bash ../../libtool  --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H   -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/../include  -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char  -std=c++11 -MT minimize.lo -MD -MP -MF $depbase.Tpo -c -o minimize.lo /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/minimize.cc &&\\\n",
      "\u001b[95mcmd1:\u001b[0m mv -f $depbase.Tpo $depbase.Plo\n",
      "\u001b[95mcmd1:\u001b[0m libtool: compile:  g++ -DHAVE_CONFIG_H -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/../include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char -std=c++11 -MT minimize.lo -MD -MP -MF .deps/minimize.Tpo -c /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/minimize.cc  -fPIC -DPIC -o .libs/minimize.o\n",
      "\u001b[95mcmd1:\u001b[0m depbase=`echo print.lo | sed 's|[^/]*$|.deps/&|;s|\\.lo$||'`;\\\n",
      "\u001b[95mcmd1:\u001b[0m /bin/bash ../../libtool  --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H   -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/../include  -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char  -std=c++11 -MT print.lo -MD -MP -MF $depbase.Tpo -c -o print.lo /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/print.cc &&\\\n",
      "\u001b[95mcmd1:\u001b[0m mv -f $depbase.Tpo $depbase.Plo\n",
      "\u001b[95mcmd1:\u001b[0m libtool: compile:  g++ -DHAVE_CONFIG_H -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/../include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char -std=c++11 -MT print.lo -MD -MP -MF .deps/print.Tpo -c /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/print.cc  -fPIC -DPIC -o .libs/print.o\n",
      "\u001b[95mcmd1:\u001b[0m depbase=`echo project.lo | sed 's|[^/]*$|.deps/&|;s|\\.lo$||'`;\\\n",
      "\u001b[95mcmd1:\u001b[0m /bin/bash ../../libtool  --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H   -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/../include  -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char  -std=c++11 -MT project.lo -MD -MP -MF $depbase.Tpo -c -o project.lo /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/project.cc &&\\\n",
      "\u001b[95mcmd1:\u001b[0m mv -f $depbase.Tpo $depbase.Plo\n",
      "\u001b[95mcmd1:\u001b[0m libtool: compile:  g++ -DHAVE_CONFIG_H -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/../include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char -std=c++11 -MT project.lo -MD -MP -MF .deps/project.Tpo -c /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/project.cc  -fPIC -DPIC -o .libs/project.o\n",
      "\u001b[95mcmd1:\u001b[0m depbase=`echo prune.lo | sed 's|[^/]*$|.deps/&|;s|\\.lo$||'`;\\\n",
      "\u001b[95mcmd1:\u001b[0m /bin/bash ../../libtool  --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H   -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/../include  -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char  -std=c++11 -MT prune.lo -MD -MP -MF $depbase.Tpo -c -o prune.lo /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/prune.cc &&\\\n",
      "\u001b[95mcmd1:\u001b[0m mv -f $depbase.Tpo $depbase.Plo\n",
      "\u001b[95mcmd1:\u001b[0m libtool: compile:  g++ -DHAVE_CONFIG_H -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/../include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char -std=c++11 -MT prune.lo -MD -MP -MF .deps/prune.Tpo -c /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/prune.cc  -fPIC -DPIC -o .libs/prune.o\n",
      "\u001b[95mcmd1:\u001b[0m depbase=`echo push.lo | sed 's|[^/]*$|.deps/&|;s|\\.lo$||'`;\\\n",
      "\u001b[95mcmd1:\u001b[0m /bin/bash ../../libtool  --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H   -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/../include  -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char  -std=c++11 -MT push.lo -MD -MP -MF $depbase.Tpo -c -o push.lo /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/push.cc &&\\\n",
      "\u001b[95mcmd1:\u001b[0m mv -f $depbase.Tpo $depbase.Plo\n",
      "\u001b[95mcmd1:\u001b[0m libtool: compile:  g++ -DHAVE_CONFIG_H -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/../include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char -std=c++11 -MT push.lo -MD -MP -MF .deps/push.Tpo -c /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/push.cc  -fPIC -DPIC -o .libs/push.o\n",
      "\u001b[95mcmd1:\u001b[0m depbase=`echo randequivalent.lo | sed 's|[^/]*$|.deps/&|;s|\\.lo$||'`;\\\n",
      "\u001b[95mcmd1:\u001b[0m /bin/bash ../../libtool  --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H   -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/../include  -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char  -std=c++11 -MT randequivalent.lo -MD -MP -MF $depbase.Tpo -c -o randequivalent.lo /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/randequivalent.cc &&\\\n",
      "\u001b[95mcmd1:\u001b[0m mv -f $depbase.Tpo $depbase.Plo\n",
      "\u001b[95mcmd1:\u001b[0m libtool: compile:  g++ -DHAVE_CONFIG_H -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/../include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char -std=c++11 -MT randequivalent.lo -MD -MP -MF .deps/randequivalent.Tpo -c /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/randequivalent.cc  -fPIC -DPIC -o .libs/randequivalent.o\n",
      "\u001b[95mcmd1:\u001b[0m depbase=`echo randgen.lo | sed 's|[^/]*$|.deps/&|;s|\\.lo$||'`;\\\n",
      "\u001b[95mcmd1:\u001b[0m /bin/bash ../../libtool  --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H   -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/../include  -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char  -std=c++11 -MT randgen.lo -MD -MP -MF $depbase.Tpo -c -o randgen.lo /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/randgen.cc &&\\\n",
      "\u001b[95mcmd1:\u001b[0m mv -f $depbase.Tpo $depbase.Plo\n",
      "\u001b[95mcmd1:\u001b[0m libtool: compile:  g++ -DHAVE_CONFIG_H -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/../include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char -std=c++11 -MT randgen.lo -MD -MP -MF .deps/randgen.Tpo -c /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/randgen.cc  -fPIC -DPIC -o .libs/randgen.o\n",
      "\u001b[95mcmd1:\u001b[0m depbase=`echo relabel.lo | sed 's|[^/]*$|.deps/&|;s|\\.lo$||'`;\\\n",
      "\u001b[95mcmd1:\u001b[0m /bin/bash ../../libtool  --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H   -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/../include  -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char  -std=c++11 -MT relabel.lo -MD -MP -MF $depbase.Tpo -c -o relabel.lo /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/relabel.cc &&\\\n",
      "\u001b[95mcmd1:\u001b[0m mv -f $depbase.Tpo $depbase.Plo\n",
      "\u001b[95mcmd1:\u001b[0m libtool: compile:  g++ -DHAVE_CONFIG_H -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/../include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char -std=c++11 -MT relabel.lo -MD -MP -MF .deps/relabel.Tpo -c /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/relabel.cc  -fPIC -DPIC -o .libs/relabel.o\n",
      "\u001b[95mcmd1:\u001b[0m depbase=`echo replace.lo | sed 's|[^/]*$|.deps/&|;s|\\.lo$||'`;\\\n",
      "\u001b[95mcmd1:\u001b[0m /bin/bash ../../libtool  --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H   -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/../include  -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char  -std=c++11 -MT replace.lo -MD -MP -MF $depbase.Tpo -c -o replace.lo /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/replace.cc &&\\\n",
      "\u001b[95mcmd1:\u001b[0m mv -f $depbase.Tpo $depbase.Plo\n",
      "\u001b[95mcmd1:\u001b[0m libtool: compile:  g++ -DHAVE_CONFIG_H -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/../include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char -std=c++11 -MT replace.lo -MD -MP -MF .deps/replace.Tpo -c /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/replace.cc  -fPIC -DPIC -o .libs/replace.o\n",
      "\u001b[95mcmd1:\u001b[0m depbase=`echo reverse.lo | sed 's|[^/]*$|.deps/&|;s|\\.lo$||'`;\\\n",
      "\u001b[95mcmd1:\u001b[0m /bin/bash ../../libtool  --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H   -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/../include  -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char  -std=c++11 -MT reverse.lo -MD -MP -MF $depbase.Tpo -c -o reverse.lo /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/reverse.cc &&\\\n",
      "\u001b[95mcmd1:\u001b[0m mv -f $depbase.Tpo $depbase.Plo\n",
      "\u001b[95mcmd1:\u001b[0m libtool: compile:  g++ -DHAVE_CONFIG_H -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/../include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char -std=c++11 -MT reverse.lo -MD -MP -MF .deps/reverse.Tpo -c /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/reverse.cc  -fPIC -DPIC -o .libs/reverse.o\n",
      "\u001b[95mcmd1:\u001b[0m depbase=`echo reweight.lo | sed 's|[^/]*$|.deps/&|;s|\\.lo$||'`;\\\n",
      "\u001b[95mcmd1:\u001b[0m /bin/bash ../../libtool  --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H   -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/../include  -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char  -std=c++11 -MT reweight.lo -MD -MP -MF $depbase.Tpo -c -o reweight.lo /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/reweight.cc &&\\\n",
      "\u001b[95mcmd1:\u001b[0m mv -f $depbase.Tpo $depbase.Plo\n",
      "\u001b[95mcmd1:\u001b[0m libtool: compile:  g++ -DHAVE_CONFIG_H -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/../include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char -std=c++11 -MT reweight.lo -MD -MP -MF .deps/reweight.Tpo -c /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/reweight.cc  -fPIC -DPIC -o .libs/reweight.o\n",
      "\u001b[95mcmd1:\u001b[0m depbase=`echo rmepsilon.lo | sed 's|[^/]*$|.deps/&|;s|\\.lo$||'`;\\\n",
      "\u001b[95mcmd1:\u001b[0m /bin/bash ../../libtool  --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H   -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/../include  -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char  -std=c++11 -MT rmepsilon.lo -MD -MP -MF $depbase.Tpo -c -o rmepsilon.lo /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/rmepsilon.cc &&\\\n",
      "\u001b[95mcmd1:\u001b[0m mv -f $depbase.Tpo $depbase.Plo\n",
      "\u001b[95mcmd1:\u001b[0m libtool: compile:  g++ -DHAVE_CONFIG_H -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/../include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char -std=c++11 -MT rmepsilon.lo -MD -MP -MF .deps/rmepsilon.Tpo -c /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/rmepsilon.cc  -fPIC -DPIC -o .libs/rmepsilon.o\n",
      "\u001b[95mcmd1:\u001b[0m depbase=`echo shortest-distance.lo | sed 's|[^/]*$|.deps/&|;s|\\.lo$||'`;\\\n",
      "\u001b[95mcmd1:\u001b[0m /bin/bash ../../libtool  --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H   -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/../include  -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char  -std=c++11 -MT shortest-distance.lo -MD -MP -MF $depbase.Tpo -c -o shortest-distance.lo /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/shortest-distance.cc &&\\\n",
      "\u001b[95mcmd1:\u001b[0m mv -f $depbase.Tpo $depbase.Plo\n",
      "\u001b[95mcmd1:\u001b[0m libtool: compile:  g++ -DHAVE_CONFIG_H -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/../include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char -std=c++11 -MT shortest-distance.lo -MD -MP -MF .deps/shortest-distance.Tpo -c /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/shortest-distance.cc  -fPIC -DPIC -o .libs/shortest-distance.o\n",
      "\u001b[95mcmd1:\u001b[0m depbase=`echo shortest-path.lo | sed 's|[^/]*$|.deps/&|;s|\\.lo$||'`;\\\n",
      "\u001b[95mcmd1:\u001b[0m /bin/bash ../../libtool  --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H   -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/../include  -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char  -std=c++11 -MT shortest-path.lo -MD -MP -MF $depbase.Tpo -c -o shortest-path.lo /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/shortest-path.cc &&\\\n",
      "\u001b[95mcmd1:\u001b[0m mv -f $depbase.Tpo $depbase.Plo\n",
      "\u001b[95mcmd1:\u001b[0m libtool: compile:  g++ -DHAVE_CONFIG_H -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/../include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char -std=c++11 -MT shortest-path.lo -MD -MP -MF .deps/shortest-path.Tpo -c /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/shortest-path.cc  -fPIC -DPIC -o .libs/shortest-path.o\n",
      "\u001b[95mcmd1:\u001b[0m depbase=`echo stateiterator-class.lo | sed 's|[^/]*$|.deps/&|;s|\\.lo$||'`;\\\n",
      "\u001b[95mcmd1:\u001b[0m /bin/bash ../../libtool  --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H   -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/../include  -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char  -std=c++11 -MT stateiterator-class.lo -MD -MP -MF $depbase.Tpo -c -o stateiterator-class.lo /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/stateiterator-class.cc &&\\\n",
      "\u001b[95mcmd1:\u001b[0m mv -f $depbase.Tpo $depbase.Plo\n",
      "\u001b[95mcmd1:\u001b[0m libtool: compile:  g++ -DHAVE_CONFIG_H -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/../include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char -std=c++11 -MT stateiterator-class.lo -MD -MP -MF .deps/stateiterator-class.Tpo -c /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/stateiterator-class.cc  -fPIC -DPIC -o .libs/stateiterator-class.o\n",
      "\u001b[95mcmd1:\u001b[0m depbase=`echo synchronize.lo | sed 's|[^/]*$|.deps/&|;s|\\.lo$||'`;\\\n",
      "\u001b[95mcmd1:\u001b[0m /bin/bash ../../libtool  --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H   -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/../include  -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char  -std=c++11 -MT synchronize.lo -MD -MP -MF $depbase.Tpo -c -o synchronize.lo /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/synchronize.cc &&\\\n",
      "\u001b[95mcmd1:\u001b[0m mv -f $depbase.Tpo $depbase.Plo\n",
      "\u001b[95mcmd1:\u001b[0m libtool: compile:  g++ -DHAVE_CONFIG_H -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/../include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char -std=c++11 -MT synchronize.lo -MD -MP -MF .deps/synchronize.Tpo -c /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/synchronize.cc  -fPIC -DPIC -o .libs/synchronize.o\n",
      "\u001b[95mcmd1:\u001b[0m depbase=`echo text-io.lo | sed 's|[^/]*$|.deps/&|;s|\\.lo$||'`;\\\n",
      "\u001b[95mcmd1:\u001b[0m /bin/bash ../../libtool  --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H   -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/../include  -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char  -std=c++11 -MT text-io.lo -MD -MP -MF $depbase.Tpo -c -o text-io.lo /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/text-io.cc &&\\\n",
      "\u001b[95mcmd1:\u001b[0m mv -f $depbase.Tpo $depbase.Plo\n",
      "\u001b[95mcmd1:\u001b[0m libtool: compile:  g++ -DHAVE_CONFIG_H -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/../include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char -std=c++11 -MT text-io.lo -MD -MP -MF .deps/text-io.Tpo -c /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/text-io.cc  -fPIC -DPIC -o .libs/text-io.o\n",
      "\u001b[95mcmd1:\u001b[0m depbase=`echo topsort.lo | sed 's|[^/]*$|.deps/&|;s|\\.lo$||'`;\\\n",
      "\u001b[95mcmd1:\u001b[0m /bin/bash ../../libtool  --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H   -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/../include  -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char  -std=c++11 -MT topsort.lo -MD -MP -MF $depbase.Tpo -c -o topsort.lo /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/topsort.cc &&\\\n",
      "\u001b[95mcmd1:\u001b[0m mv -f $depbase.Tpo $depbase.Plo\n",
      "\u001b[95mcmd1:\u001b[0m libtool: compile:  g++ -DHAVE_CONFIG_H -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/../include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char -std=c++11 -MT topsort.lo -MD -MP -MF .deps/topsort.Tpo -c /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/topsort.cc  -fPIC -DPIC -o .libs/topsort.o\n",
      "\u001b[95mcmd1:\u001b[0m depbase=`echo union.lo | sed 's|[^/]*$|.deps/&|;s|\\.lo$||'`;\\\n",
      "\u001b[95mcmd1:\u001b[0m /bin/bash ../../libtool  --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H   -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/../include  -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char  -std=c++11 -MT union.lo -MD -MP -MF $depbase.Tpo -c -o union.lo /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/union.cc &&\\\n",
      "\u001b[95mcmd1:\u001b[0m mv -f $depbase.Tpo $depbase.Plo\n",
      "\u001b[95mcmd1:\u001b[0m libtool: compile:  g++ -DHAVE_CONFIG_H -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/../include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char -std=c++11 -MT union.lo -MD -MP -MF .deps/union.Tpo -c /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/union.cc  -fPIC -DPIC -o .libs/union.o\n",
      "\u001b[95mcmd1:\u001b[0m depbase=`echo weight-class.lo | sed 's|[^/]*$|.deps/&|;s|\\.lo$||'`;\\\n",
      "\u001b[95mcmd1:\u001b[0m /bin/bash ../../libtool  --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H   -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/../include  -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char  -std=c++11 -MT weight-class.lo -MD -MP -MF $depbase.Tpo -c -o weight-class.lo /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/weight-class.cc &&\\\n",
      "\u001b[95mcmd1:\u001b[0m mv -f $depbase.Tpo $depbase.Plo\n",
      "\u001b[95mcmd1:\u001b[0m libtool: compile:  g++ -DHAVE_CONFIG_H -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/../include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char -std=c++11 -MT weight-class.lo -MD -MP -MF .deps/weight-class.Tpo -c /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/weight-class.cc  -fPIC -DPIC -o .libs/weight-class.o\n",
      "\u001b[95mcmd1:\u001b[0m depbase=`echo verify.lo | sed 's|[^/]*$|.deps/&|;s|\\.lo$||'`;\\\n",
      "\u001b[95mcmd1:\u001b[0m /bin/bash ../../libtool  --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H   -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/../include  -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char  -std=c++11 -MT verify.lo -MD -MP -MF $depbase.Tpo -c -o verify.lo /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/verify.cc &&\\\n",
      "\u001b[95mcmd1:\u001b[0m mv -f $depbase.Tpo $depbase.Plo\n",
      "\u001b[95mcmd1:\u001b[0m libtool: compile:  g++ -DHAVE_CONFIG_H -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/../include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char -std=c++11 -MT verify.lo -MD -MP -MF .deps/verify.Tpo -c /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/verify.cc  -fPIC -DPIC -o .libs/verify.o\n",
      "\u001b[95mcmd1:\u001b[0m /bin/bash ../../libtool  --tag=CXX   --mode=link g++  -std=c++11 -version-info 8:0:0 -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -o libfstscript.la -rpath /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-subbuild/openfst-populate-prefix/lib arciterator-class.lo arcsort.lo closure.lo compile.lo compose.lo concat.lo connect.lo convert.lo decode.lo determinize.lo difference.lo disambiguate.lo draw.lo encode.lo encodemapper-class.lo epsnormalize.lo equal.lo equivalent.lo fst-class.lo getters.lo info-impl.lo info.lo intersect.lo invert.lo isomorphic.lo map.lo minimize.lo print.lo project.lo prune.lo push.lo randequivalent.lo randgen.lo relabel.lo replace.lo reverse.lo reweight.lo rmepsilon.lo shortest-distance.lo shortest-path.lo stateiterator-class.lo synchronize.lo text-io.lo topsort.lo union.lo weight-class.lo verify.lo ../lib/libfst.la -lm -ldl -lgflags_nothreads -lglog -lpthread\n",
      "\u001b[95mcmd1:\u001b[0m libtool: link: g++  -fPIC -DPIC -shared -nostdlib /usr/lib/gcc/x86_64-linux-gnu/11/../../../x86_64-linux-gnu/crti.o /usr/lib/gcc/x86_64-linux-gnu/11/crtbeginS.o  .libs/arciterator-class.o .libs/arcsort.o .libs/closure.o .libs/compile.o .libs/compose.o .libs/concat.o .libs/connect.o .libs/convert.o .libs/decode.o .libs/determinize.o .libs/difference.o .libs/disambiguate.o .libs/draw.o .libs/encode.o .libs/encodemapper-class.o .libs/epsnormalize.o .libs/equal.o .libs/equivalent.o .libs/fst-class.o .libs/getters.o .libs/info-impl.o .libs/info.o .libs/intersect.o .libs/invert.o .libs/isomorphic.o .libs/map.o .libs/minimize.o .libs/print.o .libs/project.o .libs/prune.o .libs/push.o .libs/randequivalent.o .libs/randgen.o .libs/relabel.o .libs/replace.o .libs/reverse.o .libs/reweight.o .libs/rmepsilon.o .libs/shortest-distance.o .libs/shortest-path.o .libs/stateiterator-class.o .libs/synchronize.o .libs/text-io.o .libs/topsort.o .libs/union.o .libs/weight-class.o .libs/verify.o   -Wl,-rpath -Wl,/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-build/src/lib/.libs -Wl,-rpath -Wl,/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-subbuild/openfst-populate-prefix/lib -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build ../lib/.libs/libfst.so -ldl -lgflags_nothreads -lglog -lpthread -L/usr/lib/gcc/x86_64-linux-gnu/11 -L/usr/lib/gcc/x86_64-linux-gnu/11/../../../x86_64-linux-gnu -L/usr/lib/gcc/x86_64-linux-gnu/11/../../../../lib -L/lib/x86_64-linux-gnu -L/lib/../lib -L/usr/lib/x86_64-linux-gnu -L/usr/lib/../lib -L/usr/local/cuda/lib64/stubs -L/usr/lib/gcc/x86_64-linux-gnu/11/../../.. -lstdc++ -lm -lc -lgcc_s /usr/lib/gcc/x86_64-linux-gnu/11/crtendS.o /usr/lib/gcc/x86_64-linux-gnu/11/../../../x86_64-linux-gnu/crtn.o    -Wl,-soname -Wl,libfstscript.so.8 -o .libs/libfstscript.so.8.0.0\n",
      "\u001b[95mcmd1:\u001b[0m libtool: link: (cd \".libs\" && rm -f \"libfstscript.so.8\" && ln -s \"libfstscript.so.8.0.0\" \"libfstscript.so.8\")\n",
      "\u001b[95mcmd1:\u001b[0m libtool: link: (cd \".libs\" && rm -f \"libfstscript.so\" && ln -s \"libfstscript.so.8.0.0\" \"libfstscript.so\")\n",
      "\u001b[95mcmd1:\u001b[0m libtool: link: ( cd \".libs\" && rm -f \"libfstscript.la\" && ln -s \"../libfstscript.la\" \"libfstscript.la\" )\n",
      "\u001b[95mcmd1:\u001b[0m make[7]: Leaving directory '/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-build/src/script'\n",
      "\u001b[95mcmd1:\u001b[0m Making all in bin\n",
      "\u001b[95mcmd1:\u001b[0m make[7]: Entering directory '/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-build/src/bin'\n",
      "\u001b[95mcmd1:\u001b[0m depbase=`echo fstarcsort.o | sed 's|[^/]*$|.deps/&|;s|\\.o$||'`;\\\n",
      "\u001b[95mcmd1:\u001b[0m g++ -DHAVE_CONFIG_H   -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../script  -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char  -std=c++11 -MT fstarcsort.o -MD -MP -MF $depbase.Tpo -c -o fstarcsort.o /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/fstarcsort.cc &&\\\n",
      "\u001b[95mcmd1:\u001b[0m mv -f $depbase.Tpo $depbase.Po\n",
      "\u001b[95mcmd1:\u001b[0m depbase=`echo fstarcsort-main.o | sed 's|[^/]*$|.deps/&|;s|\\.o$||'`;\\\n",
      "\u001b[95mcmd1:\u001b[0m g++ -DHAVE_CONFIG_H   -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../script  -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char  -std=c++11 -MT fstarcsort-main.o -MD -MP -MF $depbase.Tpo -c -o fstarcsort-main.o /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/fstarcsort-main.cc &&\\\n",
      "\u001b[95mcmd1:\u001b[0m mv -f $depbase.Tpo $depbase.Po\n",
      "\u001b[95mcmd1:\u001b[0m depbase=`echo fstclosure.o | sed 's|[^/]*$|.deps/&|;s|\\.o$||'`;\\\n",
      "\u001b[95mcmd1:\u001b[0m g++ -DHAVE_CONFIG_H   -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../script  -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char  -std=c++11 -MT fstclosure.o -MD -MP -MF $depbase.Tpo -c -o fstclosure.o /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/fstclosure.cc &&\\\n",
      "\u001b[95mcmd1:\u001b[0m mv -f $depbase.Tpo $depbase.Po\n",
      "\u001b[95mcmd1:\u001b[0m depbase=`echo fstclosure-main.o | sed 's|[^/]*$|.deps/&|;s|\\.o$||'`;\\\n",
      "\u001b[95mcmd1:\u001b[0m g++ -DHAVE_CONFIG_H   -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../script  -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char  -std=c++11 -MT fstclosure-main.o -MD -MP -MF $depbase.Tpo -c -o fstclosure-main.o /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/fstclosure-main.cc &&\\\n",
      "\u001b[95mcmd1:\u001b[0m mv -f $depbase.Tpo $depbase.Po\n",
      "\u001b[95mcmd1:\u001b[0m depbase=`echo fstcompile.o | sed 's|[^/]*$|.deps/&|;s|\\.o$||'`;\\\n",
      "\u001b[95mcmd1:\u001b[0m g++ -DHAVE_CONFIG_H   -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../script  -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char  -std=c++11 -MT fstcompile.o -MD -MP -MF $depbase.Tpo -c -o fstcompile.o /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/fstcompile.cc &&\\\n",
      "\u001b[95mcmd1:\u001b[0m mv -f $depbase.Tpo $depbase.Po\n",
      "\u001b[95mcmd1:\u001b[0m depbase=`echo fstcompile-main.o | sed 's|[^/]*$|.deps/&|;s|\\.o$||'`;\\\n",
      "\u001b[95mcmd1:\u001b[0m g++ -DHAVE_CONFIG_H   -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../script  -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char  -std=c++11 -MT fstcompile-main.o -MD -MP -MF $depbase.Tpo -c -o fstcompile-main.o /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/fstcompile-main.cc &&\\\n",
      "\u001b[95mcmd1:\u001b[0m mv -f $depbase.Tpo $depbase.Po\n",
      "\u001b[95mcmd1:\u001b[0m depbase=`echo fstcompose.o | sed 's|[^/]*$|.deps/&|;s|\\.o$||'`;\\\n",
      "\u001b[95mcmd1:\u001b[0m g++ -DHAVE_CONFIG_H   -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../script  -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char  -std=c++11 -MT fstcompose.o -MD -MP -MF $depbase.Tpo -c -o fstcompose.o /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/fstcompose.cc &&\\\n",
      "\u001b[95mcmd1:\u001b[0m mv -f $depbase.Tpo $depbase.Po\n",
      "\u001b[95mcmd1:\u001b[0m depbase=`echo fstcompose-main.o | sed 's|[^/]*$|.deps/&|;s|\\.o$||'`;\\\n",
      "\u001b[95mcmd1:\u001b[0m g++ -DHAVE_CONFIG_H   -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../script  -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char  -std=c++11 -MT fstcompose-main.o -MD -MP -MF $depbase.Tpo -c -o fstcompose-main.o /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/fstcompose-main.cc &&\\\n",
      "\u001b[95mcmd1:\u001b[0m mv -f $depbase.Tpo $depbase.Po\n",
      "\u001b[95mcmd1:\u001b[0m depbase=`echo fstconcat.o | sed 's|[^/]*$|.deps/&|;s|\\.o$||'`;\\\n",
      "\u001b[95mcmd1:\u001b[0m g++ -DHAVE_CONFIG_H   -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../script  -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char  -std=c++11 -MT fstconcat.o -MD -MP -MF $depbase.Tpo -c -o fstconcat.o /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/fstconcat.cc &&\\\n",
      "\u001b[95mcmd1:\u001b[0m mv -f $depbase.Tpo $depbase.Po\n",
      "\u001b[95mcmd1:\u001b[0m depbase=`echo fstconcat-main.o | sed 's|[^/]*$|.deps/&|;s|\\.o$||'`;\\\n",
      "\u001b[95mcmd1:\u001b[0m g++ -DHAVE_CONFIG_H   -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../script  -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char  -std=c++11 -MT fstconcat-main.o -MD -MP -MF $depbase.Tpo -c -o fstconcat-main.o /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/fstconcat-main.cc &&\\\n",
      "\u001b[95mcmd1:\u001b[0m mv -f $depbase.Tpo $depbase.Po\n",
      "\u001b[95mcmd1:\u001b[0m depbase=`echo fstconnect.o | sed 's|[^/]*$|.deps/&|;s|\\.o$||'`;\\\n",
      "\u001b[95mcmd1:\u001b[0m g++ -DHAVE_CONFIG_H   -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../script  -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char  -std=c++11 -MT fstconnect.o -MD -MP -MF $depbase.Tpo -c -o fstconnect.o /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/fstconnect.cc &&\\\n",
      "\u001b[95mcmd1:\u001b[0m mv -f $depbase.Tpo $depbase.Po\n",
      "\u001b[95mcmd1:\u001b[0m depbase=`echo fstconnect-main.o | sed 's|[^/]*$|.deps/&|;s|\\.o$||'`;\\\n",
      "\u001b[95mcmd1:\u001b[0m g++ -DHAVE_CONFIG_H   -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../script  -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char  -std=c++11 -MT fstconnect-main.o -MD -MP -MF $depbase.Tpo -c -o fstconnect-main.o /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/fstconnect-main.cc &&\\\n",
      "\u001b[95mcmd1:\u001b[0m mv -f $depbase.Tpo $depbase.Po\n",
      "\u001b[95mcmd1:\u001b[0m depbase=`echo fstconvert.o | sed 's|[^/]*$|.deps/&|;s|\\.o$||'`;\\\n",
      "\u001b[95mcmd1:\u001b[0m g++ -DHAVE_CONFIG_H   -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../script  -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char  -std=c++11 -MT fstconvert.o -MD -MP -MF $depbase.Tpo -c -o fstconvert.o /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/fstconvert.cc &&\\\n",
      "\u001b[95mcmd1:\u001b[0m mv -f $depbase.Tpo $depbase.Po\n",
      "\u001b[95mcmd1:\u001b[0m depbase=`echo fstconvert-main.o | sed 's|[^/]*$|.deps/&|;s|\\.o$||'`;\\\n",
      "\u001b[95mcmd1:\u001b[0m g++ -DHAVE_CONFIG_H   -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../script  -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char  -std=c++11 -MT fstconvert-main.o -MD -MP -MF $depbase.Tpo -c -o fstconvert-main.o /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/fstconvert-main.cc &&\\\n",
      "\u001b[95mcmd1:\u001b[0m mv -f $depbase.Tpo $depbase.Po\n",
      "\u001b[95mcmd1:\u001b[0m depbase=`echo fstdeterminize.o | sed 's|[^/]*$|.deps/&|;s|\\.o$||'`;\\\n",
      "\u001b[95mcmd1:\u001b[0m g++ -DHAVE_CONFIG_H   -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../script  -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char  -std=c++11 -MT fstdeterminize.o -MD -MP -MF $depbase.Tpo -c -o fstdeterminize.o /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/fstdeterminize.cc &&\\\n",
      "\u001b[95mcmd1:\u001b[0m mv -f $depbase.Tpo $depbase.Po\n",
      "\u001b[95mcmd1:\u001b[0m depbase=`echo fstdeterminize-main.o | sed 's|[^/]*$|.deps/&|;s|\\.o$||'`;\\\n",
      "\u001b[95mcmd1:\u001b[0m g++ -DHAVE_CONFIG_H   -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../script  -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char  -std=c++11 -MT fstdeterminize-main.o -MD -MP -MF $depbase.Tpo -c -o fstdeterminize-main.o /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/fstdeterminize-main.cc &&\\\n",
      "\u001b[95mcmd1:\u001b[0m mv -f $depbase.Tpo $depbase.Po\n",
      "\u001b[95mcmd1:\u001b[0m depbase=`echo fstdifference.o | sed 's|[^/]*$|.deps/&|;s|\\.o$||'`;\\\n",
      "\u001b[95mcmd1:\u001b[0m g++ -DHAVE_CONFIG_H   -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../script  -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char  -std=c++11 -MT fstdifference.o -MD -MP -MF $depbase.Tpo -c -o fstdifference.o /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/fstdifference.cc &&\\\n",
      "\u001b[95mcmd1:\u001b[0m mv -f $depbase.Tpo $depbase.Po\n",
      "\u001b[95mcmd1:\u001b[0m depbase=`echo fstdifference-main.o | sed 's|[^/]*$|.deps/&|;s|\\.o$||'`;\\\n",
      "\u001b[95mcmd1:\u001b[0m g++ -DHAVE_CONFIG_H   -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../script  -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char  -std=c++11 -MT fstdifference-main.o -MD -MP -MF $depbase.Tpo -c -o fstdifference-main.o /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/fstdifference-main.cc &&\\\n",
      "\u001b[95mcmd1:\u001b[0m mv -f $depbase.Tpo $depbase.Po\n",
      "\u001b[95mcmd1:\u001b[0m depbase=`echo fstdisambiguate.o | sed 's|[^/]*$|.deps/&|;s|\\.o$||'`;\\\n",
      "\u001b[95mcmd1:\u001b[0m g++ -DHAVE_CONFIG_H   -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../script  -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char  -std=c++11 -MT fstdisambiguate.o -MD -MP -MF $depbase.Tpo -c -o fstdisambiguate.o /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/fstdisambiguate.cc &&\\\n",
      "\u001b[95mcmd1:\u001b[0m mv -f $depbase.Tpo $depbase.Po\n",
      "\u001b[95mcmd1:\u001b[0m depbase=`echo fstdisambiguate-main.o | sed 's|[^/]*$|.deps/&|;s|\\.o$||'`;\\\n",
      "\u001b[95mcmd1:\u001b[0m g++ -DHAVE_CONFIG_H   -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../script  -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char  -std=c++11 -MT fstdisambiguate-main.o -MD -MP -MF $depbase.Tpo -c -o fstdisambiguate-main.o /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/fstdisambiguate-main.cc &&\\\n",
      "\u001b[95mcmd1:\u001b[0m mv -f $depbase.Tpo $depbase.Po\n",
      "\u001b[95mcmd1:\u001b[0m depbase=`echo fstdraw.o | sed 's|[^/]*$|.deps/&|;s|\\.o$||'`;\\\n",
      "\u001b[95mcmd1:\u001b[0m g++ -DHAVE_CONFIG_H   -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../script  -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char  -std=c++11 -MT fstdraw.o -MD -MP -MF $depbase.Tpo -c -o fstdraw.o /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/fstdraw.cc &&\\\n",
      "\u001b[95mcmd1:\u001b[0m mv -f $depbase.Tpo $depbase.Po\n",
      "\u001b[95mcmd1:\u001b[0m depbase=`echo fstdraw-main.o | sed 's|[^/]*$|.deps/&|;s|\\.o$||'`;\\\n",
      "\u001b[95mcmd1:\u001b[0m g++ -DHAVE_CONFIG_H   -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../script  -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char  -std=c++11 -MT fstdraw-main.o -MD -MP -MF $depbase.Tpo -c -o fstdraw-main.o /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/fstdraw-main.cc &&\\\n",
      "\u001b[95mcmd1:\u001b[0m mv -f $depbase.Tpo $depbase.Po\n",
      "\u001b[95mcmd1:\u001b[0m depbase=`echo fstencode.o | sed 's|[^/]*$|.deps/&|;s|\\.o$||'`;\\\n",
      "\u001b[95mcmd1:\u001b[0m g++ -DHAVE_CONFIG_H   -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../script  -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char  -std=c++11 -MT fstencode.o -MD -MP -MF $depbase.Tpo -c -o fstencode.o /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/fstencode.cc &&\\\n",
      "\u001b[95mcmd1:\u001b[0m mv -f $depbase.Tpo $depbase.Po\n",
      "\u001b[95mcmd1:\u001b[0m depbase=`echo fstencode-main.o | sed 's|[^/]*$|.deps/&|;s|\\.o$||'`;\\\n",
      "\u001b[95mcmd1:\u001b[0m g++ -DHAVE_CONFIG_H   -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../script  -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char  -std=c++11 -MT fstencode-main.o -MD -MP -MF $depbase.Tpo -c -o fstencode-main.o /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/fstencode-main.cc &&\\\n",
      "\u001b[95mcmd1:\u001b[0m mv -f $depbase.Tpo $depbase.Po\n",
      "\u001b[95mcmd1:\u001b[0m depbase=`echo fstepsnormalize.o | sed 's|[^/]*$|.deps/&|;s|\\.o$||'`;\\\n",
      "\u001b[95mcmd1:\u001b[0m g++ -DHAVE_CONFIG_H   -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../script  -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char  -std=c++11 -MT fstepsnormalize.o -MD -MP -MF $depbase.Tpo -c -o fstepsnormalize.o /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/fstepsnormalize.cc &&\\\n",
      "\u001b[95mcmd1:\u001b[0m mv -f $depbase.Tpo $depbase.Po\n",
      "\u001b[95mcmd1:\u001b[0m depbase=`echo fstepsnormalize-main.o | sed 's|[^/]*$|.deps/&|;s|\\.o$||'`;\\\n",
      "\u001b[95mcmd1:\u001b[0m g++ -DHAVE_CONFIG_H   -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../script  -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char  -std=c++11 -MT fstepsnormalize-main.o -MD -MP -MF $depbase.Tpo -c -o fstepsnormalize-main.o /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/fstepsnormalize-main.cc &&\\\n",
      "\u001b[95mcmd1:\u001b[0m mv -f $depbase.Tpo $depbase.Po\n",
      "\u001b[95mcmd1:\u001b[0m depbase=`echo fstequal.o | sed 's|[^/]*$|.deps/&|;s|\\.o$||'`;\\\n",
      "\u001b[95mcmd1:\u001b[0m g++ -DHAVE_CONFIG_H   -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../script  -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char  -std=c++11 -MT fstequal.o -MD -MP -MF $depbase.Tpo -c -o fstequal.o /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/fstequal.cc &&\\\n",
      "\u001b[95mcmd1:\u001b[0m mv -f $depbase.Tpo $depbase.Po\n",
      "\u001b[95mcmd1:\u001b[0m depbase=`echo fstequal-main.o | sed 's|[^/]*$|.deps/&|;s|\\.o$||'`;\\\n",
      "\u001b[95mcmd1:\u001b[0m g++ -DHAVE_CONFIG_H   -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../script  -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char  -std=c++11 -MT fstequal-main.o -MD -MP -MF $depbase.Tpo -c -o fstequal-main.o /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/fstequal-main.cc &&\\\n",
      "\u001b[95mcmd1:\u001b[0m mv -f $depbase.Tpo $depbase.Po\n",
      "\u001b[95mcmd1:\u001b[0m depbase=`echo fstequivalent.o | sed 's|[^/]*$|.deps/&|;s|\\.o$||'`;\\\n",
      "\u001b[95mcmd1:\u001b[0m g++ -DHAVE_CONFIG_H   -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../script  -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char  -std=c++11 -MT fstequivalent.o -MD -MP -MF $depbase.Tpo -c -o fstequivalent.o /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/fstequivalent.cc &&\\\n",
      "\u001b[95mcmd1:\u001b[0m mv -f $depbase.Tpo $depbase.Po\n",
      "\u001b[95mcmd1:\u001b[0m depbase=`echo fstequivalent-main.o | sed 's|[^/]*$|.deps/&|;s|\\.o$||'`;\\\n",
      "\u001b[95mcmd1:\u001b[0m g++ -DHAVE_CONFIG_H   -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../script  -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char  -std=c++11 -MT fstequivalent-main.o -MD -MP -MF $depbase.Tpo -c -o fstequivalent-main.o /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/fstequivalent-main.cc &&\\\n",
      "\u001b[95mcmd1:\u001b[0m mv -f $depbase.Tpo $depbase.Po\n",
      "\u001b[95mcmd1:\u001b[0m depbase=`echo fstinfo.o | sed 's|[^/]*$|.deps/&|;s|\\.o$||'`;\\\n",
      "\u001b[95mcmd1:\u001b[0m g++ -DHAVE_CONFIG_H   -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../script  -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char  -std=c++11 -MT fstinfo.o -MD -MP -MF $depbase.Tpo -c -o fstinfo.o /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/fstinfo.cc &&\\\n",
      "\u001b[95mcmd1:\u001b[0m mv -f $depbase.Tpo $depbase.Po\n",
      "\u001b[95mcmd1:\u001b[0m depbase=`echo fstinfo-main.o | sed 's|[^/]*$|.deps/&|;s|\\.o$||'`;\\\n",
      "\u001b[95mcmd1:\u001b[0m g++ -DHAVE_CONFIG_H   -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../script  -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char  -std=c++11 -MT fstinfo-main.o -MD -MP -MF $depbase.Tpo -c -o fstinfo-main.o /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/fstinfo-main.cc &&\\\n",
      "\u001b[95mcmd1:\u001b[0m mv -f $depbase.Tpo $depbase.Po\n",
      "\u001b[95mcmd1:\u001b[0m depbase=`echo fstintersect.o | sed 's|[^/]*$|.deps/&|;s|\\.o$||'`;\\\n",
      "\u001b[95mcmd1:\u001b[0m g++ -DHAVE_CONFIG_H   -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../script  -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char  -std=c++11 -MT fstintersect.o -MD -MP -MF $depbase.Tpo -c -o fstintersect.o /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/fstintersect.cc &&\\\n",
      "\u001b[95mcmd1:\u001b[0m mv -f $depbase.Tpo $depbase.Po\n",
      "\u001b[95mcmd1:\u001b[0m depbase=`echo fstintersect-main.o | sed 's|[^/]*$|.deps/&|;s|\\.o$||'`;\\\n",
      "\u001b[95mcmd1:\u001b[0m g++ -DHAVE_CONFIG_H   -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../script  -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char  -std=c++11 -MT fstintersect-main.o -MD -MP -MF $depbase.Tpo -c -o fstintersect-main.o /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/fstintersect-main.cc &&\\\n",
      "\u001b[95mcmd1:\u001b[0m mv -f $depbase.Tpo $depbase.Po\n",
      "\u001b[95mcmd1:\u001b[0m depbase=`echo fstinvert.o | sed 's|[^/]*$|.deps/&|;s|\\.o$||'`;\\\n",
      "\u001b[95mcmd1:\u001b[0m g++ -DHAVE_CONFIG_H   -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../script  -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char  -std=c++11 -MT fstinvert.o -MD -MP -MF $depbase.Tpo -c -o fstinvert.o /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/fstinvert.cc &&\\\n",
      "\u001b[95mcmd1:\u001b[0m mv -f $depbase.Tpo $depbase.Po\n",
      "\u001b[95mcmd1:\u001b[0m depbase=`echo fstinvert-main.o | sed 's|[^/]*$|.deps/&|;s|\\.o$||'`;\\\n",
      "\u001b[95mcmd1:\u001b[0m g++ -DHAVE_CONFIG_H   -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../script  -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char  -std=c++11 -MT fstinvert-main.o -MD -MP -MF $depbase.Tpo -c -o fstinvert-main.o /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/fstinvert-main.cc &&\\\n",
      "\u001b[95mcmd1:\u001b[0m mv -f $depbase.Tpo $depbase.Po\n",
      "\u001b[95mcmd1:\u001b[0m depbase=`echo fstisomorphic.o | sed 's|[^/]*$|.deps/&|;s|\\.o$||'`;\\\n",
      "\u001b[95mcmd1:\u001b[0m g++ -DHAVE_CONFIG_H   -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../script  -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char  -std=c++11 -MT fstisomorphic.o -MD -MP -MF $depbase.Tpo -c -o fstisomorphic.o /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/fstisomorphic.cc &&\\\n",
      "\u001b[95mcmd1:\u001b[0m mv -f $depbase.Tpo $depbase.Po\n",
      "\u001b[95mcmd1:\u001b[0m depbase=`echo fstisomorphic-main.o | sed 's|[^/]*$|.deps/&|;s|\\.o$||'`;\\\n",
      "\u001b[95mcmd1:\u001b[0m g++ -DHAVE_CONFIG_H   -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../script  -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char  -std=c++11 -MT fstisomorphic-main.o -MD -MP -MF $depbase.Tpo -c -o fstisomorphic-main.o /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/fstisomorphic-main.cc &&\\\n",
      "\u001b[95mcmd1:\u001b[0m mv -f $depbase.Tpo $depbase.Po\n",
      "\u001b[95mcmd1:\u001b[0m depbase=`echo fstmap.o | sed 's|[^/]*$|.deps/&|;s|\\.o$||'`;\\\n",
      "\u001b[95mcmd1:\u001b[0m g++ -DHAVE_CONFIG_H   -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../script  -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char  -std=c++11 -MT fstmap.o -MD -MP -MF $depbase.Tpo -c -o fstmap.o /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/fstmap.cc &&\\\n",
      "\u001b[95mcmd1:\u001b[0m mv -f $depbase.Tpo $depbase.Po\n",
      "\u001b[95mcmd1:\u001b[0m depbase=`echo fstmap-main.o | sed 's|[^/]*$|.deps/&|;s|\\.o$||'`;\\\n",
      "\u001b[95mcmd1:\u001b[0m g++ -DHAVE_CONFIG_H   -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../script  -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char  -std=c++11 -MT fstmap-main.o -MD -MP -MF $depbase.Tpo -c -o fstmap-main.o /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/fstmap-main.cc &&\\\n",
      "\u001b[95mcmd1:\u001b[0m mv -f $depbase.Tpo $depbase.Po\n",
      "\u001b[95mcmd1:\u001b[0m depbase=`echo fstminimize.o | sed 's|[^/]*$|.deps/&|;s|\\.o$||'`;\\\n",
      "\u001b[95mcmd1:\u001b[0m g++ -DHAVE_CONFIG_H   -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../script  -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char  -std=c++11 -MT fstminimize.o -MD -MP -MF $depbase.Tpo -c -o fstminimize.o /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/fstminimize.cc &&\\\n",
      "\u001b[95mcmd1:\u001b[0m mv -f $depbase.Tpo $depbase.Po\n",
      "\u001b[95mcmd1:\u001b[0m depbase=`echo fstminimize-main.o | sed 's|[^/]*$|.deps/&|;s|\\.o$||'`;\\\n",
      "\u001b[95mcmd1:\u001b[0m g++ -DHAVE_CONFIG_H   -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../script  -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char  -std=c++11 -MT fstminimize-main.o -MD -MP -MF $depbase.Tpo -c -o fstminimize-main.o /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/fstminimize-main.cc &&\\\n",
      "\u001b[95mcmd1:\u001b[0m mv -f $depbase.Tpo $depbase.Po\n",
      "\u001b[95mcmd1:\u001b[0m depbase=`echo fstprint.o | sed 's|[^/]*$|.deps/&|;s|\\.o$||'`;\\\n",
      "\u001b[95mcmd1:\u001b[0m g++ -DHAVE_CONFIG_H   -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../script  -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char  -std=c++11 -MT fstprint.o -MD -MP -MF $depbase.Tpo -c -o fstprint.o /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/fstprint.cc &&\\\n",
      "\u001b[95mcmd1:\u001b[0m mv -f $depbase.Tpo $depbase.Po\n",
      "\u001b[95mcmd1:\u001b[0m depbase=`echo fstprint-main.o | sed 's|[^/]*$|.deps/&|;s|\\.o$||'`;\\\n",
      "\u001b[95mcmd1:\u001b[0m g++ -DHAVE_CONFIG_H   -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../script  -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char  -std=c++11 -MT fstprint-main.o -MD -MP -MF $depbase.Tpo -c -o fstprint-main.o /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/fstprint-main.cc &&\\\n",
      "\u001b[95mcmd1:\u001b[0m mv -f $depbase.Tpo $depbase.Po\n",
      "\u001b[95mcmd1:\u001b[0m depbase=`echo fstproject.o | sed 's|[^/]*$|.deps/&|;s|\\.o$||'`;\\\n",
      "\u001b[95mcmd1:\u001b[0m g++ -DHAVE_CONFIG_H   -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../script  -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char  -std=c++11 -MT fstproject.o -MD -MP -MF $depbase.Tpo -c -o fstproject.o /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/fstproject.cc &&\\\n",
      "\u001b[95mcmd1:\u001b[0m mv -f $depbase.Tpo $depbase.Po\n",
      "\u001b[95mcmd1:\u001b[0m depbase=`echo fstproject-main.o | sed 's|[^/]*$|.deps/&|;s|\\.o$||'`;\\\n",
      "\u001b[95mcmd1:\u001b[0m g++ -DHAVE_CONFIG_H   -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../script  -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char  -std=c++11 -MT fstproject-main.o -MD -MP -MF $depbase.Tpo -c -o fstproject-main.o /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/fstproject-main.cc &&\\\n",
      "\u001b[95mcmd1:\u001b[0m mv -f $depbase.Tpo $depbase.Po\n",
      "\u001b[95mcmd1:\u001b[0m depbase=`echo fstprune.o | sed 's|[^/]*$|.deps/&|;s|\\.o$||'`;\\\n",
      "\u001b[95mcmd1:\u001b[0m g++ -DHAVE_CONFIG_H   -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../script  -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char  -std=c++11 -MT fstprune.o -MD -MP -MF $depbase.Tpo -c -o fstprune.o /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/fstprune.cc &&\\\n",
      "\u001b[95mcmd1:\u001b[0m mv -f $depbase.Tpo $depbase.Po\n",
      "\u001b[95mcmd1:\u001b[0m depbase=`echo fstprune-main.o | sed 's|[^/]*$|.deps/&|;s|\\.o$||'`;\\\n",
      "\u001b[95mcmd1:\u001b[0m g++ -DHAVE_CONFIG_H   -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../script  -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char  -std=c++11 -MT fstprune-main.o -MD -MP -MF $depbase.Tpo -c -o fstprune-main.o /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/fstprune-main.cc &&\\\n",
      "\u001b[95mcmd1:\u001b[0m mv -f $depbase.Tpo $depbase.Po\n",
      "\u001b[95mcmd1:\u001b[0m depbase=`echo fstpush.o | sed 's|[^/]*$|.deps/&|;s|\\.o$||'`;\\\n",
      "\u001b[95mcmd1:\u001b[0m g++ -DHAVE_CONFIG_H   -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../script  -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char  -std=c++11 -MT fstpush.o -MD -MP -MF $depbase.Tpo -c -o fstpush.o /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/fstpush.cc &&\\\n",
      "\u001b[95mcmd1:\u001b[0m mv -f $depbase.Tpo $depbase.Po\n",
      "\u001b[95mcmd1:\u001b[0m depbase=`echo fstpush-main.o | sed 's|[^/]*$|.deps/&|;s|\\.o$||'`;\\\n",
      "\u001b[95mcmd1:\u001b[0m g++ -DHAVE_CONFIG_H   -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../script  -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char  -std=c++11 -MT fstpush-main.o -MD -MP -MF $depbase.Tpo -c -o fstpush-main.o /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/fstpush-main.cc &&\\\n",
      "\u001b[95mcmd1:\u001b[0m mv -f $depbase.Tpo $depbase.Po\n",
      "\u001b[95mcmd1:\u001b[0m depbase=`echo fstrandgen.o | sed 's|[^/]*$|.deps/&|;s|\\.o$||'`;\\\n",
      "\u001b[95mcmd1:\u001b[0m g++ -DHAVE_CONFIG_H   -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../script  -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char  -std=c++11 -MT fstrandgen.o -MD -MP -MF $depbase.Tpo -c -o fstrandgen.o /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/fstrandgen.cc &&\\\n",
      "\u001b[95mcmd1:\u001b[0m mv -f $depbase.Tpo $depbase.Po\n",
      "\u001b[95mcmd1:\u001b[0m depbase=`echo fstrandgen-main.o | sed 's|[^/]*$|.deps/&|;s|\\.o$||'`;\\\n",
      "\u001b[95mcmd1:\u001b[0m g++ -DHAVE_CONFIG_H   -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../script  -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char  -std=c++11 -MT fstrandgen-main.o -MD -MP -MF $depbase.Tpo -c -o fstrandgen-main.o /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/fstrandgen-main.cc &&\\\n",
      "\u001b[95mcmd1:\u001b[0m mv -f $depbase.Tpo $depbase.Po\n",
      "\u001b[95mcmd1:\u001b[0m depbase=`echo fstrelabel.o | sed 's|[^/]*$|.deps/&|;s|\\.o$||'`;\\\n",
      "\u001b[95mcmd1:\u001b[0m g++ -DHAVE_CONFIG_H   -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../script  -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char  -std=c++11 -MT fstrelabel.o -MD -MP -MF $depbase.Tpo -c -o fstrelabel.o /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/fstrelabel.cc &&\\\n",
      "\u001b[95mcmd1:\u001b[0m mv -f $depbase.Tpo $depbase.Po\n",
      "\u001b[95mcmd1:\u001b[0m depbase=`echo fstrelabel-main.o | sed 's|[^/]*$|.deps/&|;s|\\.o$||'`;\\\n",
      "\u001b[95mcmd1:\u001b[0m g++ -DHAVE_CONFIG_H   -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../script  -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char  -std=c++11 -MT fstrelabel-main.o -MD -MP -MF $depbase.Tpo -c -o fstrelabel-main.o /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/fstrelabel-main.cc &&\\\n",
      "\u001b[95mcmd1:\u001b[0m mv -f $depbase.Tpo $depbase.Po\n",
      "\u001b[95mcmd1:\u001b[0m depbase=`echo fstreplace.o | sed 's|[^/]*$|.deps/&|;s|\\.o$||'`;\\\n",
      "\u001b[95mcmd1:\u001b[0m g++ -DHAVE_CONFIG_H   -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../script  -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char  -std=c++11 -MT fstreplace.o -MD -MP -MF $depbase.Tpo -c -o fstreplace.o /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/fstreplace.cc &&\\\n",
      "\u001b[95mcmd1:\u001b[0m mv -f $depbase.Tpo $depbase.Po\n",
      "\u001b[95mcmd1:\u001b[0m depbase=`echo fstreplace-main.o | sed 's|[^/]*$|.deps/&|;s|\\.o$||'`;\\\n",
      "\u001b[95mcmd1:\u001b[0m g++ -DHAVE_CONFIG_H   -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../script  -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char  -std=c++11 -MT fstreplace-main.o -MD -MP -MF $depbase.Tpo -c -o fstreplace-main.o /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/fstreplace-main.cc &&\\\n",
      "\u001b[95mcmd1:\u001b[0m mv -f $depbase.Tpo $depbase.Po\n",
      "\u001b[95mcmd1:\u001b[0m depbase=`echo fstreverse.o | sed 's|[^/]*$|.deps/&|;s|\\.o$||'`;\\\n",
      "\u001b[95mcmd1:\u001b[0m g++ -DHAVE_CONFIG_H   -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../script  -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char  -std=c++11 -MT fstreverse.o -MD -MP -MF $depbase.Tpo -c -o fstreverse.o /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/fstreverse.cc &&\\\n",
      "\u001b[95mcmd1:\u001b[0m mv -f $depbase.Tpo $depbase.Po\n",
      "\u001b[95mcmd1:\u001b[0m depbase=`echo fstreverse-main.o | sed 's|[^/]*$|.deps/&|;s|\\.o$||'`;\\\n",
      "\u001b[95mcmd1:\u001b[0m g++ -DHAVE_CONFIG_H   -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../script  -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char  -std=c++11 -MT fstreverse-main.o -MD -MP -MF $depbase.Tpo -c -o fstreverse-main.o /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/fstreverse-main.cc &&\\\n",
      "\u001b[95mcmd1:\u001b[0m mv -f $depbase.Tpo $depbase.Po\n",
      "\u001b[95mcmd1:\u001b[0m depbase=`echo fstreweight.o | sed 's|[^/]*$|.deps/&|;s|\\.o$||'`;\\\n",
      "\u001b[95mcmd1:\u001b[0m g++ -DHAVE_CONFIG_H   -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../script  -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char  -std=c++11 -MT fstreweight.o -MD -MP -MF $depbase.Tpo -c -o fstreweight.o /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/fstreweight.cc &&\\\n",
      "\u001b[95mcmd1:\u001b[0m mv -f $depbase.Tpo $depbase.Po\n",
      "\u001b[95mcmd1:\u001b[0m depbase=`echo fstreweight-main.o | sed 's|[^/]*$|.deps/&|;s|\\.o$||'`;\\\n",
      "\u001b[95mcmd1:\u001b[0m g++ -DHAVE_CONFIG_H   -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../script  -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char  -std=c++11 -MT fstreweight-main.o -MD -MP -MF $depbase.Tpo -c -o fstreweight-main.o /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/fstreweight-main.cc &&\\\n",
      "\u001b[95mcmd1:\u001b[0m mv -f $depbase.Tpo $depbase.Po\n",
      "\u001b[95mcmd1:\u001b[0m depbase=`echo fstrmepsilon.o | sed 's|[^/]*$|.deps/&|;s|\\.o$||'`;\\\n",
      "\u001b[95mcmd1:\u001b[0m g++ -DHAVE_CONFIG_H   -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../script  -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char  -std=c++11 -MT fstrmepsilon.o -MD -MP -MF $depbase.Tpo -c -o fstrmepsilon.o /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/fstrmepsilon.cc &&\\\n",
      "\u001b[95mcmd1:\u001b[0m mv -f $depbase.Tpo $depbase.Po\n",
      "\u001b[95mcmd1:\u001b[0m depbase=`echo fstrmepsilon-main.o | sed 's|[^/]*$|.deps/&|;s|\\.o$||'`;\\\n",
      "\u001b[95mcmd1:\u001b[0m g++ -DHAVE_CONFIG_H   -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../script  -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char  -std=c++11 -MT fstrmepsilon-main.o -MD -MP -MF $depbase.Tpo -c -o fstrmepsilon-main.o /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/fstrmepsilon-main.cc &&\\\n",
      "\u001b[95mcmd1:\u001b[0m mv -f $depbase.Tpo $depbase.Po\n",
      "\u001b[95mcmd1:\u001b[0m depbase=`echo fstshortestdistance.o | sed 's|[^/]*$|.deps/&|;s|\\.o$||'`;\\\n",
      "\u001b[95mcmd1:\u001b[0m g++ -DHAVE_CONFIG_H   -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../script  -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char  -std=c++11 -MT fstshortestdistance.o -MD -MP -MF $depbase.Tpo -c -o fstshortestdistance.o /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/fstshortestdistance.cc &&\\\n",
      "\u001b[95mcmd1:\u001b[0m mv -f $depbase.Tpo $depbase.Po\n",
      "\u001b[95mcmd1:\u001b[0m depbase=`echo fstshortestdistance-main.o | sed 's|[^/]*$|.deps/&|;s|\\.o$||'`;\\\n",
      "\u001b[95mcmd1:\u001b[0m g++ -DHAVE_CONFIG_H   -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../script  -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char  -std=c++11 -MT fstshortestdistance-main.o -MD -MP -MF $depbase.Tpo -c -o fstshortestdistance-main.o /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/fstshortestdistance-main.cc &&\\\n",
      "\u001b[95mcmd1:\u001b[0m mv -f $depbase.Tpo $depbase.Po\n",
      "\u001b[95mcmd1:\u001b[0m depbase=`echo fstshortestpath.o | sed 's|[^/]*$|.deps/&|;s|\\.o$||'`;\\\n",
      "\u001b[95mcmd1:\u001b[0m g++ -DHAVE_CONFIG_H   -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../script  -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char  -std=c++11 -MT fstshortestpath.o -MD -MP -MF $depbase.Tpo -c -o fstshortestpath.o /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/fstshortestpath.cc &&\\\n",
      "\u001b[95mcmd1:\u001b[0m mv -f $depbase.Tpo $depbase.Po\n",
      "\u001b[95mcmd1:\u001b[0m depbase=`echo fstshortestpath-main.o | sed 's|[^/]*$|.deps/&|;s|\\.o$||'`;\\\n",
      "\u001b[95mcmd1:\u001b[0m g++ -DHAVE_CONFIG_H   -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../script  -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char  -std=c++11 -MT fstshortestpath-main.o -MD -MP -MF $depbase.Tpo -c -o fstshortestpath-main.o /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/fstshortestpath-main.cc &&\\\n",
      "\u001b[95mcmd1:\u001b[0m mv -f $depbase.Tpo $depbase.Po\n",
      "\u001b[95mcmd1:\u001b[0m depbase=`echo fstsymbols.o | sed 's|[^/]*$|.deps/&|;s|\\.o$||'`;\\\n",
      "\u001b[95mcmd1:\u001b[0m g++ -DHAVE_CONFIG_H   -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../script  -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char  -std=c++11 -MT fstsymbols.o -MD -MP -MF $depbase.Tpo -c -o fstsymbols.o /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/fstsymbols.cc &&\\\n",
      "\u001b[95mcmd1:\u001b[0m mv -f $depbase.Tpo $depbase.Po\n",
      "\u001b[95mcmd1:\u001b[0m depbase=`echo fstsymbols-main.o | sed 's|[^/]*$|.deps/&|;s|\\.o$||'`;\\\n",
      "\u001b[95mcmd1:\u001b[0m g++ -DHAVE_CONFIG_H   -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../script  -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char  -std=c++11 -MT fstsymbols-main.o -MD -MP -MF $depbase.Tpo -c -o fstsymbols-main.o /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/fstsymbols-main.cc &&\\\n",
      "\u001b[95mcmd1:\u001b[0m mv -f $depbase.Tpo $depbase.Po\n",
      "\u001b[95mcmd1:\u001b[0m depbase=`echo fstsynchronize.o | sed 's|[^/]*$|.deps/&|;s|\\.o$||'`;\\\n",
      "\u001b[95mcmd1:\u001b[0m g++ -DHAVE_CONFIG_H   -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../script  -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char  -std=c++11 -MT fstsynchronize.o -MD -MP -MF $depbase.Tpo -c -o fstsynchronize.o /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/fstsynchronize.cc &&\\\n",
      "\u001b[95mcmd1:\u001b[0m mv -f $depbase.Tpo $depbase.Po\n",
      "\u001b[95mcmd1:\u001b[0m depbase=`echo fstsynchronize-main.o | sed 's|[^/]*$|.deps/&|;s|\\.o$||'`;\\\n",
      "\u001b[95mcmd1:\u001b[0m g++ -DHAVE_CONFIG_H   -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../script  -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char  -std=c++11 -MT fstsynchronize-main.o -MD -MP -MF $depbase.Tpo -c -o fstsynchronize-main.o /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/fstsynchronize-main.cc &&\\\n",
      "\u001b[95mcmd1:\u001b[0m mv -f $depbase.Tpo $depbase.Po\n",
      "\u001b[95mcmd1:\u001b[0m depbase=`echo fsttopsort.o | sed 's|[^/]*$|.deps/&|;s|\\.o$||'`;\\\n",
      "\u001b[95mcmd1:\u001b[0m g++ -DHAVE_CONFIG_H   -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../script  -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char  -std=c++11 -MT fsttopsort.o -MD -MP -MF $depbase.Tpo -c -o fsttopsort.o /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/fsttopsort.cc &&\\\n",
      "\u001b[95mcmd1:\u001b[0m mv -f $depbase.Tpo $depbase.Po\n",
      "\u001b[95mcmd1:\u001b[0m depbase=`echo fsttopsort-main.o | sed 's|[^/]*$|.deps/&|;s|\\.o$||'`;\\\n",
      "\u001b[95mcmd1:\u001b[0m g++ -DHAVE_CONFIG_H   -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../script  -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char  -std=c++11 -MT fsttopsort-main.o -MD -MP -MF $depbase.Tpo -c -o fsttopsort-main.o /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/fsttopsort-main.cc &&\\\n",
      "\u001b[95mcmd1:\u001b[0m mv -f $depbase.Tpo $depbase.Po\n",
      "\u001b[95mcmd1:\u001b[0m depbase=`echo fstunion.o | sed 's|[^/]*$|.deps/&|;s|\\.o$||'`;\\\n",
      "\u001b[95mcmd1:\u001b[0m g++ -DHAVE_CONFIG_H   -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../script  -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char  -std=c++11 -MT fstunion.o -MD -MP -MF $depbase.Tpo -c -o fstunion.o /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/fstunion.cc &&\\\n",
      "\u001b[95mcmd1:\u001b[0m mv -f $depbase.Tpo $depbase.Po\n",
      "\u001b[95mcmd1:\u001b[0m depbase=`echo fstunion-main.o | sed 's|[^/]*$|.deps/&|;s|\\.o$||'`;\\\n",
      "\u001b[95mcmd1:\u001b[0m g++ -DHAVE_CONFIG_H   -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../script  -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char  -std=c++11 -MT fstunion-main.o -MD -MP -MF $depbase.Tpo -c -o fstunion-main.o /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/fstunion-main.cc &&\\\n",
      "\u001b[95mcmd1:\u001b[0m mv -f $depbase.Tpo $depbase.Po\n",
      "\u001b[95mcmd1:\u001b[0m /bin/bash ../../libtool  --tag=CXX   --mode=link g++  -std=c++11  -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -o fstarcsort fstarcsort.o fstarcsort-main.o ../script/libfstscript.la ../lib/libfst.la -lm -ldl -lgflags_nothreads -lglog -lpthread\n",
      "\u001b[95mcmd1:\u001b[0m libtool: link: g++ -std=c++11 -o .libs/fstarcsort fstarcsort.o fstarcsort-main.o  -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build ../script/.libs/libfstscript.so ../lib/.libs/libfst.so -lm -ldl -lgflags_nothreads -lglog -lpthread -Wl,-rpath -Wl,/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-subbuild/openfst-populate-prefix/lib\n",
      "\u001b[95mcmd1:\u001b[0m /bin/bash ../../libtool  --tag=CXX   --mode=link g++  -std=c++11  -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -o fstclosure fstclosure.o fstclosure-main.o ../script/libfstscript.la ../lib/libfst.la -lm -ldl -lgflags_nothreads -lglog -lpthread\n",
      "\u001b[95mcmd1:\u001b[0m /bin/bash ../../libtool  --tag=CXX   --mode=link g++  -std=c++11  -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -o fstcompile fstcompile.o fstcompile-main.o ../script/libfstscript.la ../lib/libfst.la -lm -ldl -lgflags_nothreads -lglog -lpthread\n",
      "\u001b[95mcmd1:\u001b[0m libtool: link: g++ -std=c++11 -o .libs/fstclosure fstclosure.o fstclosure-main.o  -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build ../script/.libs/libfstscript.so ../lib/.libs/libfst.so -lm -ldl -lgflags_nothreads -lglog -lpthread -Wl,-rpath -Wl,/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-subbuild/openfst-populate-prefix/lib\n",
      "\u001b[95mcmd1:\u001b[0m libtool: link: g++ -std=c++11 -o .libs/fstcompile fstcompile.o fstcompile-main.o  -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build ../script/.libs/libfstscript.so ../lib/.libs/libfst.so -lm -ldl -lgflags_nothreads -lglog -lpthread -Wl,-rpath -Wl,/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-subbuild/openfst-populate-prefix/lib\n",
      "\u001b[95mcmd1:\u001b[0m /bin/bash ../../libtool  --tag=CXX   --mode=link g++  -std=c++11  -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -o fstcompose fstcompose.o fstcompose-main.o ../script/libfstscript.la ../lib/libfst.la -lm -ldl -lgflags_nothreads -lglog -lpthread\n",
      "\u001b[95mcmd1:\u001b[0m libtool: link: g++ -std=c++11 -o .libs/fstcompose fstcompose.o fstcompose-main.o  -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build ../script/.libs/libfstscript.so ../lib/.libs/libfst.so -lm -ldl -lgflags_nothreads -lglog -lpthread -Wl,-rpath -Wl,/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-subbuild/openfst-populate-prefix/lib\n",
      "\u001b[95mcmd1:\u001b[0m /bin/bash ../../libtool  --tag=CXX   --mode=link g++  -std=c++11  -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -o fstconcat fstconcat.o fstconcat-main.o ../script/libfstscript.la ../lib/libfst.la -lm -ldl -lgflags_nothreads -lglog -lpthread\n",
      "\u001b[95mcmd1:\u001b[0m /bin/bash ../../libtool  --tag=CXX   --mode=link g++  -std=c++11  -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -o fstconnect fstconnect.o fstconnect-main.o ../script/libfstscript.la ../lib/libfst.la -lm -ldl -lgflags_nothreads -lglog -lpthread\n",
      "\u001b[95mcmd1:\u001b[0m libtool: link: g++ -std=c++11 -o .libs/fstconcat fstconcat.o fstconcat-main.o  -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build ../script/.libs/libfstscript.so ../lib/.libs/libfst.so -lm -ldl -lgflags_nothreads -lglog -lpthread -Wl,-rpath -Wl,/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-subbuild/openfst-populate-prefix/lib\n",
      "\u001b[95mcmd1:\u001b[0m /bin/bash ../../libtool  --tag=CXX   --mode=link g++  -std=c++11  -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -o fstconvert fstconvert.o fstconvert-main.o ../script/libfstscript.la ../lib/libfst.la -lm -ldl -lgflags_nothreads -lglog -lpthread\n",
      "\u001b[95mcmd1:\u001b[0m libtool: link: g++ -std=c++11 -o .libs/fstconnect fstconnect.o fstconnect-main.o  -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build ../script/.libs/libfstscript.so ../lib/.libs/libfst.so -lm -ldl -lgflags_nothreads -lglog -lpthread -Wl,-rpath -Wl,/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-subbuild/openfst-populate-prefix/lib\n",
      "\u001b[95mcmd1:\u001b[0m libtool: link: g++ -std=c++11 -o .libs/fstconvert fstconvert.o fstconvert-main.o  -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build ../script/.libs/libfstscript.so ../lib/.libs/libfst.so -lm -ldl -lgflags_nothreads -lglog -lpthread -Wl,-rpath -Wl,/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-subbuild/openfst-populate-prefix/lib\n",
      "\u001b[95mcmd1:\u001b[0m /bin/bash ../../libtool  --tag=CXX   --mode=link g++  -std=c++11  -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -o fstdeterminize fstdeterminize.o fstdeterminize-main.o ../script/libfstscript.la ../lib/libfst.la -lm -ldl -lgflags_nothreads -lglog -lpthread\n",
      "\u001b[95mcmd1:\u001b[0m libtool: link: g++ -std=c++11 -o .libs/fstdeterminize fstdeterminize.o fstdeterminize-main.o  -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build ../script/.libs/libfstscript.so ../lib/.libs/libfst.so -lm -ldl -lgflags_nothreads -lglog -lpthread -Wl,-rpath -Wl,/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-subbuild/openfst-populate-prefix/lib\n",
      "\u001b[95mcmd1:\u001b[0m /bin/bash ../../libtool  --tag=CXX   --mode=link g++  -std=c++11  -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -o fstdifference fstdifference.o fstdifference-main.o ../script/libfstscript.la ../lib/libfst.la -lm -ldl -lgflags_nothreads -lglog -lpthread\n",
      "\u001b[95mcmd1:\u001b[0m /bin/bash ../../libtool  --tag=CXX   --mode=link g++  -std=c++11  -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -o fstdisambiguate fstdisambiguate.o fstdisambiguate-main.o ../script/libfstscript.la ../lib/libfst.la -lm -ldl -lgflags_nothreads -lglog -lpthread\n",
      "\u001b[95mcmd1:\u001b[0m /bin/bash ../../libtool  --tag=CXX   --mode=link g++  -std=c++11  -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -o fstdraw fstdraw.o fstdraw-main.o ../script/libfstscript.la ../lib/libfst.la -lm -ldl -lgflags_nothreads -lglog -lpthread\n",
      "\u001b[95mcmd1:\u001b[0m libtool: link: g++ -std=c++11 -o .libs/fstdifference fstdifference.o fstdifference-main.o  -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build ../script/.libs/libfstscript.so ../lib/.libs/libfst.so -lm -ldl -lgflags_nothreads -lglog -lpthread -Wl,-rpath -Wl,/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-subbuild/openfst-populate-prefix/lib\n",
      "\u001b[95mcmd1:\u001b[0m libtool: link: g++ -std=c++11 -o .libs/fstdisambiguate fstdisambiguate.o fstdisambiguate-main.o  -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build ../script/.libs/libfstscript.so ../lib/.libs/libfst.so -lm -ldl -lgflags_nothreads -lglog -lpthread -Wl,-rpath -Wl,/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-subbuild/openfst-populate-prefix/lib\n",
      "\u001b[95mcmd1:\u001b[0m libtool: link: g++ -std=c++11 -o .libs/fstdraw fstdraw.o fstdraw-main.o  -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build ../script/.libs/libfstscript.so ../lib/.libs/libfst.so -lm -ldl -lgflags_nothreads -lglog -lpthread -Wl,-rpath -Wl,/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-subbuild/openfst-populate-prefix/lib\n",
      "\u001b[95mcmd1:\u001b[0m /bin/bash ../../libtool  --tag=CXX   --mode=link g++  -std=c++11  -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -o fstencode fstencode.o fstencode-main.o ../script/libfstscript.la ../lib/libfst.la -lm -ldl -lgflags_nothreads -lglog -lpthread\n",
      "\u001b[95mcmd1:\u001b[0m libtool: link: g++ -std=c++11 -o .libs/fstencode fstencode.o fstencode-main.o  -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build ../script/.libs/libfstscript.so ../lib/.libs/libfst.so -lm -ldl -lgflags_nothreads -lglog -lpthread -Wl,-rpath -Wl,/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-subbuild/openfst-populate-prefix/lib\n",
      "\u001b[95mcmd1:\u001b[0m /bin/bash ../../libtool  --tag=CXX   --mode=link g++  -std=c++11  -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -o fstepsnormalize fstepsnormalize.o fstepsnormalize-main.o ../script/libfstscript.la ../lib/libfst.la -lm -ldl -lgflags_nothreads -lglog -lpthread\n",
      "\u001b[95mcmd1:\u001b[0m /bin/bash ../../libtool  --tag=CXX   --mode=link g++  -std=c++11  -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -o fstequal fstequal.o fstequal-main.o ../script/libfstscript.la ../lib/libfst.la -lm -ldl -lgflags_nothreads -lglog -lpthread\n",
      "\u001b[95mcmd1:\u001b[0m /bin/bash ../../libtool  --tag=CXX   --mode=link g++  -std=c++11  -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -o fstequivalent fstequivalent.o fstequivalent-main.o ../script/libfstscript.la ../lib/libfst.la -lm -ldl -lgflags_nothreads -lglog -lpthread\n",
      "\u001b[95mcmd1:\u001b[0m libtool: link: g++ -std=c++11 -o .libs/fstepsnormalize fstepsnormalize.o fstepsnormalize-main.o  -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build ../script/.libs/libfstscript.so ../lib/.libs/libfst.so -lm -ldl -lgflags_nothreads -lglog -lpthread -Wl,-rpath -Wl,/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-subbuild/openfst-populate-prefix/lib\n",
      "\u001b[95mcmd1:\u001b[0m libtool: link: g++ -std=c++11 -o .libs/fstequal fstequal.o fstequal-main.o  -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build ../script/.libs/libfstscript.so ../lib/.libs/libfst.so -lm -ldl -lgflags_nothreads -lglog -lpthread -Wl,-rpath -Wl,/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-subbuild/openfst-populate-prefix/lib\n",
      "\u001b[95mcmd1:\u001b[0m libtool: link: g++ -std=c++11 -o .libs/fstequivalent fstequivalent.o fstequivalent-main.o  -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build ../script/.libs/libfstscript.so ../lib/.libs/libfst.so -lm -ldl -lgflags_nothreads -lglog -lpthread -Wl,-rpath -Wl,/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-subbuild/openfst-populate-prefix/lib\n",
      "\u001b[95mcmd1:\u001b[0m /bin/bash ../../libtool  --tag=CXX   --mode=link g++  -std=c++11  -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -o fstinfo fstinfo.o fstinfo-main.o ../script/libfstscript.la ../lib/libfst.la -lm -ldl -lgflags_nothreads -lglog -lpthread\n",
      "\u001b[95mcmd1:\u001b[0m libtool: link: g++ -std=c++11 -o .libs/fstinfo fstinfo.o fstinfo-main.o  -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build ../script/.libs/libfstscript.so ../lib/.libs/libfst.so -lm -ldl -lgflags_nothreads -lglog -lpthread -Wl,-rpath -Wl,/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-subbuild/openfst-populate-prefix/lib\n",
      "\u001b[95mcmd1:\u001b[0m /bin/bash ../../libtool  --tag=CXX   --mode=link g++  -std=c++11  -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -o fstintersect fstintersect.o fstintersect-main.o ../script/libfstscript.la ../lib/libfst.la -lm -ldl -lgflags_nothreads -lglog -lpthread\n",
      "\u001b[95mcmd1:\u001b[0m /bin/bash ../../libtool  --tag=CXX   --mode=link g++  -std=c++11  -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -o fstinvert fstinvert.o fstinvert-main.o ../script/libfstscript.la ../lib/libfst.la -lm -ldl -lgflags_nothreads -lglog -lpthread\n",
      "\u001b[95mcmd1:\u001b[0m /bin/bash ../../libtool  --tag=CXX   --mode=link g++  -std=c++11  -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -o fstisomorphic fstisomorphic.o fstisomorphic-main.o ../script/libfstscript.la ../lib/libfst.la -lm -ldl -lgflags_nothreads -lglog -lpthread\n",
      "\u001b[95mcmd1:\u001b[0m libtool: link: g++ -std=c++11 -o .libs/fstintersect fstintersect.o fstintersect-main.o  -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build ../script/.libs/libfstscript.so ../lib/.libs/libfst.so -lm -ldl -lgflags_nothreads -lglog -lpthread -Wl,-rpath -Wl,/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-subbuild/openfst-populate-prefix/lib\n",
      "\u001b[95mcmd1:\u001b[0m libtool: link: g++ -std=c++11 -o .libs/fstinvert fstinvert.o fstinvert-main.o  -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build ../script/.libs/libfstscript.so ../lib/.libs/libfst.so -lm -ldl -lgflags_nothreads -lglog -lpthread -Wl,-rpath -Wl,/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-subbuild/openfst-populate-prefix/lib\n",
      "\u001b[95mcmd1:\u001b[0m libtool: link: g++ -std=c++11 -o .libs/fstisomorphic fstisomorphic.o fstisomorphic-main.o  -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build ../script/.libs/libfstscript.so ../lib/.libs/libfst.so -lm -ldl -lgflags_nothreads -lglog -lpthread -Wl,-rpath -Wl,/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-subbuild/openfst-populate-prefix/lib\n",
      "\u001b[95mcmd1:\u001b[0m /bin/bash ../../libtool  --tag=CXX   --mode=link g++  -std=c++11  -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -o fstmap fstmap.o fstmap-main.o ../script/libfstscript.la ../lib/libfst.la -lm -ldl -lgflags_nothreads -lglog -lpthread\n",
      "\u001b[95mcmd1:\u001b[0m libtool: link: g++ -std=c++11 -o .libs/fstmap fstmap.o fstmap-main.o  -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build ../script/.libs/libfstscript.so ../lib/.libs/libfst.so -lm -ldl -lgflags_nothreads -lglog -lpthread -Wl,-rpath -Wl,/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-subbuild/openfst-populate-prefix/lib\n",
      "\u001b[95mcmd1:\u001b[0m /bin/bash ../../libtool  --tag=CXX   --mode=link g++  -std=c++11  -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -o fstminimize fstminimize.o fstminimize-main.o ../script/libfstscript.la ../lib/libfst.la -lm -ldl -lgflags_nothreads -lglog -lpthread\n",
      "\u001b[95mcmd1:\u001b[0m /bin/bash ../../libtool  --tag=CXX   --mode=link g++  -std=c++11  -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -o fstprint fstprint.o fstprint-main.o ../script/libfstscript.la ../lib/libfst.la -lm -ldl -lgflags_nothreads -lglog -lpthread\n",
      "\u001b[95mcmd1:\u001b[0m /bin/bash ../../libtool  --tag=CXX   --mode=link g++  -std=c++11  -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -o fstproject fstproject.o fstproject-main.o ../script/libfstscript.la ../lib/libfst.la -lm -ldl -lgflags_nothreads -lglog -lpthread\n",
      "\u001b[95mcmd1:\u001b[0m libtool: link: g++ -std=c++11 -o .libs/fstminimize fstminimize.o fstminimize-main.o  -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build ../script/.libs/libfstscript.so ../lib/.libs/libfst.so -lm -ldl -lgflags_nothreads -lglog -lpthread -Wl,-rpath -Wl,/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-subbuild/openfst-populate-prefix/lib\n",
      "\u001b[95mcmd1:\u001b[0m libtool: link: g++ -std=c++11 -o .libs/fstprint fstprint.o fstprint-main.o  -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build ../script/.libs/libfstscript.so ../lib/.libs/libfst.so -lm -ldl -lgflags_nothreads -lglog -lpthread -Wl,-rpath -Wl,/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-subbuild/openfst-populate-prefix/lib\n",
      "\u001b[95mcmd1:\u001b[0m libtool: link: g++ -std=c++11 -o .libs/fstproject fstproject.o fstproject-main.o  -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build ../script/.libs/libfstscript.so ../lib/.libs/libfst.so -lm -ldl -lgflags_nothreads -lglog -lpthread -Wl,-rpath -Wl,/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-subbuild/openfst-populate-prefix/lib\n",
      "\u001b[95mcmd1:\u001b[0m /bin/bash ../../libtool  --tag=CXX   --mode=link g++  -std=c++11  -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -o fstprune fstprune.o fstprune-main.o ../script/libfstscript.la ../lib/libfst.la -lm -ldl -lgflags_nothreads -lglog -lpthread\n",
      "\u001b[95mcmd1:\u001b[0m libtool: link: g++ -std=c++11 -o .libs/fstprune fstprune.o fstprune-main.o  -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build ../script/.libs/libfstscript.so ../lib/.libs/libfst.so -lm -ldl -lgflags_nothreads -lglog -lpthread -Wl,-rpath -Wl,/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-subbuild/openfst-populate-prefix/lib\n",
      "\u001b[95mcmd1:\u001b[0m /bin/bash ../../libtool  --tag=CXX   --mode=link g++  -std=c++11  -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -o fstpush fstpush.o fstpush-main.o ../script/libfstscript.la ../lib/libfst.la -lm -ldl -lgflags_nothreads -lglog -lpthread\n",
      "\u001b[95mcmd1:\u001b[0m /bin/bash ../../libtool  --tag=CXX   --mode=link g++  -std=c++11  -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -o fstrandgen fstrandgen.o fstrandgen-main.o ../script/libfstscript.la ../lib/libfst.la -lm -ldl -lgflags_nothreads -lglog -lpthread\n",
      "\u001b[95mcmd1:\u001b[0m /bin/bash ../../libtool  --tag=CXX   --mode=link g++  -std=c++11  -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -o fstrelabel fstrelabel.o fstrelabel-main.o ../script/libfstscript.la ../lib/libfst.la -lm -ldl -lgflags_nothreads -lglog -lpthread\n",
      "\u001b[95mcmd1:\u001b[0m libtool: link: g++ -std=c++11 -o .libs/fstpush fstpush.o fstpush-main.o  -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build ../script/.libs/libfstscript.so ../lib/.libs/libfst.so -lm -ldl -lgflags_nothreads -lglog -lpthread -Wl,-rpath -Wl,/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-subbuild/openfst-populate-prefix/lib\n",
      "\u001b[95mcmd1:\u001b[0m libtool: link: g++ -std=c++11 -o .libs/fstrandgen fstrandgen.o fstrandgen-main.o  -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build ../script/.libs/libfstscript.so ../lib/.libs/libfst.so -lm -ldl -lgflags_nothreads -lglog -lpthread -Wl,-rpath -Wl,/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-subbuild/openfst-populate-prefix/lib\n",
      "\u001b[95mcmd1:\u001b[0m libtool: link: g++ -std=c++11 -o .libs/fstrelabel fstrelabel.o fstrelabel-main.o  -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build ../script/.libs/libfstscript.so ../lib/.libs/libfst.so -lm -ldl -lgflags_nothreads -lglog -lpthread -Wl,-rpath -Wl,/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-subbuild/openfst-populate-prefix/lib\n",
      "\u001b[95mcmd1:\u001b[0m /bin/bash ../../libtool  --tag=CXX   --mode=link g++  -std=c++11  -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -o fstreplace fstreplace.o fstreplace-main.o ../script/libfstscript.la ../lib/libfst.la -lm -ldl -lgflags_nothreads -lglog -lpthread\n",
      "\u001b[95mcmd1:\u001b[0m libtool: link: g++ -std=c++11 -o .libs/fstreplace fstreplace.o fstreplace-main.o  -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build ../script/.libs/libfstscript.so ../lib/.libs/libfst.so -lm -ldl -lgflags_nothreads -lglog -lpthread -Wl,-rpath -Wl,/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-subbuild/openfst-populate-prefix/lib\n",
      "\u001b[95mcmd1:\u001b[0m /bin/bash ../../libtool  --tag=CXX   --mode=link g++  -std=c++11  -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -o fstreverse fstreverse.o fstreverse-main.o ../script/libfstscript.la ../lib/libfst.la -lm -ldl -lgflags_nothreads -lglog -lpthread\n",
      "\u001b[95mcmd1:\u001b[0m /bin/bash ../../libtool  --tag=CXX   --mode=link g++  -std=c++11  -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -o fstreweight fstreweight.o fstreweight-main.o ../script/libfstscript.la ../lib/libfst.la -lm -ldl -lgflags_nothreads -lglog -lpthread\n",
      "\u001b[95mcmd1:\u001b[0m libtool: link: g++ -std=c++11 -o .libs/fstreverse fstreverse.o fstreverse-main.o  -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build ../script/.libs/libfstscript.so ../lib/.libs/libfst.so -lm -ldl -lgflags_nothreads -lglog -lpthread -Wl,-rpath -Wl,/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-subbuild/openfst-populate-prefix/lib\n",
      "\u001b[95mcmd1:\u001b[0m /bin/bash ../../libtool  --tag=CXX   --mode=link g++  -std=c++11  -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -o fstrmepsilon fstrmepsilon.o fstrmepsilon-main.o ../script/libfstscript.la ../lib/libfst.la -lm -ldl -lgflags_nothreads -lglog -lpthread\n",
      "\u001b[95mcmd1:\u001b[0m libtool: link: g++ -std=c++11 -o .libs/fstreweight fstreweight.o fstreweight-main.o  -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build ../script/.libs/libfstscript.so ../lib/.libs/libfst.so -lm -ldl -lgflags_nothreads -lglog -lpthread -Wl,-rpath -Wl,/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-subbuild/openfst-populate-prefix/lib\n",
      "\u001b[95mcmd1:\u001b[0m libtool: link: g++ -std=c++11 -o .libs/fstrmepsilon fstrmepsilon.o fstrmepsilon-main.o  -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build ../script/.libs/libfstscript.so ../lib/.libs/libfst.so -lm -ldl -lgflags_nothreads -lglog -lpthread -Wl,-rpath -Wl,/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-subbuild/openfst-populate-prefix/lib\n",
      "\u001b[95mcmd1:\u001b[0m /bin/bash ../../libtool  --tag=CXX   --mode=link g++  -std=c++11  -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -o fstshortestdistance fstshortestdistance.o fstshortestdistance-main.o ../script/libfstscript.la ../lib/libfst.la -lm -ldl -lgflags_nothreads -lglog -lpthread\n",
      "\u001b[95mcmd1:\u001b[0m libtool: link: g++ -std=c++11 -o .libs/fstshortestdistance fstshortestdistance.o fstshortestdistance-main.o  -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build ../script/.libs/libfstscript.so ../lib/.libs/libfst.so -lm -ldl -lgflags_nothreads -lglog -lpthread -Wl,-rpath -Wl,/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-subbuild/openfst-populate-prefix/lib\n",
      "\u001b[95mcmd1:\u001b[0m /bin/bash ../../libtool  --tag=CXX   --mode=link g++  -std=c++11  -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -o fstshortestpath fstshortestpath.o fstshortestpath-main.o ../script/libfstscript.la ../lib/libfst.la -lm -ldl -lgflags_nothreads -lglog -lpthread\n",
      "\u001b[95mcmd1:\u001b[0m /bin/bash ../../libtool  --tag=CXX   --mode=link g++  -std=c++11  -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -o fstsymbols fstsymbols.o fstsymbols-main.o ../script/libfstscript.la ../lib/libfst.la -lm -ldl -lgflags_nothreads -lglog -lpthread\n",
      "\u001b[95mcmd1:\u001b[0m libtool: link: g++ -std=c++11 -o .libs/fstshortestpath fstshortestpath.o fstshortestpath-main.o  -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build ../script/.libs/libfstscript.so ../lib/.libs/libfst.so -lm -ldl -lgflags_nothreads -lglog -lpthread -Wl,-rpath -Wl,/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-subbuild/openfst-populate-prefix/lib\n",
      "\u001b[95mcmd1:\u001b[0m /bin/bash ../../libtool  --tag=CXX   --mode=link g++  -std=c++11  -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -o fstsynchronize fstsynchronize.o fstsynchronize-main.o ../script/libfstscript.la ../lib/libfst.la -lm -ldl -lgflags_nothreads -lglog -lpthread\n",
      "\u001b[95mcmd1:\u001b[0m libtool: link: g++ -std=c++11 -o .libs/fstsymbols fstsymbols.o fstsymbols-main.o  -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build ../script/.libs/libfstscript.so ../lib/.libs/libfst.so -lm -ldl -lgflags_nothreads -lglog -lpthread -Wl,-rpath -Wl,/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-subbuild/openfst-populate-prefix/lib\n",
      "\u001b[95mcmd1:\u001b[0m libtool: link: g++ -std=c++11 -o .libs/fstsynchronize fstsynchronize.o fstsynchronize-main.o  -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build ../script/.libs/libfstscript.so ../lib/.libs/libfst.so -lm -ldl -lgflags_nothreads -lglog -lpthread -Wl,-rpath -Wl,/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-subbuild/openfst-populate-prefix/lib\n",
      "\u001b[95mcmd1:\u001b[0m /bin/bash ../../libtool  --tag=CXX   --mode=link g++  -std=c++11  -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -o fsttopsort fsttopsort.o fsttopsort-main.o ../script/libfstscript.la ../lib/libfst.la -lm -ldl -lgflags_nothreads -lglog -lpthread\n",
      "\u001b[95mcmd1:\u001b[0m libtool: link: g++ -std=c++11 -o .libs/fsttopsort fsttopsort.o fsttopsort-main.o  -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build ../script/.libs/libfstscript.so ../lib/.libs/libfst.so -lm -ldl -lgflags_nothreads -lglog -lpthread -Wl,-rpath -Wl,/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-subbuild/openfst-populate-prefix/lib\n",
      "\u001b[95mcmd1:\u001b[0m /bin/bash ../../libtool  --tag=CXX   --mode=link g++  -std=c++11  -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -o fstunion fstunion.o fstunion-main.o ../script/libfstscript.la ../lib/libfst.la -lm -ldl -lgflags_nothreads -lglog -lpthread\n",
      "\u001b[95mcmd1:\u001b[0m libtool: link: g++ -std=c++11 -o .libs/fstunion fstunion.o fstunion-main.o  -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build ../script/.libs/libfstscript.so ../lib/.libs/libfst.so -lm -ldl -lgflags_nothreads -lglog -lpthread -Wl,-rpath -Wl,/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-subbuild/openfst-populate-prefix/lib\n",
      "\u001b[95mcmd1:\u001b[0m make[7]: Leaving directory '/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-build/src/bin'\n",
      "\u001b[95mcmd1:\u001b[0m Making all in test\n",
      "\u001b[95mcmd1:\u001b[0m make[7]: Entering directory '/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-build/src/test'\n",
      "\u001b[95mcmd1:\u001b[0m make[7]: Nothing to be done for 'all'.\n",
      "\u001b[95mcmd1:\u001b[0m make[7]: Leaving directory '/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-build/src/test'\n",
      "\u001b[95mcmd1:\u001b[0m Making all in extensions\n",
      "\u001b[95mcmd1:\u001b[0m make[7]: Entering directory '/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-build/src/extensions'\n",
      "\u001b[95mcmd1:\u001b[0m make[8]: Entering directory '/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-build/src/extensions'\n",
      "\u001b[95mcmd1:\u001b[0m make[8]: Nothing to be done for 'all-am'.\n",
      "\u001b[95mcmd1:\u001b[0m make[8]: Leaving directory '/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-build/src/extensions'\n",
      "\u001b[95mcmd1:\u001b[0m make[7]: Leaving directory '/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-build/src/extensions'\n",
      "\u001b[95mcmd1:\u001b[0m make[7]: Entering directory '/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-build/src'\n",
      "\u001b[95mcmd1:\u001b[0m make[7]: Nothing to be done for 'all-am'.\n",
      "\u001b[95mcmd1:\u001b[0m make[7]: Leaving directory '/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-build/src'\n",
      "\u001b[95mcmd1:\u001b[0m make[6]: Leaving directory '/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-build/src'\n",
      "\u001b[95mcmd1:\u001b[0m make[6]: Entering directory '/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-build'\n",
      "\u001b[95mcmd1:\u001b[0m make[6]: Leaving directory '/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-build'\n",
      "\u001b[95mcmd1:\u001b[0m make[5]: Leaving directory '/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-build'\n",
      "\u001b[95mcmd1:\u001b[0m make[4]: Leaving directory '/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-build'\n",
      "\u001b[95mcmd1:\u001b[0m cd /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-build && /usr/local/lib/python3.11/dist-packages/cmake/data/bin/cmake -E touch /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/build/temp.linux-x86_64-cpython-39/openfst-prefix/src/openfst-stamp/openfst-build\n",
      "\u001b[95mcmd1:\u001b[0m [ 39%] Performing install step for 'openfst'\n",
      "\u001b[95mcmd1:\u001b[0m cd /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-build && /usr/bin/gmake install\n",
      "\u001b[95mcmd1:\u001b[0m gmake[4]: Entering directory '/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-build'\n",
      "\u001b[95mcmd1:\u001b[0m Making install in src\n",
      "\u001b[95mcmd1:\u001b[0m gmake[5]: Entering directory '/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-build/src'\n",
      "\u001b[95mcmd1:\u001b[0m Making install in include\n",
      "\u001b[95mcmd1:\u001b[0m gmake[6]: Entering directory '/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-build/src/include'\n",
      "\u001b[95mcmd1:\u001b[0m gmake[7]: Entering directory '/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-build/src/include'\n",
      "\u001b[95mcmd1:\u001b[0m gmake[7]: Nothing to be done for 'install-exec-am'.\n",
      "\u001b[95mcmd1:\u001b[0m  /usr/bin/mkdir -p '/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-subbuild/openfst-populate-prefix/include'\n",
      "\u001b[95mcmd1:\u001b[0m  /usr/bin/mkdir -p '/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-subbuild/openfst-populate-prefix/include/fst'\n",
      "\u001b[95mcmd1:\u001b[0m  /usr/bin/install -c -m 644  /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/accumulator.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/add-on.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/arc-arena.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/arc-map.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/arc.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/arcfilter.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/arcsort.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/bi-table.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/cache.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/closure.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/compact-fst.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/compat.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/complement.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/compose-filter.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/compose.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/concat.h fst/config.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/connect.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/const-fst.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/determinize.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/dfs-visit.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/difference.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/disambiguate.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/edit-fst.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/encode.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/epsnormalize.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/equal.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/equivalent.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/expanded-fst.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/expectation-weight.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/factor-weight.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/filter-state.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/flags.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/float-weight.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/fst-decl.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/fst.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/fstlib.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/generic-register.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/heap.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/icu.h '/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-subbuild/openfst-populate-prefix/include/fst'\n",
      "\u001b[95mcmd1:\u001b[0m  /usr/bin/mkdir -p '/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-subbuild/openfst-populate-prefix/include/fst'\n",
      "\u001b[95mcmd1:\u001b[0m  /usr/bin/install -c -m 644  /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/intersect.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/interval-set.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/invert.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/isomorphic.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/label-reachable.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/lexicographic-weight.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/lock.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/log.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/lookahead-filter.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/lookahead-matcher.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/map.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/mapped-file.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/matcher-fst.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/matcher.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/memory.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/minimize.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/mutable-fst.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/pair-weight.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/partition.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/power-weight.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/product-weight.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/project.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/properties.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/prune.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/push.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/queue.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/randequivalent.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/randgen.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/rational.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/register.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/relabel.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/replace-util.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/replace.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/reverse.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/reweight.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/rmepsilon.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/rmfinalepsilon.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/set-weight.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/shortest-distance.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/shortest-path.h '/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-subbuild/openfst-populate-prefix/include/fst'\n",
      "\u001b[95mcmd1:\u001b[0m  /usr/bin/mkdir -p '/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-subbuild/openfst-populate-prefix/include/fst/script'\n",
      "\u001b[95mcmd1:\u001b[0m  /usr/bin/install -c -m 644  /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/script/arc-class.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/script/arciterator-class.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/script/arcsort.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/script/arg-packs.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/script/closure.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/script/compile-impl.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/script/compile.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/script/compose.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/script/concat.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/script/connect.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/script/convert.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/script/decode.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/script/determinize.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/script/difference.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/script/disambiguate.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/script/draw-impl.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/script/draw.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/script/encode.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/script/encodemapper-class.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/script/epsnormalize.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/script/equal.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/script/equivalent.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/script/fst-class.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/script/fstscript.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/script/getters.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/script/info-impl.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/script/info.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/script/intersect.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/script/invert.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/script/isomorphic.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/script/map.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/script/minimize.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/script/print-impl.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/script/print.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/script/project.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/script/prune.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/script/push.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/script/randequivalent.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/script/randgen.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/script/register.h '/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-subbuild/openfst-populate-prefix/include/fst/script'\n",
      "\u001b[95mcmd1:\u001b[0m  /usr/bin/mkdir -p '/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-subbuild/openfst-populate-prefix/include/fst/script'\n",
      "\u001b[95mcmd1:\u001b[0m  /usr/bin/install -c -m 644  /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/script/relabel.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/script/replace.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/script/reverse.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/script/reweight.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/script/rmepsilon.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/script/script-impl.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/script/shortest-distance.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/script/shortest-path.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/script/stateiterator-class.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/script/synchronize.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/script/text-io.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/script/topsort.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/script/union.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/script/weight-class.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/script/fstscript-decl.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/script/verify.h '/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-subbuild/openfst-populate-prefix/include/fst/script'\n",
      "\u001b[95mcmd1:\u001b[0m  /usr/bin/mkdir -p '/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-subbuild/openfst-populate-prefix/include/fst'\n",
      "\u001b[95mcmd1:\u001b[0m  /usr/bin/install -c -m 644  /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/signed-log-weight.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/sparse-power-weight.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/sparse-tuple-weight.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/state-map.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/state-reachable.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/state-table.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/statesort.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/string-weight.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/string.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/symbol-table-ops.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/symbol-table.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/synchronize.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/test-properties.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/topsort.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/tuple-weight.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/types.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/union-find.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/union-weight.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/union.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/util.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/vector-fst.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/verify.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/visit.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/weight.h '/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-subbuild/openfst-populate-prefix/include/fst'\n",
      "\u001b[95mcmd1:\u001b[0m gmake[7]: Leaving directory '/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-build/src/include'\n",
      "\u001b[95mcmd1:\u001b[0m gmake[6]: Leaving directory '/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-build/src/include'\n",
      "\u001b[95mcmd1:\u001b[0m Making install in lib\n",
      "\u001b[95mcmd1:\u001b[0m gmake[6]: Entering directory '/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-build/src/lib'\n",
      "\u001b[95mcmd1:\u001b[0m gmake[7]: Entering directory '/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-build/src/lib'\n",
      "\u001b[95mcmd1:\u001b[0m  /usr/bin/mkdir -p '/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-subbuild/openfst-populate-prefix/lib'\n",
      "\u001b[95mcmd1:\u001b[0m  /bin/bash ../../libtool   --mode=install /usr/bin/install -c   libfst.la '/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-subbuild/openfst-populate-prefix/lib'\n",
      "\u001b[95mcmd1:\u001b[0m libtool: install: /usr/bin/install -c .libs/libfst.so.8.0.0 /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-subbuild/openfst-populate-prefix/lib/libfst.so.8.0.0\n",
      "\u001b[95mcmd1:\u001b[0m libtool: install: (cd /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-subbuild/openfst-populate-prefix/lib && { ln -s -f libfst.so.8.0.0 libfst.so.8 || { rm -f libfst.so.8 && ln -s libfst.so.8.0.0 libfst.so.8; }; })\n",
      "\u001b[95mcmd1:\u001b[0m libtool: install: (cd /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-subbuild/openfst-populate-prefix/lib && { ln -s -f libfst.so.8.0.0 libfst.so || { rm -f libfst.so && ln -s libfst.so.8.0.0 libfst.so; }; })\n",
      "\u001b[95mcmd1:\u001b[0m libtool: install: /usr/bin/install -c .libs/libfst.lai /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-subbuild/openfst-populate-prefix/lib/libfst.la\n",
      "\u001b[95mcmd1:\u001b[0m libtool: finish: PATH=\"/root/miniconda3/envs/b2txt25_lm/bin:/root/miniconda3/condabin:/opt/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/tools/node/bin:/tools/google-cloud-sdk/bin:/sbin\" ldconfig -n /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-subbuild/openfst-populate-prefix/lib\n",
      "\u001b[95mcmd1:\u001b[0m ----------------------------------------------------------------------\n",
      "\u001b[95mcmd1:\u001b[0m Libraries have been installed in:\n",
      "\u001b[95mcmd1:\u001b[0m    /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-subbuild/openfst-populate-prefix/lib\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[95mcmd1:\u001b[0m If you ever happen to want to link against installed libraries\n",
      "\u001b[95mcmd1:\u001b[0m in a given directory, LIBDIR, you must either use libtool, and\n",
      "\u001b[95mcmd1:\u001b[0m specify the full pathname of the library, or use the `-LLIBDIR'\n",
      "\u001b[95mcmd1:\u001b[0m flag during linking and do at least one of the following:\n",
      "\u001b[95mcmd1:\u001b[0m    - add LIBDIR to the `LD_LIBRARY_PATH' environment variable\n",
      "\u001b[95mcmd1:\u001b[0m      during execution\n",
      "\u001b[95mcmd1:\u001b[0m    - add LIBDIR to the `LD_RUN_PATH' environment variable\n",
      "\u001b[95mcmd1:\u001b[0m      during linking\n",
      "\u001b[95mcmd1:\u001b[0m    - use the `-Wl,-rpath -Wl,LIBDIR' linker flag\n",
      "\u001b[95mcmd1:\u001b[0m    - have your system administrator add LIBDIR to `/etc/ld.so.conf'\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[95mcmd1:\u001b[0m See any operating system documentation about shared libraries for\n",
      "\u001b[95mcmd1:\u001b[0m more information, such as the ld(1) and ld.so(8) manual pages.\n",
      "\u001b[95mcmd1:\u001b[0m ----------------------------------------------------------------------\n",
      "\u001b[95mcmd1:\u001b[0m gmake[7]: Nothing to be done for 'install-data-am'.\n",
      "\u001b[95mcmd1:\u001b[0m gmake[7]: Leaving directory '/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-build/src/lib'\n",
      "\u001b[95mcmd1:\u001b[0m gmake[6]: Leaving directory '/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-build/src/lib'\n",
      "\u001b[95mcmd1:\u001b[0m Making install in script\n",
      "\u001b[95mcmd1:\u001b[0m gmake[6]: Entering directory '/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-build/src/script'\n",
      "\u001b[95mcmd1:\u001b[0m gmake[7]: Entering directory '/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-build/src/script'\n",
      "\u001b[95mcmd1:\u001b[0m  /usr/bin/mkdir -p '/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-subbuild/openfst-populate-prefix/lib'\n",
      "\u001b[95mcmd1:\u001b[0m  /bin/bash ../../libtool   --mode=install /usr/bin/install -c   libfstscript.la '/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-subbuild/openfst-populate-prefix/lib'\n",
      "\u001b[95mcmd1:\u001b[0m libtool: install: warning: relinking `libfstscript.la'\n",
      "\u001b[95mcmd1:\u001b[0m libtool: install: (cd /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-build/src/script; /bin/bash /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-build/libtool  --tag CXX --mode=relink g++ -std=c++11 -version-info 8:0:0 -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -o libfstscript.la -rpath /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-subbuild/openfst-populate-prefix/lib arciterator-class.lo arcsort.lo closure.lo compile.lo compose.lo concat.lo connect.lo convert.lo decode.lo determinize.lo difference.lo disambiguate.lo draw.lo encode.lo encodemapper-class.lo epsnormalize.lo equal.lo equivalent.lo fst-class.lo getters.lo info-impl.lo info.lo intersect.lo invert.lo isomorphic.lo map.lo minimize.lo print.lo project.lo prune.lo push.lo randequivalent.lo randgen.lo relabel.lo replace.lo reverse.lo reweight.lo rmepsilon.lo shortest-distance.lo shortest-path.lo stateiterator-class.lo synchronize.lo text-io.lo topsort.lo union.lo weight-class.lo verify.lo ../lib/libfst.la -lm -ldl -lgflags_nothreads -lglog -lpthread )\n",
      "\u001b[95mcmd1:\u001b[0m libtool: relink: g++  -fPIC -DPIC -shared -nostdlib /usr/lib/gcc/x86_64-linux-gnu/11/../../../x86_64-linux-gnu/crti.o /usr/lib/gcc/x86_64-linux-gnu/11/crtbeginS.o  .libs/arciterator-class.o .libs/arcsort.o .libs/closure.o .libs/compile.o .libs/compose.o .libs/concat.o .libs/connect.o .libs/convert.o .libs/decode.o .libs/determinize.o .libs/difference.o .libs/disambiguate.o .libs/draw.o .libs/encode.o .libs/encodemapper-class.o .libs/epsnormalize.o .libs/equal.o .libs/equivalent.o .libs/fst-class.o .libs/getters.o .libs/info-impl.o .libs/info.o .libs/intersect.o .libs/invert.o .libs/isomorphic.o .libs/map.o .libs/minimize.o .libs/print.o .libs/project.o .libs/prune.o .libs/push.o .libs/randequivalent.o .libs/randgen.o .libs/relabel.o .libs/replace.o .libs/reverse.o .libs/reweight.o .libs/rmepsilon.o .libs/shortest-distance.o .libs/shortest-path.o .libs/stateiterator-class.o .libs/synchronize.o .libs/text-io.o .libs/topsort.o .libs/union.o .libs/weight-class.o .libs/verify.o   -Wl,-rpath -Wl,/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-subbuild/openfst-populate-prefix/lib -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-subbuild/openfst-populate-prefix/lib -lfst -ldl -lgflags_nothreads -lglog -lpthread -L/usr/lib/gcc/x86_64-linux-gnu/11 -L/usr/lib/gcc/x86_64-linux-gnu/11/../../../x86_64-linux-gnu -L/usr/lib/gcc/x86_64-linux-gnu/11/../../../../lib -L/lib/x86_64-linux-gnu -L/lib/../lib -L/usr/lib/x86_64-linux-gnu -L/usr/lib/../lib -L/usr/local/cuda/lib64/stubs -L/usr/lib/gcc/x86_64-linux-gnu/11/../../.. -lstdc++ -lm -lc -lgcc_s /usr/lib/gcc/x86_64-linux-gnu/11/crtendS.o /usr/lib/gcc/x86_64-linux-gnu/11/../../../x86_64-linux-gnu/crtn.o    -Wl,-soname -Wl,libfstscript.so.8 -o .libs/libfstscript.so.8.0.0\n",
      "\u001b[95mcmd1:\u001b[0m libtool: install: /usr/bin/install -c .libs/libfstscript.so.8.0.0T /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-subbuild/openfst-populate-prefix/lib/libfstscript.so.8.0.0\n",
      "\u001b[95mcmd1:\u001b[0m libtool: install: (cd /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-subbuild/openfst-populate-prefix/lib && { ln -s -f libfstscript.so.8.0.0 libfstscript.so.8 || { rm -f libfstscript.so.8 && ln -s libfstscript.so.8.0.0 libfstscript.so.8; }; })\n",
      "\u001b[95mcmd1:\u001b[0m libtool: install: (cd /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-subbuild/openfst-populate-prefix/lib && { ln -s -f libfstscript.so.8.0.0 libfstscript.so || { rm -f libfstscript.so && ln -s libfstscript.so.8.0.0 libfstscript.so; }; })\n",
      "\u001b[95mcmd1:\u001b[0m libtool: install: /usr/bin/install -c .libs/libfstscript.lai /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-subbuild/openfst-populate-prefix/lib/libfstscript.la\n",
      "\u001b[95mcmd1:\u001b[0m libtool: finish: PATH=\"/root/miniconda3/envs/b2txt25_lm/bin:/root/miniconda3/condabin:/opt/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/tools/node/bin:/tools/google-cloud-sdk/bin:/sbin\" ldconfig -n /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-subbuild/openfst-populate-prefix/lib\n",
      "\u001b[95mcmd1:\u001b[0m ----------------------------------------------------------------------\n",
      "\u001b[95mcmd1:\u001b[0m Libraries have been installed in:\n",
      "\u001b[95mcmd1:\u001b[0m    /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-subbuild/openfst-populate-prefix/lib\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[95mcmd1:\u001b[0m If you ever happen to want to link against installed libraries\n",
      "\u001b[95mcmd1:\u001b[0m in a given directory, LIBDIR, you must either use libtool, and\n",
      "\u001b[95mcmd1:\u001b[0m specify the full pathname of the library, or use the `-LLIBDIR'\n",
      "\u001b[95mcmd1:\u001b[0m flag during linking and do at least one of the following:\n",
      "\u001b[95mcmd1:\u001b[0m    - add LIBDIR to the `LD_LIBRARY_PATH' environment variable\n",
      "\u001b[95mcmd1:\u001b[0m      during execution\n",
      "\u001b[95mcmd1:\u001b[0m    - add LIBDIR to the `LD_RUN_PATH' environment variable\n",
      "\u001b[95mcmd1:\u001b[0m      during linking\n",
      "\u001b[95mcmd1:\u001b[0m    - use the `-Wl,-rpath -Wl,LIBDIR' linker flag\n",
      "\u001b[95mcmd1:\u001b[0m    - have your system administrator add LIBDIR to `/etc/ld.so.conf'\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[95mcmd1:\u001b[0m See any operating system documentation about shared libraries for\n",
      "\u001b[95mcmd1:\u001b[0m more information, such as the ld(1) and ld.so(8) manual pages.\n",
      "\u001b[95mcmd1:\u001b[0m ----------------------------------------------------------------------\n",
      "\u001b[95mcmd1:\u001b[0m gmake[7]: Nothing to be done for 'install-data-am'.\n",
      "\u001b[95mcmd1:\u001b[0m gmake[7]: Leaving directory '/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-build/src/script'\n",
      "\u001b[95mcmd1:\u001b[0m gmake[6]: Leaving directory '/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-build/src/script'\n",
      "\u001b[95mcmd1:\u001b[0m Making install in bin\n",
      "\u001b[95mcmd1:\u001b[0m gmake[6]: Entering directory '/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-build/src/bin'\n",
      "\u001b[95mcmd1:\u001b[0m gmake[7]: Entering directory '/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-build/src/bin'\n",
      "\u001b[95mcmd1:\u001b[0m  /usr/bin/mkdir -p '/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-subbuild/openfst-populate-prefix/bin'\n",
      "\u001b[95mcmd1:\u001b[0m   /bin/bash ../../libtool   --mode=install /usr/bin/install -c fstarcsort fstclosure fstcompile fstcompose fstconcat fstconnect fstconvert fstdeterminize fstdifference fstdisambiguate fstdraw fstencode fstepsnormalize fstequal fstequivalent fstinfo fstintersect fstinvert fstisomorphic fstmap fstminimize fstprint fstproject fstprune fstpush fstrandgen fstrelabel fstreplace fstreverse fstreweight fstrmepsilon fstshortestdistance fstshortestpath fstsymbols fstsynchronize fsttopsort fstunion '/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-subbuild/openfst-populate-prefix/bin'\n",
      "\u001b[95mcmd1:\u001b[0m libtool: install: /usr/bin/install -c .libs/fstarcsort /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-subbuild/openfst-populate-prefix/bin/fstarcsort\n",
      "\u001b[95mcmd1:\u001b[0m libtool: install: /usr/bin/install -c .libs/fstclosure /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-subbuild/openfst-populate-prefix/bin/fstclosure\n",
      "\u001b[95mcmd1:\u001b[0m libtool: install: /usr/bin/install -c .libs/fstcompile /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-subbuild/openfst-populate-prefix/bin/fstcompile\n",
      "\u001b[95mcmd1:\u001b[0m libtool: install: /usr/bin/install -c .libs/fstcompose /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-subbuild/openfst-populate-prefix/bin/fstcompose\n",
      "\u001b[95mcmd1:\u001b[0m libtool: install: /usr/bin/install -c .libs/fstconcat /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-subbuild/openfst-populate-prefix/bin/fstconcat\n",
      "\u001b[95mcmd1:\u001b[0m libtool: install: /usr/bin/install -c .libs/fstconnect /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-subbuild/openfst-populate-prefix/bin/fstconnect\n",
      "\u001b[95mcmd1:\u001b[0m libtool: install: /usr/bin/install -c .libs/fstconvert /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-subbuild/openfst-populate-prefix/bin/fstconvert\n",
      "\u001b[95mcmd1:\u001b[0m libtool: install: /usr/bin/install -c .libs/fstdeterminize /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-subbuild/openfst-populate-prefix/bin/fstdeterminize\n",
      "\u001b[95mcmd1:\u001b[0m libtool: install: /usr/bin/install -c .libs/fstdifference /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-subbuild/openfst-populate-prefix/bin/fstdifference\n",
      "\u001b[95mcmd1:\u001b[0m libtool: install: /usr/bin/install -c .libs/fstdisambiguate /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-subbuild/openfst-populate-prefix/bin/fstdisambiguate\n",
      "\u001b[95mcmd1:\u001b[0m libtool: install: /usr/bin/install -c .libs/fstdraw /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-subbuild/openfst-populate-prefix/bin/fstdraw\n",
      "\u001b[95mcmd1:\u001b[0m libtool: install: /usr/bin/install -c .libs/fstencode /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-subbuild/openfst-populate-prefix/bin/fstencode\n",
      "\u001b[95mcmd1:\u001b[0m libtool: install: /usr/bin/install -c .libs/fstepsnormalize /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-subbuild/openfst-populate-prefix/bin/fstepsnormalize\n",
      "\u001b[95mcmd1:\u001b[0m libtool: install: /usr/bin/install -c .libs/fstequal /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-subbuild/openfst-populate-prefix/bin/fstequal\n",
      "\u001b[95mcmd1:\u001b[0m libtool: install: /usr/bin/install -c .libs/fstequivalent /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-subbuild/openfst-populate-prefix/bin/fstequivalent\n",
      "\u001b[95mcmd1:\u001b[0m libtool: install: /usr/bin/install -c .libs/fstinfo /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-subbuild/openfst-populate-prefix/bin/fstinfo\n",
      "\u001b[95mcmd1:\u001b[0m libtool: install: /usr/bin/install -c .libs/fstintersect /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-subbuild/openfst-populate-prefix/bin/fstintersect\n",
      "\u001b[95mcmd1:\u001b[0m libtool: install: /usr/bin/install -c .libs/fstinvert /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-subbuild/openfst-populate-prefix/bin/fstinvert\n",
      "\u001b[95mcmd1:\u001b[0m libtool: install: /usr/bin/install -c .libs/fstisomorphic /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-subbuild/openfst-populate-prefix/bin/fstisomorphic\n",
      "\u001b[95mcmd1:\u001b[0m libtool: install: /usr/bin/install -c .libs/fstmap /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-subbuild/openfst-populate-prefix/bin/fstmap\n",
      "\u001b[95mcmd1:\u001b[0m libtool: install: /usr/bin/install -c .libs/fstminimize /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-subbuild/openfst-populate-prefix/bin/fstminimize\n",
      "\u001b[95mcmd1:\u001b[0m libtool: install: /usr/bin/install -c .libs/fstprint /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-subbuild/openfst-populate-prefix/bin/fstprint\n",
      "\u001b[95mcmd1:\u001b[0m libtool: install: /usr/bin/install -c .libs/fstproject /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-subbuild/openfst-populate-prefix/bin/fstproject\n",
      "\u001b[95mcmd1:\u001b[0m libtool: install: /usr/bin/install -c .libs/fstprune /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-subbuild/openfst-populate-prefix/bin/fstprune\n",
      "\u001b[95mcmd1:\u001b[0m libtool: install: /usr/bin/install -c .libs/fstpush /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-subbuild/openfst-populate-prefix/bin/fstpush\n",
      "\u001b[95mcmd1:\u001b[0m libtool: install: /usr/bin/install -c .libs/fstrandgen /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-subbuild/openfst-populate-prefix/bin/fstrandgen\n",
      "\u001b[95mcmd1:\u001b[0m libtool: install: /usr/bin/install -c .libs/fstrelabel /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-subbuild/openfst-populate-prefix/bin/fstrelabel\n",
      "\u001b[95mcmd1:\u001b[0m libtool: install: /usr/bin/install -c .libs/fstreplace /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-subbuild/openfst-populate-prefix/bin/fstreplace\n",
      "\u001b[95mcmd1:\u001b[0m libtool: install: /usr/bin/install -c .libs/fstreverse /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-subbuild/openfst-populate-prefix/bin/fstreverse\n",
      "\u001b[95mcmd1:\u001b[0m libtool: install: /usr/bin/install -c .libs/fstreweight /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-subbuild/openfst-populate-prefix/bin/fstreweight\n",
      "\u001b[95mcmd1:\u001b[0m libtool: install: /usr/bin/install -c .libs/fstrmepsilon /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-subbuild/openfst-populate-prefix/bin/fstrmepsilon\n",
      "\u001b[95mcmd1:\u001b[0m libtool: install: /usr/bin/install -c .libs/fstshortestdistance /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-subbuild/openfst-populate-prefix/bin/fstshortestdistance\n",
      "\u001b[95mcmd1:\u001b[0m libtool: install: /usr/bin/install -c .libs/fstshortestpath /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-subbuild/openfst-populate-prefix/bin/fstshortestpath\n",
      "\u001b[95mcmd1:\u001b[0m libtool: install: /usr/bin/install -c .libs/fstsymbols /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-subbuild/openfst-populate-prefix/bin/fstsymbols\n",
      "\u001b[95mcmd1:\u001b[0m libtool: install: /usr/bin/install -c .libs/fstsynchronize /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-subbuild/openfst-populate-prefix/bin/fstsynchronize\n",
      "\u001b[95mcmd1:\u001b[0m libtool: install: /usr/bin/install -c .libs/fsttopsort /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-subbuild/openfst-populate-prefix/bin/fsttopsort\n",
      "\u001b[95mcmd1:\u001b[0m libtool: install: /usr/bin/install -c .libs/fstunion /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-subbuild/openfst-populate-prefix/bin/fstunion\n",
      "\u001b[95mcmd1:\u001b[0m gmake[7]: Nothing to be done for 'install-data-am'.\n",
      "\u001b[95mcmd1:\u001b[0m gmake[7]: Leaving directory '/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-build/src/bin'\n",
      "\u001b[95mcmd1:\u001b[0m gmake[6]: Leaving directory '/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-build/src/bin'\n",
      "\u001b[95mcmd1:\u001b[0m Making install in test\n",
      "\u001b[95mcmd1:\u001b[0m gmake[6]: Entering directory '/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-build/src/test'\n",
      "\u001b[95mcmd1:\u001b[0m gmake[7]: Entering directory '/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-build/src/test'\n",
      "\u001b[95mcmd1:\u001b[0m gmake[7]: Nothing to be done for 'install-exec-am'.\n",
      "\u001b[95mcmd1:\u001b[0m gmake[7]: Nothing to be done for 'install-data-am'.\n",
      "\u001b[95mcmd1:\u001b[0m gmake[7]: Leaving directory '/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-build/src/test'\n",
      "\u001b[95mcmd1:\u001b[0m gmake[6]: Leaving directory '/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-build/src/test'\n",
      "\u001b[95mcmd1:\u001b[0m Making install in extensions\n",
      "\u001b[95mcmd1:\u001b[0m gmake[6]: Entering directory '/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-build/src/extensions'\n",
      "\u001b[95mcmd1:\u001b[0m gmake[7]: Entering directory '/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-build/src/extensions'\n",
      "\u001b[95mcmd1:\u001b[0m gmake[8]: Entering directory '/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-build/src/extensions'\n",
      "\u001b[95mcmd1:\u001b[0m gmake[8]: Nothing to be done for 'install-exec-am'.\n",
      "\u001b[95mcmd1:\u001b[0m gmake[8]: Nothing to be done for 'install-data-am'.\n",
      "\u001b[95mcmd1:\u001b[0m gmake[8]: Leaving directory '/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-build/src/extensions'\n",
      "\u001b[95mcmd1:\u001b[0m gmake[7]: Leaving directory '/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-build/src/extensions'\n",
      "\u001b[95mcmd1:\u001b[0m gmake[6]: Leaving directory '/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-build/src/extensions'\n",
      "\u001b[95mcmd1:\u001b[0m gmake[6]: Entering directory '/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-build/src'\n",
      "\u001b[95mcmd1:\u001b[0m gmake[7]: Entering directory '/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-build/src'\n",
      "\u001b[95mcmd1:\u001b[0m gmake[7]: Nothing to be done for 'install-exec-am'.\n",
      "\u001b[95mcmd1:\u001b[0m gmake[7]: Nothing to be done for 'install-data-am'.\n",
      "\u001b[95mcmd1:\u001b[0m gmake[7]: Leaving directory '/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-build/src'\n",
      "\u001b[95mcmd1:\u001b[0m gmake[6]: Leaving directory '/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-build/src'\n",
      "\u001b[95mcmd1:\u001b[0m gmake[5]: Leaving directory '/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-build/src'\n",
      "\u001b[95mcmd1:\u001b[0m gmake[5]: Entering directory '/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-build'\n",
      "\u001b[95mcmd1:\u001b[0m gmake[6]: Entering directory '/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-build'\n",
      "\u001b[95mcmd1:\u001b[0m gmake[6]: Nothing to be done for 'install-exec-am'.\n",
      "\u001b[95mcmd1:\u001b[0m gmake[6]: Nothing to be done for 'install-data-am'.\n",
      "\u001b[95mcmd1:\u001b[0m gmake[6]: Leaving directory '/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-build'\n",
      "\u001b[95mcmd1:\u001b[0m gmake[5]: Leaving directory '/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-build'\n",
      "\u001b[95mcmd1:\u001b[0m gmake[4]: Leaving directory '/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-build'\n",
      "\u001b[95mcmd1:\u001b[0m cd /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-build && /usr/local/lib/python3.11/dist-packages/cmake/data/bin/cmake -E touch /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/build/temp.linux-x86_64-cpython-39/openfst-prefix/src/openfst-stamp/openfst-install\n",
      "\u001b[95mcmd1:\u001b[0m [ 42%] Completed 'openfst'\n",
      "\u001b[95mcmd1:\u001b[0m /usr/local/lib/python3.11/dist-packages/cmake/data/bin/cmake -E make_directory /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/build/temp.linux-x86_64-cpython-39/CMakeFiles\n",
      "\u001b[95mcmd1:\u001b[0m /usr/local/lib/python3.11/dist-packages/cmake/data/bin/cmake -E touch /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/build/temp.linux-x86_64-cpython-39/CMakeFiles/openfst-complete\n",
      "\u001b[95mcmd1:\u001b[0m /usr/local/lib/python3.11/dist-packages/cmake/data/bin/cmake -E touch /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/build/temp.linux-x86_64-cpython-39/openfst-prefix/src/openfst-stamp/openfst-done\n",
      "\u001b[95mcmd1:\u001b[0m gmake[3]: Leaving directory '/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/build/temp.linux-x86_64-cpython-39'\n",
      "\u001b[95mcmd1:\u001b[0m [ 42%] Built target openfst\n",
      "\u001b[95mcmd1:\u001b[0m /usr/bin/gmake  -f CMakeFiles/utils.dir/build.make CMakeFiles/utils.dir/depend\n",
      "\u001b[95mcmd1:\u001b[0m gmake[3]: Entering directory '/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/build/temp.linux-x86_64-cpython-39'\n",
      "\u001b[95mcmd1:\u001b[0m cd /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/build/temp.linux-x86_64-cpython-39 && /usr/local/lib/python3.11/dist-packages/cmake/data/bin/cmake -E cmake_depends \"Unix Makefiles\" /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86 /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86 /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/build/temp.linux-x86_64-cpython-39 /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/build/temp.linux-x86_64-cpython-39 /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/build/temp.linux-x86_64-cpython-39/CMakeFiles/utils.dir/DependInfo.cmake \"--color=\"\n",
      "\u001b[95mcmd1:\u001b[0m gmake[3]: Leaving directory '/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/build/temp.linux-x86_64-cpython-39'\n",
      "\u001b[95mcmd1:\u001b[0m /usr/bin/gmake  -f CMakeFiles/utils.dir/build.make CMakeFiles/utils.dir/build\n",
      "\u001b[95mcmd1:\u001b[0m gmake[3]: Entering directory '/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/build/temp.linux-x86_64-cpython-39'\n",
      "\u001b[95mcmd1:\u001b[0m [ 45%] Building CXX object CMakeFiles/utils.dir/utils/string.cc.o\n",
      "\u001b[95mcmd1:\u001b[0m /usr/bin/c++ -D_GLIBCXX_USE_CXX11_ABI=0 -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86 -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/kaldi -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/boost-src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/cnpy-src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include -std=c++14 -pthread -fPIC -D_GLIBCXX_USE_CXX11_ABI=0 -DC10_USE_GLOG -O3 -DNDEBUG -MD -MT CMakeFiles/utils.dir/utils/string.cc.o -MF CMakeFiles/utils.dir/utils/string.cc.o.d -o CMakeFiles/utils.dir/utils/string.cc.o -c /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/utils/string.cc\n",
      "\u001b[95mcmd1:\u001b[0m [ 48%] Building CXX object CMakeFiles/utils.dir/utils/utils.cc.o\n",
      "\u001b[95mcmd1:\u001b[0m /usr/bin/c++ -D_GLIBCXX_USE_CXX11_ABI=0 -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86 -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/kaldi -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/boost-src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/cnpy-src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include -std=c++14 -pthread -fPIC -D_GLIBCXX_USE_CXX11_ABI=0 -DC10_USE_GLOG -O3 -DNDEBUG -MD -MT CMakeFiles/utils.dir/utils/utils.cc.o -MF CMakeFiles/utils.dir/utils/utils.cc.o.d -o CMakeFiles/utils.dir/utils/utils.cc.o -c /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/utils/utils.cc\n",
      "\u001b[95mcmd1:\u001b[0m [ 51%] Linking CXX static library libutils.a\n",
      "\u001b[95mcmd1:\u001b[0m /usr/local/lib/python3.11/dist-packages/cmake/data/bin/cmake -P CMakeFiles/utils.dir/cmake_clean_target.cmake\n",
      "\u001b[95mcmd1:\u001b[0m /usr/local/lib/python3.11/dist-packages/cmake/data/bin/cmake -E cmake_link_script CMakeFiles/utils.dir/link.txt --verbose=1\n",
      "\u001b[95mcmd1:\u001b[0m /usr/bin/ar qc libutils.a CMakeFiles/utils.dir/utils/string.cc.o CMakeFiles/utils.dir/utils/utils.cc.o\n",
      "\u001b[95mcmd1:\u001b[0m /usr/bin/ranlib libutils.a\n",
      "\u001b[95mcmd1:\u001b[0m gmake[3]: Leaving directory '/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/build/temp.linux-x86_64-cpython-39'\n",
      "\u001b[95mcmd1:\u001b[0m [ 51%] Built target utils\n",
      "\u001b[95mcmd1:\u001b[0m /usr/bin/gmake  -f kaldi/CMakeFiles/kaldi-base.dir/build.make kaldi/CMakeFiles/kaldi-base.dir/depend\n",
      "\u001b[95mcmd1:\u001b[0m gmake[3]: Entering directory '/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/build/temp.linux-x86_64-cpython-39'\n",
      "\u001b[95mcmd1:\u001b[0m cd /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/build/temp.linux-x86_64-cpython-39 && /usr/local/lib/python3.11/dist-packages/cmake/data/bin/cmake -E cmake_depends \"Unix Makefiles\" /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86 /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/kaldi /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/build/temp.linux-x86_64-cpython-39 /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/build/temp.linux-x86_64-cpython-39/kaldi /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/build/temp.linux-x86_64-cpython-39/kaldi/CMakeFiles/kaldi-base.dir/DependInfo.cmake \"--color=\"\n",
      "\u001b[95mcmd1:\u001b[0m gmake[3]: Leaving directory '/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/build/temp.linux-x86_64-cpython-39'\n",
      "\u001b[95mcmd1:\u001b[0m /usr/bin/gmake  -f kaldi/CMakeFiles/kaldi-base.dir/build.make kaldi/CMakeFiles/kaldi-base.dir/build\n",
      "\u001b[95mcmd1:\u001b[0m gmake[3]: Entering directory '/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/build/temp.linux-x86_64-cpython-39'\n",
      "\u001b[95mcmd1:\u001b[0m [ 54%] Building CXX object kaldi/CMakeFiles/kaldi-base.dir/base/kaldi-error.cc.o\n",
      "\u001b[95mcmd1:\u001b[0m cd /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/build/temp.linux-x86_64-cpython-39/kaldi && /usr/bin/c++ -D_GLIBCXX_USE_CXX11_ABI=0 -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86 -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/kaldi -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/boost-src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/cnpy-src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include -std=c++14 -pthread -fPIC -D_GLIBCXX_USE_CXX11_ABI=0 -DC10_USE_GLOG -O3 -DNDEBUG -MD -MT kaldi/CMakeFiles/kaldi-base.dir/base/kaldi-error.cc.o -MF CMakeFiles/kaldi-base.dir/base/kaldi-error.cc.o.d -o CMakeFiles/kaldi-base.dir/base/kaldi-error.cc.o -c /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/kaldi/base/kaldi-error.cc\n",
      "\u001b[95mcmd1:\u001b[0m [ 57%] Building CXX object kaldi/CMakeFiles/kaldi-base.dir/base/kaldi-math.cc.o\n",
      "\u001b[95mcmd1:\u001b[0m cd /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/build/temp.linux-x86_64-cpython-39/kaldi && /usr/bin/c++ -D_GLIBCXX_USE_CXX11_ABI=0 -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86 -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/kaldi -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/boost-src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/cnpy-src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include -std=c++14 -pthread -fPIC -D_GLIBCXX_USE_CXX11_ABI=0 -DC10_USE_GLOG -O3 -DNDEBUG -MD -MT kaldi/CMakeFiles/kaldi-base.dir/base/kaldi-math.cc.o -MF CMakeFiles/kaldi-base.dir/base/kaldi-math.cc.o.d -o CMakeFiles/kaldi-base.dir/base/kaldi-math.cc.o -c /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/kaldi/base/kaldi-math.cc\n",
      "\u001b[95mcmd1:\u001b[0m [ 57%] Linking CXX static library libkaldi-base.a\n",
      "\u001b[95mcmd1:\u001b[0m cd /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/build/temp.linux-x86_64-cpython-39/kaldi && /usr/local/lib/python3.11/dist-packages/cmake/data/bin/cmake -P CMakeFiles/kaldi-base.dir/cmake_clean_target.cmake\n",
      "\u001b[95mcmd1:\u001b[0m cd /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/build/temp.linux-x86_64-cpython-39/kaldi && /usr/local/lib/python3.11/dist-packages/cmake/data/bin/cmake -E cmake_link_script CMakeFiles/kaldi-base.dir/link.txt --verbose=1\n",
      "\u001b[95mcmd1:\u001b[0m /usr/bin/ar qc libkaldi-base.a \"CMakeFiles/kaldi-base.dir/base/kaldi-error.cc.o\" \"CMakeFiles/kaldi-base.dir/base/kaldi-math.cc.o\"\n",
      "\u001b[95mcmd1:\u001b[0m /usr/bin/ranlib libkaldi-base.a\n",
      "\u001b[95mcmd1:\u001b[0m gmake[3]: Leaving directory '/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/build/temp.linux-x86_64-cpython-39'\n",
      "\u001b[95mcmd1:\u001b[0m [ 57%] Built target kaldi-base\n",
      "\u001b[95mcmd1:\u001b[0m /usr/bin/gmake  -f kaldi/CMakeFiles/kaldi-util.dir/build.make kaldi/CMakeFiles/kaldi-util.dir/depend\n",
      "\u001b[95mcmd1:\u001b[0m gmake[3]: Entering directory '/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/build/temp.linux-x86_64-cpython-39'\n",
      "\u001b[95mcmd1:\u001b[0m cd /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/build/temp.linux-x86_64-cpython-39 && /usr/local/lib/python3.11/dist-packages/cmake/data/bin/cmake -E cmake_depends \"Unix Makefiles\" /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86 /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/kaldi /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/build/temp.linux-x86_64-cpython-39 /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/build/temp.linux-x86_64-cpython-39/kaldi /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/build/temp.linux-x86_64-cpython-39/kaldi/CMakeFiles/kaldi-util.dir/DependInfo.cmake \"--color=\"\n",
      "\u001b[95mcmd1:\u001b[0m gmake[3]: Leaving directory '/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/build/temp.linux-x86_64-cpython-39'\n",
      "\u001b[95mcmd1:\u001b[0m /usr/bin/gmake  -f kaldi/CMakeFiles/kaldi-util.dir/build.make kaldi/CMakeFiles/kaldi-util.dir/build\n",
      "\u001b[95mcmd1:\u001b[0m gmake[3]: Entering directory '/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/build/temp.linux-x86_64-cpython-39'\n",
      "\u001b[95mcmd1:\u001b[0m [ 60%] Building CXX object kaldi/CMakeFiles/kaldi-util.dir/util/kaldi-io.cc.o\n",
      "\u001b[95mcmd1:\u001b[0m cd /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/build/temp.linux-x86_64-cpython-39/kaldi && /usr/bin/c++ -D_GLIBCXX_USE_CXX11_ABI=0 -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86 -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/kaldi -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/boost-src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/cnpy-src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include -std=c++14 -pthread -fPIC -D_GLIBCXX_USE_CXX11_ABI=0 -DC10_USE_GLOG -O3 -DNDEBUG -MD -MT kaldi/CMakeFiles/kaldi-util.dir/util/kaldi-io.cc.o -MF CMakeFiles/kaldi-util.dir/util/kaldi-io.cc.o.d -o CMakeFiles/kaldi-util.dir/util/kaldi-io.cc.o -c /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/kaldi/util/kaldi-io.cc\n",
      "\u001b[95mcmd1:\u001b[0m [ 60%] Building CXX object kaldi/CMakeFiles/kaldi-util.dir/util/parse-options.cc.o\n",
      "\u001b[95mcmd1:\u001b[0m cd /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/build/temp.linux-x86_64-cpython-39/kaldi && /usr/bin/c++ -D_GLIBCXX_USE_CXX11_ABI=0 -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86 -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/kaldi -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/boost-src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/cnpy-src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include -std=c++14 -pthread -fPIC -D_GLIBCXX_USE_CXX11_ABI=0 -DC10_USE_GLOG -O3 -DNDEBUG -MD -MT kaldi/CMakeFiles/kaldi-util.dir/util/parse-options.cc.o -MF CMakeFiles/kaldi-util.dir/util/parse-options.cc.o.d -o CMakeFiles/kaldi-util.dir/util/parse-options.cc.o -c /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/kaldi/util/parse-options.cc\n",
      "\u001b[95mcmd1:\u001b[0m [ 63%] Building CXX object kaldi/CMakeFiles/kaldi-util.dir/util/simple-io-funcs.cc.o\n",
      "\u001b[95mcmd1:\u001b[0m cd /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/build/temp.linux-x86_64-cpython-39/kaldi && /usr/bin/c++ -D_GLIBCXX_USE_CXX11_ABI=0 -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86 -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/kaldi -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/boost-src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/cnpy-src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include -std=c++14 -pthread -fPIC -D_GLIBCXX_USE_CXX11_ABI=0 -DC10_USE_GLOG -O3 -DNDEBUG -MD -MT kaldi/CMakeFiles/kaldi-util.dir/util/simple-io-funcs.cc.o -MF CMakeFiles/kaldi-util.dir/util/simple-io-funcs.cc.o.d -o CMakeFiles/kaldi-util.dir/util/simple-io-funcs.cc.o -c /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/kaldi/util/simple-io-funcs.cc\n",
      "\u001b[95mcmd1:\u001b[0m [ 66%] Building CXX object kaldi/CMakeFiles/kaldi-util.dir/util/text-utils.cc.o\n",
      "\u001b[95mcmd1:\u001b[0m cd /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/build/temp.linux-x86_64-cpython-39/kaldi && /usr/bin/c++ -D_GLIBCXX_USE_CXX11_ABI=0 -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86 -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/kaldi -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/boost-src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/cnpy-src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include -std=c++14 -pthread -fPIC -D_GLIBCXX_USE_CXX11_ABI=0 -DC10_USE_GLOG -O3 -DNDEBUG -MD -MT kaldi/CMakeFiles/kaldi-util.dir/util/text-utils.cc.o -MF CMakeFiles/kaldi-util.dir/util/text-utils.cc.o.d -o CMakeFiles/kaldi-util.dir/util/text-utils.cc.o -c /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/kaldi/util/text-utils.cc\n",
      "\u001b[95mcmd1:\u001b[0m [ 69%] Linking CXX static library libkaldi-util.a\n",
      "\u001b[95mcmd1:\u001b[0m cd /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/build/temp.linux-x86_64-cpython-39/kaldi && /usr/local/lib/python3.11/dist-packages/cmake/data/bin/cmake -P CMakeFiles/kaldi-util.dir/cmake_clean_target.cmake\n",
      "\u001b[95mcmd1:\u001b[0m cd /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/build/temp.linux-x86_64-cpython-39/kaldi && /usr/local/lib/python3.11/dist-packages/cmake/data/bin/cmake -E cmake_link_script CMakeFiles/kaldi-util.dir/link.txt --verbose=1\n",
      "\u001b[95mcmd1:\u001b[0m /usr/bin/ar qc libkaldi-util.a \"CMakeFiles/kaldi-util.dir/util/kaldi-io.cc.o\" \"CMakeFiles/kaldi-util.dir/util/parse-options.cc.o\" \"CMakeFiles/kaldi-util.dir/util/simple-io-funcs.cc.o\" \"CMakeFiles/kaldi-util.dir/util/text-utils.cc.o\"\n",
      "\u001b[95mcmd1:\u001b[0m /usr/bin/ranlib libkaldi-util.a\n",
      "\u001b[95mcmd1:\u001b[0m gmake[3]: Leaving directory '/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/build/temp.linux-x86_64-cpython-39'\n",
      "\u001b[95mcmd1:\u001b[0m [ 69%] Built target kaldi-util\n",
      "\u001b[95mcmd1:\u001b[0m /usr/bin/gmake  -f kaldi/CMakeFiles/kaldi-fstext.dir/build.make kaldi/CMakeFiles/kaldi-fstext.dir/depend\n",
      "\u001b[95mcmd1:\u001b[0m gmake[3]: Entering directory '/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/build/temp.linux-x86_64-cpython-39'\n",
      "\u001b[95mcmd1:\u001b[0m cd /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/build/temp.linux-x86_64-cpython-39 && /usr/local/lib/python3.11/dist-packages/cmake/data/bin/cmake -E cmake_depends \"Unix Makefiles\" /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86 /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/kaldi /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/build/temp.linux-x86_64-cpython-39 /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/build/temp.linux-x86_64-cpython-39/kaldi /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/build/temp.linux-x86_64-cpython-39/kaldi/CMakeFiles/kaldi-fstext.dir/DependInfo.cmake \"--color=\"\n",
      "\u001b[95mcmd1:\u001b[0m gmake[3]: Leaving directory '/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/build/temp.linux-x86_64-cpython-39'\n",
      "\u001b[95mcmd1:\u001b[0m /usr/bin/gmake  -f kaldi/CMakeFiles/kaldi-fstext.dir/build.make kaldi/CMakeFiles/kaldi-fstext.dir/build\n",
      "\u001b[95mcmd1:\u001b[0m gmake[3]: Entering directory '/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/build/temp.linux-x86_64-cpython-39'\n",
      "\u001b[95mcmd1:\u001b[0m [ 69%] Building CXX object kaldi/CMakeFiles/kaldi-fstext.dir/fstext/kaldi-fst-io.cc.o\n",
      "\u001b[95mcmd1:\u001b[0m cd /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/build/temp.linux-x86_64-cpython-39/kaldi && /usr/bin/c++ -D_GLIBCXX_USE_CXX11_ABI=0 -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86 -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/kaldi -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/boost-src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/cnpy-src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include -std=c++14 -pthread -fPIC -D_GLIBCXX_USE_CXX11_ABI=0 -DC10_USE_GLOG -O3 -DNDEBUG -MD -MT kaldi/CMakeFiles/kaldi-fstext.dir/fstext/kaldi-fst-io.cc.o -MF CMakeFiles/kaldi-fstext.dir/fstext/kaldi-fst-io.cc.o.d -o CMakeFiles/kaldi-fstext.dir/fstext/kaldi-fst-io.cc.o -c /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/kaldi/fstext/kaldi-fst-io.cc\n",
      "\u001b[95mcmd1:\u001b[0m [ 72%] Linking CXX static library libkaldi-fstext.a\n",
      "\u001b[95mcmd1:\u001b[0m cd /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/build/temp.linux-x86_64-cpython-39/kaldi && /usr/local/lib/python3.11/dist-packages/cmake/data/bin/cmake -P CMakeFiles/kaldi-fstext.dir/cmake_clean_target.cmake\n",
      "\u001b[95mcmd1:\u001b[0m cd /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/build/temp.linux-x86_64-cpython-39/kaldi && /usr/local/lib/python3.11/dist-packages/cmake/data/bin/cmake -E cmake_link_script CMakeFiles/kaldi-fstext.dir/link.txt --verbose=1\n",
      "\u001b[95mcmd1:\u001b[0m /usr/bin/ar qc libkaldi-fstext.a \"CMakeFiles/kaldi-fstext.dir/fstext/kaldi-fst-io.cc.o\"\n",
      "\u001b[95mcmd1:\u001b[0m /usr/bin/ranlib libkaldi-fstext.a\n",
      "\u001b[95mcmd1:\u001b[0m gmake[3]: Leaving directory '/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/build/temp.linux-x86_64-cpython-39'\n",
      "\u001b[95mcmd1:\u001b[0m [ 72%] Built target kaldi-fstext\n",
      "\u001b[95mcmd1:\u001b[0m /usr/bin/gmake  -f kaldi/CMakeFiles/kaldi-lat.dir/build.make kaldi/CMakeFiles/kaldi-lat.dir/depend\n",
      "\u001b[95mcmd1:\u001b[0m gmake[3]: Entering directory '/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/build/temp.linux-x86_64-cpython-39'\n",
      "\u001b[95mcmd1:\u001b[0m cd /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/build/temp.linux-x86_64-cpython-39 && /usr/local/lib/python3.11/dist-packages/cmake/data/bin/cmake -E cmake_depends \"Unix Makefiles\" /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86 /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/kaldi /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/build/temp.linux-x86_64-cpython-39 /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/build/temp.linux-x86_64-cpython-39/kaldi /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/build/temp.linux-x86_64-cpython-39/kaldi/CMakeFiles/kaldi-lat.dir/DependInfo.cmake \"--color=\"\n",
      "\u001b[95mcmd1:\u001b[0m gmake[3]: Leaving directory '/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/build/temp.linux-x86_64-cpython-39'\n",
      "\u001b[95mcmd1:\u001b[0m /usr/bin/gmake  -f kaldi/CMakeFiles/kaldi-lat.dir/build.make kaldi/CMakeFiles/kaldi-lat.dir/build\n",
      "\u001b[95mcmd1:\u001b[0m gmake[3]: Entering directory '/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/build/temp.linux-x86_64-cpython-39'\n",
      "\u001b[95mcmd1:\u001b[0m [ 75%] Building CXX object kaldi/CMakeFiles/kaldi-lat.dir/lat/determinize-lattice-pruned.cc.o\n",
      "\u001b[95mcmd1:\u001b[0m cd /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/build/temp.linux-x86_64-cpython-39/kaldi && /usr/bin/c++ -D_GLIBCXX_USE_CXX11_ABI=0 -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86 -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/kaldi -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/boost-src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/cnpy-src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include -std=c++14 -pthread -fPIC -D_GLIBCXX_USE_CXX11_ABI=0 -DC10_USE_GLOG -O3 -DNDEBUG -MD -MT kaldi/CMakeFiles/kaldi-lat.dir/lat/determinize-lattice-pruned.cc.o -MF CMakeFiles/kaldi-lat.dir/lat/determinize-lattice-pruned.cc.o.d -o CMakeFiles/kaldi-lat.dir/lat/determinize-lattice-pruned.cc.o -c /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/kaldi/lat/determinize-lattice-pruned.cc\n",
      "\u001b[95mcmd1:\u001b[0m [ 75%] Building CXX object kaldi/CMakeFiles/kaldi-lat.dir/lat/lattice-functions.cc.o\n",
      "\u001b[95mcmd1:\u001b[0m cd /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/build/temp.linux-x86_64-cpython-39/kaldi && /usr/bin/c++ -D_GLIBCXX_USE_CXX11_ABI=0 -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86 -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/kaldi -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/boost-src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/cnpy-src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include -std=c++14 -pthread -fPIC -D_GLIBCXX_USE_CXX11_ABI=0 -DC10_USE_GLOG -O3 -DNDEBUG -MD -MT kaldi/CMakeFiles/kaldi-lat.dir/lat/lattice-functions.cc.o -MF CMakeFiles/kaldi-lat.dir/lat/lattice-functions.cc.o.d -o CMakeFiles/kaldi-lat.dir/lat/lattice-functions.cc.o -c /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/kaldi/lat/lattice-functions.cc\n",
      "\u001b[95mcmd1:\u001b[0m [ 78%] Linking CXX static library libkaldi-lat.a\n",
      "\u001b[95mcmd1:\u001b[0m cd /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/build/temp.linux-x86_64-cpython-39/kaldi && /usr/local/lib/python3.11/dist-packages/cmake/data/bin/cmake -P CMakeFiles/kaldi-lat.dir/cmake_clean_target.cmake\n",
      "\u001b[95mcmd1:\u001b[0m cd /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/build/temp.linux-x86_64-cpython-39/kaldi && /usr/local/lib/python3.11/dist-packages/cmake/data/bin/cmake -E cmake_link_script CMakeFiles/kaldi-lat.dir/link.txt --verbose=1\n",
      "\u001b[95mcmd1:\u001b[0m /usr/bin/ar qc libkaldi-lat.a \"CMakeFiles/kaldi-lat.dir/lat/determinize-lattice-pruned.cc.o\" \"CMakeFiles/kaldi-lat.dir/lat/lattice-functions.cc.o\"\n",
      "\u001b[95mcmd1:\u001b[0m /usr/bin/ranlib libkaldi-lat.a\n",
      "\u001b[95mcmd1:\u001b[0m gmake[3]: Leaving directory '/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/build/temp.linux-x86_64-cpython-39'\n",
      "\u001b[95mcmd1:\u001b[0m [ 78%] Built target kaldi-lat\n",
      "\u001b[95mcmd1:\u001b[0m /usr/bin/gmake  -f kaldi/CMakeFiles/kaldi-decoder.dir/build.make kaldi/CMakeFiles/kaldi-decoder.dir/depend\n",
      "\u001b[95mcmd1:\u001b[0m gmake[3]: Entering directory '/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/build/temp.linux-x86_64-cpython-39'\n",
      "\u001b[95mcmd1:\u001b[0m cd /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/build/temp.linux-x86_64-cpython-39 && /usr/local/lib/python3.11/dist-packages/cmake/data/bin/cmake -E cmake_depends \"Unix Makefiles\" /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86 /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/kaldi /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/build/temp.linux-x86_64-cpython-39 /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/build/temp.linux-x86_64-cpython-39/kaldi /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/build/temp.linux-x86_64-cpython-39/kaldi/CMakeFiles/kaldi-decoder.dir/DependInfo.cmake \"--color=\"\n",
      "\u001b[95mcmd1:\u001b[0m gmake[3]: Leaving directory '/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/build/temp.linux-x86_64-cpython-39'\n",
      "\u001b[95mcmd1:\u001b[0m /usr/bin/gmake  -f kaldi/CMakeFiles/kaldi-decoder.dir/build.make kaldi/CMakeFiles/kaldi-decoder.dir/build\n",
      "\u001b[95mcmd1:\u001b[0m gmake[3]: Entering directory '/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/build/temp.linux-x86_64-cpython-39'\n",
      "\u001b[95mcmd1:\u001b[0m [ 81%] Building CXX object kaldi/CMakeFiles/kaldi-decoder.dir/decoder/lattice-faster-decoder.cc.o\n",
      "\u001b[95mcmd1:\u001b[0m cd /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/build/temp.linux-x86_64-cpython-39/kaldi && /usr/bin/c++ -D_GLIBCXX_USE_CXX11_ABI=0 -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86 -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/kaldi -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/boost-src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/cnpy-src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include -std=c++14 -pthread -fPIC -D_GLIBCXX_USE_CXX11_ABI=0 -DC10_USE_GLOG -O3 -DNDEBUG -MD -MT kaldi/CMakeFiles/kaldi-decoder.dir/decoder/lattice-faster-decoder.cc.o -MF CMakeFiles/kaldi-decoder.dir/decoder/lattice-faster-decoder.cc.o.d -o CMakeFiles/kaldi-decoder.dir/decoder/lattice-faster-decoder.cc.o -c /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/kaldi/decoder/lattice-faster-decoder.cc\n",
      "\u001b[95mcmd1:\u001b[0m [ 84%] Building CXX object kaldi/CMakeFiles/kaldi-decoder.dir/decoder/lattice-faster-online-decoder.cc.o\n",
      "\u001b[95mcmd1:\u001b[0m cd /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/build/temp.linux-x86_64-cpython-39/kaldi && /usr/bin/c++ -D_GLIBCXX_USE_CXX11_ABI=0 -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86 -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/kaldi -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/boost-src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/cnpy-src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include -std=c++14 -pthread -fPIC -D_GLIBCXX_USE_CXX11_ABI=0 -DC10_USE_GLOG -O3 -DNDEBUG -MD -MT kaldi/CMakeFiles/kaldi-decoder.dir/decoder/lattice-faster-online-decoder.cc.o -MF CMakeFiles/kaldi-decoder.dir/decoder/lattice-faster-online-decoder.cc.o.d -o CMakeFiles/kaldi-decoder.dir/decoder/lattice-faster-online-decoder.cc.o -c /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/kaldi/decoder/lattice-faster-online-decoder.cc\n",
      "\u001b[95mcmd1:\u001b[0m [ 87%] Linking CXX static library libkaldi-decoder.a\n",
      "\u001b[95mcmd1:\u001b[0m cd /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/build/temp.linux-x86_64-cpython-39/kaldi && /usr/local/lib/python3.11/dist-packages/cmake/data/bin/cmake -P CMakeFiles/kaldi-decoder.dir/cmake_clean_target.cmake\n",
      "\u001b[95mcmd1:\u001b[0m cd /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/build/temp.linux-x86_64-cpython-39/kaldi && /usr/local/lib/python3.11/dist-packages/cmake/data/bin/cmake -E cmake_link_script CMakeFiles/kaldi-decoder.dir/link.txt --verbose=1\n",
      "\u001b[95mcmd1:\u001b[0m /usr/bin/ar qc libkaldi-decoder.a \"CMakeFiles/kaldi-decoder.dir/decoder/lattice-faster-decoder.cc.o\" \"CMakeFiles/kaldi-decoder.dir/decoder/lattice-faster-online-decoder.cc.o\"\n",
      "\u001b[95mcmd1:\u001b[0m /usr/bin/ranlib libkaldi-decoder.a\n",
      "\u001b[95mcmd1:\u001b[0m gmake[3]: Leaving directory '/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/build/temp.linux-x86_64-cpython-39'\n",
      "\u001b[95mcmd1:\u001b[0m [ 87%] Built target kaldi-decoder\n",
      "\u001b[95mcmd1:\u001b[0m /usr/bin/gmake  -f CMakeFiles/decoder.dir/build.make CMakeFiles/decoder.dir/depend\n",
      "\u001b[95mcmd1:\u001b[0m gmake[3]: Entering directory '/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/build/temp.linux-x86_64-cpython-39'\n",
      "\u001b[95mcmd1:\u001b[0m cd /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/build/temp.linux-x86_64-cpython-39 && /usr/local/lib/python3.11/dist-packages/cmake/data/bin/cmake -E cmake_depends \"Unix Makefiles\" /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86 /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86 /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/build/temp.linux-x86_64-cpython-39 /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/build/temp.linux-x86_64-cpython-39 /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/build/temp.linux-x86_64-cpython-39/CMakeFiles/decoder.dir/DependInfo.cmake \"--color=\"\n",
      "\u001b[95mcmd1:\u001b[0m gmake[3]: Leaving directory '/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/build/temp.linux-x86_64-cpython-39'\n",
      "\u001b[95mcmd1:\u001b[0m /usr/bin/gmake  -f CMakeFiles/decoder.dir/build.make CMakeFiles/decoder.dir/build\n",
      "\u001b[95mcmd1:\u001b[0m gmake[3]: Entering directory '/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/build/temp.linux-x86_64-cpython-39'\n",
      "\u001b[95mcmd1:\u001b[0m [ 90%] Building CXX object CMakeFiles/decoder.dir/decoder/ctc_prefix_beam_search.cc.o\n",
      "\u001b[95mcmd1:\u001b[0m /usr/bin/c++ -DUSE_C10D_GLOO -DUSE_DISTRIBUTED -DUSE_RPC -DUSE_TENSORPIPE -D_GLIBCXX_USE_CXX11_ABI=0 -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86 -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/kaldi -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/boost-src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/cnpy-src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include -isystem /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/libtorch-src/include -isystem /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/libtorch-src/include/torch/csrc/api/include -std=c++14 -pthread -fPIC -D_GLIBCXX_USE_CXX11_ABI=0 -DC10_USE_GLOG -O3 -DNDEBUG -D_GLIBCXX_USE_CXX11_ABI=0 -MD -MT CMakeFiles/decoder.dir/decoder/ctc_prefix_beam_search.cc.o -MF CMakeFiles/decoder.dir/decoder/ctc_prefix_beam_search.cc.o.d -o CMakeFiles/decoder.dir/decoder/ctc_prefix_beam_search.cc.o -c /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/decoder/ctc_prefix_beam_search.cc\n",
      "\u001b[95mcmd1:\u001b[0m [ 90%] Building CXX object CMakeFiles/decoder.dir/decoder/ctc_wfst_beam_search.cc.o\n",
      "\u001b[95mcmd1:\u001b[0m /usr/bin/c++ -DUSE_C10D_GLOO -DUSE_DISTRIBUTED -DUSE_RPC -DUSE_TENSORPIPE -D_GLIBCXX_USE_CXX11_ABI=0 -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86 -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/kaldi -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/boost-src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/cnpy-src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include -isystem /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/libtorch-src/include -isystem /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/libtorch-src/include/torch/csrc/api/include -std=c++14 -pthread -fPIC -D_GLIBCXX_USE_CXX11_ABI=0 -DC10_USE_GLOG -O3 -DNDEBUG -D_GLIBCXX_USE_CXX11_ABI=0 -MD -MT CMakeFiles/decoder.dir/decoder/ctc_wfst_beam_search.cc.o -MF CMakeFiles/decoder.dir/decoder/ctc_wfst_beam_search.cc.o.d -o CMakeFiles/decoder.dir/decoder/ctc_wfst_beam_search.cc.o -c /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/decoder/ctc_wfst_beam_search.cc\n",
      "\u001b[95mcmd1:\u001b[0m [ 93%] Building CXX object CMakeFiles/decoder.dir/decoder/brain_speech_decoder.cc.o\n",
      "\u001b[95mcmd1:\u001b[0m /usr/bin/c++ -DUSE_C10D_GLOO -DUSE_DISTRIBUTED -DUSE_RPC -DUSE_TENSORPIPE -D_GLIBCXX_USE_CXX11_ABI=0 -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86 -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/kaldi -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/boost-src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/cnpy-src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include -isystem /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/libtorch-src/include -isystem /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/libtorch-src/include/torch/csrc/api/include -std=c++14 -pthread -fPIC -D_GLIBCXX_USE_CXX11_ABI=0 -DC10_USE_GLOG -O3 -DNDEBUG -D_GLIBCXX_USE_CXX11_ABI=0 -MD -MT CMakeFiles/decoder.dir/decoder/brain_speech_decoder.cc.o -MF CMakeFiles/decoder.dir/decoder/brain_speech_decoder.cc.o.d -o CMakeFiles/decoder.dir/decoder/brain_speech_decoder.cc.o -c /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/decoder/brain_speech_decoder.cc\n",
      "\u001b[95mcmd1:\u001b[0m [ 96%] Linking CXX static library libdecoder.a\n",
      "\u001b[95mcmd1:\u001b[0m /usr/local/lib/python3.11/dist-packages/cmake/data/bin/cmake -P CMakeFiles/decoder.dir/cmake_clean_target.cmake\n",
      "\u001b[95mcmd1:\u001b[0m /usr/local/lib/python3.11/dist-packages/cmake/data/bin/cmake -E cmake_link_script CMakeFiles/decoder.dir/link.txt --verbose=1\n",
      "\u001b[95mcmd1:\u001b[0m /usr/bin/ar qc libdecoder.a CMakeFiles/decoder.dir/decoder/ctc_prefix_beam_search.cc.o CMakeFiles/decoder.dir/decoder/ctc_wfst_beam_search.cc.o CMakeFiles/decoder.dir/decoder/brain_speech_decoder.cc.o\n",
      "\u001b[95mcmd1:\u001b[0m /usr/bin/ranlib libdecoder.a\n",
      "\u001b[95mcmd1:\u001b[0m gmake[3]: Leaving directory '/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/build/temp.linux-x86_64-cpython-39'\n",
      "\u001b[95mcmd1:\u001b[0m [ 96%] Built target decoder\n",
      "\u001b[95mcmd1:\u001b[0m /usr/bin/gmake  -f CMakeFiles/lm_decoder.dir/build.make CMakeFiles/lm_decoder.dir/depend\n",
      "\u001b[95mcmd1:\u001b[0m gmake[3]: Entering directory '/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/build/temp.linux-x86_64-cpython-39'\n",
      "\u001b[95mcmd1:\u001b[0m cd /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/build/temp.linux-x86_64-cpython-39 && /usr/local/lib/python3.11/dist-packages/cmake/data/bin/cmake -E cmake_depends \"Unix Makefiles\" /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86 /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86 /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/build/temp.linux-x86_64-cpython-39 /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/build/temp.linux-x86_64-cpython-39 /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/build/temp.linux-x86_64-cpython-39/CMakeFiles/lm_decoder.dir/DependInfo.cmake \"--color=\"\n",
      "\u001b[95mcmd1:\u001b[0m gmake[3]: Leaving directory '/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/build/temp.linux-x86_64-cpython-39'\n",
      "\u001b[95mcmd1:\u001b[0m /usr/bin/gmake  -f CMakeFiles/lm_decoder.dir/build.make CMakeFiles/lm_decoder.dir/build\n",
      "\u001b[95mcmd1:\u001b[0m gmake[3]: Entering directory '/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/build/temp.linux-x86_64-cpython-39'\n",
      "\u001b[95mcmd1:\u001b[0m [ 96%] Building CXX object CMakeFiles/lm_decoder.dir/python/lm_decoder.cc.o\n",
      "\u001b[95mcmd1:\u001b[0m /usr/bin/c++ -DUSE_C10D_GLOO -DUSE_DISTRIBUTED -DUSE_RPC -DUSE_TENSORPIPE -D_GLIBCXX_USE_CXX11_ABI=0 -Dlm_decoder_EXPORTS -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86 -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/kaldi -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/boost-src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/cnpy-src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include -isystem /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/pybind11/include -isystem /root/miniconda3/envs/b2txt25_lm/include/python3.9 -isystem /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/libtorch-src/include -isystem /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/libtorch-src/include/torch/csrc/api/include -std=c++14 -pthread -fPIC -D_GLIBCXX_USE_CXX11_ABI=0 -DC10_USE_GLOG -O3 -DNDEBUG -fPIC -fvisibility=hidden -flto -fno-fat-lto-objects -D_GLIBCXX_USE_CXX11_ABI=0 -MD -MT CMakeFiles/lm_decoder.dir/python/lm_decoder.cc.o -MF CMakeFiles/lm_decoder.dir/python/lm_decoder.cc.o.d -o CMakeFiles/lm_decoder.dir/python/lm_decoder.cc.o -c /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/python/lm_decoder.cc\n",
      "\u001b[95mcmd1:\u001b[0m [100%] Linking CXX shared module /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/build/lib.linux-x86_64-cpython-39/lm_decoder.cpython-39-x86_64-linux-gnu.so\n",
      "\u001b[95mcmd1:\u001b[0m /usr/local/lib/python3.11/dist-packages/cmake/data/bin/cmake -E cmake_link_script CMakeFiles/lm_decoder.dir/link.txt --verbose=1\n",
      "\u001b[95mcmd1:\u001b[0m lto-wrapper: warning: using serial compilation of 5 LTRANS jobs\n",
      "\u001b[95mcmd1:\u001b[0m /usr/bin/c++ -fPIC  -std=c++14 -pthread -fPIC -D_GLIBCXX_USE_CXX11_ABI=0 -DC10_USE_GLOG -O3 -DNDEBUG -flto -shared  -o /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/build/lib.linux-x86_64-cpython-39/lm_decoder.cpython-39-x86_64-linux-gnu.so CMakeFiles/lm_decoder.dir/python/lm_decoder.cc.o   -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-subbuild/openfst-populate-prefix/lib  -Wl,-rpath,/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-subbuild/openfst-populate-prefix/lib:/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/libtorch-src/lib libdecoder.a /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/libtorch-src/lib/libtorch.so -Wl,--no-as-needed,\"/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/libtorch-src/lib/libtorch_cpu.so\" -Wl,--as-needed /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/libtorch-src/lib/libc10.so -Wl,--no-as-needed,\"/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/libtorch-src/lib/libtorch.so\" -Wl,--as-needed /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/libtorch-src/lib/libc10.so /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/libtorch-src/lib/libkineto.a kaldi/libkaldi-decoder.a kaldi/libkaldi-lat.a kaldi/libkaldi-fstext.a kaldi/libkaldi-util.a kaldi/libkaldi-base.a libutils.a -lfst -ldl\n",
      "\u001b[95mcmd1:\u001b[0m /usr/bin/strip /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/build/lib.linux-x86_64-cpython-39/lm_decoder.cpython-39-x86_64-linux-gnu.so\n",
      "\u001b[95mcmd1:\u001b[0m gmake[3]: Leaving directory '/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/build/temp.linux-x86_64-cpython-39'\n",
      "\u001b[95mcmd1:\u001b[0m [100%] Built target lm_decoder\n",
      "\u001b[95mcmd1:\u001b[0m gmake[2]: Leaving directory '/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/build/temp.linux-x86_64-cpython-39'\n",
      "\u001b[95mcmd1:\u001b[0m /usr/local/lib/python3.11/dist-packages/cmake/data/bin/cmake -E cmake_progress_start /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/build/temp.linux-x86_64-cpython-39/CMakeFiles 0\n",
      "\u001b[95mcmd1:\u001b[0m gmake[1]: Leaving directory '/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/build/temp.linux-x86_64-cpython-39'\n",
      "\u001b[95mcmd1:\u001b[0m running install_lib\n",
      "\u001b[95mcmd1:\u001b[0m copying build/lib.linux-x86_64-cpython-39/lm_decoder.cpython-39-x86_64-linux-gnu.so -> /root/miniconda3/envs/b2txt25_lm/lib/python3.9/site-packages\n",
      "\u001b[95mcmd1:\u001b[0m running install_egg_info\n",
      "\u001b[95mcmd1:\u001b[0m running egg_info\n",
      "\u001b[95mcmd1:\u001b[0m creating lm_decoder.egg-info\n",
      "\u001b[95mcmd1:\u001b[0m writing lm_decoder.egg-info/PKG-INFO\n",
      "\u001b[95mcmd1:\u001b[0m writing dependency_links to lm_decoder.egg-info/dependency_links.txt\n",
      "\u001b[95mcmd1:\u001b[0m writing top-level names to lm_decoder.egg-info/top_level.txt\n",
      "\u001b[95mcmd1:\u001b[0m writing manifest file 'lm_decoder.egg-info/SOURCES.txt'\n",
      "\u001b[95mcmd1:\u001b[0m reading manifest file 'lm_decoder.egg-info/SOURCES.txt'\n",
      "\u001b[95mcmd1:\u001b[0m writing manifest file 'lm_decoder.egg-info/SOURCES.txt'\n",
      "\u001b[95mcmd1:\u001b[0m Copying lm_decoder.egg-info to /root/miniconda3/envs/b2txt25_lm/lib/python3.9/site-packages/lm_decoder-0.0.1-py3.9.egg-info\n",
      "\u001b[95mcmd1:\u001b[0m running install_scripts\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[95mcmd1:\u001b[0m Setup complete! Verify it worked by activating the conda environment with the command 'conda activate b2txt25_lm'.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:35:41,520 INFO: Using device: cuda:0\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:35:41,520 INFO: Building opt model from None...\n",
      "\u001b[95mcmd1:\u001b[0m /root/miniconda3/envs/b2txt25_lm/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "\u001b[95mcmd1:\u001b[0m   warnings.warn(\n",
      "\u001b[95mcmd1:\u001b[0m /root/miniconda3/envs/b2txt25_lm/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "\u001b[95mcmd1:\u001b[0m   warnings.warn(\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[95mcmd1:\u001b[0m Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "\u001b[95mcmd1:\u001b[0m Downloading shards:  50%|█████     | 1/2 [00:56<00:56, 56.11s/it]\n",
      "\u001b[95mcmd1:\u001b[0m Downloading shards: 100%|██████████| 2/2 [01:16<00:00, 35.33s/it]\n",
      "\u001b[95mcmd1:\u001b[0m Downloading shards: 100%|██████████| 2/2 [01:16<00:00, 38.45s/it]\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[95mcmd1:\u001b[0m Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "\u001b[95mcmd1:\u001b[0m Loading checkpoint shards:  50%|█████     | 1/2 [00:35<00:35, 35.23s/it]\n",
      "\u001b[95mcmd1:\u001b[0m Loading checkpoint shards: 100%|██████████| 2/2 [00:49<00:00, 22.92s/it]\n",
      "\u001b[95mcmd1:\u001b[0m Loading checkpoint shards: 100%|██████████| 2/2 [00:49<00:00, 24.77s/it]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:37:57,389 INFO: OPT model successfully built in 135.8688 seconds.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:37:57,389 INFO: Initializing language model decoder from language_model/pretrained_language_models/openwebtext_1gram_lm_sil...\n",
      "\u001b[95mcmd1:\u001b[0m WARNING: Logging before InitGoogleLogging() is written to STDERR\n",
      "\u001b[95mcmd1:\u001b[0m I1224 07:37:57.394755  1137 brain_speech_decoder.h:52] Reading fst language_model/pretrained_language_models/openwebtext_1gram_lm_sil/TLG.fst\n",
      "\u001b[95mcmd1:\u001b[0m I1224 07:37:57.499943  1137 brain_speech_decoder.h:81] Reading symbol table language_model/pretrained_language_models/openwebtext_1gram_lm_sil/words.txt\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:37:57,665 INFO: Language model successfully initialized in 0.2758 seconds.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:37:57,665 INFO: Attempting to connect to redis at localhost:6379...\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:37:57,671 INFO: Connected to redis.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:37:57,671 INFO: Successfully connected to redis server at localhost:6379.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:37:57,671 INFO: Entering main loop...\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:37:57,671 INFO: Successfully connected to the redis server.\n",
      "\u001b[35mcmd2:\u001b[0m Jupyter detected...\n",
      "\u001b[35mcmd2:\u001b[0m 2 channel Terms of Service accepted\n",
      "\u001b[35mcmd2:\u001b[0m Channels:\n",
      "\u001b[35mcmd2:\u001b[0m  - defaults\n",
      "\u001b[35mcmd2:\u001b[0m Platform: linux-64\n",
      "\u001b[35mcmd2:\u001b[0m Collecting package metadata (repodata.json): done\n",
      "\u001b[35mcmd2:\u001b[0m Solving environment: done\n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m ## Package Plan ##\n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m   environment location: /root/miniconda3/envs/b2txt25\n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m   added / updated specs:\n",
      "\u001b[35mcmd2:\u001b[0m     - python=3.10\n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m The following packages will be downloaded:\n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m     package                    |            build\n",
      "\u001b[35mcmd2:\u001b[0m     ---------------------------|-----------------\n",
      "\u001b[35mcmd2:\u001b[0m     python-3.10.19             |       h6fa692b_0        24.5 MB\n",
      "\u001b[35mcmd2:\u001b[0m     setuptools-80.9.0          |  py310h06a4308_0         1.4 MB\n",
      "\u001b[35mcmd2:\u001b[0m     wheel-0.45.1               |  py310h06a4308_0         115 KB\n",
      "\u001b[35mcmd2:\u001b[0m     ------------------------------------------------------------\n",
      "\u001b[35mcmd2:\u001b[0m                                            Total:        26.0 MB\n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m The following NEW packages will be INSTALLED:\n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m   _libgcc_mutex      pkgs/main/linux-64::_libgcc_mutex-0.1-main \n",
      "\u001b[35mcmd2:\u001b[0m   _openmp_mutex      pkgs/main/linux-64::_openmp_mutex-5.1-1_gnu \n",
      "\u001b[35mcmd2:\u001b[0m   bzip2              pkgs/main/linux-64::bzip2-1.0.8-h5eee18b_6 \n",
      "\u001b[35mcmd2:\u001b[0m   ca-certificates    pkgs/main/linux-64::ca-certificates-2025.12.2-h06a4308_0 \n",
      "\u001b[35mcmd2:\u001b[0m   expat              pkgs/main/linux-64::expat-2.7.3-h7354ed3_4 \n",
      "\u001b[35mcmd2:\u001b[0m   ld_impl_linux-64   pkgs/main/linux-64::ld_impl_linux-64-2.44-h153f514_2 \n",
      "\u001b[35mcmd2:\u001b[0m   libexpat           pkgs/main/linux-64::libexpat-2.7.3-h7354ed3_4 \n",
      "\u001b[35mcmd2:\u001b[0m   libffi             pkgs/main/linux-64::libffi-3.4.4-h6a678d5_1 \n",
      "\u001b[35mcmd2:\u001b[0m   libgcc             pkgs/main/linux-64::libgcc-15.2.0-h69a1729_7 \n",
      "\u001b[35mcmd2:\u001b[0m   libgcc-ng          pkgs/main/linux-64::libgcc-ng-15.2.0-h166f726_7 \n",
      "\u001b[35mcmd2:\u001b[0m   libgomp            pkgs/main/linux-64::libgomp-15.2.0-h4751f2c_7 \n",
      "\u001b[35mcmd2:\u001b[0m   libnsl             pkgs/main/linux-64::libnsl-2.0.0-h5eee18b_0 \n",
      "\u001b[35mcmd2:\u001b[0m   libstdcxx          pkgs/main/linux-64::libstdcxx-15.2.0-h39759b7_7 \n",
      "\u001b[35mcmd2:\u001b[0m   libstdcxx-ng       pkgs/main/linux-64::libstdcxx-ng-15.2.0-hc03a8fd_7 \n",
      "\u001b[35mcmd2:\u001b[0m   libuuid            pkgs/main/linux-64::libuuid-1.41.5-h5eee18b_0 \n",
      "\u001b[35mcmd2:\u001b[0m   libxcb             pkgs/main/linux-64::libxcb-1.17.0-h9b100fa_0 \n",
      "\u001b[35mcmd2:\u001b[0m   libzlib            pkgs/main/linux-64::libzlib-1.3.1-hb25bd0a_0 \n",
      "\u001b[35mcmd2:\u001b[0m   ncurses            pkgs/main/linux-64::ncurses-6.5-h7934f7d_0 \n",
      "\u001b[35mcmd2:\u001b[0m   openssl            pkgs/main/linux-64::openssl-3.0.18-hd6dcaed_0 \n",
      "\u001b[35mcmd2:\u001b[0m   pip                pkgs/main/noarch::pip-25.3-pyhc872135_0 \n",
      "\u001b[35mcmd2:\u001b[0m   pthread-stubs      pkgs/main/linux-64::pthread-stubs-0.3-h0ce48e5_1 \n",
      "\u001b[35mcmd2:\u001b[0m   python             pkgs/main/linux-64::python-3.10.19-h6fa692b_0 \n",
      "\u001b[35mcmd2:\u001b[0m   readline           pkgs/main/linux-64::readline-8.3-hc2a1206_0 \n",
      "\u001b[35mcmd2:\u001b[0m   setuptools         pkgs/main/linux-64::setuptools-80.9.0-py310h06a4308_0 \n",
      "\u001b[35mcmd2:\u001b[0m   sqlite             pkgs/main/linux-64::sqlite-3.51.0-h2a70700_0 \n",
      "\u001b[35mcmd2:\u001b[0m   tk                 pkgs/main/linux-64::tk-8.6.15-h54e0aa7_0 \n",
      "\u001b[35mcmd2:\u001b[0m   tzdata             pkgs/main/noarch::tzdata-2025b-h04d1e81_0 \n",
      "\u001b[35mcmd2:\u001b[0m   wheel              pkgs/main/linux-64::wheel-0.45.1-py310h06a4308_0 \n",
      "\u001b[35mcmd2:\u001b[0m   xorg-libx11        pkgs/main/linux-64::xorg-libx11-1.8.12-h9b100fa_1 \n",
      "\u001b[35mcmd2:\u001b[0m   xorg-libxau        pkgs/main/linux-64::xorg-libxau-1.0.12-h9b100fa_0 \n",
      "\u001b[35mcmd2:\u001b[0m   xorg-libxdmcp      pkgs/main/linux-64::xorg-libxdmcp-1.1.5-h9b100fa_0 \n",
      "\u001b[35mcmd2:\u001b[0m   xorg-xorgproto     pkgs/main/linux-64::xorg-xorgproto-2024.1-h5eee18b_1 \n",
      "\u001b[35mcmd2:\u001b[0m   xz                 pkgs/main/linux-64::xz-5.6.4-h5eee18b_1 \n",
      "\u001b[35mcmd2:\u001b[0m   zlib               pkgs/main/linux-64::zlib-1.3.1-hb25bd0a_0 \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Downloading and Extracting Packages: ...working...\n",
      "\u001b[35mcmd2:\u001b[0m python-3.10.19       | 24.5 MB   |            |   0% \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m setuptools-80.9.0    | 1.4 MB    |            |   0% \u001b[A\n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m wheel-0.45.1         | 115 KB    |            |   0% \u001b[A\u001b[A\n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m wheel-0.45.1         | 115 KB    | #3         |  14% \u001b[A\u001b[A\n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m wheel-0.45.1         | 115 KB    | ########## | 100% \u001b[A\u001b[A\n",
      "\u001b[35mcmd2:\u001b[0m python-3.10.19       | 24.5 MB   |            |   0% \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m setuptools-80.9.0    | 1.4 MB    | 1          |   1% \u001b[A\n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m wheel-0.45.1         | 115 KB    | ########## | 100% \u001b[A\u001b[A\n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m setuptools-80.9.0    | 1.4 MB    | ########## | 100% \u001b[A\n",
      "\u001b[35mcmd2:\u001b[0m python-3.10.19       | 24.5 MB   | ###7       |  38% \n",
      "\u001b[35mcmd2:\u001b[0m python-3.10.19       | 24.5 MB   | ########## | 100% \n",
      "\u001b[35mcmd2:\u001b[0m python-3.10.19       | 24.5 MB   | ########## | 100% \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m setuptools-80.9.0    | 1.4 MB    | ########## | 100% \u001b[A\n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m setuptools-80.9.0    | 1.4 MB    | ########## | 100% \u001b[A\n",
      "\u001b[35mcmd2:\u001b[0m python-3.10.19       | 24.5 MB   | ########## | 100% \n",
      "\u001b[35mcmd2:\u001b[0m                                                      \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m                                                      \u001b[A\n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m                                                      \u001b[A\u001b[A done\n",
      "\u001b[35mcmd2:\u001b[0m Preparing transaction: done\n",
      "\u001b[35mcmd2:\u001b[0m Verifying transaction: done\n",
      "\u001b[35mcmd2:\u001b[0m Executing transaction: done\n",
      "\u001b[35mcmd2:\u001b[0m #\n",
      "\u001b[35mcmd2:\u001b[0m # To activate this environment, use\n",
      "\u001b[35mcmd2:\u001b[0m #\n",
      "\u001b[35mcmd2:\u001b[0m #     $ conda activate b2txt25\n",
      "\u001b[35mcmd2:\u001b[0m #\n",
      "\u001b[35mcmd2:\u001b[0m # To deactivate an active environment, use\n",
      "\u001b[35mcmd2:\u001b[0m #\n",
      "\u001b[35mcmd2:\u001b[0m #     $ conda deactivate\n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Requirement already satisfied: pip in /root/miniconda3/envs/b2txt25/lib/python3.10/site-packages (25.3)\n",
      "\u001b[35mcmd2:\u001b[0m Looking in indexes: https://download.pytorch.org/whl/cu126\n",
      "\u001b[35mcmd2:\u001b[0m Collecting torch\n",
      "\u001b[35mcmd2:\u001b[0m   Downloading https://download.pytorch.org/whl/cu126/torch-2.9.1%2Bcu126-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (30 kB)\n",
      "\u001b[35mcmd2:\u001b[0m Collecting torchvision\n",
      "\u001b[35mcmd2:\u001b[0m   Downloading https://download.pytorch.org/whl/cu126/torchvision-0.24.1%2Bcu126-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (5.9 kB)\n",
      "\u001b[35mcmd2:\u001b[0m Collecting torchaudio\n",
      "\u001b[35mcmd2:\u001b[0m   Downloading https://download.pytorch.org/whl/cu126/torchaudio-2.9.1%2Bcu126-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (6.9 kB)\n",
      "\u001b[35mcmd2:\u001b[0m Collecting filelock (from torch)\n",
      "\u001b[35mcmd2:\u001b[0m   Downloading filelock-3.20.0-py3-none-any.whl.metadata (2.1 kB)\n",
      "\u001b[35mcmd2:\u001b[0m Collecting typing-extensions>=4.10.0 (from torch)\n",
      "\u001b[35mcmd2:\u001b[0m   Downloading https://download.pytorch.org/whl/typing_extensions-4.15.0-py3-none-any.whl.metadata (3.3 kB)\n",
      "\u001b[35mcmd2:\u001b[0m Collecting sympy>=1.13.3 (from torch)\n",
      "\u001b[35mcmd2:\u001b[0m   Downloading sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
      "\u001b[35mcmd2:\u001b[0m Collecting networkx>=2.5.1 (from torch)\n",
      "\u001b[35mcmd2:\u001b[0m   Downloading networkx-3.4.2-py3-none-any.whl.metadata (6.3 kB)\n",
      "\u001b[35mcmd2:\u001b[0m Collecting jinja2 (from torch)\n",
      "\u001b[35mcmd2:\u001b[0m   Downloading https://download.pytorch.org/whl/jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
      "\u001b[35mcmd2:\u001b[0m Collecting fsspec>=0.8.5 (from torch)\n",
      "\u001b[35mcmd2:\u001b[0m   Downloading fsspec-2025.12.0-py3-none-any.whl.metadata (10 kB)\n",
      "\u001b[35mcmd2:\u001b[0m Collecting nvidia-cuda-nvrtc-cu12==12.6.77 (from torch)\n",
      "\u001b[35mcmd2:\u001b[0m   Downloading https://pypi.nvidia.com/nvidia-cuda-nvrtc-cu12/nvidia_cuda_nvrtc_cu12-12.6.77-py3-none-manylinux2014_x86_64.whl (23.7 MB)\n",
      "\u001b[35mcmd2:\u001b[0m      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 23.7/23.7 MB 86.9 MB/s  0:00:00\n",
      "\u001b[35mcmd2:\u001b[0m Collecting nvidia-cuda-runtime-cu12==12.6.77 (from torch)\n",
      "\u001b[35mcmd2:\u001b[0m   Downloading https://pypi.nvidia.com/nvidia-cuda-runtime-cu12/nvidia_cuda_runtime_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (897 kB)\n",
      "\u001b[35mcmd2:\u001b[0m      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 897.7/897.7 kB 80.5 MB/s  0:00:00\n",
      "\u001b[35mcmd2:\u001b[0m Collecting nvidia-cuda-cupti-cu12==12.6.80 (from torch)\n",
      "\u001b[35mcmd2:\u001b[0m   Downloading https://pypi.nvidia.com/nvidia-cuda-cupti-cu12/nvidia_cuda_cupti_cu12-12.6.80-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (8.9 MB)\n",
      "\u001b[35mcmd2:\u001b[0m      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 8.9/8.9 MB 212.2 MB/s  0:00:00\n",
      "\u001b[35mcmd2:\u001b[0m Collecting nvidia-cudnn-cu12==9.10.2.21 (from torch)\n",
      "\u001b[35mcmd2:\u001b[0m   Downloading https://pypi.nvidia.com/nvidia-cudnn-cu12/nvidia_cudnn_cu12-9.10.2.21-py3-none-manylinux_2_27_x86_64.whl (706.8 MB)\n",
      "\u001b[35mcmd2:\u001b[0m      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 706.8/706.8 MB 248.3 MB/s  0:00:02\n",
      "\u001b[35mcmd2:\u001b[0m Collecting nvidia-cublas-cu12==12.6.4.1 (from torch)\n",
      "\u001b[35mcmd2:\u001b[0m   Downloading https://pypi.nvidia.com/nvidia-cublas-cu12/nvidia_cublas_cu12-12.6.4.1-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (393.1 MB)\n",
      "\u001b[35mcmd2:\u001b[0m      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 393.1/393.1 MB 266.3 MB/s  0:00:01\n",
      "\u001b[35mcmd2:\u001b[0m Collecting nvidia-cufft-cu12==11.3.0.4 (from torch)\n",
      "\u001b[35mcmd2:\u001b[0m   Downloading https://pypi.nvidia.com/nvidia-cufft-cu12/nvidia_cufft_cu12-11.3.0.4-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (200.2 MB)\n",
      "\u001b[35mcmd2:\u001b[0m      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 200.2/200.2 MB 257.2 MB/s  0:00:00\n",
      "\u001b[35mcmd2:\u001b[0m Collecting nvidia-curand-cu12==10.3.7.77 (from torch)\n",
      "\u001b[35mcmd2:\u001b[0m   Downloading https://pypi.nvidia.com/nvidia-curand-cu12/nvidia_curand_cu12-10.3.7.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (56.3 MB)\n",
      "\u001b[35mcmd2:\u001b[0m      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 56.3/56.3 MB 277.7 MB/s  0:00:00\n",
      "\u001b[35mcmd2:\u001b[0m Collecting nvidia-cusolver-cu12==11.7.1.2 (from torch)\n",
      "\u001b[35mcmd2:\u001b[0m   Downloading https://pypi.nvidia.com/nvidia-cusolver-cu12/nvidia_cusolver_cu12-11.7.1.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (158.2 MB)\n",
      "\u001b[35mcmd2:\u001b[0m      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 158.2/158.2 MB 257.7 MB/s  0:00:00\n",
      "\u001b[35mcmd2:\u001b[0m Collecting nvidia-cusparse-cu12==12.5.4.2 (from torch)\n",
      "\u001b[35mcmd2:\u001b[0m   Downloading https://pypi.nvidia.com/nvidia-cusparse-cu12/nvidia_cusparse_cu12-12.5.4.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (216.6 MB)\n",
      "\u001b[35mcmd2:\u001b[0m      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 216.6/216.6 MB 267.4 MB/s  0:00:00\n",
      "\u001b[35mcmd2:\u001b[0m Collecting nvidia-cusparselt-cu12==0.7.1 (from torch)\n",
      "\u001b[35mcmd2:\u001b[0m   Downloading https://pypi.nvidia.com/nvidia-cusparselt-cu12/nvidia_cusparselt_cu12-0.7.1-py3-none-manylinux2014_x86_64.whl (287.2 MB)\n",
      "\u001b[35mcmd2:\u001b[0m      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 287.2/287.2 MB 269.3 MB/s  0:00:01\n",
      "\u001b[35mcmd2:\u001b[0m Collecting nvidia-nccl-cu12==2.27.5 (from torch)\n",
      "\u001b[35mcmd2:\u001b[0m   Downloading https://pypi.nvidia.com/nvidia-nccl-cu12/nvidia_nccl_cu12-2.27.5-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (322.3 MB)\n",
      "\u001b[35mcmd2:\u001b[0m      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 322.3/322.3 MB 236.3 MB/s  0:00:01\n",
      "\u001b[35mcmd2:\u001b[0m Collecting nvidia-nvshmem-cu12==3.3.20 (from torch)\n",
      "\u001b[35mcmd2:\u001b[0m   Downloading https://pypi.nvidia.com/nvidia-nvshmem-cu12/nvidia_nvshmem_cu12-3.3.20-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (124.7 MB)\n",
      "\u001b[35mcmd2:\u001b[0m      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 124.7/124.7 MB 273.2 MB/s  0:00:00\n",
      "\u001b[35mcmd2:\u001b[0m Collecting nvidia-nvtx-cu12==12.6.77 (from torch)\n",
      "\u001b[35mcmd2:\u001b[0m   Downloading https://pypi.nvidia.com/nvidia-nvtx-cu12/nvidia_nvtx_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89 kB)\n",
      "\u001b[35mcmd2:\u001b[0m Collecting nvidia-nvjitlink-cu12==12.6.85 (from torch)\n",
      "\u001b[35mcmd2:\u001b[0m   Downloading https://pypi.nvidia.com/nvidia-nvjitlink-cu12/nvidia_nvjitlink_cu12-12.6.85-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (19.7 MB)\n",
      "\u001b[35mcmd2:\u001b[0m      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 19.7/19.7 MB 271.1 MB/s  0:00:00\n",
      "\u001b[35mcmd2:\u001b[0m Collecting nvidia-cufile-cu12==1.11.1.6 (from torch)\n",
      "\u001b[35mcmd2:\u001b[0m   Downloading https://pypi.nvidia.com/nvidia-cufile-cu12/nvidia_cufile_cu12-1.11.1.6-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.1 MB)\n",
      "\u001b[35mcmd2:\u001b[0m      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.1/1.1 MB 364.9 MB/s  0:00:00\n",
      "\u001b[35mcmd2:\u001b[0m Collecting triton==3.5.1 (from torch)\n",
      "\u001b[35mcmd2:\u001b[0m   Downloading https://download.pytorch.org/whl/triton-3.5.1-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.7 kB)\n",
      "\u001b[35mcmd2:\u001b[0m Collecting numpy (from torchvision)\n",
      "\u001b[35mcmd2:\u001b[0m   Downloading numpy-2.2.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n",
      "\u001b[35mcmd2:\u001b[0m Collecting pillow!=8.3.*,>=5.3.0 (from torchvision)\n",
      "\u001b[35mcmd2:\u001b[0m   Downloading pillow-12.0.0-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (8.8 kB)\n",
      "\u001b[35mcmd2:\u001b[0m Collecting mpmath<1.4,>=1.1.0 (from sympy>=1.13.3->torch)\n",
      "\u001b[35mcmd2:\u001b[0m   Downloading mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "\u001b[35mcmd2:\u001b[0m Collecting MarkupSafe>=2.0 (from jinja2->torch)\n",
      "\u001b[35mcmd2:\u001b[0m   Downloading https://download.pytorch.org/whl/MarkupSafe-2.1.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)\n",
      "\u001b[35mcmd2:\u001b[0m Downloading https://download.pytorch.org/whl/cu126/torch-2.9.1%2Bcu126-cp310-cp310-manylinux_2_28_x86_64.whl (832.9 MB)\n",
      "\u001b[35mcmd2:\u001b[0m    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 832.9/832.9 MB 29.3 MB/s  0:00:10\n",
      "\u001b[35mcmd2:\u001b[0m Downloading https://download.pytorch.org/whl/triton-3.5.1-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (170.3 MB)\n",
      "\u001b[35mcmd2:\u001b[0m    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 170.3/170.3 MB 108.9 MB/s  0:00:01\n",
      "\u001b[35mcmd2:\u001b[0m Downloading https://download.pytorch.org/whl/cu126/torchvision-0.24.1%2Bcu126-cp310-cp310-manylinux_2_28_x86_64.whl (7.3 MB)\n",
      "\u001b[35mcmd2:\u001b[0m    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 7.3/7.3 MB 67.4 MB/s  0:00:00\n",
      "\u001b[35mcmd2:\u001b[0m Downloading https://download.pytorch.org/whl/cu126/torchaudio-2.9.1%2Bcu126-cp310-cp310-manylinux_2_28_x86_64.whl (1.9 MB)\n",
      "\u001b[35mcmd2:\u001b[0m    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.9/1.9 MB 92.1 MB/s  0:00:00\n",
      "\u001b[35mcmd2:\u001b[0m Downloading fsspec-2025.12.0-py3-none-any.whl (201 kB)\n",
      "\u001b[35mcmd2:\u001b[0m Downloading networkx-3.4.2-py3-none-any.whl (1.7 MB)\n",
      "\u001b[35mcmd2:\u001b[0m    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.7/1.7 MB 36.8 MB/s  0:00:00\n",
      "\u001b[35mcmd2:\u001b[0m Downloading pillow-12.0.0-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (7.0 MB)\n",
      "\u001b[35mcmd2:\u001b[0m    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 7.0/7.0 MB 119.5 MB/s  0:00:00\n",
      "\u001b[35mcmd2:\u001b[0m Downloading sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
      "\u001b[35mcmd2:\u001b[0m    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 6.3/6.3 MB 129.4 MB/s  0:00:00\n",
      "\u001b[35mcmd2:\u001b[0m Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "\u001b[35mcmd2:\u001b[0m    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 536.2/536.2 kB 20.9 MB/s  0:00:00\n",
      "\u001b[35mcmd2:\u001b[0m Downloading https://download.pytorch.org/whl/typing_extensions-4.15.0-py3-none-any.whl (44 kB)\n",
      "\u001b[35mcmd2:\u001b[0m Downloading filelock-3.20.0-py3-none-any.whl (16 kB)\n",
      "\u001b[35mcmd2:\u001b[0m Downloading https://download.pytorch.org/whl/jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
      "\u001b[35mcmd2:\u001b[0m Downloading numpy-2.2.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.8 MB)\n",
      "\u001b[35mcmd2:\u001b[0m    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 16.8/16.8 MB 131.5 MB/s  0:00:00\n",
      "\u001b[35mcmd2:\u001b[0m Installing collected packages: nvidia-cusparselt-cu12, mpmath, typing-extensions, triton, sympy, pillow, nvidia-nvtx-cu12, nvidia-nvshmem-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufile-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, networkx, MarkupSafe, fsspec, filelock, nvidia-cusparse-cu12, nvidia-cufft-cu12, nvidia-cudnn-cu12, jinja2, nvidia-cusolver-cu12, torch, torchvision, torchaudio\n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Successfully installed MarkupSafe-2.1.5 filelock-3.20.0 fsspec-2025.12.0 jinja2-3.1.6 mpmath-1.3.0 networkx-3.4.2 numpy-2.2.6 nvidia-cublas-cu12-12.6.4.1 nvidia-cuda-cupti-cu12-12.6.80 nvidia-cuda-nvrtc-cu12-12.6.77 nvidia-cuda-runtime-cu12-12.6.77 nvidia-cudnn-cu12-9.10.2.21 nvidia-cufft-cu12-11.3.0.4 nvidia-cufile-cu12-1.11.1.6 nvidia-curand-cu12-10.3.7.77 nvidia-cusolver-cu12-11.7.1.2 nvidia-cusparse-cu12-12.5.4.2 nvidia-cusparselt-cu12-0.7.1 nvidia-nccl-cu12-2.27.5 nvidia-nvjitlink-cu12-12.6.85 nvidia-nvshmem-cu12-3.3.20 nvidia-nvtx-cu12-12.6.77 pillow-12.0.0 sympy-1.14.0 torch-2.9.1+cu126 torchaudio-2.9.1+cu126 torchvision-0.24.1+cu126 triton-3.5.1 typing-extensions-4.15.0\n",
      "\u001b[35mcmd2:\u001b[0m Obtaining file:///kaggle/working/Brain-To-Text-MOA\n",
      "\u001b[35mcmd2:\u001b[0m   Installing build dependencies: started\n",
      "\u001b[35mcmd2:\u001b[0m   Installing build dependencies: finished with status 'done'\n",
      "\u001b[35mcmd2:\u001b[0m   Checking if build backend supports build_editable: started\n",
      "\u001b[35mcmd2:\u001b[0m   Checking if build backend supports build_editable: finished with status 'done'\n",
      "\u001b[35mcmd2:\u001b[0m   Getting requirements to build editable: started\n",
      "\u001b[35mcmd2:\u001b[0m   Getting requirements to build editable: finished with status 'done'\n",
      "\u001b[35mcmd2:\u001b[0m   Preparing editable metadata (pyproject.toml): started\n",
      "\u001b[35mcmd2:\u001b[0m   Preparing editable metadata (pyproject.toml): finished with status 'done'\n",
      "\u001b[35mcmd2:\u001b[0m Collecting redis==5.2.1\n",
      "\u001b[35mcmd2:\u001b[0m   Downloading redis-5.2.1-py3-none-any.whl.metadata (9.1 kB)\n",
      "\u001b[35mcmd2:\u001b[0m Collecting jupyter==1.1.1\n",
      "\u001b[35mcmd2:\u001b[0m   Using cached jupyter-1.1.1-py2.py3-none-any.whl.metadata (2.0 kB)\n",
      "\u001b[35mcmd2:\u001b[0m Collecting numpy==2.1.2\n",
      "\u001b[35mcmd2:\u001b[0m   Downloading numpy-2.1.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
      "\u001b[35mcmd2:\u001b[0m Collecting pandas==2.3.0\n",
      "\u001b[35mcmd2:\u001b[0m   Downloading pandas-2.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (91 kB)\n",
      "\u001b[35mcmd2:\u001b[0m Collecting matplotlib==3.10.1\n",
      "\u001b[35mcmd2:\u001b[0m   Downloading matplotlib-3.10.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
      "\u001b[35mcmd2:\u001b[0m Collecting scipy==1.15.2\n",
      "\u001b[35mcmd2:\u001b[0m   Downloading scipy-1.15.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
      "\u001b[35mcmd2:\u001b[0m Collecting scikit-learn==1.6.1\n",
      "\u001b[35mcmd2:\u001b[0m   Downloading scikit_learn-1.6.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
      "\u001b[35mcmd2:\u001b[0m Collecting tqdm==4.67.1\n",
      "\u001b[35mcmd2:\u001b[0m   Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "\u001b[35mcmd2:\u001b[0m Collecting g2p_en==2.1.0\n",
      "\u001b[35mcmd2:\u001b[0m   Using cached g2p_en-2.1.0-py3-none-any.whl.metadata (4.5 kB)\n",
      "\u001b[35mcmd2:\u001b[0m Collecting h5py==3.13.0\n",
      "\u001b[35mcmd2:\u001b[0m   Downloading h5py-3.13.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.5 kB)\n",
      "\u001b[35mcmd2:\u001b[0m Collecting omegaconf==2.3.0\n",
      "\u001b[35mcmd2:\u001b[0m   Using cached omegaconf-2.3.0-py3-none-any.whl.metadata (3.9 kB)\n",
      "\u001b[35mcmd2:\u001b[0m Collecting editdistance==0.8.1\n",
      "\u001b[35mcmd2:\u001b[0m   Downloading editdistance-0.8.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.9 kB)\n",
      "\u001b[35mcmd2:\u001b[0m Collecting huggingface-hub==0.33.1\n",
      "\u001b[35mcmd2:\u001b[0m   Downloading huggingface_hub-0.33.1-py3-none-any.whl.metadata (14 kB)\n",
      "\u001b[35mcmd2:\u001b[0m Collecting transformers==4.53.0\n",
      "\u001b[35mcmd2:\u001b[0m   Downloading transformers-4.53.0-py3-none-any.whl.metadata (39 kB)\n",
      "\u001b[35mcmd2:\u001b[0m Collecting tokenizers==0.21.2\n",
      "\u001b[35mcmd2:\u001b[0m   Downloading tokenizers-0.21.2-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "\u001b[35mcmd2:\u001b[0m Collecting accelerate==1.8.1\n",
      "\u001b[35mcmd2:\u001b[0m   Downloading accelerate-1.8.1-py3-none-any.whl.metadata (19 kB)\n",
      "\u001b[35mcmd2:\u001b[0m Collecting bitsandbytes==0.46.0\n",
      "\u001b[35mcmd2:\u001b[0m   Downloading bitsandbytes-0.46.0-py3-none-manylinux_2_24_x86_64.whl.metadata (10 kB)\n",
      "\u001b[35mcmd2:\u001b[0m Collecting async-timeout>=4.0.3 (from redis==5.2.1)\n",
      "\u001b[35mcmd2:\u001b[0m   Using cached async_timeout-5.0.1-py3-none-any.whl.metadata (5.1 kB)\n",
      "\u001b[35mcmd2:\u001b[0m Collecting notebook (from jupyter==1.1.1)\n",
      "\u001b[35mcmd2:\u001b[0m   Using cached notebook-7.5.1-py3-none-any.whl.metadata (10 kB)\n",
      "\u001b[35mcmd2:\u001b[0m Collecting jupyter-console (from jupyter==1.1.1)\n",
      "\u001b[35mcmd2:\u001b[0m   Using cached jupyter_console-6.6.3-py3-none-any.whl.metadata (5.8 kB)\n",
      "\u001b[35mcmd2:\u001b[0m Collecting nbconvert (from jupyter==1.1.1)\n",
      "\u001b[35mcmd2:\u001b[0m   Using cached nbconvert-7.16.6-py3-none-any.whl.metadata (8.5 kB)\n",
      "\u001b[35mcmd2:\u001b[0m Collecting ipykernel (from jupyter==1.1.1)\n",
      "\u001b[35mcmd2:\u001b[0m   Downloading ipykernel-7.1.0-py3-none-any.whl.metadata (4.5 kB)\n",
      "\u001b[35mcmd2:\u001b[0m Collecting ipywidgets (from jupyter==1.1.1)\n",
      "\u001b[35mcmd2:\u001b[0m   Using cached ipywidgets-8.1.8-py3-none-any.whl.metadata (2.4 kB)\n",
      "\u001b[35mcmd2:\u001b[0m Collecting jupyterlab (from jupyter==1.1.1)\n",
      "\u001b[35mcmd2:\u001b[0m   Using cached jupyterlab-4.5.1-py3-none-any.whl.metadata (16 kB)\n",
      "\u001b[35mcmd2:\u001b[0m Collecting python-dateutil>=2.8.2 (from pandas==2.3.0)\n",
      "\u001b[35mcmd2:\u001b[0m   Using cached python_dateutil-2.9.0.post0-py2.py3-none-any.whl.metadata (8.4 kB)\n",
      "\u001b[35mcmd2:\u001b[0m Collecting pytz>=2020.1 (from pandas==2.3.0)\n",
      "\u001b[35mcmd2:\u001b[0m   Downloading pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "\u001b[35mcmd2:\u001b[0m Collecting tzdata>=2022.7 (from pandas==2.3.0)\n",
      "\u001b[35mcmd2:\u001b[0m   Using cached tzdata-2025.3-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "\u001b[35mcmd2:\u001b[0m Collecting contourpy>=1.0.1 (from matplotlib==3.10.1)\n",
      "\u001b[35mcmd2:\u001b[0m   Downloading contourpy-1.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.5 kB)\n",
      "\u001b[35mcmd2:\u001b[0m Collecting cycler>=0.10 (from matplotlib==3.10.1)\n",
      "\u001b[35mcmd2:\u001b[0m   Using cached cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "\u001b[35mcmd2:\u001b[0m Collecting fonttools>=4.22.0 (from matplotlib==3.10.1)\n",
      "\u001b[35mcmd2:\u001b[0m   Downloading fonttools-4.61.1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (114 kB)\n",
      "\u001b[35mcmd2:\u001b[0m Collecting kiwisolver>=1.3.1 (from matplotlib==3.10.1)\n",
      "\u001b[35mcmd2:\u001b[0m   Downloading kiwisolver-1.4.9-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (6.3 kB)\n",
      "\u001b[35mcmd2:\u001b[0m Collecting packaging>=20.0 (from matplotlib==3.10.1)\n",
      "\u001b[35mcmd2:\u001b[0m   Using cached packaging-25.0-py3-none-any.whl.metadata (3.3 kB)\n",
      "\u001b[35mcmd2:\u001b[0m Requirement already satisfied: pillow>=8 in /root/miniconda3/envs/b2txt25/lib/python3.10/site-packages (from matplotlib==3.10.1) (12.0.0)\n",
      "\u001b[35mcmd2:\u001b[0m Collecting pyparsing>=2.3.1 (from matplotlib==3.10.1)\n",
      "\u001b[35mcmd2:\u001b[0m   Using cached pyparsing-3.3.1-py3-none-any.whl.metadata (5.6 kB)\n",
      "\u001b[35mcmd2:\u001b[0m Collecting joblib>=1.2.0 (from scikit-learn==1.6.1)\n",
      "\u001b[35mcmd2:\u001b[0m   Using cached joblib-1.5.3-py3-none-any.whl.metadata (5.5 kB)\n",
      "\u001b[35mcmd2:\u001b[0m Collecting threadpoolctl>=3.1.0 (from scikit-learn==1.6.1)\n",
      "\u001b[35mcmd2:\u001b[0m   Using cached threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "\u001b[35mcmd2:\u001b[0m Collecting nltk>=3.2.4 (from g2p_en==2.1.0)\n",
      "\u001b[35mcmd2:\u001b[0m   Using cached nltk-3.9.2-py3-none-any.whl.metadata (3.2 kB)\n",
      "\u001b[35mcmd2:\u001b[0m Collecting inflect>=0.3.1 (from g2p_en==2.1.0)\n",
      "\u001b[35mcmd2:\u001b[0m   Using cached inflect-7.5.0-py3-none-any.whl.metadata (24 kB)\n",
      "\u001b[35mcmd2:\u001b[0m Collecting distance>=0.1.3 (from g2p_en==2.1.0)\n",
      "\u001b[35mcmd2:\u001b[0m   Using cached Distance-0.1.3.tar.gz (180 kB)\n",
      "\u001b[35mcmd2:\u001b[0m   Installing build dependencies: started\n",
      "\u001b[35mcmd2:\u001b[0m   Installing build dependencies: finished with status 'done'\n",
      "\u001b[35mcmd2:\u001b[0m   Getting requirements to build wheel: started\n",
      "\u001b[35mcmd2:\u001b[0m   Getting requirements to build wheel: finished with status 'done'\n",
      "\u001b[35mcmd2:\u001b[0m   Preparing metadata (pyproject.toml): started\n",
      "\u001b[35mcmd2:\u001b[0m   Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "\u001b[35mcmd2:\u001b[0m Collecting antlr4-python3-runtime==4.9.* (from omegaconf==2.3.0)\n",
      "\u001b[35mcmd2:\u001b[0m   Using cached antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n",
      "\u001b[35mcmd2:\u001b[0m   Installing build dependencies: started\n",
      "\u001b[35mcmd2:\u001b[0m   Installing build dependencies: finished with status 'done'\n",
      "\u001b[35mcmd2:\u001b[0m   Getting requirements to build wheel: started\n",
      "\u001b[35mcmd2:\u001b[0m   Getting requirements to build wheel: finished with status 'done'\n",
      "\u001b[35mcmd2:\u001b[0m   Preparing metadata (pyproject.toml): started\n",
      "\u001b[35mcmd2:\u001b[0m   Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "\u001b[35mcmd2:\u001b[0m Collecting PyYAML>=5.1.0 (from omegaconf==2.3.0)\n",
      "\u001b[35mcmd2:\u001b[0m   Downloading pyyaml-6.0.3-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (2.4 kB)\n",
      "\u001b[35mcmd2:\u001b[0m Requirement already satisfied: filelock in /root/miniconda3/envs/b2txt25/lib/python3.10/site-packages (from huggingface-hub==0.33.1) (3.20.0)\n",
      "\u001b[35mcmd2:\u001b[0m Requirement already satisfied: fsspec>=2023.5.0 in /root/miniconda3/envs/b2txt25/lib/python3.10/site-packages (from huggingface-hub==0.33.1) (2025.12.0)\n",
      "\u001b[35mcmd2:\u001b[0m Collecting requests (from huggingface-hub==0.33.1)\n",
      "\u001b[35mcmd2:\u001b[0m   Using cached requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
      "\u001b[35mcmd2:\u001b[0m Requirement already satisfied: typing-extensions>=3.7.4.3 in /root/miniconda3/envs/b2txt25/lib/python3.10/site-packages (from huggingface-hub==0.33.1) (4.15.0)\n",
      "\u001b[35mcmd2:\u001b[0m Collecting hf-xet<2.0.0,>=1.1.2 (from huggingface-hub==0.33.1)\n",
      "\u001b[35mcmd2:\u001b[0m   Downloading hf_xet-1.2.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
      "\u001b[35mcmd2:\u001b[0m Collecting regex!=2019.12.17 (from transformers==4.53.0)\n",
      "\u001b[35mcmd2:\u001b[0m   Downloading regex-2025.11.3-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (40 kB)\n",
      "\u001b[35mcmd2:\u001b[0m Collecting safetensors>=0.4.3 (from transformers==4.53.0)\n",
      "\u001b[35mcmd2:\u001b[0m   Using cached safetensors-0.7.0-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
      "\u001b[35mcmd2:\u001b[0m Collecting psutil (from accelerate==1.8.1)\n",
      "\u001b[35mcmd2:\u001b[0m   Using cached psutil-7.2.0-cp36-abi3-manylinux2010_x86_64.manylinux_2_12_x86_64.manylinux_2_28_x86_64.whl.metadata (22 kB)\n",
      "\u001b[35mcmd2:\u001b[0m Requirement already satisfied: torch>=2.0.0 in /root/miniconda3/envs/b2txt25/lib/python3.10/site-packages (from accelerate==1.8.1) (2.9.1+cu126)\n",
      "\u001b[35mcmd2:\u001b[0m Requirement already satisfied: sympy>=1.13.3 in /root/miniconda3/envs/b2txt25/lib/python3.10/site-packages (from torch>=2.0.0->accelerate==1.8.1) (1.14.0)\n",
      "\u001b[35mcmd2:\u001b[0m Requirement already satisfied: networkx>=2.5.1 in /root/miniconda3/envs/b2txt25/lib/python3.10/site-packages (from torch>=2.0.0->accelerate==1.8.1) (3.4.2)\n",
      "\u001b[35mcmd2:\u001b[0m Requirement already satisfied: jinja2 in /root/miniconda3/envs/b2txt25/lib/python3.10/site-packages (from torch>=2.0.0->accelerate==1.8.1) (3.1.6)\n",
      "\u001b[35mcmd2:\u001b[0m Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /root/miniconda3/envs/b2txt25/lib/python3.10/site-packages (from torch>=2.0.0->accelerate==1.8.1) (12.6.77)\n",
      "\u001b[35mcmd2:\u001b[0m Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /root/miniconda3/envs/b2txt25/lib/python3.10/site-packages (from torch>=2.0.0->accelerate==1.8.1) (12.6.77)\n",
      "\u001b[35mcmd2:\u001b[0m Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /root/miniconda3/envs/b2txt25/lib/python3.10/site-packages (from torch>=2.0.0->accelerate==1.8.1) (12.6.80)\n",
      "\u001b[35mcmd2:\u001b[0m Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /root/miniconda3/envs/b2txt25/lib/python3.10/site-packages (from torch>=2.0.0->accelerate==1.8.1) (9.10.2.21)\n",
      "\u001b[35mcmd2:\u001b[0m Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /root/miniconda3/envs/b2txt25/lib/python3.10/site-packages (from torch>=2.0.0->accelerate==1.8.1) (12.6.4.1)\n",
      "\u001b[35mcmd2:\u001b[0m Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /root/miniconda3/envs/b2txt25/lib/python3.10/site-packages (from torch>=2.0.0->accelerate==1.8.1) (11.3.0.4)\n",
      "\u001b[35mcmd2:\u001b[0m Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /root/miniconda3/envs/b2txt25/lib/python3.10/site-packages (from torch>=2.0.0->accelerate==1.8.1) (10.3.7.77)\n",
      "\u001b[35mcmd2:\u001b[0m Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /root/miniconda3/envs/b2txt25/lib/python3.10/site-packages (from torch>=2.0.0->accelerate==1.8.1) (11.7.1.2)\n",
      "\u001b[35mcmd2:\u001b[0m Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /root/miniconda3/envs/b2txt25/lib/python3.10/site-packages (from torch>=2.0.0->accelerate==1.8.1) (12.5.4.2)\n",
      "\u001b[35mcmd2:\u001b[0m Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /root/miniconda3/envs/b2txt25/lib/python3.10/site-packages (from torch>=2.0.0->accelerate==1.8.1) (0.7.1)\n",
      "\u001b[35mcmd2:\u001b[0m Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /root/miniconda3/envs/b2txt25/lib/python3.10/site-packages (from torch>=2.0.0->accelerate==1.8.1) (2.27.5)\n",
      "\u001b[35mcmd2:\u001b[0m Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /root/miniconda3/envs/b2txt25/lib/python3.10/site-packages (from torch>=2.0.0->accelerate==1.8.1) (3.3.20)\n",
      "\u001b[35mcmd2:\u001b[0m Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /root/miniconda3/envs/b2txt25/lib/python3.10/site-packages (from torch>=2.0.0->accelerate==1.8.1) (12.6.77)\n",
      "\u001b[35mcmd2:\u001b[0m Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /root/miniconda3/envs/b2txt25/lib/python3.10/site-packages (from torch>=2.0.0->accelerate==1.8.1) (12.6.85)\n",
      "\u001b[35mcmd2:\u001b[0m Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /root/miniconda3/envs/b2txt25/lib/python3.10/site-packages (from torch>=2.0.0->accelerate==1.8.1) (1.11.1.6)\n",
      "\u001b[35mcmd2:\u001b[0m Requirement already satisfied: triton==3.5.1 in /root/miniconda3/envs/b2txt25/lib/python3.10/site-packages (from torch>=2.0.0->accelerate==1.8.1) (3.5.1)\n",
      "\u001b[35mcmd2:\u001b[0m Collecting more_itertools>=8.5.0 (from inflect>=0.3.1->g2p_en==2.1.0)\n",
      "\u001b[35mcmd2:\u001b[0m   Using cached more_itertools-10.8.0-py3-none-any.whl.metadata (39 kB)\n",
      "\u001b[35mcmd2:\u001b[0m Collecting typeguard>=4.0.1 (from inflect>=0.3.1->g2p_en==2.1.0)\n",
      "\u001b[35mcmd2:\u001b[0m   Using cached typeguard-4.4.4-py3-none-any.whl.metadata (3.3 kB)\n",
      "\u001b[35mcmd2:\u001b[0m Collecting click (from nltk>=3.2.4->g2p_en==2.1.0)\n",
      "\u001b[35mcmd2:\u001b[0m   Downloading click-8.3.1-py3-none-any.whl.metadata (2.6 kB)\n",
      "\u001b[35mcmd2:\u001b[0m Collecting six>=1.5 (from python-dateutil>=2.8.2->pandas==2.3.0)\n",
      "\u001b[35mcmd2:\u001b[0m   Using cached six-1.17.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
      "\u001b[35mcmd2:\u001b[0m Requirement already satisfied: mpmath<1.4,>=1.1.0 in /root/miniconda3/envs/b2txt25/lib/python3.10/site-packages (from sympy>=1.13.3->torch>=2.0.0->accelerate==1.8.1) (1.3.0)\n",
      "\u001b[35mcmd2:\u001b[0m Collecting comm>=0.1.1 (from ipykernel->jupyter==1.1.1)\n",
      "\u001b[35mcmd2:\u001b[0m   Using cached comm-0.2.3-py3-none-any.whl.metadata (3.7 kB)\n",
      "\u001b[35mcmd2:\u001b[0m Collecting debugpy>=1.6.5 (from ipykernel->jupyter==1.1.1)\n",
      "\u001b[35mcmd2:\u001b[0m   Downloading debugpy-1.8.19-cp310-cp310-manylinux_2_34_x86_64.whl.metadata (1.4 kB)\n",
      "\u001b[35mcmd2:\u001b[0m Collecting ipython>=7.23.1 (from ipykernel->jupyter==1.1.1)\n",
      "\u001b[35mcmd2:\u001b[0m   Downloading ipython-8.37.0-py3-none-any.whl.metadata (5.1 kB)\n",
      "\u001b[35mcmd2:\u001b[0m Collecting jupyter-client>=8.0.0 (from ipykernel->jupyter==1.1.1)\n",
      "\u001b[35mcmd2:\u001b[0m   Downloading jupyter_client-8.7.0-py3-none-any.whl.metadata (8.3 kB)\n",
      "\u001b[35mcmd2:\u001b[0m Collecting jupyter-core!=5.0.*,>=4.12 (from ipykernel->jupyter==1.1.1)\n",
      "\u001b[35mcmd2:\u001b[0m   Downloading jupyter_core-5.9.1-py3-none-any.whl.metadata (1.5 kB)\n",
      "\u001b[35mcmd2:\u001b[0m Collecting matplotlib-inline>=0.1 (from ipykernel->jupyter==1.1.1)\n",
      "\u001b[35mcmd2:\u001b[0m   Using cached matplotlib_inline-0.2.1-py3-none-any.whl.metadata (2.3 kB)\n",
      "\u001b[35mcmd2:\u001b[0m Collecting nest-asyncio>=1.4 (from ipykernel->jupyter==1.1.1)\n",
      "\u001b[35mcmd2:\u001b[0m   Using cached nest_asyncio-1.6.0-py3-none-any.whl.metadata (2.8 kB)\n",
      "\u001b[35mcmd2:\u001b[0m Collecting pyzmq>=25 (from ipykernel->jupyter==1.1.1)\n",
      "\u001b[35mcmd2:\u001b[0m   Downloading pyzmq-27.1.0-cp310-cp310-manylinux_2_26_x86_64.manylinux_2_28_x86_64.whl.metadata (6.0 kB)\n",
      "\u001b[35mcmd2:\u001b[0m Collecting tornado>=6.2 (from ipykernel->jupyter==1.1.1)\n",
      "\u001b[35mcmd2:\u001b[0m   Using cached tornado-6.5.4-cp39-abi3-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.8 kB)\n",
      "\u001b[35mcmd2:\u001b[0m Collecting traitlets>=5.4.0 (from ipykernel->jupyter==1.1.1)\n",
      "\u001b[35mcmd2:\u001b[0m   Using cached traitlets-5.14.3-py3-none-any.whl.metadata (10 kB)\n",
      "\u001b[35mcmd2:\u001b[0m Collecting decorator (from ipython>=7.23.1->ipykernel->jupyter==1.1.1)\n",
      "\u001b[35mcmd2:\u001b[0m   Using cached decorator-5.2.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "\u001b[35mcmd2:\u001b[0m Collecting exceptiongroup (from ipython>=7.23.1->ipykernel->jupyter==1.1.1)\n",
      "\u001b[35mcmd2:\u001b[0m   Using cached exceptiongroup-1.3.1-py3-none-any.whl.metadata (6.7 kB)\n",
      "\u001b[35mcmd2:\u001b[0m Collecting jedi>=0.16 (from ipython>=7.23.1->ipykernel->jupyter==1.1.1)\n",
      "\u001b[35mcmd2:\u001b[0m   Using cached jedi-0.19.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "\u001b[35mcmd2:\u001b[0m Collecting pexpect>4.3 (from ipython>=7.23.1->ipykernel->jupyter==1.1.1)\n",
      "\u001b[35mcmd2:\u001b[0m   Using cached pexpect-4.9.0-py2.py3-none-any.whl.metadata (2.5 kB)\n",
      "\u001b[35mcmd2:\u001b[0m Collecting prompt_toolkit<3.1.0,>=3.0.41 (from ipython>=7.23.1->ipykernel->jupyter==1.1.1)\n",
      "\u001b[35mcmd2:\u001b[0m   Using cached prompt_toolkit-3.0.52-py3-none-any.whl.metadata (6.4 kB)\n",
      "\u001b[35mcmd2:\u001b[0m Collecting pygments>=2.4.0 (from ipython>=7.23.1->ipykernel->jupyter==1.1.1)\n",
      "\u001b[35mcmd2:\u001b[0m   Using cached pygments-2.19.2-py3-none-any.whl.metadata (2.5 kB)\n",
      "\u001b[35mcmd2:\u001b[0m Collecting stack_data (from ipython>=7.23.1->ipykernel->jupyter==1.1.1)\n",
      "\u001b[35mcmd2:\u001b[0m   Using cached stack_data-0.6.3-py3-none-any.whl.metadata (18 kB)\n",
      "\u001b[35mcmd2:\u001b[0m Collecting wcwidth (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=7.23.1->ipykernel->jupyter==1.1.1)\n",
      "\u001b[35mcmd2:\u001b[0m   Using cached wcwidth-0.2.14-py2.py3-none-any.whl.metadata (15 kB)\n",
      "\u001b[35mcmd2:\u001b[0m Collecting parso<0.9.0,>=0.8.4 (from jedi>=0.16->ipython>=7.23.1->ipykernel->jupyter==1.1.1)\n",
      "\u001b[35mcmd2:\u001b[0m   Using cached parso-0.8.5-py2.py3-none-any.whl.metadata (8.3 kB)\n",
      "\u001b[35mcmd2:\u001b[0m Collecting platformdirs>=2.5 (from jupyter-core!=5.0.*,>=4.12->ipykernel->jupyter==1.1.1)\n",
      "\u001b[35mcmd2:\u001b[0m   Downloading platformdirs-4.5.1-py3-none-any.whl.metadata (12 kB)\n",
      "\u001b[35mcmd2:\u001b[0m Collecting ptyprocess>=0.5 (from pexpect>4.3->ipython>=7.23.1->ipykernel->jupyter==1.1.1)\n",
      "\u001b[35mcmd2:\u001b[0m   Using cached ptyprocess-0.7.0-py2.py3-none-any.whl.metadata (1.3 kB)\n",
      "\u001b[35mcmd2:\u001b[0m Collecting widgetsnbextension~=4.0.14 (from ipywidgets->jupyter==1.1.1)\n",
      "\u001b[35mcmd2:\u001b[0m   Using cached widgetsnbextension-4.0.15-py3-none-any.whl.metadata (1.6 kB)\n",
      "\u001b[35mcmd2:\u001b[0m Collecting jupyterlab_widgets~=3.0.15 (from ipywidgets->jupyter==1.1.1)\n",
      "\u001b[35mcmd2:\u001b[0m   Using cached jupyterlab_widgets-3.0.16-py3-none-any.whl.metadata (20 kB)\n",
      "\u001b[35mcmd2:\u001b[0m Requirement already satisfied: MarkupSafe>=2.0 in /root/miniconda3/envs/b2txt25/lib/python3.10/site-packages (from jinja2->torch>=2.0.0->accelerate==1.8.1) (2.1.5)\n",
      "\u001b[35mcmd2:\u001b[0m Collecting async-lru>=1.0.0 (from jupyterlab->jupyter==1.1.1)\n",
      "\u001b[35mcmd2:\u001b[0m   Using cached async_lru-2.0.5-py3-none-any.whl.metadata (4.5 kB)\n",
      "\u001b[35mcmd2:\u001b[0m Collecting httpx<1,>=0.25.0 (from jupyterlab->jupyter==1.1.1)\n",
      "\u001b[35mcmd2:\u001b[0m   Using cached httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "\u001b[35mcmd2:\u001b[0m Collecting jupyter-lsp>=2.0.0 (from jupyterlab->jupyter==1.1.1)\n",
      "\u001b[35mcmd2:\u001b[0m   Using cached jupyter_lsp-2.3.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "\u001b[35mcmd2:\u001b[0m Collecting jupyter-server<3,>=2.4.0 (from jupyterlab->jupyter==1.1.1)\n",
      "\u001b[35mcmd2:\u001b[0m   Using cached jupyter_server-2.17.0-py3-none-any.whl.metadata (8.5 kB)\n",
      "\u001b[35mcmd2:\u001b[0m Collecting jupyterlab-server<3,>=2.28.0 (from jupyterlab->jupyter==1.1.1)\n",
      "\u001b[35mcmd2:\u001b[0m   Using cached jupyterlab_server-2.28.0-py3-none-any.whl.metadata (5.9 kB)\n",
      "\u001b[35mcmd2:\u001b[0m Collecting notebook-shim>=0.2 (from jupyterlab->jupyter==1.1.1)\n",
      "\u001b[35mcmd2:\u001b[0m   Using cached notebook_shim-0.2.4-py3-none-any.whl.metadata (4.0 kB)\n",
      "\u001b[35mcmd2:\u001b[0m Requirement already satisfied: setuptools>=41.1.0 in /root/miniconda3/envs/b2txt25/lib/python3.10/site-packages (from jupyterlab->jupyter==1.1.1) (80.9.0)\n",
      "\u001b[35mcmd2:\u001b[0m Collecting tomli>=1.2.2 (from jupyterlab->jupyter==1.1.1)\n",
      "\u001b[35mcmd2:\u001b[0m   Using cached tomli-2.3.0-py3-none-any.whl.metadata (10 kB)\n",
      "\u001b[35mcmd2:\u001b[0m Collecting anyio (from httpx<1,>=0.25.0->jupyterlab->jupyter==1.1.1)\n",
      "\u001b[35mcmd2:\u001b[0m   Using cached anyio-4.12.0-py3-none-any.whl.metadata (4.3 kB)\n",
      "\u001b[35mcmd2:\u001b[0m Collecting certifi (from httpx<1,>=0.25.0->jupyterlab->jupyter==1.1.1)\n",
      "\u001b[35mcmd2:\u001b[0m   Using cached certifi-2025.11.12-py3-none-any.whl.metadata (2.5 kB)\n",
      "\u001b[35mcmd2:\u001b[0m Collecting httpcore==1.* (from httpx<1,>=0.25.0->jupyterlab->jupyter==1.1.1)\n",
      "\u001b[35mcmd2:\u001b[0m   Using cached httpcore-1.0.9-py3-none-any.whl.metadata (21 kB)\n",
      "\u001b[35mcmd2:\u001b[0m Collecting idna (from httpx<1,>=0.25.0->jupyterlab->jupyter==1.1.1)\n",
      "\u001b[35mcmd2:\u001b[0m   Using cached idna-3.11-py3-none-any.whl.metadata (8.4 kB)\n",
      "\u001b[35mcmd2:\u001b[0m Collecting h11>=0.16 (from httpcore==1.*->httpx<1,>=0.25.0->jupyterlab->jupyter==1.1.1)\n",
      "\u001b[35mcmd2:\u001b[0m   Using cached h11-0.16.0-py3-none-any.whl.metadata (8.3 kB)\n",
      "\u001b[35mcmd2:\u001b[0m Collecting argon2-cffi>=21.1 (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter==1.1.1)\n",
      "\u001b[35mcmd2:\u001b[0m   Using cached argon2_cffi-25.1.0-py3-none-any.whl.metadata (4.1 kB)\n",
      "\u001b[35mcmd2:\u001b[0m Collecting jupyter-events>=0.11.0 (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter==1.1.1)\n",
      "\u001b[35mcmd2:\u001b[0m   Using cached jupyter_events-0.12.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "\u001b[35mcmd2:\u001b[0m Collecting jupyter-server-terminals>=0.4.4 (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter==1.1.1)\n",
      "\u001b[35mcmd2:\u001b[0m   Using cached jupyter_server_terminals-0.5.3-py3-none-any.whl.metadata (5.6 kB)\n",
      "\u001b[35mcmd2:\u001b[0m Collecting nbformat>=5.3.0 (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter==1.1.1)\n",
      "\u001b[35mcmd2:\u001b[0m   Using cached nbformat-5.10.4-py3-none-any.whl.metadata (3.6 kB)\n",
      "\u001b[35mcmd2:\u001b[0m Collecting overrides>=5.0 (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter==1.1.1)\n",
      "\u001b[35mcmd2:\u001b[0m   Using cached overrides-7.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "\u001b[35mcmd2:\u001b[0m Collecting prometheus-client>=0.9 (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter==1.1.1)\n",
      "\u001b[35mcmd2:\u001b[0m   Using cached prometheus_client-0.23.1-py3-none-any.whl.metadata (1.9 kB)\n",
      "\u001b[35mcmd2:\u001b[0m Collecting send2trash>=1.8.2 (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter==1.1.1)\n",
      "\u001b[35mcmd2:\u001b[0m   Using cached Send2Trash-1.8.3-py3-none-any.whl.metadata (4.0 kB)\n",
      "\u001b[35mcmd2:\u001b[0m Collecting terminado>=0.8.3 (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter==1.1.1)\n",
      "\u001b[35mcmd2:\u001b[0m   Using cached terminado-0.18.1-py3-none-any.whl.metadata (5.8 kB)\n",
      "\u001b[35mcmd2:\u001b[0m Collecting websocket-client>=1.7 (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter==1.1.1)\n",
      "\u001b[35mcmd2:\u001b[0m   Using cached websocket_client-1.9.0-py3-none-any.whl.metadata (8.3 kB)\n",
      "\u001b[35mcmd2:\u001b[0m Collecting babel>=2.10 (from jupyterlab-server<3,>=2.28.0->jupyterlab->jupyter==1.1.1)\n",
      "\u001b[35mcmd2:\u001b[0m   Using cached babel-2.17.0-py3-none-any.whl.metadata (2.0 kB)\n",
      "\u001b[35mcmd2:\u001b[0m Collecting json5>=0.9.0 (from jupyterlab-server<3,>=2.28.0->jupyterlab->jupyter==1.1.1)\n",
      "\u001b[35mcmd2:\u001b[0m   Using cached json5-0.12.1-py3-none-any.whl.metadata (36 kB)\n",
      "\u001b[35mcmd2:\u001b[0m Collecting jsonschema>=4.18.0 (from jupyterlab-server<3,>=2.28.0->jupyterlab->jupyter==1.1.1)\n",
      "\u001b[35mcmd2:\u001b[0m   Using cached jsonschema-4.25.1-py3-none-any.whl.metadata (7.6 kB)\n",
      "\u001b[35mcmd2:\u001b[0m Collecting argon2-cffi-bindings (from argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab->jupyter==1.1.1)\n",
      "\u001b[35mcmd2:\u001b[0m   Using cached argon2_cffi_bindings-25.1.0-cp39-abi3-manylinux_2_26_x86_64.manylinux_2_28_x86_64.whl.metadata (7.4 kB)\n",
      "\u001b[35mcmd2:\u001b[0m Collecting attrs>=22.2.0 (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.28.0->jupyterlab->jupyter==1.1.1)\n",
      "\u001b[35mcmd2:\u001b[0m   Using cached attrs-25.4.0-py3-none-any.whl.metadata (10 kB)\n",
      "\u001b[35mcmd2:\u001b[0m Collecting jsonschema-specifications>=2023.03.6 (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.28.0->jupyterlab->jupyter==1.1.1)\n",
      "\u001b[35mcmd2:\u001b[0m   Using cached jsonschema_specifications-2025.9.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "\u001b[35mcmd2:\u001b[0m Collecting referencing>=0.28.4 (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.28.0->jupyterlab->jupyter==1.1.1)\n",
      "\u001b[35mcmd2:\u001b[0m   Downloading referencing-0.37.0-py3-none-any.whl.metadata (2.8 kB)\n",
      "\u001b[35mcmd2:\u001b[0m Collecting rpds-py>=0.7.1 (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.28.0->jupyterlab->jupyter==1.1.1)\n",
      "\u001b[35mcmd2:\u001b[0m   Downloading rpds_py-0.30.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
      "\u001b[35mcmd2:\u001b[0m Collecting python-json-logger>=2.0.4 (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter==1.1.1)\n",
      "\u001b[35mcmd2:\u001b[0m   Using cached python_json_logger-4.0.0-py3-none-any.whl.metadata (4.0 kB)\n",
      "\u001b[35mcmd2:\u001b[0m Collecting rfc3339-validator (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter==1.1.1)\n",
      "\u001b[35mcmd2:\u001b[0m   Using cached rfc3339_validator-0.1.4-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "\u001b[35mcmd2:\u001b[0m Collecting rfc3986-validator>=0.1.1 (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter==1.1.1)\n",
      "\u001b[35mcmd2:\u001b[0m   Using cached rfc3986_validator-0.1.1-py2.py3-none-any.whl.metadata (1.7 kB)\n",
      "\u001b[35mcmd2:\u001b[0m Collecting fqdn (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter==1.1.1)\n",
      "\u001b[35mcmd2:\u001b[0m   Using cached fqdn-1.5.1-py3-none-any.whl.metadata (1.4 kB)\n",
      "\u001b[35mcmd2:\u001b[0m Collecting isoduration (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter==1.1.1)\n",
      "\u001b[35mcmd2:\u001b[0m   Using cached isoduration-20.11.0-py3-none-any.whl.metadata (5.7 kB)\n",
      "\u001b[35mcmd2:\u001b[0m Collecting jsonpointer>1.13 (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter==1.1.1)\n",
      "\u001b[35mcmd2:\u001b[0m   Using cached jsonpointer-3.0.0-py2.py3-none-any.whl.metadata (2.3 kB)\n",
      "\u001b[35mcmd2:\u001b[0m Collecting rfc3987-syntax>=1.1.0 (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter==1.1.1)\n",
      "\u001b[35mcmd2:\u001b[0m   Using cached rfc3987_syntax-1.1.0-py3-none-any.whl.metadata (7.7 kB)\n",
      "\u001b[35mcmd2:\u001b[0m Collecting uri-template (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter==1.1.1)\n",
      "\u001b[35mcmd2:\u001b[0m   Using cached uri_template-1.3.0-py3-none-any.whl.metadata (8.8 kB)\n",
      "\u001b[35mcmd2:\u001b[0m Collecting webcolors>=24.6.0 (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter==1.1.1)\n",
      "\u001b[35mcmd2:\u001b[0m   Downloading webcolors-25.10.0-py3-none-any.whl.metadata (2.2 kB)\n",
      "\u001b[35mcmd2:\u001b[0m Collecting beautifulsoup4 (from nbconvert->jupyter==1.1.1)\n",
      "\u001b[35mcmd2:\u001b[0m   Using cached beautifulsoup4-4.14.3-py3-none-any.whl.metadata (3.8 kB)\n",
      "\u001b[35mcmd2:\u001b[0m Collecting bleach!=5.0.0 (from bleach[css]!=5.0.0->nbconvert->jupyter==1.1.1)\n",
      "\u001b[35mcmd2:\u001b[0m   Downloading bleach-6.3.0-py3-none-any.whl.metadata (31 kB)\n",
      "\u001b[35mcmd2:\u001b[0m Collecting defusedxml (from nbconvert->jupyter==1.1.1)\n",
      "\u001b[35mcmd2:\u001b[0m   Using cached defusedxml-0.7.1-py2.py3-none-any.whl.metadata (32 kB)\n",
      "\u001b[35mcmd2:\u001b[0m Collecting jupyterlab-pygments (from nbconvert->jupyter==1.1.1)\n",
      "\u001b[35mcmd2:\u001b[0m   Using cached jupyterlab_pygments-0.3.0-py3-none-any.whl.metadata (4.4 kB)\n",
      "\u001b[35mcmd2:\u001b[0m Collecting mistune<4,>=2.0.3 (from nbconvert->jupyter==1.1.1)\n",
      "\u001b[35mcmd2:\u001b[0m   Using cached mistune-3.2.0-py3-none-any.whl.metadata (1.9 kB)\n",
      "\u001b[35mcmd2:\u001b[0m Collecting nbclient>=0.5.0 (from nbconvert->jupyter==1.1.1)\n",
      "\u001b[35mcmd2:\u001b[0m   Downloading nbclient-0.10.4-py3-none-any.whl.metadata (8.3 kB)\n",
      "\u001b[35mcmd2:\u001b[0m Collecting pandocfilters>=1.4.1 (from nbconvert->jupyter==1.1.1)\n",
      "\u001b[35mcmd2:\u001b[0m   Using cached pandocfilters-1.5.1-py2.py3-none-any.whl.metadata (9.0 kB)\n",
      "\u001b[35mcmd2:\u001b[0m Collecting webencodings (from bleach!=5.0.0->bleach[css]!=5.0.0->nbconvert->jupyter==1.1.1)\n",
      "\u001b[35mcmd2:\u001b[0m   Using cached webencodings-0.5.1-py2.py3-none-any.whl.metadata (2.1 kB)\n",
      "\u001b[35mcmd2:\u001b[0m Collecting tinycss2<1.5,>=1.1.0 (from bleach[css]!=5.0.0->nbconvert->jupyter==1.1.1)\n",
      "\u001b[35mcmd2:\u001b[0m   Using cached tinycss2-1.4.0-py3-none-any.whl.metadata (3.0 kB)\n",
      "\u001b[35mcmd2:\u001b[0m Collecting fastjsonschema>=2.15 (from nbformat>=5.3.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter==1.1.1)\n",
      "\u001b[35mcmd2:\u001b[0m   Using cached fastjsonschema-2.21.2-py3-none-any.whl.metadata (2.3 kB)\n",
      "\u001b[35mcmd2:\u001b[0m Collecting charset_normalizer<4,>=2 (from requests->huggingface-hub==0.33.1)\n",
      "\u001b[35mcmd2:\u001b[0m   Downloading charset_normalizer-3.4.4-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (37 kB)\n",
      "\u001b[35mcmd2:\u001b[0m Collecting urllib3<3,>=1.21.1 (from requests->huggingface-hub==0.33.1)\n",
      "\u001b[35mcmd2:\u001b[0m   Using cached urllib3-2.6.2-py3-none-any.whl.metadata (6.6 kB)\n",
      "\u001b[35mcmd2:\u001b[0m Collecting lark>=1.2.2 (from rfc3987-syntax>=1.1.0->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter==1.1.1)\n",
      "\u001b[35mcmd2:\u001b[0m   Using cached lark-1.3.1-py3-none-any.whl.metadata (1.8 kB)\n",
      "\u001b[35mcmd2:\u001b[0m Collecting cffi>=1.0.1 (from argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab->jupyter==1.1.1)\n",
      "\u001b[35mcmd2:\u001b[0m   Downloading cffi-2.0.0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.6 kB)\n",
      "\u001b[35mcmd2:\u001b[0m Collecting pycparser (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab->jupyter==1.1.1)\n",
      "\u001b[35mcmd2:\u001b[0m   Using cached pycparser-2.23-py3-none-any.whl.metadata (993 bytes)\n",
      "\u001b[35mcmd2:\u001b[0m Collecting soupsieve>=1.6.1 (from beautifulsoup4->nbconvert->jupyter==1.1.1)\n",
      "\u001b[35mcmd2:\u001b[0m   Using cached soupsieve-2.8.1-py3-none-any.whl.metadata (4.6 kB)\n",
      "\u001b[35mcmd2:\u001b[0m Collecting arrow>=0.15.0 (from isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter==1.1.1)\n",
      "\u001b[35mcmd2:\u001b[0m   Using cached arrow-1.4.0-py3-none-any.whl.metadata (7.7 kB)\n",
      "\u001b[35mcmd2:\u001b[0m Collecting executing>=1.2.0 (from stack_data->ipython>=7.23.1->ipykernel->jupyter==1.1.1)\n",
      "\u001b[35mcmd2:\u001b[0m   Using cached executing-2.2.1-py2.py3-none-any.whl.metadata (8.9 kB)\n",
      "\u001b[35mcmd2:\u001b[0m Collecting asttokens>=2.1.0 (from stack_data->ipython>=7.23.1->ipykernel->jupyter==1.1.1)\n",
      "\u001b[35mcmd2:\u001b[0m   Using cached asttokens-3.0.1-py3-none-any.whl.metadata (4.9 kB)\n",
      "\u001b[35mcmd2:\u001b[0m Collecting pure-eval (from stack_data->ipython>=7.23.1->ipykernel->jupyter==1.1.1)\n",
      "\u001b[35mcmd2:\u001b[0m   Using cached pure_eval-0.2.3-py3-none-any.whl.metadata (6.3 kB)\n",
      "\u001b[35mcmd2:\u001b[0m Downloading redis-5.2.1-py3-none-any.whl (261 kB)\n",
      "\u001b[35mcmd2:\u001b[0m Using cached jupyter-1.1.1-py2.py3-none-any.whl (2.7 kB)\n",
      "\u001b[35mcmd2:\u001b[0m Downloading numpy-2.1.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.3 MB)\n",
      "\u001b[35mcmd2:\u001b[0m    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 16.3/16.3 MB 17.2 MB/s  0:00:00\n",
      "\u001b[35mcmd2:\u001b[0m Downloading pandas-2.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.3 MB)\n",
      "\u001b[35mcmd2:\u001b[0m    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 12.3/12.3 MB 62.2 MB/s  0:00:00\n",
      "\u001b[35mcmd2:\u001b[0m Downloading matplotlib-3.10.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.6 MB)\n",
      "\u001b[35mcmd2:\u001b[0m    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 8.6/8.6 MB 81.2 MB/s  0:00:00\n",
      "\u001b[35mcmd2:\u001b[0m Downloading scipy-1.15.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (37.6 MB)\n",
      "\u001b[35mcmd2:\u001b[0m    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 37.6/37.6 MB 109.8 MB/s  0:00:00\n",
      "\u001b[35mcmd2:\u001b[0m Downloading scikit_learn-1.6.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.5 MB)\n",
      "\u001b[35mcmd2:\u001b[0m    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 13.5/13.5 MB 119.7 MB/s  0:00:00\n",
      "\u001b[35mcmd2:\u001b[0m Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "\u001b[35mcmd2:\u001b[0m Using cached g2p_en-2.1.0-py3-none-any.whl (3.1 MB)\n",
      "\u001b[35mcmd2:\u001b[0m Downloading h5py-3.13.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.5 MB)\n",
      "\u001b[35mcmd2:\u001b[0m    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 4.5/4.5 MB 110.8 MB/s  0:00:00\n",
      "\u001b[35mcmd2:\u001b[0m Using cached omegaconf-2.3.0-py3-none-any.whl (79 kB)\n",
      "\u001b[35mcmd2:\u001b[0m Downloading editdistance-0.8.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (401 kB)\n",
      "\u001b[35mcmd2:\u001b[0m Downloading huggingface_hub-0.33.1-py3-none-any.whl (515 kB)\n",
      "\u001b[35mcmd2:\u001b[0m Downloading transformers-4.53.0-py3-none-any.whl (10.8 MB)\n",
      "\u001b[35mcmd2:\u001b[0m    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 10.8/10.8 MB 111.8 MB/s  0:00:00\n",
      "\u001b[35mcmd2:\u001b[0m Downloading tokenizers-0.21.2-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
      "\u001b[35mcmd2:\u001b[0m    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.1/3.1 MB 118.7 MB/s  0:00:00\n",
      "\u001b[35mcmd2:\u001b[0m Downloading accelerate-1.8.1-py3-none-any.whl (365 kB)\n",
      "\u001b[35mcmd2:\u001b[0m Downloading bitsandbytes-0.46.0-py3-none-manylinux_2_24_x86_64.whl (67.0 MB)\n",
      "\u001b[35mcmd2:\u001b[0m    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 67.0/67.0 MB 99.8 MB/s  0:00:00\n",
      "\u001b[35mcmd2:\u001b[0m Downloading hf_xet-1.2.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
      "\u001b[35mcmd2:\u001b[0m    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.3/3.3 MB 114.4 MB/s  0:00:00\n",
      "\u001b[35mcmd2:\u001b[0m Using cached async_timeout-5.0.1-py3-none-any.whl (6.2 kB)\n",
      "\u001b[35mcmd2:\u001b[0m Downloading contourpy-1.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (325 kB)\n",
      "\u001b[35mcmd2:\u001b[0m Using cached cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "\u001b[35mcmd2:\u001b[0m Downloading fonttools-4.61.1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (4.9 MB)\n",
      "\u001b[35mcmd2:\u001b[0m    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 4.9/4.9 MB 108.0 MB/s  0:00:00\n",
      "\u001b[35mcmd2:\u001b[0m Using cached inflect-7.5.0-py3-none-any.whl (35 kB)\n",
      "\u001b[35mcmd2:\u001b[0m Using cached joblib-1.5.3-py3-none-any.whl (309 kB)\n",
      "\u001b[35mcmd2:\u001b[0m Downloading kiwisolver-1.4.9-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.6 MB)\n",
      "\u001b[35mcmd2:\u001b[0m    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.6/1.6 MB 73.9 MB/s  0:00:00\n",
      "\u001b[35mcmd2:\u001b[0m Using cached more_itertools-10.8.0-py3-none-any.whl (69 kB)\n",
      "\u001b[35mcmd2:\u001b[0m Using cached nltk-3.9.2-py3-none-any.whl (1.5 MB)\n",
      "\u001b[35mcmd2:\u001b[0m Using cached packaging-25.0-py3-none-any.whl (66 kB)\n",
      "\u001b[35mcmd2:\u001b[0m Using cached pyparsing-3.3.1-py3-none-any.whl (121 kB)\n",
      "\u001b[35mcmd2:\u001b[0m Using cached python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)\n",
      "\u001b[35mcmd2:\u001b[0m Downloading pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "\u001b[35mcmd2:\u001b[0m Downloading pyyaml-6.0.3-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (770 kB)\n",
      "\u001b[35mcmd2:\u001b[0m    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 770.3/770.3 kB 35.6 MB/s  0:00:00\n",
      "\u001b[35mcmd2:\u001b[0m Downloading regex-2025.11.3-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (791 kB)\n",
      "\u001b[35mcmd2:\u001b[0m    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 791.7/791.7 kB 37.7 MB/s  0:00:00\n",
      "\u001b[35mcmd2:\u001b[0m Using cached safetensors-0.7.0-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (507 kB)\n",
      "\u001b[35mcmd2:\u001b[0m Using cached six-1.17.0-py2.py3-none-any.whl (11 kB)\n",
      "\u001b[35mcmd2:\u001b[0m Using cached threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "\u001b[35mcmd2:\u001b[0m Using cached typeguard-4.4.4-py3-none-any.whl (34 kB)\n",
      "\u001b[35mcmd2:\u001b[0m Using cached tzdata-2025.3-py2.py3-none-any.whl (348 kB)\n",
      "\u001b[35mcmd2:\u001b[0m Downloading click-8.3.1-py3-none-any.whl (108 kB)\n",
      "\u001b[35mcmd2:\u001b[0m Downloading ipykernel-7.1.0-py3-none-any.whl (117 kB)\n",
      "\u001b[35mcmd2:\u001b[0m Using cached comm-0.2.3-py3-none-any.whl (7.3 kB)\n",
      "\u001b[35mcmd2:\u001b[0m Downloading debugpy-1.8.19-cp310-cp310-manylinux_2_34_x86_64.whl (3.1 MB)\n",
      "\u001b[35mcmd2:\u001b[0m    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.1/3.1 MB 18.8 MB/s  0:00:00\n",
      "\u001b[35mcmd2:\u001b[0m Downloading ipython-8.37.0-py3-none-any.whl (831 kB)\n",
      "\u001b[35mcmd2:\u001b[0m    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 831.9/831.9 kB 37.5 MB/s  0:00:00\n",
      "\u001b[35mcmd2:\u001b[0m Using cached prompt_toolkit-3.0.52-py3-none-any.whl (391 kB)\n",
      "\u001b[35mcmd2:\u001b[0m Using cached jedi-0.19.2-py2.py3-none-any.whl (1.6 MB)\n",
      "\u001b[35mcmd2:\u001b[0m Using cached parso-0.8.5-py2.py3-none-any.whl (106 kB)\n",
      "\u001b[35mcmd2:\u001b[0m Downloading jupyter_client-8.7.0-py3-none-any.whl (106 kB)\n",
      "\u001b[35mcmd2:\u001b[0m Downloading jupyter_core-5.9.1-py3-none-any.whl (29 kB)\n",
      "\u001b[35mcmd2:\u001b[0m Using cached matplotlib_inline-0.2.1-py3-none-any.whl (9.5 kB)\n",
      "\u001b[35mcmd2:\u001b[0m Using cached nest_asyncio-1.6.0-py3-none-any.whl (5.2 kB)\n",
      "\u001b[35mcmd2:\u001b[0m Using cached pexpect-4.9.0-py2.py3-none-any.whl (63 kB)\n",
      "\u001b[35mcmd2:\u001b[0m Downloading platformdirs-4.5.1-py3-none-any.whl (18 kB)\n",
      "\u001b[35mcmd2:\u001b[0m Using cached psutil-7.2.0-cp36-abi3-manylinux2010_x86_64.manylinux_2_12_x86_64.manylinux_2_28_x86_64.whl (154 kB)\n",
      "\u001b[35mcmd2:\u001b[0m Using cached ptyprocess-0.7.0-py2.py3-none-any.whl (13 kB)\n",
      "\u001b[35mcmd2:\u001b[0m Using cached pygments-2.19.2-py3-none-any.whl (1.2 MB)\n",
      "\u001b[35mcmd2:\u001b[0m Downloading pyzmq-27.1.0-cp310-cp310-manylinux_2_26_x86_64.manylinux_2_28_x86_64.whl (854 kB)\n",
      "\u001b[35mcmd2:\u001b[0m    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 854.1/854.1 kB 40.9 MB/s  0:00:00\n",
      "\u001b[35mcmd2:\u001b[0m Using cached tornado-6.5.4-cp39-abi3-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (445 kB)\n",
      "\u001b[35mcmd2:\u001b[0m Using cached traitlets-5.14.3-py3-none-any.whl (85 kB)\n",
      "\u001b[35mcmd2:\u001b[0m Using cached decorator-5.2.1-py3-none-any.whl (9.2 kB)\n",
      "\u001b[35mcmd2:\u001b[0m Using cached exceptiongroup-1.3.1-py3-none-any.whl (16 kB)\n",
      "\u001b[35mcmd2:\u001b[0m Using cached ipywidgets-8.1.8-py3-none-any.whl (139 kB)\n",
      "\u001b[35mcmd2:\u001b[0m Using cached jupyterlab_widgets-3.0.16-py3-none-any.whl (914 kB)\n",
      "\u001b[35mcmd2:\u001b[0m Using cached widgetsnbextension-4.0.15-py3-none-any.whl (2.2 MB)\n",
      "\u001b[35mcmd2:\u001b[0m Using cached jupyter_console-6.6.3-py3-none-any.whl (24 kB)\n",
      "\u001b[35mcmd2:\u001b[0m Using cached jupyterlab-4.5.1-py3-none-any.whl (12.4 MB)\n",
      "\u001b[35mcmd2:\u001b[0m Using cached httpx-0.28.1-py3-none-any.whl (73 kB)\n",
      "\u001b[35mcmd2:\u001b[0m Using cached httpcore-1.0.9-py3-none-any.whl (78 kB)\n",
      "\u001b[35mcmd2:\u001b[0m Using cached jupyter_server-2.17.0-py3-none-any.whl (388 kB)\n",
      "\u001b[35mcmd2:\u001b[0m Using cached jupyterlab_server-2.28.0-py3-none-any.whl (59 kB)\n",
      "\u001b[35mcmd2:\u001b[0m Using cached anyio-4.12.0-py3-none-any.whl (113 kB)\n",
      "\u001b[35mcmd2:\u001b[0m Using cached argon2_cffi-25.1.0-py3-none-any.whl (14 kB)\n",
      "\u001b[35mcmd2:\u001b[0m Using cached async_lru-2.0.5-py3-none-any.whl (6.1 kB)\n",
      "\u001b[35mcmd2:\u001b[0m Using cached babel-2.17.0-py3-none-any.whl (10.2 MB)\n",
      "\u001b[35mcmd2:\u001b[0m Using cached h11-0.16.0-py3-none-any.whl (37 kB)\n",
      "\u001b[35mcmd2:\u001b[0m Using cached idna-3.11-py3-none-any.whl (71 kB)\n",
      "\u001b[35mcmd2:\u001b[0m Using cached json5-0.12.1-py3-none-any.whl (36 kB)\n",
      "\u001b[35mcmd2:\u001b[0m Using cached jsonschema-4.25.1-py3-none-any.whl (90 kB)\n",
      "\u001b[35mcmd2:\u001b[0m Using cached attrs-25.4.0-py3-none-any.whl (67 kB)\n",
      "\u001b[35mcmd2:\u001b[0m Using cached jsonschema_specifications-2025.9.1-py3-none-any.whl (18 kB)\n",
      "\u001b[35mcmd2:\u001b[0m Using cached jupyter_events-0.12.0-py3-none-any.whl (19 kB)\n",
      "\u001b[35mcmd2:\u001b[0m Using cached jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
      "\u001b[35mcmd2:\u001b[0m Using cached jupyter_lsp-2.3.0-py3-none-any.whl (76 kB)\n",
      "\u001b[35mcmd2:\u001b[0m Using cached jupyter_server_terminals-0.5.3-py3-none-any.whl (13 kB)\n",
      "\u001b[35mcmd2:\u001b[0m Using cached nbconvert-7.16.6-py3-none-any.whl (258 kB)\n",
      "\u001b[35mcmd2:\u001b[0m Using cached mistune-3.2.0-py3-none-any.whl (53 kB)\n",
      "\u001b[35mcmd2:\u001b[0m Downloading bleach-6.3.0-py3-none-any.whl (164 kB)\n",
      "\u001b[35mcmd2:\u001b[0m Using cached tinycss2-1.4.0-py3-none-any.whl (26 kB)\n",
      "\u001b[35mcmd2:\u001b[0m Downloading nbclient-0.10.4-py3-none-any.whl (25 kB)\n",
      "\u001b[35mcmd2:\u001b[0m Using cached nbformat-5.10.4-py3-none-any.whl (78 kB)\n",
      "\u001b[35mcmd2:\u001b[0m Using cached fastjsonschema-2.21.2-py3-none-any.whl (24 kB)\n",
      "\u001b[35mcmd2:\u001b[0m Using cached notebook_shim-0.2.4-py3-none-any.whl (13 kB)\n",
      "\u001b[35mcmd2:\u001b[0m Using cached overrides-7.7.0-py3-none-any.whl (17 kB)\n",
      "\u001b[35mcmd2:\u001b[0m Using cached pandocfilters-1.5.1-py2.py3-none-any.whl (8.7 kB)\n",
      "\u001b[35mcmd2:\u001b[0m Using cached prometheus_client-0.23.1-py3-none-any.whl (61 kB)\n",
      "\u001b[35mcmd2:\u001b[0m Using cached python_json_logger-4.0.0-py3-none-any.whl (15 kB)\n",
      "\u001b[35mcmd2:\u001b[0m Downloading referencing-0.37.0-py3-none-any.whl (26 kB)\n",
      "\u001b[35mcmd2:\u001b[0m Using cached requests-2.32.5-py3-none-any.whl (64 kB)\n",
      "\u001b[35mcmd2:\u001b[0m Downloading charset_normalizer-3.4.4-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (153 kB)\n",
      "\u001b[35mcmd2:\u001b[0m Using cached urllib3-2.6.2-py3-none-any.whl (131 kB)\n",
      "\u001b[35mcmd2:\u001b[0m Using cached certifi-2025.11.12-py3-none-any.whl (159 kB)\n",
      "\u001b[35mcmd2:\u001b[0m Using cached rfc3986_validator-0.1.1-py2.py3-none-any.whl (4.2 kB)\n",
      "\u001b[35mcmd2:\u001b[0m Using cached rfc3987_syntax-1.1.0-py3-none-any.whl (8.0 kB)\n",
      "\u001b[35mcmd2:\u001b[0m Using cached lark-1.3.1-py3-none-any.whl (113 kB)\n",
      "\u001b[35mcmd2:\u001b[0m Downloading rpds_py-0.30.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (390 kB)\n",
      "\u001b[35mcmd2:\u001b[0m Using cached Send2Trash-1.8.3-py3-none-any.whl (18 kB)\n",
      "\u001b[35mcmd2:\u001b[0m Using cached terminado-0.18.1-py3-none-any.whl (14 kB)\n",
      "\u001b[35mcmd2:\u001b[0m Using cached tomli-2.3.0-py3-none-any.whl (14 kB)\n",
      "\u001b[35mcmd2:\u001b[0m Downloading webcolors-25.10.0-py3-none-any.whl (14 kB)\n",
      "\u001b[35mcmd2:\u001b[0m Using cached webencodings-0.5.1-py2.py3-none-any.whl (11 kB)\n",
      "\u001b[35mcmd2:\u001b[0m Using cached websocket_client-1.9.0-py3-none-any.whl (82 kB)\n",
      "\u001b[35mcmd2:\u001b[0m Using cached argon2_cffi_bindings-25.1.0-cp39-abi3-manylinux_2_26_x86_64.manylinux_2_28_x86_64.whl (87 kB)\n",
      "\u001b[35mcmd2:\u001b[0m Downloading cffi-2.0.0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (216 kB)\n",
      "\u001b[35mcmd2:\u001b[0m Using cached beautifulsoup4-4.14.3-py3-none-any.whl (107 kB)\n",
      "\u001b[35mcmd2:\u001b[0m Using cached soupsieve-2.8.1-py3-none-any.whl (36 kB)\n",
      "\u001b[35mcmd2:\u001b[0m Using cached defusedxml-0.7.1-py2.py3-none-any.whl (25 kB)\n",
      "\u001b[35mcmd2:\u001b[0m Using cached fqdn-1.5.1-py3-none-any.whl (9.1 kB)\n",
      "\u001b[35mcmd2:\u001b[0m Using cached isoduration-20.11.0-py3-none-any.whl (11 kB)\n",
      "\u001b[35mcmd2:\u001b[0m Using cached arrow-1.4.0-py3-none-any.whl (68 kB)\n",
      "\u001b[35mcmd2:\u001b[0m Using cached jupyterlab_pygments-0.3.0-py3-none-any.whl (15 kB)\n",
      "\u001b[35mcmd2:\u001b[0m Using cached notebook-7.5.1-py3-none-any.whl (14.5 MB)\n",
      "\u001b[35mcmd2:\u001b[0m Using cached pycparser-2.23-py3-none-any.whl (118 kB)\n",
      "\u001b[35mcmd2:\u001b[0m Using cached rfc3339_validator-0.1.4-py2.py3-none-any.whl (3.5 kB)\n",
      "\u001b[35mcmd2:\u001b[0m Using cached stack_data-0.6.3-py3-none-any.whl (24 kB)\n",
      "\u001b[35mcmd2:\u001b[0m Using cached asttokens-3.0.1-py3-none-any.whl (27 kB)\n",
      "\u001b[35mcmd2:\u001b[0m Using cached executing-2.2.1-py2.py3-none-any.whl (28 kB)\n",
      "\u001b[35mcmd2:\u001b[0m Using cached pure_eval-0.2.3-py3-none-any.whl (11 kB)\n",
      "\u001b[35mcmd2:\u001b[0m Using cached uri_template-1.3.0-py3-none-any.whl (11 kB)\n",
      "\u001b[35mcmd2:\u001b[0m Using cached wcwidth-0.2.14-py2.py3-none-any.whl (37 kB)\n",
      "\u001b[35mcmd2:\u001b[0m Building wheels for collected packages: nejm_b2txt_utils, antlr4-python3-runtime, distance\n",
      "\u001b[35mcmd2:\u001b[0m   Building editable for nejm_b2txt_utils (pyproject.toml): started\n",
      "\u001b[35mcmd2:\u001b[0m   Building editable for nejm_b2txt_utils (pyproject.toml): finished with status 'done'\n",
      "\u001b[35mcmd2:\u001b[0m   Created wheel for nejm_b2txt_utils: filename=nejm_b2txt_utils-0.0.0-0.editable-py3-none-any.whl size=2759 sha256=c42a0eff4dfacab393d92ac9e297b383e54dd91c25c32c50f2c8f0b9ded1bc9d\n",
      "\u001b[35mcmd2:\u001b[0m   Stored in directory: /tmp/pip-ephem-wheel-cache-5fkyrdly/wheels/f1/bb/ed/4c4e219a40e20301249801636520e56cac16d086b1b99a89cd\n",
      "\u001b[35mcmd2:\u001b[0m   Building wheel for antlr4-python3-runtime (pyproject.toml): started\n",
      "\u001b[35mcmd2:\u001b[0m   Building wheel for antlr4-python3-runtime (pyproject.toml): finished with status 'done'\n",
      "\u001b[35mcmd2:\u001b[0m   Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144591 sha256=65738e9c183327fb97102ea88b14ad61d3f5003d5d85a19aff791b878c4fd2ae\n",
      "\u001b[35mcmd2:\u001b[0m   Stored in directory: /root/.cache/pip/wheels/12/93/dd/1f6a127edc45659556564c5730f6d4e300888f4bca2d4c5a88\n",
      "\u001b[35mcmd2:\u001b[0m   Building wheel for distance (pyproject.toml): started\n",
      "\u001b[35mcmd2:\u001b[0m   Building wheel for distance (pyproject.toml): finished with status 'done'\n",
      "\u001b[35mcmd2:\u001b[0m   Created wheel for distance: filename=distance-0.1.3-py3-none-any.whl size=16321 sha256=8b93a58ee01ffcc776976584dc9d8fcec1f80fa670e5dacc98cfb9bca6d738e9\n",
      "\u001b[35mcmd2:\u001b[0m   Stored in directory: /root/.cache/pip/wheels/e8/bb/de/f71bf63559ea9a921059a5405806f7ff6ed612a9231c4a9309\n",
      "\u001b[35mcmd2:\u001b[0m Successfully built nejm_b2txt_utils antlr4-python3-runtime distance\n",
      "\u001b[35mcmd2:\u001b[0m Installing collected packages: webencodings, pytz, pure-eval, ptyprocess, nejm_b2txt_utils, fastjsonschema, distance, antlr4-python3-runtime, widgetsnbextension, websocket-client, webcolors, wcwidth, urllib3, uri-template, tzdata, typeguard, traitlets, tqdm, tornado, tomli, tinycss2, threadpoolctl, soupsieve, six, send2trash, safetensors, rpds-py, rfc3986-validator, regex, pyzmq, PyYAML, python-json-logger, pyparsing, pygments, pycparser, psutil, prometheus-client, platformdirs, pexpect, parso, pandocfilters, packaging, overrides, numpy, nest-asyncio, more_itertools, mistune, lark, kiwisolver, jupyterlab_widgets, jupyterlab-pygments, jsonpointer, json5, joblib, idna, hf-xet, h11, fqdn, fonttools, executing, exceptiongroup, editdistance, defusedxml, decorator, debugpy, cycler, comm, click, charset_normalizer, certifi, bleach, babel, attrs, async-timeout, async-lru, asttokens, terminado, stack_data, scipy, rfc3987-syntax, rfc3339-validator, requests, referencing, redis, python-dateutil, prompt_toolkit, omegaconf, nltk, matplotlib-inline, jupyter-core, jedi, inflect, httpcore, h5py, contourpy, cffi, beautifulsoup4, anyio, scikit-learn, pandas, matplotlib, jupyter-server-terminals, jupyter-client, jsonschema-specifications, ipython, huggingface-hub, httpx, g2p_en, arrow, argon2-cffi-bindings, tokenizers, jsonschema, isoduration, ipywidgets, ipykernel, bitsandbytes, argon2-cffi, accelerate, transformers, nbformat, jupyter-console, nbclient, jupyter-events, nbconvert, jupyter-server, notebook-shim, jupyterlab-server, jupyter-lsp, jupyterlab, notebook, jupyter\n",
      "\u001b[35mcmd2:\u001b[0m   Attempting uninstall: numpy\n",
      "\u001b[35mcmd2:\u001b[0m     Found existing installation: numpy 2.2.6\n",
      "\u001b[35mcmd2:\u001b[0m     Uninstalling numpy-2.2.6:\n",
      "\u001b[35mcmd2:\u001b[0m       Successfully uninstalled numpy-2.2.6\n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Successfully installed PyYAML-6.0.3 accelerate-1.8.1 antlr4-python3-runtime-4.9.3 anyio-4.12.0 argon2-cffi-25.1.0 argon2-cffi-bindings-25.1.0 arrow-1.4.0 asttokens-3.0.1 async-lru-2.0.5 async-timeout-5.0.1 attrs-25.4.0 babel-2.17.0 beautifulsoup4-4.14.3 bitsandbytes-0.46.0 bleach-6.3.0 certifi-2025.11.12 cffi-2.0.0 charset_normalizer-3.4.4 click-8.3.1 comm-0.2.3 contourpy-1.3.2 cycler-0.12.1 debugpy-1.8.19 decorator-5.2.1 defusedxml-0.7.1 distance-0.1.3 editdistance-0.8.1 exceptiongroup-1.3.1 executing-2.2.1 fastjsonschema-2.21.2 fonttools-4.61.1 fqdn-1.5.1 g2p_en-2.1.0 h11-0.16.0 h5py-3.13.0 hf-xet-1.2.0 httpcore-1.0.9 httpx-0.28.1 huggingface-hub-0.33.1 idna-3.11 inflect-7.5.0 ipykernel-7.1.0 ipython-8.37.0 ipywidgets-8.1.8 isoduration-20.11.0 jedi-0.19.2 joblib-1.5.3 json5-0.12.1 jsonpointer-3.0.0 jsonschema-4.25.1 jsonschema-specifications-2025.9.1 jupyter-1.1.1 jupyter-client-8.7.0 jupyter-console-6.6.3 jupyter-core-5.9.1 jupyter-events-0.12.0 jupyter-lsp-2.3.0 jupyter-server-2.17.0 jupyter-server-terminals-0.5.3 jupyterlab-4.5.1 jupyterlab-pygments-0.3.0 jupyterlab-server-2.28.0 jupyterlab_widgets-3.0.16 kiwisolver-1.4.9 lark-1.3.1 matplotlib-3.10.1 matplotlib-inline-0.2.1 mistune-3.2.0 more_itertools-10.8.0 nbclient-0.10.4 nbconvert-7.16.6 nbformat-5.10.4 nejm_b2txt_utils-0.0.0 nest-asyncio-1.6.0 nltk-3.9.2 notebook-7.5.1 notebook-shim-0.2.4 numpy-2.1.2 omegaconf-2.3.0 overrides-7.7.0 packaging-25.0 pandas-2.3.0 pandocfilters-1.5.1 parso-0.8.5 pexpect-4.9.0 platformdirs-4.5.1 prometheus-client-0.23.1 prompt_toolkit-3.0.52 psutil-7.2.0 ptyprocess-0.7.0 pure-eval-0.2.3 pycparser-2.23 pygments-2.19.2 pyparsing-3.3.1 python-dateutil-2.9.0.post0 python-json-logger-4.0.0 pytz-2025.2 pyzmq-27.1.0 redis-5.2.1 referencing-0.37.0 regex-2025.11.3 requests-2.32.5 rfc3339-validator-0.1.4 rfc3986-validator-0.1.1 rfc3987-syntax-1.1.0 rpds-py-0.30.0 safetensors-0.7.0 scikit-learn-1.6.1 scipy-1.15.2 send2trash-1.8.3 six-1.17.0 soupsieve-2.8.1 stack_data-0.6.3 terminado-0.18.1 threadpoolctl-3.6.0 tinycss2-1.4.0 tokenizers-0.21.2 tomli-2.3.0 tornado-6.5.4 tqdm-4.67.1 traitlets-5.14.3 transformers-4.53.0 typeguard-4.4.4 tzdata-2025.3 uri-template-1.3.0 urllib3-2.6.2 wcwidth-0.2.14 webcolors-25.10.0 webencodings-0.5.1 websocket-client-1.9.0 widgetsnbextension-4.0.15\n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Setup complete! Verify it worked by activating the conda environment with the command 'conda activate b2txt25'.\n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Using cuda:1 for model inference.\n",
      "\u001b[35mcmd2:\u001b[0m Loaded 35 test trials for session t15.2023.08.13.\n",
      "\u001b[35mcmd2:\u001b[0m Loaded 50 test trials for session t15.2023.08.18.\n",
      "\u001b[35mcmd2:\u001b[0m Loaded 49 test trials for session t15.2023.08.20.\n",
      "\u001b[35mcmd2:\u001b[0m Loaded 25 test trials for session t15.2023.08.25.\n",
      "\u001b[35mcmd2:\u001b[0m Loaded 25 test trials for session t15.2023.08.27.\n",
      "\u001b[35mcmd2:\u001b[0m Loaded 50 test trials for session t15.2023.09.01.\n",
      "\u001b[35mcmd2:\u001b[0m Loaded 35 test trials for session t15.2023.09.03.\n",
      "\u001b[35mcmd2:\u001b[0m Loaded 35 test trials for session t15.2023.09.24.\n",
      "\u001b[35mcmd2:\u001b[0m Loaded 49 test trials for session t15.2023.09.29.\n",
      "\u001b[35mcmd2:\u001b[0m Loaded 45 test trials for session t15.2023.10.01.\n",
      "\u001b[35mcmd2:\u001b[0m Loaded 37 test trials for session t15.2023.10.06.\n",
      "\u001b[35mcmd2:\u001b[0m Loaded 18 test trials for session t15.2023.10.08.\n",
      "\u001b[35mcmd2:\u001b[0m Loaded 45 test trials for session t15.2023.10.13.\n",
      "\u001b[35mcmd2:\u001b[0m Loaded 45 test trials for session t15.2023.10.15.\n",
      "\u001b[35mcmd2:\u001b[0m Loaded 9 test trials for session t15.2023.10.20.\n",
      "\u001b[35mcmd2:\u001b[0m Loaded 35 test trials for session t15.2023.10.22.\n",
      "\u001b[35mcmd2:\u001b[0m Loaded 50 test trials for session t15.2023.11.03.\n",
      "\u001b[35mcmd2:\u001b[0m Loaded 15 test trials for session t15.2023.11.04.\n",
      "\u001b[35mcmd2:\u001b[0m Loaded 25 test trials for session t15.2023.11.17.\n",
      "\u001b[35mcmd2:\u001b[0m Loaded 20 test trials for session t15.2023.11.19.\n",
      "\u001b[35mcmd2:\u001b[0m Loaded 45 test trials for session t15.2023.11.26.\n",
      "\u001b[35mcmd2:\u001b[0m Loaded 34 test trials for session t15.2023.12.03.\n",
      "\u001b[35mcmd2:\u001b[0m Loaded 50 test trials for session t15.2023.12.08.\n",
      "\u001b[35mcmd2:\u001b[0m Loaded 25 test trials for session t15.2023.12.10.\n",
      "\u001b[35mcmd2:\u001b[0m Loaded 30 test trials for session t15.2023.12.17.\n",
      "\u001b[35mcmd2:\u001b[0m Loaded 50 test trials for session t15.2023.12.29.\n",
      "\u001b[35mcmd2:\u001b[0m Loaded 24 test trials for session t15.2024.02.25.\n",
      "\u001b[35mcmd2:\u001b[0m Loaded 25 test trials for session t15.2024.03.08.\n",
      "\u001b[35mcmd2:\u001b[0m Loaded 50 test trials for session t15.2024.03.15.\n",
      "\u001b[35mcmd2:\u001b[0m Loaded 49 test trials for session t15.2024.03.17.\n",
      "\u001b[35mcmd2:\u001b[0m Loaded 25 test trials for session t15.2024.05.10.\n",
      "\u001b[35mcmd2:\u001b[0m Loaded 25 test trials for session t15.2024.06.14.\n",
      "\u001b[35mcmd2:\u001b[0m Loaded 49 test trials for session t15.2024.07.19.\n",
      "\u001b[35mcmd2:\u001b[0m Loaded 47 test trials for session t15.2024.07.21.\n",
      "\u001b[35mcmd2:\u001b[0m Loaded 49 test trials for session t15.2024.07.28.\n",
      "\u001b[35mcmd2:\u001b[0m Loaded 24 test trials for session t15.2025.01.10.\n",
      "\u001b[35mcmd2:\u001b[0m Loaded 47 test trials for session t15.2025.01.12.\n",
      "\u001b[35mcmd2:\u001b[0m Loaded 26 test trials for session t15.2025.03.14.\n",
      "\u001b[35mcmd2:\u001b[0m Loaded 24 test trials for session t15.2025.03.16.\n",
      "\u001b[35mcmd2:\u001b[0m Loaded 30 test trials for session t15.2025.03.30.\n",
      "\u001b[35mcmd2:\u001b[0m Loaded 25 test trials for session t15.2025.04.13.\n",
      "\u001b[35mcmd2:\u001b[0m Total number of test trials: 1450\n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:   0%|          | 0/1450 [00:00<?, ?trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:   0%|          | 1/1450 [00:00<12:36,  1.92trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:   0%|          | 6/1450 [00:00<02:00, 11.95trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:   1%|          | 11/1450 [00:00<01:09, 20.61trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:   1%|          | 15/1450 [00:00<00:58, 24.42trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:   1%|▏         | 20/1450 [00:00<00:46, 30.52trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:   2%|▏         | 26/1450 [00:01<00:38, 36.63trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:   2%|▏         | 31/1450 [00:01<00:36, 39.36trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:   3%|▎         | 37/1450 [00:01<00:32, 43.06trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:   3%|▎         | 42/1450 [00:01<00:31, 44.38trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:   3%|▎         | 47/1450 [00:01<00:31, 44.76trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:   4%|▎         | 52/1450 [00:01<00:31, 44.11trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:   4%|▍         | 57/1450 [00:01<00:31, 44.29trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:   4%|▍         | 63/1450 [00:01<00:31, 44.58trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:   5%|▍         | 68/1450 [00:01<00:32, 43.08trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:   5%|▌         | 73/1450 [00:02<00:32, 42.51trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:   5%|▌         | 79/1450 [00:02<00:30, 45.21trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:   6%|▌         | 84/1450 [00:02<00:30, 44.74trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:   6%|▌         | 89/1450 [00:02<00:31, 42.99trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:   7%|▋         | 95/1450 [00:02<00:28, 47.03trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:   7%|▋         | 100/1450 [00:02<00:30, 44.92trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:   7%|▋         | 105/1450 [00:02<00:30, 44.58trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:   8%|▊         | 111/1450 [00:02<00:27, 47.84trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:   8%|▊         | 116/1450 [00:03<00:28, 47.16trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:   8%|▊         | 122/1450 [00:03<00:28, 47.39trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:   9%|▉         | 128/1450 [00:03<00:26, 50.42trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:   9%|▉         | 134/1450 [00:03<00:27, 48.66trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  10%|▉         | 140/1450 [00:03<00:25, 51.33trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  10%|█         | 146/1450 [00:03<00:25, 51.18trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  10%|█         | 152/1450 [00:03<00:27, 47.98trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  11%|█         | 157/1450 [00:03<00:27, 46.65trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  11%|█         | 163/1450 [00:03<00:26, 48.12trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  12%|█▏        | 168/1450 [00:04<00:26, 47.49trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  12%|█▏        | 174/1450 [00:04<00:26, 48.67trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  12%|█▏        | 179/1450 [00:04<00:27, 45.47trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  13%|█▎        | 184/1450 [00:04<00:29, 43.06trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  13%|█▎        | 189/1450 [00:04<00:28, 44.10trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  13%|█▎        | 195/1450 [00:04<00:26, 48.05trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  14%|█▍        | 200/1450 [00:04<00:26, 47.53trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  14%|█▍        | 206/1450 [00:04<00:25, 49.38trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  15%|█▍        | 211/1450 [00:05<00:25, 48.97trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  15%|█▍        | 216/1450 [00:05<00:25, 47.48trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  15%|█▌        | 221/1450 [00:05<00:25, 48.04trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  16%|█▌        | 226/1450 [00:05<00:25, 48.28trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  16%|█▌        | 231/1450 [00:05<00:26, 46.29trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  16%|█▋        | 237/1450 [00:05<00:25, 48.52trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  17%|█▋        | 242/1450 [00:05<00:26, 45.47trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  17%|█▋        | 248/1450 [00:05<00:25, 47.45trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  17%|█▋        | 253/1450 [00:05<00:25, 47.66trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  18%|█▊        | 259/1450 [00:06<00:24, 49.36trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  18%|█▊        | 264/1450 [00:06<00:23, 49.48trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  19%|█▊        | 269/1450 [00:06<00:24, 48.16trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  19%|█▉        | 274/1450 [00:06<00:24, 47.38trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  19%|█▉        | 279/1450 [00:06<00:24, 46.86trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  20%|█▉        | 284/1450 [00:06<00:25, 45.22trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  20%|█▉        | 289/1450 [00:06<00:25, 45.25trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  20%|██        | 294/1450 [00:06<00:27, 42.74trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  21%|██        | 299/1450 [00:06<00:27, 41.20trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  21%|██        | 304/1450 [00:07<00:26, 42.68trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  21%|██▏       | 309/1450 [00:07<00:26, 42.94trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  22%|██▏       | 314/1450 [00:07<00:26, 43.31trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  22%|██▏       | 319/1450 [00:07<00:25, 43.73trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  22%|██▏       | 324/1450 [00:07<00:27, 40.81trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  23%|██▎       | 329/1450 [00:07<00:28, 39.34trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  23%|██▎       | 333/1450 [00:07<00:31, 35.81trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  23%|██▎       | 337/1450 [00:07<00:32, 33.87trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  24%|██▎       | 341/1450 [00:08<00:33, 33.00trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  24%|██▍       | 345/1450 [00:08<00:32, 33.85trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  24%|██▍       | 349/1450 [00:08<00:34, 32.03trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  24%|██▍       | 353/1450 [00:08<00:36, 30.29trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  25%|██▍       | 359/1450 [00:08<00:29, 36.59trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  25%|██▌       | 366/1450 [00:08<00:24, 44.35trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  26%|██▌       | 372/1450 [00:08<00:23, 45.93trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  26%|██▌       | 379/1450 [00:08<00:21, 48.76trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  26%|██▋       | 384/1450 [00:09<00:24, 43.91trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  27%|██▋       | 389/1450 [00:09<00:26, 40.48trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  27%|██▋       | 394/1450 [00:09<00:28, 36.44trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  27%|██▋       | 398/1450 [00:09<00:29, 35.56trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  28%|██▊       | 403/1450 [00:09<00:28, 36.34trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  28%|██▊       | 407/1450 [00:09<00:28, 36.54trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  28%|██▊       | 412/1450 [00:09<00:27, 38.22trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  29%|██▉       | 418/1450 [00:09<00:23, 43.14trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  29%|██▉       | 423/1450 [00:10<00:24, 42.53trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  30%|██▉       | 428/1450 [00:10<00:23, 42.67trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  30%|██▉       | 433/1450 [00:10<00:24, 40.75trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  30%|███       | 438/1450 [00:10<00:25, 39.87trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  31%|███       | 443/1450 [00:10<00:25, 40.09trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  31%|███       | 448/1450 [00:10<00:26, 38.29trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  31%|███       | 452/1450 [00:10<00:26, 37.28trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  31%|███▏      | 456/1450 [00:10<00:27, 36.68trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  32%|███▏      | 461/1450 [00:11<00:24, 39.75trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  32%|███▏      | 466/1450 [00:11<00:23, 42.42trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  33%|███▎      | 472/1450 [00:11<00:21, 45.42trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  33%|███▎      | 477/1450 [00:11<00:22, 43.68trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  33%|███▎      | 482/1450 [00:11<00:23, 42.03trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  34%|███▎      | 487/1450 [00:11<00:24, 38.87trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  34%|███▍      | 491/1450 [00:11<00:25, 37.19trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  34%|███▍      | 495/1450 [00:11<00:26, 36.43trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  34%|███▍      | 499/1450 [00:12<00:26, 35.92trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  35%|███▍      | 505/1450 [00:12<00:23, 40.40trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  35%|███▌      | 511/1450 [00:12<00:21, 42.83trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  36%|███▌      | 516/1450 [00:12<00:21, 43.72trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  36%|███▌      | 521/1450 [00:12<00:20, 44.51trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  36%|███▋      | 526/1450 [00:12<00:21, 43.26trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  37%|███▋      | 531/1450 [00:12<00:23, 39.46trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  37%|███▋      | 536/1450 [00:12<00:24, 37.83trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  37%|███▋      | 540/1450 [00:13<00:24, 36.98trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  38%|███▊      | 544/1450 [00:13<00:25, 35.04trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  38%|███▊      | 548/1450 [00:13<00:25, 35.39trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  38%|███▊      | 552/1450 [00:13<00:25, 34.97trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  38%|███▊      | 556/1450 [00:13<00:26, 33.90trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  39%|███▊      | 560/1450 [00:13<00:25, 34.77trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  39%|███▉      | 564/1450 [00:13<00:25, 34.50trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  39%|███▉      | 568/1450 [00:13<00:24, 35.36trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  40%|███▉      | 573/1450 [00:13<00:23, 37.69trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  40%|███▉      | 577/1450 [00:14<00:23, 37.71trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  40%|████      | 581/1450 [00:14<00:22, 38.12trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  40%|████      | 586/1450 [00:14<00:21, 39.49trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  41%|████      | 590/1450 [00:14<00:25, 34.35trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  41%|████      | 594/1450 [00:14<00:25, 33.28trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  41%|████      | 598/1450 [00:14<00:25, 33.50trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  42%|████▏     | 602/1450 [00:14<00:25, 33.35trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  42%|████▏     | 606/1450 [00:14<00:26, 31.95trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  42%|████▏     | 610/1450 [00:15<00:28, 29.90trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  42%|████▏     | 614/1450 [00:15<00:26, 31.43trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  43%|████▎     | 618/1450 [00:15<00:25, 33.02trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  43%|████▎     | 622/1450 [00:15<00:24, 34.44trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  43%|████▎     | 627/1450 [00:15<00:22, 36.96trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  44%|████▎     | 631/1450 [00:15<00:22, 36.48trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  44%|████▍     | 636/1450 [00:15<00:21, 38.53trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  44%|████▍     | 641/1450 [00:15<00:20, 40.01trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  45%|████▍     | 646/1450 [00:16<00:20, 38.98trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  45%|████▍     | 650/1450 [00:16<00:21, 37.21trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  45%|████▌     | 654/1450 [00:16<00:21, 37.58trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  45%|████▌     | 658/1450 [00:16<00:21, 36.21trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  46%|████▌     | 662/1450 [00:16<00:21, 36.19trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  46%|████▌     | 666/1450 [00:16<00:22, 35.15trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  46%|████▌     | 670/1450 [00:16<00:22, 34.86trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  46%|████▋     | 674/1450 [00:16<00:22, 35.27trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  47%|████▋     | 678/1450 [00:16<00:22, 34.82trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  47%|████▋     | 683/1450 [00:17<00:20, 37.03trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  47%|████▋     | 688/1450 [00:17<00:19, 38.56trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  48%|████▊     | 693/1450 [00:17<00:19, 39.53trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  48%|████▊     | 697/1450 [00:17<00:19, 39.58trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  48%|████▊     | 701/1450 [00:17<00:21, 35.41trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  49%|████▊     | 705/1450 [00:17<00:21, 34.20trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  49%|████▉     | 709/1450 [00:17<00:21, 34.56trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  49%|████▉     | 713/1450 [00:17<00:21, 33.83trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  49%|████▉     | 717/1450 [00:18<00:22, 33.28trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  50%|████▉     | 721/1450 [00:18<00:21, 33.74trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  50%|█████     | 725/1450 [00:18<00:21, 34.33trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  50%|█████     | 729/1450 [00:18<00:20, 35.83trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  51%|█████     | 733/1450 [00:18<00:19, 36.40trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  51%|█████     | 738/1450 [00:18<00:18, 39.20trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  51%|█████     | 743/1450 [00:18<00:17, 40.84trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  52%|█████▏    | 749/1450 [00:18<00:16, 43.80trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  52%|█████▏    | 754/1450 [00:18<00:16, 42.25trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  52%|█████▏    | 759/1450 [00:19<00:15, 43.63trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  53%|█████▎    | 764/1450 [00:19<00:15, 44.58trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  53%|█████▎    | 769/1450 [00:19<00:15, 43.92trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  53%|█████▎    | 774/1450 [00:19<00:16, 39.85trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  54%|█████▎    | 779/1450 [00:19<00:17, 38.58trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  54%|█████▍    | 783/1450 [00:19<00:17, 38.91trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  54%|█████▍    | 787/1450 [00:19<00:17, 38.80trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  55%|█████▍    | 791/1450 [00:19<00:17, 38.43trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  55%|█████▍    | 795/1450 [00:20<00:17, 38.53trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  55%|█████▌    | 800/1450 [00:20<00:16, 40.23trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  56%|█████▌    | 805/1450 [00:20<00:15, 40.66trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  56%|█████▌    | 810/1450 [00:20<00:15, 40.46trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  56%|█████▌    | 815/1450 [00:20<00:15, 40.81trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  57%|█████▋    | 820/1450 [00:20<00:15, 41.27trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  57%|█████▋    | 825/1450 [00:20<00:15, 39.54trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  57%|█████▋    | 829/1450 [00:20<00:17, 35.63trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  57%|█████▋    | 833/1450 [00:21<00:17, 34.67trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  58%|█████▊    | 837/1450 [00:21<00:17, 34.87trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  58%|█████▊    | 841/1450 [00:21<00:18, 33.53trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  58%|█████▊    | 845/1450 [00:21<00:18, 33.57trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  59%|█████▊    | 849/1450 [00:21<00:19, 30.97trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  59%|█████▉    | 853/1450 [00:21<00:18, 32.58trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  59%|█████▉    | 857/1450 [00:21<00:17, 34.01trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  59%|█████▉    | 861/1450 [00:21<00:16, 35.03trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  60%|█████▉    | 866/1450 [00:21<00:15, 37.02trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  60%|██████    | 870/1450 [00:22<00:16, 35.64trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  60%|██████    | 874/1450 [00:22<00:15, 36.02trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  61%|██████    | 879/1450 [00:22<00:15, 37.86trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  61%|██████    | 884/1450 [00:22<00:13, 40.63trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  61%|██████▏   | 889/1450 [00:22<00:13, 42.67trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  62%|██████▏   | 895/1450 [00:22<00:12, 46.09trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  62%|██████▏   | 900/1450 [00:22<00:11, 46.04trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  62%|██████▏   | 905/1450 [00:22<00:12, 44.80trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  63%|██████▎   | 910/1450 [00:22<00:12, 42.44trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  63%|██████▎   | 915/1450 [00:23<00:12, 41.43trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  63%|██████▎   | 920/1450 [00:23<00:14, 37.67trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  64%|██████▎   | 924/1450 [00:23<00:13, 38.20trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  64%|██████▍   | 928/1450 [00:23<00:13, 38.23trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  64%|██████▍   | 932/1450 [00:23<00:13, 38.55trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  65%|██████▍   | 936/1450 [00:23<00:13, 37.70trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  65%|██████▍   | 940/1450 [00:23<00:13, 37.60trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  65%|██████▌   | 944/1450 [00:23<00:13, 36.71trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  65%|██████▌   | 948/1450 [00:24<00:13, 35.98trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  66%|██████▌   | 952/1450 [00:24<00:13, 35.95trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  66%|██████▌   | 957/1450 [00:24<00:13, 37.56trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  66%|██████▋   | 962/1450 [00:24<00:12, 40.43trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  67%|██████▋   | 967/1450 [00:24<00:11, 42.46trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  67%|██████▋   | 972/1450 [00:24<00:10, 44.40trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  67%|██████▋   | 977/1450 [00:24<00:10, 44.53trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  68%|██████▊   | 982/1450 [00:24<00:10, 44.20trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  68%|██████▊   | 987/1450 [00:24<00:11, 41.07trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  68%|██████▊   | 992/1450 [00:25<00:12, 37.54trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  69%|██████▊   | 996/1450 [00:25<00:12, 36.84trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  69%|██████▉   | 1000/1450 [00:25<00:13, 34.56trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  69%|██████▉   | 1004/1450 [00:25<00:12, 35.08trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  70%|██████▉   | 1009/1450 [00:25<00:11, 38.23trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  70%|██████▉   | 1014/1450 [00:25<00:10, 40.75trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  70%|███████   | 1019/1450 [00:25<00:10, 39.27trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  71%|███████   | 1025/1450 [00:25<00:09, 42.70trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  71%|███████   | 1030/1450 [00:26<00:09, 43.79trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  71%|███████▏  | 1035/1450 [00:26<00:10, 41.40trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  72%|███████▏  | 1040/1450 [00:26<00:11, 36.84trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  72%|███████▏  | 1045/1450 [00:26<00:10, 37.91trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  72%|███████▏  | 1049/1450 [00:26<00:10, 37.45trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  73%|███████▎  | 1053/1450 [00:26<00:11, 35.92trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  73%|███████▎  | 1057/1450 [00:26<00:10, 36.44trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  73%|███████▎  | 1062/1450 [00:26<00:09, 38.96trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  74%|███████▎  | 1067/1450 [00:27<00:09, 41.34trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  74%|███████▍  | 1072/1450 [00:27<00:08, 43.32trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  74%|███████▍  | 1077/1450 [00:27<00:08, 44.82trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  75%|███████▍  | 1082/1450 [00:27<00:08, 45.98trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  75%|███████▌  | 1088/1450 [00:27<00:07, 47.14trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  75%|███████▌  | 1093/1450 [00:27<00:07, 45.69trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  76%|███████▌  | 1098/1450 [00:27<00:08, 43.65trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  76%|███████▌  | 1103/1450 [00:27<00:08, 41.10trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  76%|███████▋  | 1108/1450 [00:27<00:08, 42.29trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  77%|███████▋  | 1113/1450 [00:28<00:08, 40.01trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  77%|███████▋  | 1118/1450 [00:28<00:07, 42.36trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  77%|███████▋  | 1123/1450 [00:28<00:07, 41.51trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  78%|███████▊  | 1128/1450 [00:28<00:07, 42.08trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  78%|███████▊  | 1133/1450 [00:28<00:07, 42.31trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  79%|███████▊  | 1139/1450 [00:28<00:07, 43.13trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  79%|███████▉  | 1144/1450 [00:28<00:06, 44.14trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  79%|███████▉  | 1149/1450 [00:28<00:06, 45.43trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  80%|███████▉  | 1154/1450 [00:29<00:06, 44.74trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  80%|███████▉  | 1159/1450 [00:29<00:06, 45.21trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  80%|████████  | 1164/1450 [00:29<00:06, 42.97trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  81%|████████  | 1169/1450 [00:29<00:06, 40.55trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  81%|████████  | 1174/1450 [00:29<00:06, 42.42trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  81%|████████▏ | 1179/1450 [00:29<00:06, 40.64trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  82%|████████▏ | 1184/1450 [00:29<00:07, 37.18trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  82%|████████▏ | 1188/1450 [00:29<00:07, 37.41trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  82%|████████▏ | 1192/1450 [00:30<00:07, 35.75trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  82%|████████▏ | 1196/1450 [00:30<00:07, 35.65trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  83%|████████▎ | 1200/1450 [00:30<00:07, 34.93trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  83%|████████▎ | 1204/1450 [00:30<00:06, 35.24trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  83%|████████▎ | 1208/1450 [00:30<00:07, 34.01trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  84%|████████▎ | 1212/1450 [00:30<00:07, 33.69trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  84%|████████▍ | 1216/1450 [00:30<00:06, 33.51trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  84%|████████▍ | 1221/1450 [00:30<00:06, 36.20trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  84%|████████▍ | 1225/1450 [00:30<00:06, 34.99trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  85%|████████▍ | 1229/1450 [00:31<00:06, 32.66trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  85%|████████▌ | 1233/1450 [00:31<00:06, 32.43trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  85%|████████▌ | 1237/1450 [00:31<00:06, 31.50trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  86%|████████▌ | 1241/1450 [00:31<00:06, 30.68trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  86%|████████▌ | 1245/1450 [00:31<00:06, 30.47trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  86%|████████▌ | 1249/1450 [00:31<00:06, 29.63trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  86%|████████▋ | 1253/1450 [00:31<00:06, 30.37trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  87%|████████▋ | 1257/1450 [00:32<00:06, 31.55trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  87%|████████▋ | 1261/1450 [00:32<00:05, 31.91trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  87%|████████▋ | 1265/1450 [00:32<00:05, 33.02trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  88%|████████▊ | 1269/1450 [00:32<00:05, 33.42trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  88%|████████▊ | 1273/1450 [00:32<00:05, 34.63trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  88%|████████▊ | 1277/1450 [00:32<00:04, 35.57trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  88%|████████▊ | 1283/1450 [00:32<00:04, 39.64trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  89%|████████▉ | 1288/1450 [00:32<00:03, 41.47trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  89%|████████▉ | 1293/1450 [00:32<00:03, 41.99trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  90%|████████▉ | 1298/1450 [00:33<00:03, 43.50trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  90%|████████▉ | 1303/1450 [00:33<00:03, 44.46trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  90%|█████████ | 1308/1450 [00:33<00:03, 40.68trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  91%|█████████ | 1313/1450 [00:33<00:03, 37.33trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  91%|█████████ | 1317/1450 [00:33<00:03, 36.87trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  91%|█████████ | 1321/1450 [00:33<00:03, 36.61trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  91%|█████████▏| 1326/1450 [00:33<00:03, 38.05trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  92%|█████████▏| 1330/1450 [00:33<00:03, 33.05trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  92%|█████████▏| 1334/1450 [00:34<00:03, 31.56trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  92%|█████████▏| 1338/1450 [00:34<00:03, 33.51trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  93%|█████████▎| 1342/1450 [00:34<00:03, 33.07trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  93%|█████████▎| 1347/1450 [00:34<00:02, 36.57trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  93%|█████████▎| 1352/1450 [00:34<00:02, 39.56trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  94%|█████████▎| 1357/1450 [00:34<00:02, 42.17trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  94%|█████████▍| 1362/1450 [00:34<00:01, 44.08trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  94%|█████████▍| 1367/1450 [00:34<00:01, 41.93trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  95%|█████████▍| 1372/1450 [00:35<00:02, 38.48trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  95%|█████████▍| 1376/1450 [00:35<00:02, 36.16trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  95%|█████████▌| 1380/1450 [00:35<00:02, 33.55trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  95%|█████████▌| 1384/1450 [00:35<00:02, 32.01trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  96%|█████████▌| 1388/1450 [00:35<00:01, 31.28trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  96%|█████████▌| 1392/1450 [00:35<00:01, 30.52trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  96%|█████████▋| 1396/1450 [00:35<00:01, 31.68trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  97%|█████████▋| 1400/1450 [00:35<00:01, 33.32trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  97%|█████████▋| 1404/1450 [00:36<00:01, 34.58trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  97%|█████████▋| 1408/1450 [00:36<00:01, 34.56trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  97%|█████████▋| 1412/1450 [00:36<00:01, 33.52trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  98%|█████████▊| 1416/1450 [00:36<00:01, 32.55trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  98%|█████████▊| 1420/1450 [00:36<00:00, 32.70trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  98%|█████████▊| 1424/1450 [00:36<00:00, 31.12trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  98%|█████████▊| 1428/1450 [00:36<00:00, 31.80trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  99%|█████████▉| 1432/1450 [00:36<00:00, 33.16trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  99%|█████████▉| 1436/1450 [00:37<00:00, 32.67trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences:  99%|█████████▉| 1440/1450 [00:37<00:00, 33.92trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences: 100%|█████████▉| 1444/1450 [00:37<00:00, 32.73trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences: 100%|█████████▉| 1448/1450 [00:37<00:00, 33.93trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Predicting phoneme sequences: 100%|██████████| 1450/1450 [00:37<00:00, 38.71trial/s]\n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.08.13, Block: 8, Trial: 20\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AY  |  G EH T  |  T AY ER D  |  W IH DH  |  DH AH  |  S AO NG  |  AH N D  |  D EY K S  |  R IH T UW N  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.08.13, Block: 8, Trial: 21\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  IH M ER JH AH S IY  |  K EH R  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.08.13, Block: 8, Trial: 22\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  Y UW  |  K R IY EH N T  |  AH  |  B IH G ER  |  S ER P R AY Z  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.08.13, Block: 8, Trial: 23\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AY  |  TH IH NG K  |  M EY B IY  |  Y UW  |  L UH K  |  AE T  |  IH T  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.08.13, Block: 8, Trial: 24\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  SH OW  |  DH AE T  |  DH EY  |  D UW  |  HH AE V  |  P R AA B L AH M Z  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.08.13, Block: 8, Trial: 25\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AY  |  EH N JH OY  |  DH AE T  |  T UW  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.08.13, Block: 8, Trial: 26\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AY  |  M UW V D  |  T UW  |  G EH Z AH S T  |  S IH T IY  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.08.13, Block: 8, Trial: 27\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  M EY B IY  |  F AO R  |  T AY M Z  |  AH  |  W IY K  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.08.13, Block: 8, Trial: 28\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  W EH N  |  HH IY  |  S IY D Z  |  IH T  |  T UW  |  HH IH Z  |  IH V EH N AH S T  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.08.13, Block: 8, Trial: 29\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  DH EH R Z  |  JH AH S T  |  N OW  |  W AH N  |  ER AW N D  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.08.13, Block: 8, Trial: 30\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  DH AH  |  S IH S T AH M  |  R AY T  |  N AW  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.08.13, Block: 8, Trial: 31\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  IY DH ER  |  W AH N  |  AH V  |  DH EH M  |  W UH D  |  B IY  |  AH  |  T IY SH AH N  |  CH OY S  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.08.13, Block: 8, Trial: 32\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  TH IH NG Z  |  L AY K  |  DH AE T  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.08.13, Block: 8, Trial: 33\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AY  |  L AY V D  |  IH N  |  P L EY S AH Z  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.08.13, Block: 8, Trial: 34\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  Y UW  |  HH AE D  |  T UW  |  CH EY N JH  |  IH T  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.08.13, Block: 8, Trial: 35\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  IH T  |  JH AH S T  |  S AO R T  |  AH V  |  HH AE P AH N Z  |  AH N AH M AE T IH K L IY  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.08.13, Block: 8, Trial: 36\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  M IH N AH S T  |  Y AO R  |  AH P  |  IH N  |  DH AH  |  AH S IH UW  |  P AA R T AH L  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.08.13, Block: 8, Trial: 37\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  IH T S  |  AH  |  JH OW K IH NG  |  HH AE Z ER D  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.08.13, Block: 8, Trial: 38\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  IY V IH N  |  AE F T ER  |  Y UW  |  W EY T  |  Y AO R  |  DH AE N  |  N EH K S  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.08.13, Block: 8, Trial: 39\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AY  |  G EH S  |  DH EY  |  M AH CH  |  B IY  |  V IH N IH S T  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.08.13, Block: 9, Trial: 15\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  DH EY  |  K EY M  |  B AE K  |  L IH T ER  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.08.13, Block: 9, Trial: 16\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  W EH L  |  W AH T  |  D UW  |  Y UW  |  D UW  |  AA N  |  Y AO R  |  Y AA R D  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.08.13, Block: 9, Trial: 17\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  DH AE T S  |  W AY  |  DH EY  |  K AO L  |  DH EH M  |  S W OW M IH NG  |  B UW L Z  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.08.13, Block: 9, Trial: 18\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  IH T  |  K AH V ER Z  |  DH AH  |  B UH K  |  AH V  |  DH AH  |  N IY T AH L  |  IH K S EH N S AH S  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.08.13, Block: 9, Trial: 19\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  T AO K  |  T UW  |  AW ER  |  W IH K T ER  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.08.13, Block: 9, Trial: 20\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  Y UW  |  W ER  |  JH AH S T  |  AH P  |  DH EH R  |  DH EH N  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.08.13, Block: 9, Trial: 21\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  L AE S T  |  Y IH R  |  AO R  |  DH AH  |  Y IH R  |  B IH F AO R\n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.08.13, Block: 9, Trial: 22\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  K UW  |  TH IH NG  |  S AH NG  |  AH V  |  Y AO R  |  CH OY S  |  F R AH M  |  DH AE T  |  SH OW  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.08.13, Block: 9, Trial: 23\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  L AY K  |  B L AE K  |  AY D  |  B IY  |  AH N D  |  DH AE T  |  K AY N D  |  AH V  |  TH IH NG  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.08.13, Block: 9, Trial: 24\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  IH F  |  HH IY  |  D IH D  |  S AH M TH IH NG  |  B AE D  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.08.13, Block: 9, Trial: 25\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AY  |  TH IH NG K  |  DH EH R  |  AH  |  G UH D  |  T IY M  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.08.13, Block: 9, Trial: 26\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AY  |  K AE N T  |  TH IH NG K  |  AH V  |  DH AH  |  N EY M  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.08.13, Block: 9, Trial: 27\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AH  |  L AA R JH  |  S AY L D  |  K EH R  |  F AH S IH L AH T IY  |  N AW  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.08.13, Block: 9, Trial: 28\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AA R  |  Y UW  |  R IH M AH N  |  K AH TH L IY  |  AO R  |  S AH M TH IH NG  |  EH L S  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.08.13, Block: 9, Trial: 29\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  DH AE T  |  K AY N D  |  Y UW V  |  R EH D  |  R IY S AH N T L IY  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.08.18, Block: 6, Trial: 24\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  IH T  |  IH Z  |  R IH L IY  |  G UH D  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.08.18, Block: 6, Trial: 25\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AY  |  D UW  |  P L EY  |  DH AH  |  P IY AE N OW  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.08.18, Block: 6, Trial: 26\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  K AH M AH N T  |  AH N D  |  JH OY N  |  DH AH  |  K AA N F ER S IH SH AH N  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.08.18, Block: 6, Trial: 27\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  DH AE T  |  IH Z  |  DH AH  |  P OY N T  |  AH V  |  DH IH S  |  AA R D AH L  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.08.18, Block: 6, Trial: 28\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  W IY V  |  R IH M AA L D AH L D  |  AO L  |  AW ER  |  Y UW N AH T S  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.08.18, Block: 6, Trial: 29\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AH N AH DH ER  |  R IY L  |  G UH D  |  W AH N  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.08.18, Block: 6, Trial: 30\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  IH T S  |  M AO R  |  IH F IH SH AH N T  |  T UW  |  D UW  |  TH IH NG Z  |  S AH S EH L F  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.08.18, Block: 6, Trial: 31\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AY  |  G EH S  |  DH AE T  |  AY  |  R IH L IY  |  D OW N T  |  N OW  |  DH AE T  |  M AH CH  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.08.18, Block: 6, Trial: 32\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  D OW N T  |  T EH L  |  DH AE T  |  T UW  |  AH  |  N EH D AH F  |  T EH K S AH N  |  N OW  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.08.18, Block: 6, Trial: 33\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AY  |  W IH SH  |  AY  |  K UH D  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.08.18, Block: 6, Trial: 34\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AY  |  K AE N  |  AA R D L IY  |  W EY T  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.08.18, Block: 6, Trial: 35\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  DH EH R  |  G OW IH NG  |  T UW  |  B IY  |  IH N  |  IY V IH N  |  W ER S  |  SH EH P  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.08.18, Block: 6, Trial: 36\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  DH EY  |  B L AO  |  DH AH  |  W EY SH AH L  |  AA N  |  IH T  |  AH DH ER  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.08.18, Block: 6, Trial: 37\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AY  |  W UH D  |  M AH CH  |  R AE DH ER  |  OW N  |  M AY  |  OW N  |  HH OW M  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.08.18, Block: 6, Trial: 38\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  N AA T  |  IY V IH N  |  AH  |  T R EH S IY  |  S L AH K  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.08.18, Block: 6, Trial: 39\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  JH R AO  |  EH N IY  |  K AH N K L UW ZH AH N Z  |  B EY K S T  |  AA N  |  R IY L  |  IH N T EH L AH S AH N S  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.08.18, Block: 6, Trial: 41\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  JH AH S T  |  T UW  |  F AO T  |  IH T  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.08.18, Block: 6, Trial: 42\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  DH AE T  |  IH Z  |  JH AH S T  |  P ER S IH N AH L  |  F IY L IH NG  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.08.18, Block: 6, Trial: 43\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  DH EY  |  D OW N T  |  S IY  |  IH CH  |  AH DH ER  |  V EH R IY  |  HH AO F AH N  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.08.18, Block: 6, Trial: 44\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  IH T  |  HH AE Z  |  B IH N  |  R IY L  |  G UH D  |  T AO K IH NG  |  T UW  |  Y UW  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.08.18, Block: 6, Trial: 45\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  R EH D IH NG  |  AH N D  |  TH IH NG Z  |  L AY K  |  DH IH S  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.08.18, Block: 6, Trial: 46\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  DH EY  |  T R AY  |  T UW  |  DH OW  |  IH N  |  G UH D  |  S T AH F  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.08.18, Block: 6, Trial: 47\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  IH F  |  Y UW  |  G EH T  |  P L EY S  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.08.18, Block: 6, Trial: 48\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AY  |  TH IH NG K  |  DH IH S  |  IH Z  |  L AY K  |  T UW  |  Y IH R Z  |  AH G OW  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.08.18, Block: 6, Trial: 49\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  DH AH  |  B IY P  |  IH N  |  DH AH  |  B R EH G R AE M  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.08.18, Block: 7, Trial: 25\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  HH IY  |  HH AE S  |  IH T  |  R IH L IY  |  N AY S  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.08.18, Block: 7, Trial: 26\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  IH Z  |  HH IY  |  AH  |  P R AA B L AH M  |  T R AY L D  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.08.18, Block: 7, Trial: 27\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  T UW  |  G R OW  |  AH P  |  AH N D  |  T UW  |  D IH S AY D  |  W AH T  |  DH EY  |  W AA N T  |  T UW  |  D UW  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.08.18, Block: 7, Trial: 28\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  DH EY  |  HH AE D  |  N OW  |  CH OY S  |  B AH T  |  T UW  |  L IY V  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.08.18, Block: 7, Trial: 29\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  S EH N D L IY  |  DH EH R  |  HH AE Z K  |  T UW  |  B IY  |  AH  |  K AH L IH ZH AH N  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.08.18, Block: 7, Trial: 30\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  Y UW  |  G EH T  |  M AO R  |  S T AH F  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.08.18, Block: 7, Trial: 31\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  SH IY  |  S EH D  |  DH AE T  |  DH AH  |  K L OW ZH R ER Z  |  W UH D  |  B IY  |  P R ER M AH N AH N T  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.08.18, Block: 7, Trial: 32\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  DH EY  |  AO L  |  L EH P T  |  AE Z  |  HH IY  |  JH AA L D  |  AW T  |  T UW  |  JH OY N  |  DH EH M  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.08.18, Block: 7, Trial: 33\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AY  |  TH IH NG K  |  IH T  |  W AH N  |  D UW  |  S AH M TH IH NG  |  F AO R  |  IH T  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.08.18, Block: 7, Trial: 34\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AY  |  D OW N T  |  L AY V  |  IH N  |  AH  |  HH AW S  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.08.18, Block: 7, Trial: 35\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  S OW  |  HH IY Z  |  AH  |  F AE N  |  AH V  |  IH N S T UW IY  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.08.18, Block: 7, Trial: 36\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  DH AE T  |  W AA Z  |  AO L M OW S T  |  AE N  |  IH N S AE M P AH L  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.08.18, Block: 7, Trial: 37\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AH P T EH SH AH N  |  IH Z  |  W AH T  |  M OW S T  |  AH V  |  DH EH M  |  N IY D  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.08.18, Block: 7, Trial: 38\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AE N  |  IH N D AH AE SH AH N AH L  |  P AH K Y AH L EY SH AH N  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.08.18, Block: 7, Trial: 39\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  W AH T  |  T UW  |  G OW  |  AE K T IH NG  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.08.18, Block: 7, Trial: 40\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  N OW  |  AH M IY D IY AH  |  R IH P AO R D S  |  AH V  |  K AE ZH AH L T IY Z  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.08.18, Block: 7, Trial: 41\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  Y UW  |  HH AE V  |  T UW  |  W ER K  |  ER AW N D  |  IH T  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.08.18, Block: 7, Trial: 42\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  K AH N F Y UW ZH AH N  |  AH N D  |  AH P S OW T AH N T IY  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.08.18, Block: 7, Trial: 43\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  DH EH R  |  IH Z  |  N OW  |  K OW B  |  B IH G  |  AH P  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.08.18, Block: 7, Trial: 44\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  W AH T  |  HH AE P AH Z  |  IH F  |  W IY  |  L UW Z  |  W ER S  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.08.18, Block: 7, Trial: 45\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  DH EH R  |  W AA Z  |  N OW  |  P OY N T  |  IH N  |  D EH L IH NG  |  W IH DH  |  HH IH M  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.08.18, Block: 7, Trial: 46\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  N AA T  |  K W AY T  |  DH AE T  |  AO F AH N  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.08.18, Block: 7, Trial: 47\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  D OW N T  |  T R AE V AH L  |  T UW  |  M AH CH  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.08.18, Block: 7, Trial: 48\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  W AH T S  |  IH N  |  L AY K  |  F R AH M  |  AE N  |  AA R D IH S T S  |  P OY N T  |  AH V  |  V Y UW  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.08.18, Block: 7, Trial: 49\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  IH T  |  L UH K S  |  L AY K  |  DH EY V  |  G AA T  |  AH  |  W IH P AH N  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.08.20, Block: 7, Trial: 25\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AY  |  HH AE V  |  TH R IY  |  L EH F T  |  IH N  |  DH AH  |  HH AW S  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.08.20, Block: 7, Trial: 26\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  DH AE T  |  AY D IY AH  |  F IH K S  |  M IY  |  IH G Z AE K T L IY  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.08.20, Block: 7, Trial: 27\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  IH F  |  AY  |  HH AE D  |  T UW  |  B IH G  |  AH  |  F EY V ER IH T  |  T IY M  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.08.20, Block: 7, Trial: 28\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  B R IH NG IH NG  |  S AH M TH IH NG  |  F AO R  |  AH  |  P AH B L IH K  |  P IH G N AH K  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.08.20, Block: 7, Trial: 29\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AY M  |  B IY IH NG  |  V EH R IY  |  G UH D  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.08.20, Block: 7, Trial: 30\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  HH IY  |  W ER K S  |  AA N  |  DH AH  |  R AW R AH N D  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.08.20, Block: 7, Trial: 31\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AY  |  G OW  |  W IH DH  |  G UH D  |  IH N T IH SH AH N Z  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.08.20, Block: 7, Trial: 32\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  N OW  |  DH EH R Z  |  N OW  |  W EY  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.08.20, Block: 7, Trial: 33\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  DH AE T  |  W IH L  |  S EH D  |  W AH N D ER F AH L  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.08.20, Block: 7, Trial: 34\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  Y AO R  |  K AA R  |  IH Z  |  F AY N  |  AH N D  |  EH V R IY TH IH NG  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.08.20, Block: 7, Trial: 35\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  L AY K  |  S EH K AH N D  |  JH AA B Z  |  DH AE T  |  DH EY  |  W ER K  |  IH N  |  DH AH  |  AE K T ER D ER N Z  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.08.20, Block: 7, Trial: 36\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  W UH D AH N T  |  DH AE T  |  B IY  |  AO F AH L  |  IH F  |  Y UW  |  W ER  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.08.20, Block: 7, Trial: 37\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  W IY R  |  S AH P OW S T  |  T UW  |  B IY  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.08.20, Block: 7, Trial: 38\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  G OW  |  T UW  |  T EY K  |  AH  |  SH AW ER  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.08.20, Block: 7, Trial: 39\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  HH AW EH V ER  |  DH EH R  |  IH Z  |  N OW  |  AE K CH UW AH L  |  W EY  |  T UW  |  M EH ZH ER  |  DH IH S  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.08.20, Block: 7, Trial: 40\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  R IH L IY  |  W EH L  |  R EH G Y AH L EY T AH D  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.08.20, Block: 7, Trial: 41\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  DH EH R Z  |  N AH TH IH NG  |  R AO NG  |  W IH DH  |  DH AE T  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.08.20, Block: 7, Trial: 42\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AH DH ER  |  S T EY T S  |  HH AE V  |  T EY K AH N  |  S T R AA G ER  |  M V IH ZH ER Z  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.08.20, Block: 7, Trial: 43\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  W IH CH  |  AY  |  TH AO T  |  W AA Z  |  AH  |  R IY L  |  IH N T AH R EH S T IH NG  |  K W AA S AH N  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.08.20, Block: 7, Trial: 44\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  IH T S  |  AE Z  |  M AH CH  |  R IY S ER Z  |  AE Z  |  DH EY  |  K AE N  |  P AA S AH B L IY  |  D UW  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.08.20, Block: 7, Trial: 45\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  Y UH R  |  N AA L AH JH AH B AH L  |  AA N  |  DH AE T  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.08.20, Block: 7, Trial: 46\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  D UW  |  Y UW  |  S EH L  |  DH EH M  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.08.20, Block: 7, Trial: 47\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  N EH V ER  |  B EY T IH D  |  DH AH  |  AW T S AY D  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.08.20, Block: 7, Trial: 48\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  N AW  |  IH T S  |  B AE K  |  AH G EH N  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.08.20, Block: 7, Trial: 49\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  W IY R  |  N EH V ER  |  G OW IH NG  |  T UW  |  G EH T  |  DH AE T  |  B AE K  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.08.20, Block: 8, Trial: 25\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AY  |  D OW N T  |  S IY  |  TH IH NG Z  |  CH EY N JH IH NG  |  R IH L IY  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.08.20, Block: 8, Trial: 26\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  HH UW  |  Y UW  |  N EH V ER  |  IH K S P EH K T  |  T UW  |  W EH N  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.08.20, Block: 8, Trial: 27\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  D IH D  |  Y UW  |  S IY  |  P AH S IH F IH K  |  AY S  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.08.20, Block: 8, Trial: 28\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  DH EH R  |  W AA Z  |  S AH M  |  R IH L IY  |  N EH S T IY  |  P ER P AH N AY Z IH NG  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.08.20, Block: 8, Trial: 29\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  DH AH  |  D IH S IH ZH AH N  |  AH P IH L D  |  AH  |  L OW ER  |  K AA R T  |  R IH L IH NG  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.08.20, Block: 8, Trial: 30\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AY  |  TH IH NG K  |  DH AE T  |  IH Z  |  AE N  |  AE K S AH L AH N T  |  P R OW G R AE M  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.08.20, Block: 8, Trial: 31\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  DH AH  |  P AH L IH T AH K AH L  |  AE K S P IH K T  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.08.20, Block: 8, Trial: 32\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  S IH N S  |  AY  |  D UW  |  AH  |  L AA T  |  AH V  |  P R AA JH EH K S  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.08.20, Block: 8, Trial: 33\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  DH EY  |  D IH D AH N T  |  K AH T  |  AH S  |  AO F  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.08.20, Block: 8, Trial: 34\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  EH V ER IY  |  M EY JH ER  |  S IH T IY  |  HH AE Z  |  AH  |  TH IY D AH  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.08.20, Block: 8, Trial: 35\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  DH AH  |  R OW L  |  IH N  |  DH AH  |  F AE M AH L IY  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.08.20, Block: 8, Trial: 36\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  W IY  |  D OW N T  |  R IH L IY  |  IH T  |  AW T  |  T UW  |  M AH CH  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.08.20, Block: 8, Trial: 38\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  G IH V  |  AH N D  |  IH N S EH D AH V  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.08.20, Block: 8, Trial: 39\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  DH EY  |  L AY V  |  IH T  |  AH P  |  T UW  |  Y UW  |  AH N D  |  Y AO R  |  JH AH B M IH K T  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.08.20, Block: 8, Trial: 40\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  T UW  |  B AE K S  |  S T UW P L EY S  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.08.20, Block: 8, Trial: 41\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  K UH D  |  Y UW  |  HH AE V  |  S N OW  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.08.20, Block: 8, Trial: 42\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  W EH N  |  DH EY  |  W ER  |  Y AH NG G ER  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.08.20, Block: 8, Trial: 43\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AY  |  HH OW P  |  Y UW  |  EH N JH OY D  |  DH IH S  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.08.20, Block: 8, Trial: 44\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AY  |  W AA Z  |  P R IH T IY  |  SH AA K T  |  AE T  |  DH AE T  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.08.20, Block: 8, Trial: 45\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  N AA T  |  DH AE T  |  AY V  |  B IH N  |  AH W EH R  |  AH V  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.08.20, Block: 8, Trial: 46\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AY  |  W AA Z  |  G OW IH NG  |  T UW  |  S EY  |  AY  |  AO L W EY Z  |  EH N JH OY D  |  DH AE T  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.08.20, Block: 8, Trial: 47\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  IH T S  |  N AA T  |  L AY K  |  AY M  |  G OW IH NG  |  HH OW M  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.08.20, Block: 8, Trial: 48\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  D UW  |  DH EY  |  AO L  |  L IY V  |  IH N  |  DH AH  |  EH R IY AH  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.08.20, Block: 8, Trial: 49\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AA R  |  R OW D  |  B AY  |  DH EH R  |  K IH D Z  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.08.25, Block: 1, Trial: 25\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  IH T S  |  AH  |  M IH N IY AH\n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.08.25, Block: 1, Trial: 26\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  DH EY  |  HH AE V  |  DH AH  |  M EH R AH\n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.08.25, Block: 1, Trial: 27\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AH L T AH M AH T L IY  |  W AH T  |  Y UW  |  D UW  |  IH Z  |  Y AO R  |  D IH S IH ZH AH N\n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.08.25, Block: 1, Trial: 28\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AY  |  TH IH NG K  |  DH EY  |  G OW  |  T UW  |  F AA R\n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.08.25, Block: 1, Trial: 29\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  DH AH  |  B EH S T  |  IH N Z AE M P AH L  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.08.25, Block: 1, Trial: 30\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  S OW L ER  |  P AW ER  |  S AE T AH L IH\n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.08.25, Block: 1, Trial: 31\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  B IH F AO R  |  AY  |  R IH T AY R D\n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.08.25, Block: 1, Trial: 32\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  DH EY  |  K AE N  |  B IY  |  S AH L EH K T IH V  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.08.25, Block: 1, Trial: 33\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AY  |  W EH R  |  L AA T S  |  AH V  |  CH AO R T S\n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.08.25, Block: 1, Trial: 34\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  M EY B IY  |  F AY V  |  AO R  |  S IH K S  |  Y IH R Z  |  AH G OW  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.08.25, Block: 1, Trial: 35\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AY V  |  D AH N  |  P R IH T IY  |  G UH D  |  AE T  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.08.25, Block: 1, Trial: 36\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  DH AH  |  M AO R  |  R UW V  |  DH EY  |  N IY D  |  T UW  |  IH N S T ER S AY\n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.08.25, Block: 1, Trial: 37\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  W IY  |  W IH L  |  AH P IY L  |  DH IH S  |  D IH S IH ZH AH N\n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.08.25, Block: 1, Trial: 38\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AH N D  |  HH IY  |  DH AE T  |  L IY K S  |  AH S  |  T UW  |  AW ER  |  N EH K S T  |  P OY N T  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.08.25, Block: 1, Trial: 39\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AH S EH N T L IY  |  W EH N  |  Y UW  |  G EH T  |  D AH N  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.08.25, Block: 1, Trial: 40\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AY  |  N UW  |  R AY T  |  AH W EY  |  HH IY  |  S IH UH D AH N T  |  T R AY  |  T UW  |  N AH CH  |  DH AH  |  T AO T ER  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.08.25, Block: 1, Trial: 41\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  HH AW  |  SH UH D  |  DH EY  |  D UW  |  IH\n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.08.25, Block: 1, Trial: 42\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  M AY  |  W AY F  |  K AY N D  |  AH V  |  L AH P S  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.08.25, Block: 1, Trial: 43\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AE F T ER  |  F AY V  |  Y UW Z  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.08.25, Block: 1, Trial: 44\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  D UW  |  S AH M TH IH NG  |  T UW  |  P IH T AH F AY  |  DH AH  |  S K UW L  |  P R AA P AH T IY\n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.08.25, Block: 1, Trial: 45\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  JH AH S T  |  T UW  |  G EH T  |  AH  |  T AY M  |  DH AE T  |  W IY  |  K AE N  |  B OW TH  |  G OW  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.08.25, Block: 1, Trial: 46\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  DH EH N  |  Y UW  |  HH AE V  |  T UW  |  M EY K  |  AH  |  S AE L AH\n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.08.25, Block: 1, Trial: 47\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  B AH T  |  IH T S  |  AH L AO NG  |  DH AH  |  L AY K S\n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.08.25, Block: 1, Trial: 48\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  DH AE T S  |  N IY T  |  DH AH M Y UW  |  L AY K  |  W ER S  |  T IH CH IH NG  |  AO L S OW  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.08.25, Block: 1, Trial: 49\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AY M  |  AO L R EH D IY  |  AA N  |  M AY  |  JH AA B\n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.08.27, Block: 1, Trial: 25\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AH  |  L IH T AH L  |  T R EY K AH N  |  F AO R  |  IY CH  |  D\n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.08.27, Block: 1, Trial: 26\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  N OW IH NG  |  Y AO R  |  CH OY S AH Z\n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.08.27, Block: 1, Trial: 27\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  K R AY D  |  L AH V Z  |  HH IH D  |  AH G EH N S T  |  T EH S\n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.08.27, Block: 1, Trial: 28\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  Y UW  |  G AE T  |  P L IY M  |  DH EH M  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.08.27, Block: 1, Trial: 29\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  P R AA B AH B L IY  |  M IH L AH T S  |  AH V  |  D AA L ER Z\n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.08.27, Block: 1, Trial: 30\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  S OW  |  AY  |  G AA T  |  AH N D ER  |  DH EH R  |  AH N D  |  M EH S T  |  W IH DH  |  DH AH  |  V\n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.08.27, Block: 1, Trial: 31\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AE Z  |  F AA R  |  AE Z  |  JH AH S T  |  HH AE V IH NG  |  HH AH N D AH Z  |  ER AW N D  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.08.27, Block: 1, Trial: 32\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  IH T  |  W UH D  |  D IH P EH N D  |  AH B AW N  |  W IH CH  |  W AH N  |  Y UW  |  W AA N\n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.08.27, Block: 1, Trial: 33\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  DH AE T  |  W AH N  |  W AA Z IH N T  |  R IH L IY  |  W EH L  |  T R EY D\n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.08.27, Block: 1, Trial: 34\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  HH IY  |  AO L S OW  |  W AH T S  |  T UW  |  S IY  |  M AO R  |  S K UW L  |  S EH P T IY  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.08.27, Block: 1, Trial: 35\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  L EH S  |  S EY  |  T IH P AH K AH L\n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.08.27, Block: 1, Trial: 36\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  D UW  |  Y UW  |  K AH N T IH N IY UW  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.08.27, Block: 1, Trial: 37\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AY  |  P UH T  |  AO L  |  DH AH  |  M AH N IY  |  IH N T UW  |  IH T  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.08.27, Block: 1, Trial: 38\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AH N D  |  IH T S  |  JH AH S T  |  IH N EH D AH B\n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.08.27, Block: 1, Trial: 39\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  IH T S  |  F AH N IY  |  AY  |  W AA Z  |  R EY D\n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.08.27, Block: 1, Trial: 40\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AY  |  S T IH L  |  G AA T  |  AH  |  K AH P AH L  |  AH V  |  Y IH R Z  |  AA N  |  IH N  |  T UW  |  G OW  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.08.27, Block: 1, Trial: 41\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  W IY  |  D OW N T  |  HH AE V  |  EH N IY W EH R  |  T UW  |  G OW  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.08.27, Block: 1, Trial: 42\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AH N D  |  IH T S  |  D IH S IH ZH AH N  |  K AE N  |  L IY N  |  T UW  |  AH  |  D IH F ER AH N T  |  R IY Z\n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.08.27, Block: 1, Trial: 43\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  W AH N  |  IH N  |  DH AH  |  M AO R N IH NG  |  AH N D  |  W AH N  |  IH N  |  DH AH  |  IY V N IH NG  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.08.27, Block: 1, Trial: 44\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  K AE N  |  Y UW  |  IH M AE JH AH N\n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.08.27, Block: 1, Trial: 45\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  IH T S  |  AH B AW T  |  TH ER D IY  |  S IH N S  |  M AY L Z  |  AH W EY  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.08.27, Block: 1, Trial: 46\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AY  |  K AE N  |  G AA T  |  DH AE T  |  M AH CH  |  AO F  |  DH AH  |  EH N D  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.08.27, Block: 1, Trial: 47\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AE Z  |  L AO NG  |  AE Z  |  HH IY  |  P AH S T  |  IH N  |  DH AH  |  AW ER Z  |  HH IY  |  N IY D S  |  T UW  |  D UW  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.08.27, Block: 1, Trial: 48\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  DH AE T  |  W AH N  |  DH AE T  |  Y UW  |  HH AE D  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.08.27, Block: 1, Trial: 49\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  B OW TH  |  AH V  |  DH AH  |  CH IH L D R AH N  |  W ER  |  IH N  |  K AA L IH JH  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.09.01, Block: 8, Trial: 25\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  Y UW  |  K AE N  |  G EH T  |  DH AH  |  EH N F ER R M EY SH AH N  |  T UW  |  S EH T  |  IH T  |  AH P  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.09.01, Block: 8, Trial: 26\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  F AY N D  |  AH  |  P L EY S  |  DH AE T  |  HH AE Z  |  AH  |  N AY S  |  JH AA B  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.09.01, Block: 8, Trial: 27\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  T UW  |  B IH K  |  DH AH  |  R AY T  |  P ER S AH N  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.09.01, Block: 8, Trial: 28\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AY  |  G EH T  |  K AO L Z  |  AE T  |  HH OW M  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.09.01, Block: 8, Trial: 29\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  S AH M B AA D IY  |  W AA Z  |  T EH L IH NG  |  M IY  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.09.01, Block: 8, Trial: 30\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AH  |  K AH P AH L  |  AH V  |  P R AA B L AH M Z  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.09.01, Block: 8, Trial: 31\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  B AH T  |  DH AE T  |  W AA Z  |  AH  |  R IH L IY  |  F AH N  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.09.01, Block: 8, Trial: 32\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  IH T  |  S AW M Z  |  L AY K  |  IH T S  |  G UH D  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.09.01, Block: 8, Trial: 33\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AY  |  V OW T  |  R IH L IH JH AH K L IY  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.09.01, Block: 8, Trial: 34\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  DH EH R  |  EH K S AH L AH N T  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.09.01, Block: 8, Trial: 35\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  N EH K  |  HH AE Z  |  G R EY T  |  V IH ZH AH N  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.09.01, Block: 8, Trial: 36\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  DH AE T S  |  JH AH S T  |  AE N  |  IH K S T R IY M  |  IH K S EH P AH L  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.09.01, Block: 8, Trial: 37\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AH  |  L AA T  |  AH V  |  TH IH NG Z  |  AA R  |  R IH L IY  |  V AE L AH N T  |  T AY P  |  M UW V IY Z  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.09.01, Block: 8, Trial: 38\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AY  |  TH IH NG K  |  DH AE T  |  B IY  |  N IY T  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.09.01, Block: 8, Trial: 39\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  P UH T  |  AO L  |  Y AO R  |  R IY S AY K AH B AH L Z  |  IH N  |  DH AE T  |  W AH N  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.09.01, Block: 8, Trial: 40\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  Y UH R  |  P R IH Z AH N T  |  L OW K EY SH AH N  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.09.01, Block: 8, Trial: 41\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AY L  |  T EY K  |  IH T  |  AW T  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.09.01, Block: 8, Trial: 42\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  P IY P AH L  |  G OW IH NG  |  IH N T UW  |  D IH F ER AH N T  |  F IY L D Z  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.09.01, Block: 8, Trial: 43\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AY  |  G EH S  |  DH AH  |  K W EH S CH AH N  |  IH Z  |  IH N  |  M AY  |  M AY N D  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.09.01, Block: 8, Trial: 44\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  L EH T S  |  T AO K  |  AH B AW T  |  HH IY R  |  P AH L UW SH AH N  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.09.01, Block: 8, Trial: 45\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AY  |  W OW N T  |  B IY  |  D R AY V IH NG  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.09.01, Block: 8, Trial: 46\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  W IH CH  |  IH Z  |  AH  |  G UH D  |  D IY L  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.09.01, Block: 8, Trial: 47\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AY  |  N OW  |  L AA T S  |  AH V  |  W IH M AH N  |  W UH D  |  D UW  |  IH T  |  AO L  |  DH AH  |  T AY M  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.09.01, Block: 8, Trial: 48\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  DH IH S  |  IH Z  |  M AY  |  D EY D S  |  P AA R T  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.09.01, Block: 8, Trial: 49\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  Y UW  |  K UH D  |  S T IH K  |  T UW  |  DH AE T  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.09.01, Block: 9, Trial: 25\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  EH N JH OY  |  DH AH  |  IH N V EH K SH ER  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.09.01, Block: 9, Trial: 26\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AY  |  D OW N T  |  HH AE V  |  AE K S EH S  |  AH DH ER  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.09.01, Block: 9, Trial: 27\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  S ER T AH N L IY  |  IH F  |  Y UW  |  W AA CH  |  IH T  |  EH N IY  |  AH M AW N T  |  AH V  |  T AY M  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.09.01, Block: 9, Trial: 28\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  N OW  |  IH N K AH M  |  T AE K S AH Z  |  IH N  |  T EH K S AH Z  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.09.01, Block: 9, Trial: 29\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AY  |  D OW N T  |  N OW  |  IH F  |  Y UW  |  HH AE V  |  W AH N  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.09.01, Block: 9, Trial: 30\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  W AY  |  AA R  |  AW ER  |  P R IH Z AH N Z  |  OW V ER AW N D IH D  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.09.01, Block: 9, Trial: 31\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  DH EY  |  W UH D  |  V OW T  |  P T R UW  |  CH OY S  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.09.01, Block: 9, Trial: 32\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  W EH N  |  HH IY  |  G OW Z  |  T UW  |  S K UW L  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.09.01, Block: 9, Trial: 33\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  IH T  |  W AA Z  |  L AY K  |  F AY V  |  AO R  |  S IH K S  |  D AA L ER Z  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.09.01, Block: 9, Trial: 34\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AY  |  JH AH S T  |  TH AO T  |  DH AE T  |  DH EY  |  B R AH G  |  AH P  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.09.01, Block: 9, Trial: 35\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  IH T S  |  OW N L IY  |  L AY K  |  IH L EH V AH N T  |  HH AH N D R AH D  |  S K W EH R  |  F IY T  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.09.01, Block: 9, Trial: 36\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  D OW N T  |  B L AO  |  DH EH R  |  AE N D  |  AH V  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.09.01, Block: 9, Trial: 37\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  W EH N  |  HH IY  |  K AH M Z  |  DH AH  |  F AY N AH L  |  D IH S IH ZH AH N  |  W IH L  |  B IY  |  M EY D  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.09.01, Block: 9, Trial: 38\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  DH AH  |  K AA R P AH N IH NG  |  IH Z  |  G R OW Z  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.09.01, Block: 9, Trial: 39\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  K IY  |  P OY N T S  |  F R AH M  |  DH AH  |  M EY N Z  |  R IH P AO R T  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.09.01, Block: 9, Trial: 40\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  K DH EH R  |  AW T  |  AW ER  |  B IH S N M AH N T  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.09.01, Block: 9, Trial: 41\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  N UW  |  K AA M P AH N T  |  AH N D  |  EH V R IY TH IH NG  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.09.01, Block: 9, Trial: 42\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  DH EY  |  W UH D  |  HH AE V  |  HH AE D  |  K IH D Z  |  R AH N IH NG  |  ER AW N D  |  B AY  |  DH EH N  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.09.01, Block: 9, Trial: 43\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AY  |  TH IH NG K  |  AW ER  |  N EH K S T  |  K AA R  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.09.01, Block: 9, Trial: 44\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AY  |  TH IH NG K  |  IH T S  |  DH EH R  |  W EY  |  AH V  |  S EY IH NG  |  HH AW  |  W EH L  |  Y UW  |  D UW  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.09.01, Block: 9, Trial: 45\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AO L  |  AH V  |  AH  |  S AH T AH D  |  Y UW  |  L UH K  |  AH N D  |  DH EH R Z  |  TH R IY  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.09.01, Block: 9, Trial: 46\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  HH IY  |  B EH T ER  |  N AA T  |  B IY  |  M AY N  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.09.01, Block: 9, Trial: 47\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AH  |  M EY D  |  D IY SH  |  AH N D  |  AH  |  D IH S ER T  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.09.01, Block: 9, Trial: 48\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  HH AW  |  M EH N IY  |  D IH V IH ZH AH N Z  |  D AH Z  |  HH IY  |  HH AE V  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.09.01, Block: 9, Trial: 49\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  L AO NG  |  T ER M  |  K AA N S AH K W EY S SH AH Z  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.09.03, Block: 8, Trial: 25\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AY  |  N OW  |  AH  |  G ER L  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.09.03, Block: 8, Trial: 26\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  W IY  |  S EH T  |  AH  |  R EH D ER  |  S EH S T IH D  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.09.03, Block: 8, Trial: 27\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AY  |  D OW N T  |  HH AE V  |  EH N IY  |  P R AA B AH M  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.09.03, Block: 8, Trial: 28\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AY  |  HH AE D  |  AH  |  HH AA R D  |  T AY M  |  G EH T IH NG  |  S IH T IY  |  AA N  |  AH  |  JH UH R IY  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.09.03, Block: 8, Trial: 29\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  D OW N T  |  IY T  |  DH AH  |  Y AO NG K  |  AE T  |  AO L  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.09.03, Block: 8, Trial: 30\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  DH EY  |  HH AE S K T  |  AH S  |  T UW  |  B AH L D ER L  |  AW ER  |  N UW Z P EY P T ER K Z  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.09.03, Block: 8, Trial: 31\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  DH EY  |  M EY K  |  AH  |  K AH L EH K SH AH N  |  AA N  |  M AH N D IY  |  F AO R  |  Y AO R D  |  W EY T S\n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.09.03, Block: 8, Trial: 32\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  K UH D AH N T  |  K AE CH  |  W AH N  |  T UW  |  S EY M  |  Y AO R  |  L AY F  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.09.03, Block: 8, Trial: 33\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  IH T  |  W AH Z  |  AH  |  G R EY T  |  P L EH S ER  |  S P IY K IH NG  |  W IH DH  |  Y UW  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.09.03, Block: 8, Trial: 34\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  D UW  |  W IY  |  JH AH S T  |  G OW  |  AH HH EH D  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.09.03, Block: 8, Trial: 35\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AY  |  F EH L T  |  K AY N D  |  AH V  |  S T AH B AH D  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.09.03, Block: 8, Trial: 36\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AY  |  TH IH NG Z  |  IH T S  |  G R EY D  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.09.03, Block: 8, Trial: 37\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AH  |  M IH JH ER AH IY  |  AH V  |  DH AH  |  JH UH R IY  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.09.03, Block: 8, Trial: 38\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  Y UW  |  N OW  |  W AH T  |  AY  |  AE M  |  S EY IH NG  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.09.03, Block: 8, Trial: 39\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  DH EY  |  T ER N  |  DH EH M  |  L UW S  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.09.03, Block: 8, Trial: 40\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  HH IY  |  W EH N T  |  T UW  |  V IY N AA F  |  W AH N  |  M AY N  |  AE N D  |  K EY M  |  B AE K  |  AH N AH DH ER  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.09.03, Block: 8, Trial: 41\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  M AO R  |  AO R  |  L EH S  |  AE T  |  HH OW M  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.09.03, Block: 8, Trial: 42\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  Y UW  |  K AE N  |  AH V OY D  |  DH IH S  |  P R AA B L AH M  |  IH N  |  T UW  |  W\n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.09.03, Block: 8, Trial: 43\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  W AH T S  |  DH AH  |  S P EH N SH IH L T IY  |  DH AE T  |  Y UH R  |  L UH K IH NG  |  F AO R\n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.09.03, Block: 8, Trial: 44\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  JH ER B AH N IY  |  IH Z  |  AH  |  G EH S  |  IH N  |  P OY N T  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.09.03, Block: 8, Trial: 45\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  S AH M T ER  |  IH T  |  W AA Z  |  IY Z IY  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.09.03, Block: 8, Trial: 46\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AY V  |  D AH N  |  DH OW Z  |  T UW  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.09.03, Block: 8, Trial: 47\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  IH T S  |  AH  |  HH OW L  |  IH K S P R IH EH R AH IH S  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.09.03, Block: 8, Trial: 48\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  IH N  |  AO R D ER  |  T UW  |  B AA L IH JH  |  DH AH  |  D IH V IH ZH AH N  |  DH AH  |  S K UW L Z  |  M AH CH  |  B IY  |  S P L AE N T  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.09.03, Block: 8, Trial: 49\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  T R IH D AH B AH L  |  D EH S P AH  |  S IH SH IH N  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.09.03, Block: 9, Trial: 9\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  IH T S  |  AO L  |  R OW D  |  AH P  |  IH N T UW  |  W AH N  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.09.03, Block: 9, Trial: 10\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  Y UW  |  D UW  |  HH AE V  |  AH  |  S EH P ER R IH T  |  EH R IY AH  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.09.03, Block: 9, Trial: 11\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  TH IH NG K  |  AH B AW T  |  HH AW  |  M EH N IY  |  AO T AH M OW B IY L Z  |  DH EH R  |  AA R  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.09.03, Block: 9, Trial: 12\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  W AH T  |  AA R  |  DH AH  |  AH DH ER Z  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.09.03, Block: 9, Trial: 13\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  IH T S  |  R IH L IY  |  K AY N D  |  AH V  |  K R EY Z IY\n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.09.03, Block: 9, Trial: 14\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  DH AH  |  L EY T AH S T  |  AE N D R OY D  |  F OW D Z  |  F AO R  |  L EH S\n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.09.03, Block: 9, Trial: 15\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AH G EH N  |  AW ER  |  CH OY S AH Z  |  AA R  |  N AA T  |  M EY D  |  IH N  |  AH  |  F AE K Y UW M  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.09.03, Block: 9, Trial: 17\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  B EY B AH Z  |  AH V  |  K AH N D R AH S  |  SH UH D  |  HH AE V  |  N OW  |  IH L UW ZH AH N Z  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.09.03, Block: 9, Trial: 18\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  DH EY  |  AH S AY D  |  Y UW  |  AH  |  T AA P IH K  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.09.03, Block: 9, Trial: 19\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  DH EH R Z  |  DH IH S  |  W AH N  |  AE K T ER  |  EH V R IY W AH N  |  L AY K S  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.09.24, Block: 8, Trial: 10\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AE Z  |  HH IY  |  G AA T  |  T UW  |  B IY  |  AH  |  T EH N AH JH AH ER  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.09.24, Block: 8, Trial: 11\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AY  |  W EH D  |  L AH V  |  T UW  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.09.24, Block: 8, Trial: 12\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AO L  |  DH IY Z  |  AH DH ER  |  P IY P AH L  |  AA R  |  AW T  |  R AH N IH NG  |  ER AW N D  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.09.24, Block: 8, Trial: 13\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AH  |  L AA T  |  AH V  |  M UW V ER D ER  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.09.24, Block: 8, Trial: 14\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  W IY  |  HH AE D  |  AE N  |  OW K EY N AH N  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.09.24, Block: 8, Trial: 15\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  DH AE T  |  IH Z  |  T R UW  |  IH N  |  AH L AH N T AY  |  AH N D  |  AH K R AO S  |  DH IH S  |  T EY SH AH N  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.09.24, Block: 8, Trial: 16\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  IH Z AH N  |  DH AE T  |  F AH N IY  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.09.24, Block: 8, Trial: 17\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  W IH DH  |  T EY M Z  |  K AE N JH ER L  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.09.24, Block: 8, Trial: 18\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  DH AH  |  ER L IY  |  R IH M P AH B L B IH IY  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.09.24, Block: 8, Trial: 19\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  D UW  |  Y UW  |  G OW  |  F AO R  |  L AH NG  |  V EY K IH K T EY SH Z  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.09.24, Block: 9, Trial: 25\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AH N D  |  HH AH N D AH S T  |  AH M AW N T  |  AH V  |  T AY M  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.09.24, Block: 9, Trial: 26\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  B R EY IH NG  |  M AO R  |  AO F T AH D  |  DH AE N  |  Y UW ZH AH W AH L  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.09.24, Block: 9, Trial: 27\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AY  |  TH AO T  |  IH T  |  W AA Z  |  P R IH T IY  |  G UH D  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.09.24, Block: 9, Trial: 28\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  R EY S  |  AO R IY AH T AH D  |  R AE DH ER  |  DH AE N  |  CH IH N D ER  |  B EY S  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.09.24, Block: 9, Trial: 29\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  DH EH R  |  N IY D Z  |  T UW  |  B IY  |  AH  |  L AA N  |  D JH R AH N  |  S AH M W EH R  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.09.24, Block: 9, Trial: 30\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  HH AW  |  S T R AH NG  |  IH Z  |  IH T  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.09.24, Block: 9, Trial: 31\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AY  |  W EH L  |  AH G R IY  |  T UW  |  DH AE T  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.09.24, Block: 9, Trial: 32\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  IH F  |  Y UH R  |  IH N V AA L D  |  Y ER S EH L F  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.09.24, Block: 9, Trial: 33\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  DH EY  |  K AE N  |  AO L W EY Z  |  M EY B IY  |  G EH T  |  S AH M B AA D IY  |  AW S  |  T UW  |  K UH K  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.09.24, Block: 9, Trial: 34\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AY  |  K UH D  |  D UW  |  IH T  |  N AW  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.09.24, Block: 9, Trial: 35\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  D UW  |  Y UW  |  HH AE V  |  AH  |  R OW N T OW  |  D EH L ER  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.09.24, Block: 9, Trial: 36\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  IH F  |  DH EY  |  D UW  |  K AH M  |  B AE K  |  DH AE S  |  Y IH R  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.09.24, Block: 9, Trial: 37\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AY  |  TH IH NG K  |  SH IY  |  HH AE Z  |  P R AA B L AH M Z  |  W IH DH  |  DH AE T  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.09.24, Block: 9, Trial: 38\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  IH T S  |  S AH T  |  AH  |  T R AH B AH L  |  HH IY R  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.09.24, Block: 9, Trial: 39\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  DH EY  |  T R EY T  |  DH AH  |  N UW S L IY Z  |  AH V  |  DH EH R  |  P EH ER  |  R AY T  |  N AW  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.09.24, Block: 9, Trial: 40\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AE F T ER  |  DH AE T  |  S IY Z AH N  |  AA L AH Z  |  HH AE D  |  AH  |  D IH S IH ZH AH N  |  T UW  |  M EY K  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.09.24, Block: 9, Trial: 41\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  HH IY Z  |  D AH N  |  AH  |  B AH N CH  |  AH V  |  P AA K T AH M AO R  |  M UW V IY Z  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.09.24, Block: 9, Trial: 42\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AH N D  |  W AH T  |  W AA Z  |  DH AH  |  P OY N T  |  AH V  |  IH T  |  AO L  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.09.24, Block: 9, Trial: 43\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  P IY P AH L  |  G EH T  |  V EH R IY  |  AH B F S EH T  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.09.24, Block: 9, Trial: 44\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  IH T S  |  D UW IH NG  |  AH  |  L AA T  |  AH V  |  D EH M AH S  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.09.24, Block: 9, Trial: 45\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  HH AE V  |  Y UW  |  EH V ER  |  HH AE D  |  AH V  |  HH ER  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.09.24, Block: 9, Trial: 46\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  DH EH R  |  P R IH T IY  |  F ER G IH M IH NG  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.09.24, Block: 9, Trial: 47\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  W EH R  |  Y UW  |  F R AH M  |  ER IH JH AH N AH L IY  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.09.24, Block: 9, Trial: 48\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  W IY  |  M AE N AH JH Z  |  T UW  |  G EH T  |  T UW  |  W AH N  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.09.24, Block: 9, Trial: 49\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  W EH N  |  Y UW  |  W AA CH  |  DH EH M  |  G OW  |  AH P  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.09.29, Block: 3, Trial: 25\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  DH AH  |  G R IY N  |  T AE K S  |  AH B AH V  |  IH Z  |  AH  |  M AE T ER  |  AH V  |  CH OY S  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.09.29, Block: 3, Trial: 26\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  L AA T  |  AH V  |  F IH L IH S AE L F IH K AH L  |  K AA N T EH N T  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.09.29, Block: 3, Trial: 27\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  L EH T S  |  DH AE N  |  HH AE V  |  DH AH  |  T R AY AH L Z  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.09.29, Block: 3, Trial: 28\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  IY V IH N  |  IH F  |  IH T S  |  S M OW K IH NG  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.09.29, Block: 3, Trial: 29\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AY  |  G EH T  |  TH IH NG Z  |  D AH N  |  F AE N T D ER  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.09.29, Block: 3, Trial: 30\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  IH T  |  W AA Z  |  F AH N  |  T UW  |  W ER K  |  W IH DH  |  HH IH M  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.09.29, Block: 3, Trial: 31\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AY  |  TH IH NG K  |  M AH S T  |  P IY P AH L  |  W AH N  |  T UW  |  B IY  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.09.29, Block: 3, Trial: 32\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  T R AY V IH NG  |  AH  |  K AA R  |  F AO R  |  L AO NG G ER  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.09.29, Block: 3, Trial: 33\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  DH AH  |  K L AE S IH K AH L  |  TH IH NG K  |  DH AE T  |  Y UW  |  S IY  |  AA N  |  T IY V IY  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.09.29, Block: 3, Trial: 34\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  IH T  |  IH Z  |  N EH R F AO R  |  D IH S AH P OY R T IH NG  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.09.29, Block: 3, Trial: 35\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  D OW N T  |  G EH T  |  T UW  |  M AH CH  |  M AH N IY  |  F AO R  |  DH EH M  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.09.29, Block: 3, Trial: 36\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AY V  |  B IH N  |  HH IY R  |  S EH N S  |  S EH V AH N T IY  |  F AO R  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.09.29, Block: 3, Trial: 37\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AY  |  HH AE V AH N T  |  HH AE D  |  T UW  |  R IH P L EY S  |  DH AH  |  TH IH NG  |  Y EH T  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.09.29, Block: 3, Trial: 38\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AY  |  AE L IY  |  R EH K AH M AH N D  |  IH T  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.09.29, Block: 3, Trial: 39\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AE T  |  L IY S T  |  D IH D IH SH AH N AH L IY  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.09.29, Block: 3, Trial: 40\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  W IY R  |  K AY N D  |  AH V  |  AE T  |  DH AH  |  EH N D  |  AH V  |  DH AE T  |  T R IH L  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.09.29, Block: 3, Trial: 41\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AY  |  K AE N  |  G EH T  |  DH IH S  |  Y AA R D  |  IH N  |  SH EY P  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.09.29, Block: 3, Trial: 42\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  SH IY Z  |  R IH L IY  |  AH  |  G UH D  |  F IH SH ER  |  W UH M AH N  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.09.29, Block: 3, Trial: 43\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  IH N  |  AW ER  |  P AH T IH K Y AH L ER  |  S IH CH UW EY SH AH N  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.09.29, Block: 3, Trial: 44\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AY  |  Y UW ZH AH W AH L IY  |  W AA N T  |  M AY  |  D AO G  |  IH N  |  DH AH  |  P OY R K  |  N IH R  |  M AY  |  HH OW M  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.09.29, Block: 3, Trial: 45\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AY  |  D IH D  |  DH AE T  |  W IH DH  |  DH AH  |  S T EH K T AH N  |  B EY B IY  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.09.29, Block: 3, Trial: 46\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  IH T S  |  D IH S AH P OY R T IH NG  |  HH AW  |  DH IH S  |  W AA Z  |  HH AE N D AH L D  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.09.29, Block: 3, Trial: 47\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  HH IY  |  T OW L D  |  AH S  |  T UW  |  G EH T  |  IH K S AY D  |  AW ER  |  K AA R  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.09.29, Block: 3, Trial: 48\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AY  |  G EH S  |  W EH N  |  Y UH R  |  F IH L IH NG  |  D IH F IH D IH D  |  D OW N T  |  G IH V  |  AH P  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.09.29, Block: 3, Trial: 49\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  DH AE T  |  W UH D  |  B IY  |  AO L  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.09.29, Block: 4, Trial: 25\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  L AH V  |  IH Z  |  EH N AH JH IY  |  B IY T AH F AH L  |  EH N ER S IY  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.09.29, Block: 4, Trial: 26\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  M EY B IY  |  DH AH  |  K AE B P  |  R IY K  |  M EY D  |  W AA Z  |  B IH T W IY N  |  HH IH M  |  AH N D  |  DH AH  |  AA N IY AH F L OY M AH N T  |  L AY N  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.09.29, Block: 4, Trial: 27\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  HH IY  |  T R AY D  |  T UW  |  HH AY D  |  IH N  |  DH AH  |  B AE K  |  AH V  |  DH AH  |  R UW M  |  R UW M  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.09.29, Block: 4, Trial: 29\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  SH IY  |  IH Z  |  AO L S OW  |  K L AE S Z  |  T UW  |  DH AH  |  T R AE P  |  IH M AH N AH S T R EY SH AH N  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.09.29, Block: 4, Trial: 30\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AH  |  D IH T EH R IY AH L  |  AA N  |  AH M P L OY IH NG  |  DH AH  |  P R EH N S AH B AH L Z  |  AH V  |  EH N IY AE D IY  |  K UH D  |  S T IH L  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.09.29, Block: 4, Trial: 31\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  G EH T  |  B R EY NG IH NG  |  N OW Z  |  AH L ER Z  |  AH N D  |  S P EH SH AH L  |  R IY P AO R T S  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.09.29, Block: 4, Trial: 32\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  DH AH  |  T AY M  |  F AO R  |  JH R UW V IY AH L  |  F AY N Z  |  IH Z  |  B IH HH AY N D  |  AH S  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.09.29, Block: 4, Trial: 33\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  DH EH R  |  W AA Z  |  T AO K  |  AE T  |  DH AH  |  S IH T ER  |  AA N  |  M EH S T IH NG  |  AH V  |  DH AH  |  T R AH P  |  T R AE JH AH D IY  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.09.29, Block: 4, Trial: 34\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  SH IY  |  IH Z  |  DH AH  |  OW N L IY  |  G ER L  |  HH UW  |  K AH M Z  |  T UW  |  AW ER  |  S K UW L  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.09.29, Block: 4, Trial: 35\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  DH EH R  |  N UW  |  HH AW S  |  K AA S T  |  JH AH S T  |  AE Z  |  M AH CH  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.09.29, Block: 4, Trial: 36\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  DH AE T  |  M AA R T  |  IH T S  |  HH AY ER AH N D  |  L EH V ER  |  AA N  |  R EH K ER D  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.09.29, Block: 4, Trial: 37\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  P L IY Z  |  S IY  |  AW ER  |  P R AY V AH S IY  |  N OW T ER Z  |  F AO R  |  D IY T ER L Z  |  AH V  |  Y AO R  |  D EY T AH  |  P R AH T EH SH AH N  |  R AY T S  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.09.29, Block: 4, Trial: 38\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AE T  |  DH AH  |  EH N D  |  DH AH  |  W ER K ER Z  |  T ER N D  |  ER AW N D  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.09.29, Block: 4, Trial: 39\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  S T IH L  |  OW N L IY  |  L AA T S  |  AH V  |  CH IY D ER Z  |  AH N D  |  S AH M  |  IH V ER S AH T IY  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.09.29, Block: 4, Trial: 40\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  JH AH S T  |  K AH N V ER N  |  DH IH S  |  W IH DH  |  Y AO R  |  F IH N D ER  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.09.29, Block: 4, Trial: 41\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  S T IH L  |  M AY L Z  |  Y UW Z  |  W AO T ER  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.09.29, Block: 4, Trial: 42\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  B EH T ER  |  T AH G EH DH ER  |  HH AE V  |  S IH R IY AH N S  |  K W EH S CH AH N Z  |  T UW  |  EH K S ER  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.09.29, Block: 4, Trial: 43\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  S EH D  |  AH  |  R IY P AO R T  |  DH AE T  |  DH IH S  |  B UH G  |  L AO NG  |  K AH N T EH N D Z  |  S P AE M  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.09.29, Block: 4, Trial: 44\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  DH IH S  |  IH Z  |  AH  |  V EH R IY  |  IH M P AO R T AH N T  |  G EY S  |  F R AH M  |  AW ER  |  P OY N T  |  AH V  |  V Y UW  |  HH IY  |  AE D AH D  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.09.29, Block: 4, Trial: 45\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  W IY  |  B AA T  |  Y UW  |  B UH S  |  AH N D  |  T OY Z S  |  T UW  |  F IY D  |  Y AO R  |  AE P AH T AY N T  |  F AO R  |  S P EY S  |  IH K S T L ER EY SH AH N  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.09.29, Block: 4, Trial: 46\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AY  |  K AE N T  |  P UH T  |  IH T  |  D AW N  |  AH N D  |  AY  |  K UH D  |  L AH K  |  AE T  |  IH T  |  F AO R  |  D EY Z  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.09.29, Block: 4, Trial: 47\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  DH AH  |  OW N L IY  |  TH IH NG  |  L EH F  |  T UW  |  D UW  |  IH Z  |  T UW  |  HH AE D  |  OW V ER  |  DH AH  |  K AH N T R UW L Z  |  T UW  |  EH Z UW OW  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.09.29, Block: 4, Trial: 48\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AH N D  |  HH IY  |  W OW N T  |  T EY K  |  IH T  |  F R EH R L IY  |  AH IH L EH K S  |  Y UW  |  G EY V  |  IH T  |  T UW  |  HH IH M  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.09.29, Block: 4, Trial: 49\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AH N D  |  Y UW  |  S IY  |  W AH T  |  HH AE P AH N D  |  R IY S AH N T L IY  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.10.01, Block: 7, Trial: 25\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  W IY V  |  G AA T  |  S AH M  |  G AY Z  |  HH IY R  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.10.01, Block: 7, Trial: 26\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  HH IY  |  G EH S  |  HH OW M  |  F R AH M  |  W ER K  |  L EY T  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.10.01, Block: 7, Trial: 27\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  M AY  |  T AE K S AH Z  |  HH AE V  |  G AO N  |  AH P  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.10.01, Block: 7, Trial: 28\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  IH T S  |  W AH N S  |  IH M P AO R T AH N T  |  T UW  |  Y UW  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.10.01, Block: 7, Trial: 29\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  W IY  |  EH N JH OY  |  D UW IH NG  |  IH T  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.10.01, Block: 7, Trial: 30\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  D IH D  |  P ER S EH N T  |  AO R  |  TH ER T IY N  |  P ER S EH N T  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.10.01, Block: 7, Trial: 31\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  DH AH  |  D IH T R OY T  |  N UW Z  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.10.01, Block: 7, Trial: 32\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  HH AE Z  |  W EH L  |  AE Z  |  Y UW  |  D UW  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.10.01, Block: 7, Trial: 33\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  HH UW  |  D IH D  |  Y UW  |  V OW T  |  F AO R  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.10.01, Block: 7, Trial: 34\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AY  |  R IH L IY  |  L AH V  |  IH T  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.10.01, Block: 7, Trial: 35\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  DH EY  |  HH AE V  |  DH IH S  |  W ER L D  |  F UH T B AO L  |  L IH NG K  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.10.01, Block: 7, Trial: 36\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AH  |  V OY S  |  F R AH M  |  DH AH  |  G R AW D  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.10.01, Block: 7, Trial: 37\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  DH AH  |  W AH N Z  |  DH AE T  |  K IH R D  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.10.01, Block: 7, Trial: 38\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AY  |  L AY K  |  DH AH  |  W EY  |  DH AE T  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.10.01, Block: 7, Trial: 39\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  V IH ZH AH N  |  IH Z  |  W AH N  |  AH V  |  DH AH  |  F AH N D EY N AH N AH L  |  P L EY G Z  |  F AO R  |  EH N IY  |  AE N T R AH B AH T UW IY  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.10.01, Block: 7, Trial: 40\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  DH AE T  |  W AA Z AH N T  |  AH  |  S T EH N D ER D  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.10.01, Block: 7, Trial: 41\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  DH AH  |  P L EY N D Z  |  AH N D  |  AO L  |  DH AE T  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.10.01, Block: 7, Trial: 42\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  W IY  |  M UW V D  |  T UW  |  HH AY W EY  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.10.01, Block: 7, Trial: 43\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  N OW  |  D IH S IH ZH AH N Z  |  HH AE V  |  B IH N  |  M EY D  |  AE T  |  DH IH S  |  T AY M  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.10.01, Block: 7, Trial: 44\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  B IH K AO Z  |  Y UH R  |  R AY T  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.10.01, Block: 7, Trial: 45\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  N AA T  |  D AH N  |  EH N IY TH IH NG  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.10.01, Block: 7, Trial: 46\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  W AH T  |  D UW  |  DH EY  |  K AO L  |  IH T  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.10.01, Block: 7, Trial: 47\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  L AY V T  |  AA N  |  AH  |  F AA R M  |  F AO R  |  S IH S T IH NG  |  Y IH R Z  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.10.01, Block: 7, Trial: 48\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AH DH ER  |  S AY N D  |  AH V  |  DH AH  |  K OY N  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.10.01, Block: 7, Trial: 49\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  B AH T  |  AY  |  TH IH NG K  |  IH T S  |  S AE L AH D  |  AH N D  |  DH IH S  |  P OY N T  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.10.01, Block: 8, Trial: 20\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  P L AA Z  |  HH IY  |  Y UW Z D  |  T UW  |  L IH L EH V ER  |  P IY IH Z AH N Z  |  B IH F AO R  |  DH AH  |  AH B AE K L AH L IY V Z  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.10.01, Block: 8, Trial: 21\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  D UW  |  N AA T  |  K AE M P IY  |  R ER D Z  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.10.01, Block: 8, Trial: 22\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AH N D  |  DH EH R  |  AA R  |  AH DH ER  |  V IH CH ER Z  |  IH N  |  DH AH  |  P R AA B IH K S  |  T UW  |  N OW T  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.10.01, Block: 8, Trial: 23\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  L AH V IH K ER Z  |  IH N  |  B OW TH  |  M AA R T IY Z  |  HH AE V  |  K AO L D  |  F AO R  |  S EY B AH L AY Z IH NG  |  DH AH  |  R AY D AH M P L EY S AH Z  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.10.01, Block: 8, Trial: 24\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  SH IY  |  K L AE N Z  |  AY L AH V IY  |  N EH V ER  |  SH UH D  |  S AY N Z  |  AH V  |  DH AH  |  EH N V EH K SH AH N  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.10.01, Block: 8, Trial: 25\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  HH IY R  |  IH Z  |  DH AH  |  V EH D IY OW  |  AH V  |  DH AH  |  CH AY L IY  |  R OW Z  |  S AH M B IH D  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.10.01, Block: 8, Trial: 26\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  DH IH S  |  IH Z  |  S OW  |  B Y UW T AH F AH L  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.10.01, Block: 8, Trial: 27\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  G OW D AH L Z  |  W IH SH AH N  |  T UW  |  P IY D  |  AH P  |  DH AH  |  W EY M P  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.10.01, Block: 8, Trial: 28\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  HH IY  |  S EH D  |  B IH L IY S  |  R IY S P AA N D IH D  |  S W EH M L IY  |  T UW  |  DH AE T  |  IH N SH AH D AH D  |  F AO R  |  DH AH  |  D R AY V ER Z  |  S EH M P T IY NG  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.10.01, Block: 8, Trial: 29\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  W IH TH EH N  |  M ER D ER Z T  |  DH EY  |  S EY  |  DH AH  |  F AY ER D  |  W AA Z  |  AH N D ER  |  K AH N T R OW L  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.10.01, Block: 8, Trial: 30\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  HH IY  |  L UH K T  |  AH P  |  T UW  |  F AY N D  |  DH AH  |  TH R AO NG  |  F L IY IH NG  |  IH N T UW  |  DH AH  |  V EH R AH N S  |  AH V  |  B OW TH  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.10.01, Block: 8, Trial: 31\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  DH AH  |  T UW  |  AH V  |  DH EH M  |  IH T EH M D  |  T UW  |  M EY K  |  AH  |  B R IH NG  |  F AO R  |  IH N  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.10.01, Block: 8, Trial: 32\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  W IY  |  B R AO T  |  G R EY T  |  N UW Z  |  F AO R  |  Y UW  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.10.01, Block: 8, Trial: 33\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AE N  |  AE K T AH M AH T  |  AH N D  |  T EH N D ER  |  D R ER V ER  |  AH B AW T  |  K EH R IH NG  |  AA N  |  AH G EY S  |  L AY K S  |  HH AH NG P G R AH Z  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.10.01, Block: 8, Trial: 34\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  S OW IH NG  |  IY S T  |  K AE N Z IH S  |  AH N AH DH ER  |  S P EH SH AH L  |  V AE L AH JH S  |  IH N  |  DH AH  |  T AW N  |  AH V  |  S AH N D AH L AY N  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.10.01, Block: 8, Trial: 35\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AY  |  M UW V D  |  T UW  |  L AO N D IH D  |  IH N  |  S ER CH  |  AH V  |  B AA S IH L  |  B AH T  |  F R EH N D Z  |  W ER  |  HH AA R D  |  T UW  |  K AH M  |  M AY  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.10.01, Block: 8, Trial: 36\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  SH OW L IY  |  DH AH  |  S AW N D  |  AH V  |  S AE L IH Z  |  W AA Z  |  DH AH  |  OW N L IY  |  AH P R OW B AH T  |  W AH N  |  HH IY R  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.10.01, Block: 8, Trial: 37\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  S OW  |  DH AH  |  W ER R L D  |  K AE N  |  S AE L AH B R EY N  |  D IH S EH DH ER  |  HH IY R  |  HH IY  |  AE D IH D  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.10.01, Block: 8, Trial: 38\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AH  |  G R IH N CH ER  |  IH N  |  DH AH  |  HH AY S  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.10.01, Block: 8, Trial: 39\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AO L  |  DH AH  |  L AY V  |  AH N D  |  DH AH  |  P R IH R Z  |  G AO N D  |  W IH L IH NG  |  HH IY L  |  B IY  |  F AY N  |  S UW N  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.10.06, Block: 6, Trial: 15\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  IH T  |  M IY  |  B IY  |  IH N  |  DH AH  |  F Y IH SH ER  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.10.06, Block: 6, Trial: 16\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  ER N IH NG  |  IH Z  |  M AH N IY  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.10.06, Block: 6, Trial: 17\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AH N D  |  DH EH R  |  AA R D ER  |  T UW  |  G EH T  |  R EH D  |  AH V  |  F AO R  |  DH AH  |  W IY K EH N D  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.10.06, Block: 6, Trial: 18\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AY  |  TH IH NG K  |  IH T S  |  JH AH S T  |  AH  |  K R AY IH NG  |  S EY M  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.10.06, Block: 6, Trial: 19\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  S EH L  |  P R AA D AH K T S  |  AH B OY R D  |  AE Z  |  M AH CH  |  AE Z  |  W IY  |  B R IH NG  |  IH N  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.10.06, Block: 6, Trial: 20\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  DH IH S  |  Y IH R  |  AH N D  |  L AE S T  |  Y IH R  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.10.06, Block: 6, Trial: 21\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AY  |  D OW N T  |  HH OW N  |  M AY  |  HH OW M  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.10.06, Block: 6, Trial: 22\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  DH EH R L  |  D UW  |  F AY N D  |  IH N  |  DH EH R  |  S T AH D IY Z  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.10.06, Block: 6, Trial: 23\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  DH AE T S  |  DH AH  |  B EH S T  |  W EY  |  T UW  |  D UW  |  IH T  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.10.06, Block: 6, Trial: 24\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  IH T  |  W AA Z  |  HH AA R D  |  T UW  |  EH K S EH P T  |  DH AE T  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.10.06, Block: 6, Trial: 25\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  M AY  |  F AA DH ER  |  D IY Z AH Z  |  M IY  |  AH B AW T  |  K AO R M IH NG  |  K AA R K IH NG  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.10.06, Block: 6, Trial: 26\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  Y UW  |  N OW  |  IH T S  |  S OW  |  IH K S AE T IH NG  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.10.06, Block: 6, Trial: 27\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  IH T  |  W AA Z  |  P R IH T IY  |  S EH V AH L ER  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.10.06, Block: 6, Trial: 28\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  IH T  |  W AA Z  |  W EH N  |  AY  |  W AA Z  |  AH  |  CH AY L D  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.10.06, Block: 6, Trial: 29\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AY  |  HH AE V AH N T  |  HH AE D  |  AH  |  CH EY N JH S  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.10.06, Block: 7, Trial: 21\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  HH AE V  |  Y UW  |  S IY N  |  G OW Z  |  Y EH T  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.10.06, Block: 7, Trial: 22\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  HH IY  |  M EY D  |  M IY  |  L AE F  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.10.06, Block: 7, Trial: 23\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  W EH R  |  W IY  |  W EH N T  |  F R AH M  |  DH EH R  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.10.06, Block: 7, Trial: 24\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  DH AH  |  M IH T ER EY T  |  CH OY S  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.10.06, Block: 7, Trial: 25\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  SH IY  |  W AA Z  |  IH N AE L Y ER AH T IH D  |  IH N  |  CH AE N ER AH IY  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.10.06, Block: 7, Trial: 26\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  W EH L  |  W IY R  |  R IH L IY  |  OW F ER B OW T AH N T  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.10.06, Block: 7, Trial: 27\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AY  |  B IH L IY V  |  IH T  |  IH Z  |  T UW  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.10.06, Block: 7, Trial: 28\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  G EY V  |  Y UW  |  AH  |  R AH N  |  F AO R  |  Y AO R  |  M AH N IY  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.10.06, Block: 7, Trial: 29\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AY  |  D OW T IH S T  |  DH AE T  |  IH Z  |  V OY S  |  T R IH B L AH L D  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.10.06, Block: 7, Trial: 30\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  S OW  |  AY  |  K AE N  |  G OW  |  AW T  |  AH N D  |  G OW  |  T UW  |  DH AH  |  B AA R  |  DH IH S  |  L EY T  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.10.06, Block: 7, Trial: 31\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  M AY  |  R UW M AH N T  |  S AY N D  |  M IY  |  AH P  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.10.06, Block: 7, Trial: 32\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AY  |  W AA Z  |  L AE N D  |  T UW  |  G EH T  |  R EH D  |  AH V  |  L IH T IH D  |  K AE S AH L AH N  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.10.06, Block: 7, Trial: 33\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  DH EY  |  W ER  |  SH OW IH NG  |  S AH M  |  AH N D  |  AY  |  W AA Z  |  W AA CH IH NG  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.10.06, Block: 7, Trial: 34\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  HH AW  |  W IH L  |  Y UW  |  M EH ZH ER  |  Y AO R  |  L AY F  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.10.06, Block: 7, Trial: 35\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AY  |  L AY K  |  AO R K AH N JH  |  M Y UW Z IH K  |  T UW  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.10.06, Block: 7, Trial: 36\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  DH EH R  |  G AA T IH NG  |  S AH M  |  AH V  |  DH AE T  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.10.06, Block: 7, Trial: 37\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AY  |  D OW N T  |  N OW  |  IH F  |  Y UH R  |  L AY K  |  M IY  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.10.06, Block: 7, Trial: 38\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  W IY  |  R IH Z AH L F  |  DH AH  |  R AY T  |  T UW  |  M EY K  |  DH AH  |  F AY N AH L  |  D IH S IH ZH AH N  |  AA N  |  AO L  |  N EY M  |  CH IH N S T AH Z  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.10.06, Block: 7, Trial: 39\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  EH V ER IY  |  T AY M  |  S AH M TH IH NG  |  N UW  |  K EY M  |  AH P  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.10.06, Block: 7, Trial: 40\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AH N D  |  HH IY  |  D AH Z T  |  IH T  |  AO L  |  W IH DH  |  AH  |  S M AY L  |  AH N D  |  AH  |  K W AY AH T  |  T JH OY  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.10.06, Block: 7, Trial: 41\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  IH T  |  IH Z  |  AH  |  Y UW Z JH D  |  P L EY S  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.10.06, Block: 7, Trial: 42\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  IH T  |  L EH T S  |  AH  |  L AO NG  |  T AY M  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.10.08, Block: 11, Trial: 10\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  HH IY  |  JH AH S T  |  HH AE Z  |  T UW  |  B IY  |  K AA N F AH D AH  |  IH N  |  IH K S EH L F  |  AH N D  |  AY  |  TH IH NG K  |  AH  |  IH Z  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.10.08, Block: 11, Trial: 11\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  F AO R  |  DH IY Z  |  R IY Z AH N Z  |  AH  |  F AE K T  |  IH Z  |  DH AH  |  B EH S T  |  K AH N F Y IH N Y UW EY SH AH N  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.10.08, Block: 11, Trial: 12\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  HH AE V  |  DH EY  |  R IH T ER T  |  IH T  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.10.08, Block: 11, Trial: 13\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  W AH T  |  D IH D  |  DH AH  |  S AH P R IY M  |  K AO R T  |  D IH S AY D  |  AH B AW T  |  W EY T AH N  |  K AA L IH JH  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.10.08, Block: 11, Trial: 14\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  Y UW  |  G EH T  |  T UW  |  L ER N  |  AH N D  |  R EY Z  |  Y AO R  |  K IH D Z  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.10.08, Block: 11, Trial: 15\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  DH EY  |  HH AE V  |  N OW  |  ER IH JH AH N AH L  |  AY D IY AH Z  |  K Y UH R IY EY S AH T  |  T AH T IY  |  AO R  |  AE S ER EY SH IH N Z  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.10.08, Block: 11, Trial: 16\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  S OW  |  B EY S IH K L IY  |  HH IY  |  JH AH S T  |  M IY D  |  F UW L Z  |  AH V  |  Y UW  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.10.08, Block: 11, Trial: 17\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AH  |  TH AW Z AH N D  |  M AY L Z  |  AH W EY  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.10.08, Block: 11, Trial: 18\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  IH N  |  DH IH S  |  F AO R M  |  SH IY  |  W AA Z  |  L IH T ER  |  S EH T  |  AW T  |  T UW  |  AH V EH N CH T  |  HH ER  |  F AA DH ER  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.10.08, Block: 11, Trial: 19\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  DH IH S  |  W UH D  |  IH N K L UW D N  |  K W IH P S  |  S AH S T  |  AE Z  |  P AA T AH N IH T IY  |  S UW T S  |  F AO R  |  IH N S T EH N S  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.10.08, Block: 12, Trial: 7\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  F AE K T ER Z  |  AA R T AH S IY  |  AH V  |  AE K S IH Z  |  F AA R M  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.10.08, Block: 12, Trial: 8\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  DH AH  |  M AE N D  |  W AA Z  |  AH T AE K T  |  AH N D  |  S T AE P  |  M AA L T AH B AH L  |  T AY M Z  |  DH AH  |  F AE M AH L IY  |  M EY M B ER  |  IH L EH K T D  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.10.08, Block: 12, Trial: 9\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  W AH D  |  B IY  |  AH  |  SH EY M  |  IH F  |  DH AE T  |  CH EY N JH D  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.10.08, Block: 12, Trial: 10\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AH D M AE T AH S T R EY SH AH N  |  AH V  |  JH AH S T AH S  |  B IH K AO M Z  |  AH  |  S T EY T  |  F AA K SH AH N  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.10.08, Block: 12, Trial: 11\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  DH AH  |  AY D IY AH  |  IH Z  |  F AY N  |  IH N  |  P R IH S AH B AH L  |  B AH T  |  DH AH  |  D IH S AY D  |  IH Z  |  AO L  |  R AO NG  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.10.08, Block: 12, Trial: 12\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  IH F  |  Y UW  |  F AY N D  |  DH IH S  |  AA R T AH K AH L  |  Y UW Z F AH L  |  DH AE T  |  P L EY Z  |  SH EH R  |  IH T  |  W IH DH  |  AH DH ER Z  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.10.08, Block: 12, Trial: 13\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  B AH T  |  B IH HH AY N D  |  DH AH  |  S IY N D Z  |  DH AH  |  W AY T  |  HH AW S  |  T UH K  |  AH  |  L EH S  |  F R EH N D L IY  |  AH P R OW CH T  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.10.08, Block: 12, Trial: 14\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  W AA Z  |  DH EH R  |  EH N IY TH IH NG  |  P AH S IH F ER  |  Y UW  |  S EH D  |  T UW  |  DH EH M  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.10.13, Block: 5, Trial: 25\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  IH T  |  HH AE D  |  AO L  |  DH AH  |  F AE JH T AH B AH L Z  |  IH N  |  IH T  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.10.13, Block: 5, Trial: 26\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  HH IY  |  HH AE D  |  CH OY S AH Z  |  T UW  |  M EY K  |  DH AH  |  K AE L S L ER  |  T OW L D  |  HH IH M  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.10.13, Block: 5, Trial: 27\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  G EH T IH NG  |  P L EY JH  |  CH IY N S Z  |  F AO R  |  DH AH  |  B OY  |  S K IH R T S  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.10.13, Block: 5, Trial: 28\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AY V  |  D AW N D  |  DH AH  |  P R AA B L AH M  |  D AW N  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.10.13, Block: 5, Trial: 29\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  F R AH M  |  EY T S  |  T UW  |  S IH N S T IH N Z  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.10.13, Block: 5, Trial: 30\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  N AW  |  DH AE T  |  DH AH  |  G R EY N T IY N Z  |  AA R  |  HH IY R  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.10.13, Block: 5, Trial: 31\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  D UW  |  Y UW  |  W AA CH  |  S T AA R  |  T R AH K  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.10.13, Block: 5, Trial: 32\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  W IY  |  S EH T  |  ER AW N D  |  AH N D  |  IY T  |  P AA P F AH N  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.10.13, Block: 5, Trial: 33\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AW T  |  AH V  |  AO F EY S  |  EH V ER IY  |  D EY  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.10.13, Block: 5, Trial: 34\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  S OW  |  DH AE T  |  L IY V Z  |  M IY  |  W IH DH  |  AH  |  CH OY S  |  T UW  |  M EY K  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.10.13, Block: 5, Trial: 35\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  Y UW  |  N OW  |  DH AE  |  B IH N  |  AE F V ER T AA N IH NG  |  DH AE T  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.10.13, Block: 5, Trial: 36\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  W UH D  |  Y UW  |  K AH N S IH D ER  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.10.13, Block: 5, Trial: 37\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  DH EY  |  D UW  |  EH V R IY TH IH NG  |  W EH L  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.10.13, Block: 5, Trial: 38\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  DH EY  |  HH AE V  |  AH  |  L IH T AH L  |  K AH N IH K Y AH L AH V  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.10.13, Block: 5, Trial: 39\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  DH AE T  |  W AA Z  |  IH M P R EH SH AH N  |  AY  |  G AA T  |  W EH N  |  AY  |  W AA Z  |  DH EH R  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.10.13, Block: 5, Trial: 40\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AA S T AH D  |  IH Z  |  S OW  |  P R IH T IY  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.10.13, Block: 5, Trial: 41\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AY  |  D UW  |  S AH M  |  EH V ER IY  |  N AW  |  AE T  |  DH EH N  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.10.13, Block: 5, Trial: 42\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  DH AE T S  |  W AH T  |  AY  |  N IY D AH D  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.10.13, Block: 5, Trial: 43\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  IH Z  |  D UW IH NG  |  S AH M  |  AH DH ER  |  M UW V IY  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.10.13, Block: 5, Trial: 44\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AY  |  R IH L IY  |  D OW N T  |  W AA N T  |  T UW  |  S T EY  |  IH N  |  N UW Z  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.10.13, Block: 5, Trial: 45\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  W IY R  |  P AH T IH NG  |  AH P  |  W IH DH  |  AO L  |  HH ER  |  AE K S AH D AH Z S  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.10.13, Block: 5, Trial: 46\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AY M  |  F AE R AH L IY  |  N UW  |  T UW  |  IH T  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.10.13, Block: 5, Trial: 47\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AY  |  N OW  |  DH EH R Z  |  N AA T  |  EH N IY  |  F UW D  |  DH AE T  |  Y UW  |  K AE N  |  G EH T  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.10.13, Block: 5, Trial: 48\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  Y UW  |  HH AE V  |  Y AO R  |  K ER EH R  |  AH N D  |  Y AO R  |  HH OW M  |  L AY F  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.10.13, Block: 5, Trial: 49\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AO R AH B AH L  |  S T AH F  |  L AY K  |  DH AE T  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.10.13, Block: 6, Trial: 20\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  B IY S IY  |  IH N V EY D AH D  |  K AW L S AH L  |  S T AO L Z  |  F AH N T AE S IH K L IY  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.10.13, Block: 6, Trial: 21\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  S IH S T  |  B EH N  |  AH V EH K T  |  K AA M OW S T  |  IH N T ER IH SH AH N Z  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.10.13, Block: 6, Trial: 22\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  D AH M AH N UW Z  |  D IH S AO T AH N IH NG  |  S T AA R  |  W EH R  |  D EH R Z  |  T R EH ZH ER IY Z  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.10.13, Block: 6, Trial: 23\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  IH T AE L AH JH IH N Z  |  K R AA M P EH R AH N T S  |  V IH ZH AH N Z  |  P R EH D AH D  |  S T IH K  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.10.13, Block: 6, Trial: 24\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  M AE S AH K AH T  |  B IH AE N  |  K IY T IH NG  |  W EY T  |  AE T  |  SH AY N AH  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.10.13, Block: 6, Trial: 25\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  K AH V EY N D  |  L DH AE S  |  AO L F W EY  |  AA B V IY AH L IY  |  M IH N AH T ER  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.10.13, Block: 6, Trial: 26\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  T  |  AH P OW M IY  |  P EY P ER  |  V AY S  |  S OW AY AH T IY  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.10.13, Block: 6, Trial: 27\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  DH TH OW L IY  |  AH P AO R IH T IH NG  |  N AA T  |  K R EH S T AH N  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.10.13, Block: 6, Trial: 28\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  M EY K  |  D IH S IY Z  |  W AH N EH V ER  |  T EH M P AH L Z  |  K AE R AH T UW Z  |  L AE T AH T IH L IY  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.10.13, Block: 6, Trial: 29\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  T AO K AO Z  |  R IY HH AH B IH L AH  |  T IH S AH N  |  L AO S  |  D IY L  |  D ER EH K T ER IY  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.10.13, Block: 6, Trial: 30\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  IH L EH K SH ER  |  F IH SH ER  |  M AH DH ER Z  |  B R IH R  |  AW AH Z  |  D AH N AH K AE F AH Z  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.10.13, Block: 6, Trial: 31\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AH K IH ZH AH N AH L IY  |  F L OY N D IH NG  |  S AY N IH NG  |  W IY N Z  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.10.13, Block: 6, Trial: 32\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  EH N AH AA Z  |  AO V ER  |  AW N D R AH D  |  OW V ER G R EY Z D  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.10.13, Block: 6, Trial: 33\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AH D T EH L AH JH IH S T  |  S AE M AH L ER  |  F IY  |  P ER S EH S  |  AE T  |  S T IH L  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.10.13, Block: 6, Trial: 34\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  IH N AH F  |  K AO R S  |  S UW T  |  AH L AW N D  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.10.13, Block: 6, Trial: 35\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  B AE N D AH L  |  D IH S EH K SH ER AH S  |  D AH L UW ZH AH N  |  B R IH NG K  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.10.13, Block: 6, Trial: 36\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  B IH G IH N IH NG  |  IH K S T R EH S  |  L AE S AH B AH L  |  P R AA S EH S K T L IY  |  SH UW Z  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.10.13, Block: 6, Trial: 37\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  IH M AH T R EY SH AH N  |  L AO NG CH IH NG  |  K AH M P AO N  |  AH B Y UW S  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.10.13, Block: 6, Trial: 38\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  K Y UW Z D  |  IH K S EH L F  |  CH AE IH L IY  |  K AH N S ER M IH NG  |  AH T AE K IH NG  |  S AO R T  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.10.13, Block: 6, Trial: 39\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  L AA T  |  IH N AH S AH D  |  AW L D  |  K AH M P AH N EY SH AH N  |  IH M P EH R AH N S T  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.10.15, Block: 9, Trial: 24\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  DH EY  |  AA R  |  L AH V L IY  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.10.15, Block: 9, Trial: 25\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  HH IY R Z  |  W AH T  |  Y UW  |  HH AE V  |  G AA T  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.10.15, Block: 9, Trial: 26\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  W AH N  |  DH AE T  |  AY  |  Y UW Z  |  JH AH S T  |  F AO R  |  IH M ER JH AH N S T IY Z  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.10.15, Block: 9, Trial: 27\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  DH EH R  |  IH N  |  T UW N  |  W IH DH  |  DH AE T  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.10.15, Block: 9, Trial: 28\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  D UW  |  Y UW  |  R IH L IY  |  N AA T  |  R IH M EH M B ER  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.10.15, Block: 9, Trial: 29\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  W IY  |  D OW N T  |  AE F T AH L  |  DH EH M  |  V EH R IY  |  W EH L  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.10.15, Block: 9, Trial: 30\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  DH AE T S  |  AH N AH DH ER  |  TH IH NG  |  AY  |  D OW N T  |  AH N T ER S T AE D  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.10.15, Block: 9, Trial: 31\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AY  |  B IH F AO R  |  AH  |  S W IH M IH NG  |  P UW L  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.10.15, Block: 9, Trial: 32\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AO L  |  R AY T  |  AY M  |  R EH D IY  |  T UW  |  G OW  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.10.15, Block: 9, Trial: 33\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AY  |  K AE N  |  R IH L EY T  |  T UW  |  DH AE T  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.10.15, Block: 9, Trial: 34\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  Y UW  |  G OW  |  T UW  |  W ER K  |  EH V ER IY  |  W IY K EH N D  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.10.15, Block: 9, Trial: 35\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AY M  |  N AA T  |  F AO R  |  K AH N T R OY L IH NG  |  HH AW  |  M AH CH  |  IH Z  |  P EH T  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.10.15, Block: 9, Trial: 36\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  DH AH  |  Y UW N EY T IH D  |  S T EY T S  |  AE N  |  K AE N AH D AH  |  AA R  |  S OW  |  D IH F ER AH N T  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.10.15, Block: 9, Trial: 37\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  W EH L  |  T UW  |  Y UW  |  N OW  |  S AH M TH IH NG  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.10.15, Block: 9, Trial: 38\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  N AA T  |  EH V ER IY  |  G EY M  |  S EH T S  |  AW T  |  T UW  |  M EY K  |  AH  |  P OY N T  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.10.15, Block: 9, Trial: 39\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  N AY S  |  IH Z AH N T  |  DH AH  |  W ER D  |  AY D  |  CH UW Z  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.10.15, Block: 9, Trial: 40\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  TH R IY  |  AO R  |  F AO R  |  N EY Z  |  AH N D  |  DH AE T  |  W UH D  |  B IY  |  IH T  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.10.15, Block: 9, Trial: 41\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  IH T S  |  AH  |  B EY S AH L  |  AH K EY ZH AH N  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.10.15, Block: 9, Trial: 42\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  W AH T  |  L EH V AH L  |  AH V  |  K EH R  |  T UW  |  Y UW  |  N IY D  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.10.15, Block: 9, Trial: 44\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AY M  |  Y AO R  |  K AH S T ER AH M B ER  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.10.15, Block: 9, Trial: 45\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  D IH D  |  DH EY  |  HH AE V  |  S AH M  |  P R IH T IY  |  G UH D  |  S P EH S SH AH L  |  IH F EH K T  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.10.15, Block: 9, Trial: 46\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  SH IY  |  G EH T S  |  R AY T  |  IH N T UW  |  IH T  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.10.15, Block: 9, Trial: 47\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  B AH T  |  W IY  |  HH AE V AH N T  |  S IY N  |  DH AE T  |  W AH N  |  IY DH ER  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.10.15, Block: 9, Trial: 48\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AE F T ER  |  W IY  |  HH AE D  |  DH EH M  |  F AO R  |  S EH V ER AH L  |  Y IH R Z  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.10.15, Block: 9, Trial: 49\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AY  |  HH AE V  |  AH  |  D AO G  |  DH AE T  |  G AY D  |  G IH V  |  AH S  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.10.15, Block: 10, Trial: 20\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  T R EY N  |  Y AO R  |  D AO G  |  F AO R  |  K AH N F AH N IY Z S  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.10.15, Block: 10, Trial: 21\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  F AY N D  |  DH AH  |  M IH S IH NG  |  K L UW  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.10.15, Block: 10, Trial: 22\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AE Z  |  IH Z  |  N AW  |  W EH L  |  N OW N  |  K AE T AH T IY  |  HH AE D  |  N UW V ER AH S  |  EH K JH AH L AH T AH L  |  AH V OY R D Z  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.10.15, Block: 10, Trial: 23\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  R AH K AO R D IH D  |  AH N D  |  IH T AH T AH D  |  B AY  |  B IH N  |  W OY AH N Z  |  F AO R  |  P L EY S IH V  |  P R AH D AH K SH AH N S  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.10.15, Block: 10, Trial: 24\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  HH AY ER  |  Y AO R  |  F R EH K S AY Z  |  S T AA F  |  IH N  |  IH N V EH N S T  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.10.15, Block: 10, Trial: 25\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  S OW  |  AY  |  W AA Z  |  S AH P AO Z D  |  W EH N  |  AY  |  G AA T  |  DH IH S  |  M EH SH AH N  |  AW T  |  AH V  |  DH AH  |  B L UW  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.10.15, Block: 10, Trial: 26\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AA N  |  IH K AH M UW M IH NG  |  HH IH SH AH Z  |  P IH T ER  |  SH IH F  |  IH Z  |  B AA T  |  AA N  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.10.15, Block: 10, Trial: 27\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  IH F  |  Y UW  |  AA R  |  N AA T  |  AH W EY  |  AH V  |  IH T  |  DH AE T  |  HH IY R  |  IH Z  |  AH  |  R IH V IY  |  IH N  |  SH AO R T  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.10.15, Block: 10, Trial: 28\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  R EH D IY  |  T UW  |  IH T  |  B AE K  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.10.15, Block: 10, Trial: 29\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  D IH S P AY R T  |  DH AE T  |  S K W AO R  |  S AE Z  |  IH T  |  W AA Z  |  AA N D IY M B AH L  |  T UW  |  AH D AH T AH F AY  |  AO R  |  K AA N T IH K T  |  DH AH  |  F AE M AH L IY  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.10.15, Block: 10, Trial: 30\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  SH EH R AH T IY  |  IH Z  |  N OW  |  L AO K IH NG  |  S OW  |  IY Z IY  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.10.15, Block: 10, Trial: 31\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  IH N  |  DH AH  |  S T AY Z  |  OW V ER  |  AH M EH R IH K AH  |  DH AH  |  S K W IH NG Z  |  IH Z  |  AA N  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.10.15, Block: 10, Trial: 32\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  Y UW  |  AA R  |  R EH D IH NG  |  OW N  |  DH AH  |  F AE K T  |  DH AE T  |  Y UW  |  AA R  |  R EH D IY  |  AH N D  |  G EH T  |  T UW  |  W ER K  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.10.15, Block: 10, Trial: 33\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AY  |  W IH Z AH N S  |  D IH S P R AE M Z  |  B AO L  |  AH V  |  P L EY T S  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.10.15, Block: 10, Trial: 34\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  HH IY  |  P AH B L IH K  |  HH IY R IH NG  |  IH Z  |  P L AE N D  |  F AO R  |  N AH M EH M B ER  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.10.15, Block: 10, Trial: 35\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  W IY  |  W AA N T  |  T UW  |  S AH P AO R T  |  AW ER  |  L OW K AH L  |  P R AH D IH S IH Z  |  S AH P AO R T  |  IY CH  |  AH DH ER  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.10.15, Block: 10, Trial: 36\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  DH AH  |  F R AH F EY T IH NG  |  IH N T ER IY  |  IH Z  |  IH S P EH K L IY  |  F R AE L AH V AH T  |  T AH D EY  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.10.15, Block: 10, Trial: 37\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  K AH N IY N IY AH Z  |  AA R  |  AO L R EH D IY  |  F AH M IH L Y ER  |  W IH DH  |  DH IH S  |  S IH S T AH M  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.10.15, Block: 10, Trial: 38\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AO R  |  B IH R ER  |  IH M B AH Z IY Z  |  AH V  |  DH AE T  |  G AY  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.10.15, Block: 10, Trial: 39\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AE N  |  AH P AH N D  |  AH  |  L AO  |  K AE N SH AH L IY  |  AO F AH S  |  AE T  |  HH OW M  |  AE F T ER  |  G R AE JH UW W EY T IH NG  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.10.20, Block: 3, Trial: 9\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AH  |  L AA R JH  |  S AY Z  |  IH N  |  S AA K IH NG N Z  |  IH Z  |  HH AA R D  |  T UW  |  S EH L  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.10.20, Block: 3, Trial: 11\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AH  |  R AY N D  |  IH Z  |  Y UW Z D  |  T UW  |  K AE CH  |  P IH K  |  S EH V AH N  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.10.20, Block: 3, Trial: 13\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  K IH K  |  DH AH  |  B AO L  |  S T R IY T  |  AH N D  |  F AA L OW  |  TH R UW  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.10.20, Block: 3, Trial: 14\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  HH EH L P  |  DH AH  |  W UH M AH N  |  G EH T  |  B AE K  |  T UW  |  HH ER  |  F IY T  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.10.20, Block: 3, Trial: 15\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AH  |  P AA T  |  AH V  |  T IY  |  EH L P S  |  T UW  |  P AE S  |  DH AH  |  IY V N IH NG  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.10.20, Block: 3, Trial: 16\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  M ER K IY  |  F AY R ER Z  |  L AY K  |  F L EY M  |  AH N D  |  IY T  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.10.20, Block: 3, Trial: 17\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  DH AH  |  S AH F  |  K AH SH AH N  |  B R OW K  |  DH AH  |  M EY N D Z  |  F AO L  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.10.20, Block: 3, Trial: 18\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  DH AH  |  S AO L T  |  B R IY NG Z  |  K EY M  |  AH K R AO S  |  F R AH M  |  DH AH  |  S IY  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.10.20, Block: 3, Trial: 19\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  DH AH  |  G ER L  |  AH N D  |  DH AH  |  B UH K TH  |  S OW L D  |  F IH F T IY  |  P OY N T Z  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.10.22, Block: 5, Trial: 11\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  T EY K  |  DH AH  |  W AH N D IH NG  |  B AE TH  |  T UW  |  W IH CH  |  DH AH  |  L AY K  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.10.22, Block: 5, Trial: 12\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  N OW T  |  K L OW S L IY  |  DH AH  |  S AY Z  |  AH V  |  DH AH  |  G EH S  |  T EY K  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.10.22, Block: 5, Trial: 13\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  W EH P  |  DH AH  |  R EY S  |  AH V  |  IH Z  |  D AO T IY  |  F IH S  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.10.22, Block: 5, Trial: 14\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  M EH D  |  DH AH  |  K UH D  |  B IH F AO R  |  Y UW  |  G OW  |  AW T  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.10.22, Block: 5, Trial: 15\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  DH AH  |  R EY S T  |  W AA Z  |  B IH B L IY  |  S T R EY D  |  AH N D  |  HH OW L  |  L IH P  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.10.22, Block: 5, Trial: 16\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  DH AH  |  T R IY  |  K AE T  |  G IH V  |  B OW TH  |  T UW  |  D IH T AH N Z  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.10.22, Block: 5, Trial: 17\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  DH AH  |  Y AH NG  |  G ER L  |  G IH V  |  N OW  |  K L IH R  |  R IH S P EH N S  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.10.22, Block: 5, Trial: 18\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  DH AH  |  M IY L  |  W AA Z  |  K UH K T  |  B IH F AO R  |  DH AH  |  B AY L  |  R AE NG  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.10.22, Block: 5, Trial: 26\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  DH AH  |  R UW P  |  W IH L  |  B AY N D  |  DH AH  |  S EH V AH N  |  B UH K S  |  AE T  |  W AH N S  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.10.22, Block: 5, Trial: 27\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  HH AE L P  |  OW V ER  |  DH AH  |  F IH K S  |  AH N D  |  P L AA CH  |  IH N  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.10.22, Block: 5, Trial: 28\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  DH AH  |  F R EH N AH L IY  |  G IH NG  |  L EH F  |  DH AH  |  D R AH G  |  S T AO R  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.10.22, Block: 5, Trial: 29\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  M EH S CH  |  W AY ER  |  K IH P S  |  T EH S  |  IH N S AY D  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.10.22, Block: 9, Trial: 22\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  DH EY  |  S AW N D  |  P AH L IH L Y ER  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.10.22, Block: 9, Trial: 23\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  IH N  |  DH IH S  |  W EY  |  EH V ER IY  |  D IH S IH ZH AH N  |  Y UW  |  M EY K  |  M AH CH  |  B IY  |  K AH N F AH L IY  |  K AH N S IH D AH N T  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.10.22, Block: 9, Trial: 24\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  D UW  |  DH OW Z  |  K AE N  |  K R OW S AH Z  |  W ER K  |  W EH L  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.10.22, Block: 9, Trial: 25\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AY  |  D OW N T  |  R IH L IY  |  K EH R  |  W AH T  |  IH T  |  T EY K S  |  T UW  |  W AA L AH F AY  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.10.22, Block: 9, Trial: 26\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  IH T S  |  DH AH  |  D EH S AH S  |  HH IY R  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.10.22, Block: 9, Trial: 27\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  IH F  |  IH T S  |  P IY P AH L  |  IH T  |  W IH L  |  P R AA B AH B L IY  |  SH R EH D  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.10.22, Block: 9, Trial: 28\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  W AH T S  |  DH AH  |  W ER D  |  AY M  |  L UH K IH NG  |  F AO R  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.10.22, Block: 9, Trial: 29\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  DH AE T S  |  AH B AW T  |  W EH R  |  AY  |  S T EH D  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.10.22, Block: 9, Trial: 30\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  IH T  |  JH AH S T  |  D IH D AH N T  |  F IY T  |  DH AH  |  K AA R  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.10.22, Block: 9, Trial: 31\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  W AH T  |  D UW  |  Y UW  |  TH IH NG K  |  K AE N  |  B IY  |  D AH N  |  AH B AW T  |  DH AE T  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.10.22, Block: 9, Trial: 32\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  W IY  |  Y UW ZH W AH L IY  |  AO R D ER  |  AW ER  |  T IH K AH Z  |  W EY  |  IH N  |  IH D V EH N T S  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.10.22, Block: 9, Trial: 33\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AY  |  L AH V  |  T UW  |  R AH N  |  IH N  |  DH AH  |  R EH N  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.10.22, Block: 9, Trial: 34\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  M AY  |  L IH V AH L  |  AH V  |  EH K M P ER T IH Z  |  IH Z  |  IH K R IY S IH NG  |  AO L M OW S T  |  D EY L IY  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.10.22, Block: 9, Trial: 35\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  Y UW  |  S AO  |  DH AH  |  B AE S AH N  |  AH V  |  DH AH  |  S EY V AH L  |  R AY T S  |  AE T  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.10.22, Block: 9, Trial: 36\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AY D  |  R AE DH ER  |  B IY  |  D UW IH NG  |  DH AE T  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.10.22, Block: 9, Trial: 37\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  G OW IH NG  |  B AE K  |  T UW  |  DH AH  |  B EY S AH Z  |  IH N  |  DH AH  |  ER L IY  |  G R EY T S  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.10.22, Block: 9, Trial: 38\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  W AH T EH V ER  |  P AH P  |  W IY  |  T R IH K  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.10.22, Block: 9, Trial: 39\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  R IY P AO R D T S  |  AA N  |  DH AH  |  AH K EY ZH AH N  |  AH V  |  DH AH  |  S IH K S  |  EH N IY AH V EH ZH SH AH IY  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.10.22, Block: 9, Trial: 40\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AY  |  HH AE V  |  T UW  |  TH IH NG K  |  AH B AW T  |  IH T  |  S AH M  |  M AO R  |  N AW  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.10.22, Block: 9, Trial: 41\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  B AY  |  AH  |  S OW IH NG  |  M AH S IY N  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.10.22, Block: 9, Trial: 42\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  Y UW  |  T EY K  |  AH W EY  |  AH  |  B ER S AH N Z  |  F R IY D AH M  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.10.22, Block: 9, Trial: 43\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  M AY  |  HH EH M P L OY IY AH  |  F IY L Z  |  DH AE T  |  HH IY  |  W AA N Z  |  T UW  |  K AH N T R OW L  |  AH S  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.10.22, Block: 9, Trial: 44\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AY  |  F AW N D  |  DH AE T  |  AO L  |  AY  |  T AO K T  |  AH B AW T  |  W AA Z  |  M AY  |  B EY B IY  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.11.03, Block: 5, Trial: 25\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AH  |  T EY M  |  S K UW L  |  M EY K S  |  AH  |  N AY S  |  B IH T  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.11.03, Block: 5, Trial: 26\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  DH AH  |  HH AA R D  |  AH V  |  DH AH  |  K AA R  |  W ER K  |  DH AH  |  L IY P IH NG  |  K AH M P  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.11.03, Block: 5, Trial: 27\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  DH AH  |  HH AA R T  |  B IY T  |  CH R AE R L IY  |  AH N D  |  W IH DH  |  F OW M  |  CH R AH S  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.11.03, Block: 5, Trial: 28\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  DH AH  |  B IY L  |  W AA Z  |  W AO R D  |  IH T  |  AH  |  DH EH N  |  S EH V ER  |  R IY K  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.11.03, Block: 5, Trial: 29\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  DH AH  |  R EH T  |  B IY L  |  W AA Z  |  G AA T  |  IH N  |  TH IH NG K  |  L AY S AH Z  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.11.03, Block: 5, Trial: 30\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  DH AH  |  N EY V IY  |  AH T AW EH N D  |  DH AH  |  B IH G  |  T AE S T  |  F AO S  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.11.03, Block: 5, Trial: 31\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  SH IY  |  DH AH  |  G EH T  |  L IH NG  |  AH N  |  DH AH  |  S K EH R D  |  M AH S  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.11.03, Block: 5, Trial: 32\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  DH EH R  |  AA R  |  M AO R  |  DH AE T  |  D UW  |  F IH F T ER D  |  HH IY R  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.11.03, Block: 5, Trial: 33\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  DH AH  |  HH AE T  |  P R IH M  |  W AA Z  |  W AY N D  |  AH N D  |  T UW  |  T R UW P IH NG  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.11.03, Block: 5, Trial: 34\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  DH AH  |  L AO NG ER  |  T CH AY D  |  T UW  |  L UW Z  |  IH Z  |  G EH S  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.11.03, Block: 5, Trial: 35\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  DH AH  |  D R EH S  |  K AA L D  |  AH AW N D  |  DH AH  |  F IH N S T  |  P OW S T  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.11.03, Block: 5, Trial: 36\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  K AH T  |  DH AH  |  P AY  |  IH N T UW  |  L AA R JH  |  P AA N T S  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.11.03, Block: 5, Trial: 37\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  M EH N  |  D R AY V  |  W AH T  |  S AH M AH M  |  G EH T  |  W IH CH  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.11.03, Block: 5, Trial: 38\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AO L W EY Z  |  L OW S  |  DH P AA R T  |  N AO R  |  T EY T  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.11.03, Block: 5, Trial: 39\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  HH IY  |  L EY  |  P R OW N  |  AH N D  |  OW N L IY  |  M UW V D  |  AH  |  L AY M  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.11.03, Block: 5, Trial: 40\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  DH AH  |  K L AH S  |  L AY K  |  G IY P  |  AH L AO NG  |  DH AH  |  T R IY T  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.11.03, Block: 5, Trial: 41\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AH  |  W IH K S  |  AH V  |  L AW D  |  HH OW NG  |  IH N  |  DH AH  |  B L IH L  |  HH EH R  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.11.03, Block: 5, Trial: 42\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AH  |  P AW N D  |  AH V  |  S ER T ER  |  K AA S T S  |  M AO R  |  DH AE N  |  EH N JH  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.11.03, Block: 5, Trial: 43\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  DH AH  |  F IY N  |  W AA Z  |  SH AA P  |  AH N D  |  G AA T  |  DH AH  |  L IH R  |  W AO T ER  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.11.03, Block: 5, Trial: 44\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  DH AH  |  P L EY  |  S IY M Z  |  T EH L  |  AH N D  |  K W AY T  |  S UW P AH N  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.11.03, Block: 5, Trial: 45\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  B EH L  |  DH AH  |  P UH T  |  T UW  |  S AH M  |  IH T  |  F R AH M  |  S IH K IH NG  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.11.03, Block: 5, Trial: 46\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  DH AH  |  T AH M  |  IH N T ER D  |  IH N  |  L EH T  |  SH UH N  |  DH AE T  |  HH IY R  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.11.03, Block: 5, Trial: 47\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AH  |  JH AH S T  |  IH Z  |  Y UW Z  |  T UW  |  M EY K  |  K AH N D L IY  |  G IH V Z  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.11.03, Block: 5, Trial: 48\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  D IH D  |  M EH N S Z  |  W ER  |  S EH D  |  IH N  |  IH N  |  AO R D ER  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.11.03, Block: 5, Trial: 49\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  DH AH  |  B IH L  |  W AA Z  |  EY D  |  EH V ER IY  |  TH ER T  |  W IY K  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.11.03, Block: 6, Trial: 25\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  DH AE T S  |  W AH T  |  AY  |  HH AE D  |  DH AH  |  AA P AH T AH T IH D  |  T UW  |  D UW  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.11.03, Block: 6, Trial: 26\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  B IH K AO Z  |  IH T  |  AE K CH UW AH L IY  |  D AH Z AH N T  |  B EH T ER  |  HH UW  |  SH OW Z  |  AH P  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.11.03, Block: 6, Trial: 27\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  DH EY  |  HH AE V  |  DH AH  |  B EH S T  |  AH V  |  B OW TH  |  W ER S Z  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.11.03, Block: 6, Trial: 28\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  W IY  |  F AY N D  |  IH T  |  IY Z IY ER  |  T UW  |  D IH V AY N D  |  DH AH  |  M EH ZH ER  |  B OY L Z  |  HH AH P  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.11.03, Block: 6, Trial: 29\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  P AH M AH N AH T L IY  |  AH T EH S T  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.11.03, Block: 6, Trial: 30\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AY  |  D OW N T  |  N OW  |  AH B AW T  |  N EY N T IY  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.11.03, Block: 6, Trial: 31\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  G UH D  |  R AH DH ER  |  S IY  |  IH T  |  HH AA R D ER  |  T UW  |  K AH M EY N T  |  S AH M B AA D IY  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.11.03, Block: 6, Trial: 32\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  M AO R  |  AH N T IH V AH T IY  |  AA N  |  AW ER  |  P AA R T  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.11.03, Block: 6, Trial: 33\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  K IY P  |  CH IY K AH N Z  |  IH N  |  AH  |  G ER AA ZH  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.11.03, Block: 6, Trial: 34\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  SH IY D Z  |  L AY V  |  W IH DH  |  AH S  |  F AO R  |  L AY K  |  F AY V  |  Y IH R Z  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.11.03, Block: 6, Trial: 35\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  IH T S  |  L AY K  |  S EH V AH D IY  |  D ER W IY S  |  HH IY R  |  R AY T  |  N AW  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.11.03, Block: 6, Trial: 36\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  B IH K  |  DH AE T  |  K AA R  |  AW T  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.11.03, Block: 6, Trial: 37\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  W IY  |  HH AE D  |  T UW  |  G IH V  |  HH IH M  |  AH  |  D AH M EH T ER  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.11.03, Block: 6, Trial: 38\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  IH T S  |  R IY L  |  HH AA R D  |  T UW  |  M EY K  |  DH EH M  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.11.03, Block: 6, Trial: 39\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  W EH N  |  AY  |  F ER S T  |  S T AO T ER D  |  W ER K IH NG  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.11.03, Block: 6, Trial: 40\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  DH EY  |  TH IH NG K  |  DH AE T S  |  AH  |  F AE M AH L IY  |  IH N T IH V AH D IY  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.11.03, Block: 6, Trial: 41\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  IH T  |  S IY M Z  |  L AY K  |  DH EY  |  TH IH NG K  |  DH AH  |  N OW  |  W AH T  |  DH EY  |  W AA N T  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.11.03, Block: 6, Trial: 42\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  HH IY  |  P R IH T IY  |  M AH CH  |  JH AA B  |  AW T  |  AH V  |  P AH B L IH K  |  L AH V  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.11.03, Block: 6, Trial: 43\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AH  |  L AA T  |  AH V  |  G UH D  |  AE Z  |  K AH M  |  F R AH M  |  DH IH S  |  W AH N  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.11.03, Block: 6, Trial: 44\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  DH AE T S  |  W AH T  |  DH EY  |  S EY  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.11.03, Block: 6, Trial: 45\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  N AA T  |  W IH TH AW T  |  Y AO R  |  P ER F IH SH AH N  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.11.03, Block: 6, Trial: 46\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  DH AY S  |  JH AH S T  |  S AH M TH IH NG  |  AH B AW T  |  DH AE T  |  T EH L AH L IH K  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.11.03, Block: 6, Trial: 47\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  HH AW  |  D UW  |  Y UW  |  F IY L  |  AH B AW T  |  S P AA R T  |  T EH S T  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.11.03, Block: 6, Trial: 48\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  N AA T  |  B IH K AO Z  |  AY  |  HH AE V AH N T  |  G AA T  |  DH AH  |  D IH S AY R ER  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.11.03, Block: 6, Trial: 49\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  R IH M EH M B ER  |  M EY K  |  D IH S IH ZH AH N Z  |  AH N D  |  S T IH K  |  T UW  |  DH EH M  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.11.04, Block: 4, Trial: 15\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  DH AE T S  |  JH AH S T  |  N AA T  |  AW ER  |  TH IH NG K  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.11.04, Block: 4, Trial: 16\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AY  |  L AH V  |  IH T  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.11.04, Block: 4, Trial: 17\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AY  |  JH AH S T  |  W AH T  |  T UW  |  T EH L  |  Y UW  |  DH IH S  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.11.04, Block: 4, Trial: 18\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  W IY  |  SH UH D  |  G OW  |  D IH F ER AH N T  |  W EY  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.11.04, Block: 4, Trial: 19\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AY  |  HH OW P  |  Y UW  |  HH ER D  |  W AH T  |  DH EY  |  S EH D  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.11.04, Block: 4, Trial: 20\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AA R  |  Y UW  |  SH UH R  |  Y UW  |  S AO  |  IH T  |  DH EH R  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.11.04, Block: 4, Trial: 21\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  W AH T  |  S AO R T  |  AH V  |  W ER K  |  D UW  |  Y UW  |  D UW  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.11.04, Block: 4, Trial: 22\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AY  |  W UH D  |  L AY K  |  T UW  |  B AY  |  AH  |  K AA R  |  N EH K S T  |  Y IH R  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.11.04, Block: 4, Trial: 23\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  EH N IY TH IH NG  |  OW L D  |  IH Z  |  N AA T  |  AO L W EY Z  |  G UH D  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.11.04, Block: 4, Trial: 24\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  SH IY  |  JH AH S T  |  S EH D  |  N OW  |  T UW  |  D UW  |  M AY  |  W ER K  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.11.04, Block: 4, Trial: 25\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AE T  |  DH AH  |  EH N D  |  EH V R IY TH IH NG  |  W AA Z  |  N AY S  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.11.04, Block: 4, Trial: 26\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  DH IH S  |  IH Z  |  AH  |  HH AA R D  |  P R AA B L AH M  |  T UW  |  W ER K  |  AA N  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.11.04, Block: 4, Trial: 27\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AY  |  W AA Z  |  N AA T  |  EY B AH L  |  T UW  |  W ER K  |  V EH R IY  |  F AA R  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.11.04, Block: 4, Trial: 28\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  Y AO R  |  N EY M  |  IH Z  |  IY Z IY  |  T UW  |  R IH M EH M B ER  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.11.04, Block: 4, Trial: 29\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  S AH M W AH N  |  M AH S T  |  T EH L  |  HH ER  |  DH AE T  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.11.17, Block: 3, Trial: 25\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  W AH T  |  M EY K S  |  Y UW  |  TH IH NG K  |  DH AE T  |  IH Z  |  T R UW  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.11.17, Block: 3, Trial: 26\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AY M  |  N AA T  |  T AO K IH NG  |  T UW  |  Y UW  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.11.17, Block: 3, Trial: 27\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AY  |  HH AE D  |  T UW  |  G OW  |  F ER S T  |  W IH DH  |  DH EH M  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.11.17, Block: 3, Trial: 28\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  Y UW  |  SH UH D  |  T EY K  |  S AH M  |  B R IH NG K  |  F R AH M  |  W ER K  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.11.17, Block: 3, Trial: 29\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  W AH T  |  P AA R T  |  AH V  |  DH IH S  |  IH Z  |  R IH L IY  |  T R UW  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.11.17, Block: 3, Trial: 30\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  W AH D  |  Y UW  |  L AY K  |  T UW  |  JH OY N  |  M IY  |  N EH K S T  |  W IY K  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.11.17, Block: 3, Trial: 31\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  HH AW  |  AA R  |  TH IH NG Z  |  OW V ER  |  DH EH R  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.11.17, Block: 3, Trial: 32\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  DH IH S  |  IH Z  |  W AH T  |  AY  |  W UH N AH D  |  T UW  |  N OW  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.11.17, Block: 3, Trial: 33\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  EH N IY  |  N UW  |  N UW Z  |  AA N  |  DH IH S  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.11.17, Block: 3, Trial: 34\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  T EH L  |  M IY  |  Y AO R  |  D IH S IH ZH AH N  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.11.17, Block: 3, Trial: 35\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AY  |  K AE N  |  K AH M  |  P EY  |  HH OW M  |  W IH DH  |  K IH D Z  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.11.17, Block: 3, Trial: 36\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AO L  |  DH IH S  |  IH Z  |  S OW  |  IH N T AH R EH S T IH NG  |  T UW  |  M IY  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.11.17, Block: 3, Trial: 37\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AY  |  L AH V  |  T UW  |  T UW  |  W ER K  |  AH V  |  HH AY N D  |  P R AA B L AH M Z  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.11.17, Block: 3, Trial: 38\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  DH AE T  |  M EY K S  |  IH T  |  M AO R  |  IH N T AH R EH S T IH NG  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.11.17, Block: 3, Trial: 39\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AY  |  TH IH NG K  |  DH IH S  |  W IH L  |  K AH M  |  ER AW N D  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.11.17, Block: 3, Trial: 40\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AY  |  HH AE V  |  N EH V ER  |  ER N  |  AH V  |  DH IH S  |  B IH B IH F AO R  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.11.17, Block: 3, Trial: 41\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AY  |  HH OW P  |  Y UW  |  L UH K  |  IH T  |  DH AH  |  HH OW L  |  HH AW S  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.11.17, Block: 3, Trial: 42\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  EH N JH OY  |  Y AO R  |  T AY M  |  AH W EY  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.11.17, Block: 3, Trial: 43\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  W AH T  |  IH Z  |  DH AH  |  M EY K  |  AH V  |  Y AO R  |  K AA R  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.11.17, Block: 3, Trial: 44\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  S AH M TH IH NG  |  IH Z  |  R AO NG  |  HH IY R  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.11.17, Block: 3, Trial: 45\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  D IH D  |  Y UW  |  G EH T  |  EH V R IY TH IH NG  |  AY  |  S EH D  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.11.17, Block: 3, Trial: 46\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  W AH T  |  AH  |  F AH N  |  P L EY S  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.11.17, Block: 3, Trial: 47\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  S AH M  |  AH V  |  AH S  |  W IH L  |  P EY  |  DH AH  |  M AH N IY  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.11.17, Block: 3, Trial: 48\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  DH AE T  |  IH Z  |  L UH K IH NG  |  V EH R IY  |  IY Z IY  |  T UW  |  M IY  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.11.17, Block: 3, Trial: 49\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  W IH L  |  Y UW  |  JH OY N  |  DH AH  |  K AA L IH JH  |  N EH K S T  |  Y IH R  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.11.19, Block: 4, Trial: 20\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AA R  |  Y UW  |  S T IH L  |  DH EH R  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.11.19, Block: 4, Trial: 21\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AY  |  W IH L  |  W EY T  |  F AO R  |  AH  |  K AH P AH L  |  AH V  |  D EY Z  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.11.19, Block: 4, Trial: 22\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  DH EY  |  K EY M  |  TH R UW  |  JH AH S T  |  N AW  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.11.19, Block: 4, Trial: 23\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  D UW  |  Y UW  |  EH V ER  |  G OW  |  DH EH R  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.11.19, Block: 4, Trial: 24\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AY  |  HH OW P  |  DH IH S  |  W IH L  |  L UH K  |  G UH D  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.11.19, Block: 4, Trial: 25\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  HH UW  |  N EH S  |  M AO R  |  AH B AW T  |  DH IH S  |  DH AE N  |  Y UW  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.11.19, Block: 4, Trial: 26\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AY  |  N OW  |  DH IH S  |  W IH L  |  AO L  |  W IY K  |  AW T  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.11.19, Block: 4, Trial: 27\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  HH AW  |  M EH N IY  |  P IY P AH L  |  AA R  |  K AH M IH NG  |  HH IY R  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.11.19, Block: 4, Trial: 28\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AE T  |  DH AH  |  EH N D  |  IH T  |  W AA Z  |  L UH K IH NG  |  V EH R IY  |  G UH D  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.11.19, Block: 4, Trial: 29\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  DH EY  |  W IH L  |  OW N L IY  |  L EH T  |  DH IH S  |  K AH P AH L  |  IH N  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.11.19, Block: 4, Trial: 30\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  S OW  |  W AH T S  |  N EH K S T  |  F AO R  |  Y UW  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.11.19, Block: 4, Trial: 31\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  IH T S  |  AH  |  P L EH ZH ER  |  W ER K IH NG  |  W IH DH  |  Y UW  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.11.19, Block: 4, Trial: 32\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AY  |  TH IH NG K  |  IH T S  |  AH B AW T  |  DH AH  |  S EY M  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.11.19, Block: 4, Trial: 33\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  SH IY  |  K AO L D  |  M IY  |  DH AH  |  AH DH ER  |  D EY  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.11.19, Block: 4, Trial: 34\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  G EH S  |  W AH T  |  W IY  |  AA R  |  D UW IH NG  |  N EH K S T  |  Y IH R  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.11.19, Block: 4, Trial: 35\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  D UW  |  Y UW  |  B IH L IY V  |  DH AE T  |  B OY  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.11.19, Block: 4, Trial: 36\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AY  |  N AA T  |  W AA N T  |  T UW  |  G OW  |  DH EH R  |  AH G EH N  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.11.19, Block: 4, Trial: 37\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  HH AE V IH NG  |  CH IH L D R AH N  |  ER EY N D  |  IH Z  |  F AH N  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.11.19, Block: 4, Trial: 38\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  DH IH S  |  IH Z  |  S AH CH  |  AH  |  G R EY T  |  AH G IY AH  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.11.19, Block: 4, Trial: 39\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  B OW TH  |  AH V  |  Y UW  |  AA R  |  D UW IH NG  |  S OW  |  W EH L  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.11.26, Block: 7, Trial: 20\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  S OW SH AH L  |  G R UW P  |  IH K S P IH R IY AH N S  |  S AH P EH Z D  |  S AY N  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.11.26, Block: 7, Trial: 21\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  K AE T  |  N OY  |  T AE P IH K  |  B EY S IH K L IY  |  K EH R  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.11.26, Block: 7, Trial: 22\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  JH UH R IY  |  N ER S IH NG  |  D IH P EH N D Z  |  L EY  |  W AH T EH V ER  |  Y UW ZH AH W AH L  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.11.26, Block: 7, Trial: 23\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  M IH D AH L  |  AW ER Z  |  N AO R TH  |  W AO N T IH D  |  S EH V AH N  |  L AA R JH  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.11.26, Block: 7, Trial: 24\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  K R AY M  |  B EH N AH F IH T S  |  L IH V Z  |  G AY  |  K AH M IH NG  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.11.26, Block: 7, Trial: 25\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  IH P AH N D  |  L IY S T  |  AH Z B AH N D  |  K AH M Z  |  W IH TH AW T  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.11.26, Block: 7, Trial: 26\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  B EY S B AO L  |  B AH JH IH T  |  HH AH Z B AH N D  |  V IH ZH ER  |  B OY Z  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.11.26, Block: 7, Trial: 27\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  TH R UW  |  W AH T EH V ER  |  S UW P ER  |  S AW N D Z  |  K UH K  |  W ER T  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.11.26, Block: 7, Trial: 28\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  TH IH NG K  |  EH N IY M AO R  |  Y UW ZH AH W AH L  |  S AW N D  |  AE N  |  R IY S IH S T IH ER  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.11.26, Block: 7, Trial: 29\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  M EH R IY D  |  V IH ZH AH W AH L  |  B IH G AH T S  |  N OY Z  |  R IY P AO R T  |  IH K S P IH R IY AH N S  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.11.26, Block: 7, Trial: 30\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  S IH T  |  S EH V AH N  |  M AY N  |  S EH K AH N D  |  D AE L AH S  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.11.26, Block: 7, Trial: 31\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  L UH K  |  W EH K ER D  |  T AA P IH K  |  P AA L AH S IY  |  G ER L  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.11.26, Block: 7, Trial: 32\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AH G R IY  |  K AE ZH AH W AH L T IY Z  |  EH M P L OY IY Z  |  S N OW  |  HH EH L P S  |  W UH M AH N  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.11.26, Block: 7, Trial: 33\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  DH EH Z  |  P AW ER  |  B EY B IY  |  K AO R S  |  M AY L Z  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.11.26, Block: 7, Trial: 34\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  W AY F  |  T IY M Z  |  W EY Z  |  L IH V IH NG  |  S EH N S  |  G AY  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.11.26, Block: 7, Trial: 35\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  IY V N IH NG  |  TH ER D IH NG  |  Y IH R Z  |  D EH TH  |  TH IH NG K IH NG  |  F AE T  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.11.26, Block: 7, Trial: 36\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  B EH N AH F IH T S  |  V OW T  |  T AH D EY  |  F Y UW CH ER  |  V AO R W AH D  |  IH K S P IH R IY AH N S  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.11.26, Block: 7, Trial: 37\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  Y UW R Z  |  T AE K S  |  G AH V ER M AH N T  |  D IY L  |  G R UW  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.11.26, Block: 7, Trial: 38\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  CH OY S AH Z  |  HH UW Z  |  W AH T EH V ER  |  M AH DH ER  |  EH N D  |  R EH G Y AH L ER  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.11.26, Block: 7, Trial: 39\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  T AH K T  |  L IH V Z  |  S OW SH AH L  |  P AH N IH SH M AH N T  |  T R AH B AH L  |  L AA S  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.11.26, Block: 9, Trial: 25\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  B EY S IH K L IY  |  DH IH S  |  IH Z  |  L OW  |  IH N  |  M AY  |  B UH K S  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.11.26, Block: 9, Trial: 26\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AE Z  |  Y UW ZH AH W AH L  |  AW ER  |  T ER N  |  K AH M Z  |  W EH N  |  W IY  |  W ER  |  AH B AW T  |  T UW  |  L IY V  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.11.26, Block: 9, Trial: 27\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  S AH M T AY M Z  |  AY  |  EH N JH OY  |  F AH N IY  |  M UW V IY Z  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.11.26, Block: 9, Trial: 28\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  D OW N T  |  M EH ZH ER  |  Y ER S EH L F  |  AH G EH N S T  |  DH IH S  |  Y AA R D  |  S T IH K  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.11.26, Block: 9, Trial: 29\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AY  |  T OW L D  |  Y UW  |  T UW  |  S EH L  |  DH AE T  |  P AA T  |  AH V  |  DH AH  |  K AH M P AH N IY  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.11.26, Block: 9, Trial: 30\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  DH EH R Z  |  AH  |  L AA T  |  AH V  |  S N OW  |  AH N D ER  |  M AY  |  K AA R  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.11.26, Block: 9, Trial: 31\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AY  |  K UH D AH N T  |  W EY T  |  F AO R  |  DH IH S  |  V ER ZH AH N  |  AH V  |  DH AH  |  G EY M  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.11.26, Block: 9, Trial: 32\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AY  |  IH K S P EH N T AH D  |  Y UW  |  HH IY R  |  W AH N  |  AW ER  |  AH G OW  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.11.26, Block: 9, Trial: 33\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  K AE N  |  Y UW  |  CH EH K  |  DH AH  |  R EH D IH NG  |  AA N  |  DH AH  |  K AH M P Y UW T ER  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.11.26, Block: 9, Trial: 34\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AW ER  |  S IH CH UW EY SH AH N  |  IH Z  |  N AA T  |  V EH R IY  |  D IH F ER AH N T  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.11.26, Block: 9, Trial: 35\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  D UW  |  Y UW  |  N OW  |  HH AW  |  T UW  |  R EH D  |  M Y UW Z IH K  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.11.26, Block: 9, Trial: 36\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AY  |  JH AH S T  |  W AO N T IH D  |  AW ER  |  Y UW ZH AH W AH L  |  F UW D  |  T UW  |  IY T  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.11.26, Block: 9, Trial: 37\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  HH AW  |  M EH N IY  |  K AE ZH AH W AH L T IY Z  |  W ER  |  DH EH R  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.11.26, Block: 9, Trial: 38\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  L IH V IH NG  |  W IH DH  |  DH IH S  |  G R UW P  |  AH V  |  F R EH N D Z  |  F AE L T  |  W AH N D ER F AH L  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.11.26, Block: 9, Trial: 39\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  W AH T  |  B R IH NG Z  |  Y UW  |  T UW  |  AW ER  |  HH OW M  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.11.26, Block: 9, Trial: 40\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  SH IY  |  S EH T  |  SH IY  |  IH K S P EH SH L IY  |  W UH D AH N T  |  T UW  |  T AO K  |  T UW  |  Y UW  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.11.26, Block: 9, Trial: 41\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  B R IH NG  |  M IY  |  DH AH  |  N OY Z  |  R IY P AO R T  |  P L IY Z  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.11.26, Block: 9, Trial: 42\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  D UW  |  Y UW  |  AH N D ER S T AE N D  |  DH AE T  |  R IY S AY K AH L IY  |  IH Z  |  IH M P AO R T AH N T  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.11.26, Block: 9, Trial: 43\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  M AY  |  K AH M P Y UW T ER  |  IH Z  |  K W AY T  |  IH K S P EH N S IH V  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.11.26, Block: 9, Trial: 44\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  EH V R IY W AH N  |  SH UH D  |  R EH D  |  N UW Z P EY P ER  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.11.26, Block: 9, Trial: 45\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AY  |  HH AE V  |  S ER T AH N L IY  |  M EY D  |  F R EH N D Z  |  HH IY R  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.11.26, Block: 9, Trial: 46\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  N AH TH IH NG  |  T UW  |  IH K S P EH N S IH V  |  P L IY Z  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.11.26, Block: 9, Trial: 47\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  M EH N IY  |  L OW K AH L  |  P IY P AH L  |  W ER K T  |  AE T  |  DH IH S  |  K AH M P AH N IY  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.11.26, Block: 9, Trial: 48\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  P IH K  |  AH P  |  Y AO R  |  B IH G AH S T  |  B UH K  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.11.26, Block: 9, Trial: 49\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  W AH T  |  D IH F ER AH N S  |  D AH Z  |  DH IH S  |  M EY K  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.12.03, Block: 4, Trial: 24\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  DH AE T AH L  |  B IY  |  N AY S  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.12.03, Block: 4, Trial: 25\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  P EY S T S  |  DH AH  |  F ER S T  |  L EH AH V  |  G EY M  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.12.03, Block: 4, Trial: 26\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  W ER  |  Y UW  |  HH IY R  |  L AE S T  |  S AH M ER  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.12.03, Block: 4, Trial: 27\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  DH AE T S  |  V AA V AH L AH N S  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.12.03, Block: 4, Trial: 28\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AY  |  T R AY D  |  T UW  |  HH AE V  |  AH  |  K AH M P AH SH  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.12.03, Block: 4, Trial: 29\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AH N D  |  D R AH P  |  DH OW Z  |  AO F  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.12.03, Block: 4, Trial: 31\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  W IY  |  HH AE V  |  AH  |  L AA T  |  AH V  |  P IY P AH L  |  HH UW  |  W ER K  |  AA N  |  DH AH  |  L AY T  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.12.03, Block: 4, Trial: 32\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  DH AE T S  |  R IH L IY  |  IH M P AO R T AH N T  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.12.03, Block: 4, Trial: 33\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  Y UW ZH AH L IY  |  SH IY  |  W IH L  |  AH T AW N T  |  T UW  |  S EH D  |  AH V  |  DH AH  |  V IH JH T ER  |  AH P  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.12.03, Block: 4, Trial: 34\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  IH T  |  M EY D  |  AH  |  P IH G  |  D IH F ER AH N S  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.12.03, Block: 4, Trial: 35\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  DH IH S  |  AO R AH JH SH AH P  |  K AE N  |  S EH T  |  AH V  |  N UW  |  D IH G EH SH AH N  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.12.03, Block: 4, Trial: 36\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  Y UW  |  R IH L IY  |  K AE N  |  K AW T  |  TH AH Z  |  AH V  |  S T AO R Z  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.12.03, Block: 4, Trial: 37\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AW ER  |  K R AY M  |  R AY T  |  HH AE Z  |  IH N K R EH S T  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.12.03, Block: 4, Trial: 38\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AA N  |  T AA P  |  AH V  |  DH AH  |  F IH D ER AH  |  D AE S  |  AA N  |  K AE S AH L IY  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.12.03, Block: 4, Trial: 39\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  IH T S  |  G OW IH NG  |  T UW  |  B IY  |  HH AA R D  |  T UW  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.12.03, Block: 4, Trial: 40\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  T R EH N S  |  AA R  |  B IH L T  |  EH K CH T R EH AH  |  S T AH D IY  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.12.03, Block: 4, Trial: 41\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  S AH M B AA D IY  |  W UH D  |  S IY  |  IH T  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.12.03, Block: 4, Trial: 42\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  IH Z  |  K AH L IH SH UW AH L  |  B IH N  |  F AO R  |  Y UW  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.12.03, Block: 4, Trial: 43\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  M AO R  |  AH V  |  DH AH  |  V AA L IH T IH R  |  N IH K ER AH K  |  S ER V AH S  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.12.03, Block: 4, Trial: 44\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  Y UW  |  W L AY K  |  IH T  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.12.03, Block: 4, Trial: 45\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  DH AE T S  |  P R AH V AH V AH D AH D  |  W EH R  |  W IY  |  W ER K  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.12.03, Block: 4, Trial: 46\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  B AH T  |  DH AH  |  TH IH NG K  |  W AA Z  |  DH AE T  |  AY  |  K UH D  |  D UW  |  DH AH  |  JH AA B  |  M AY S IH L  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.12.03, Block: 4, Trial: 48\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  W IY  |  W ER  |  S IH T IH NG  |  DH EH R  |  W AH N D ER IH NG  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.12.03, Block: 4, Trial: 49\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  DH EY V  |  K AH M  |  AH  |  L AO NG  |  W EY  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.12.03, Block: 8, Trial: 10\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  DH EY  |  W IH L  |  AO R D ER  |  EH V R IY W AH N  |  T UW  |  G OW  |  AH L AO NG  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.12.03, Block: 8, Trial: 11\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  B EY S IH K L IY  |  AY  |  W IH L  |  JH AH S T  |  S T IH K  |  ER AW N D  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.12.03, Block: 8, Trial: 12\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  DH IH S  |  K AE M P IH NG  |  S P EY S  |  IH Z  |  IH K S P EH N S IH V  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.12.03, Block: 8, Trial: 13\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  W AH T  |  W AA Z  |  IH N  |  DH AH  |  L OW K AH L  |  N UW Z P EY P ER  |  T AH D EY  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.12.03, Block: 8, Trial: 14\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  DH IH S  |  S IY Z AH N  |  W IH L  |  B R IH NG  |  M AO R  |  S AH N  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.12.03, Block: 8, Trial: 15\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  W AH T  |  AA R  |  Y UW  |  W AA CH IH NG  |  DH IH S  |  S IY Z AH N  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.12.03, Block: 8, Trial: 16\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  W AH T S  |  DH AH  |  D IY L  |  W IH DH  |  EH V R IY W AH N  |  IH N  |  DH IH S  |  K AH M P AH N IY  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.12.03, Block: 8, Trial: 17\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  M AO R N IH NG  |  AW ER Z  |  W IH DH  |  S AH N  |  AA R  |  K W AY T  |  W AH N D ER F AH L  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.12.03, Block: 8, Trial: 18\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  P IY P AH L  |  Y UW Z D  |  W AY T  |  K L OW DH Z  |  F AO R  |  DH IH S  |  G EY M  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.12.03, Block: 8, Trial: 19\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  SH OW SH AH L  |  S IH CH UW EY SH AH N  |  HH IY R  |  IH Z  |  G EH T IH NG  |  B EH T ER  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.12.08, Block: 8, Trial: 25\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  DH AE T  |  OW L D  |  M Y UW Z IH K  |  R EH K ER N D  |  IH Z  |  S T IH L  |  V EH R IY  |  G UH D  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.12.08, Block: 8, Trial: 26\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  T EH N  |  G AY Z  |  K EY M  |  IH N  |  F AO R  |  K AA R D Z  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.12.08, Block: 8, Trial: 27\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  DH IH S  |  P AA L AH S IY  |  W IH L  |  CH EY N JH  |  DH AH  |  L AO  |  IH N  |  M EH N IY  |  S T EY T S  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.12.08, Block: 8, Trial: 28\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  IH T  |  IH Z  |  AH  |  G R EY T  |  AO K EY ZH AH N  |  T UW  |  S T AA R T  |  R ER IH NG  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.12.08, Block: 8, Trial: 29\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  DH IH S  |  S IH CH UW EY SH AH N  |  IH Z  |  N AA T  |  D IH S AH S IH K AH L IY  |  S P EH SH AH L  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.12.08, Block: 8, Trial: 30\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  DH EH R  |  IH Z  |  AH  |  B IH G  |  K AE M P IH NG  |  S P EY S  |  OW V ER  |  HH IY R  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.12.08, Block: 8, Trial: 31\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  M AY  |  W ER D  |  IH Z  |  F AY N AH L  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.12.08, Block: 8, Trial: 32\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  P AH B L IH K  |  EH JH AH K EY SH AH N  |  IH Z  |  G EH T IH NG  |  B EH T ER  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.12.08, Block: 8, Trial: 33\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  DH IH S  |  IH Z  |  S ER T AH N L IY  |  N AA T  |  W IH DH  |  TH AW Z D AH N D  |  D AA L ER Z  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.12.08, Block: 8, Trial: 34\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  DH IH S  |  L UH K S  |  S UW P ER  |  IH K S P EH N S IH V  |  B AH T  |  IH T S  |  N AA T  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.12.08, Block: 8, Trial: 35\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AY  |  TH IH NG K  |  DH EH R  |  IH Z  |  S T IH L  |  S AH M  |  K AH N F Y UW ZH AH N  |  AH B AW T  |  DH IH S  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.12.08, Block: 8, Trial: 36\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AY  |  W IH L  |  N AA T  |  M IH S  |  AH N AH DH ER  |  G EY M  |  DH IH S  |  S IY Z AH N  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.12.08, Block: 8, Trial: 37\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  IH T  |  F EH L T  |  K W AY T  |  AH N Y UW ZH UW AH L  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.12.08, Block: 8, Trial: 38\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  W AH T S  |  B IH T EH N  |  M AY  |  HH OW M  |  AH N  |  DH IH S  |  N UW  |  S IH T IY  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.12.08, Block: 8, Trial: 39\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  R IY S AY K AH L IH NG  |  M AO R  |  W IH L  |  S ER T AH N L IY  |  HH EH L P  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.12.08, Block: 8, Trial: 40\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  F AY V  |  V AY L Z  |  N AO R TH  |  AH V  |  HH IY R  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.12.08, Block: 8, Trial: 41\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AY  |  AH V OY D  |  W AY T  |  K L OW DH Z  |  F AO R  |  DH IH S  |  G EY M  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.12.08, Block: 8, Trial: 42\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  W IH CH  |  EH R IY AH Z  |  AH V  |  DH AH  |  S IH T IY  |  AA R  |  G UH D  |  F AO R  |  L IH V IH NG  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.12.08, Block: 8, Trial: 43\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  HH IY  |  IH Z  |  B IH N  |  AH  |  G UH D  |  CH AE L D  |  S OW  |  F AO R  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.12.08, Block: 8, Trial: 44\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  Y UW  |  HH AE V  |  T UW  |  B IY  |  K W AY T  |  S OW SH AH L  |  T UW  |  M EY K  |  F R EH N D Z  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.12.08, Block: 8, Trial: 45\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  IH T  |  IH Z  |  B EH T ER  |  DH AE T  |  Y UW  |  AA R  |  HH OW M  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.12.08, Block: 8, Trial: 46\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  S OW SH AH L  |  K AH N T R IY Z  |  AA R  |  W AH N D ER F AH L  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.12.08, Block: 8, Trial: 47\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AA R  |  Y UW  |  W ER K IH NG  |  DH IH S  |  F UH L  |  G EY M  |  S IY Z AH N  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.12.08, Block: 8, Trial: 48\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  P L IY Z  |  P L EY  |  M AY  |  F EY V IH T  |  M Y UW Z IH K  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.12.08, Block: 8, Trial: 49\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  DH AH  |  S AH N  |  SH UH D  |  P OY N T  |  AH S  |  T UW  |  DH AH  |  N AO R TH  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.12.08, Block: 9, Trial: 25\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AY  |  W AA Z  |  S EY IH NG  |  IH K Z AE K T L IY  |  DH IH S  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.12.08, Block: 9, Trial: 26\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  SH IY  |  L AH V D  |  N AH TH IH NG  |  M AO R  |  DH AE N  |  HH ER  |  F EY V ER IH T  |  B UH K  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.12.08, Block: 9, Trial: 27\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  T EH S T IH NG  |  IH Z  |  IH M P AO R T AH N T  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.12.08, Block: 9, Trial: 28\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  DH EY  |  R IH K AO R D  |  M Y UW Z IH K  |  IH N  |  S M AO L  |  R UW M  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.12.08, Block: 9, Trial: 29\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  DH EY  |  AA R  |  F Y UW CH ER  |  HH AH Z B AH N D  |  AH N D  |  W AY F  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.12.08, Block: 9, Trial: 30\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  K L AH N ZH ER IY  |  K L OW DH Z  |  AA R  |  IH K S P EH N S IH V  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.12.08, Block: 9, Trial: 31\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  T EH L  |  M IY  |  AH B AW T  |  N AY S  |  P L EY S AH Z  |  N IH R  |  Y UW  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.12.08, Block: 9, Trial: 32\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  DH IH S  |  IH Z  |  N AA T  |  D IH S AH S EH L AH L IY  |  T R UW  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.12.08, Block: 9, Trial: 33\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AY  |  D OW N T  |  AH N D ER S T AE N D  |  W AH T  |  Y UW  |  AA R  |  S EY IH NG  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.12.08, Block: 9, Trial: 34\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AY  |  P EY D  |  W IH DH  |  M AY  |  Y UW ZH AH W AH L  |  K R EH D AH T  |  K AA R D  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.12.08, Block: 9, Trial: 35\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  W AH T  |  IH Z  |  Y AO R  |  N EH K S T  |  L AY N  |  IH N  |  DH AH  |  P L EY  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.12.08, Block: 9, Trial: 36\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  M AY  |  F AA DH ER  |  W AA Z  |  TH AE NG K IH NG  |  AH B AW T  |  IH T  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.12.08, Block: 9, Trial: 37\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  B AH T  |  DH AE T  |  AH K R AO S  |  DH AH  |  R UW M  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.12.08, Block: 9, Trial: 38\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  M AY  |  HH AA R T  |  IH Z  |  W IH DH  |  Y UW  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.12.08, Block: 9, Trial: 39\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  W AH T  |  IH G Z AE K T L IY  |  D UW  |  Y UW  |  N OW  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.12.08, Block: 9, Trial: 40\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  Y UW V  |  AO L R EH D IY  |  T AO K T  |  AH N AH F T  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.12.08, Block: 9, Trial: 41\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  M AY  |  D AO T ER  |  L EH K S  |  HH ER  |  K AA R  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.12.08, Block: 9, Trial: 42\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  DH AE T  |  S IY M Z  |  L AY K  |  AH N AH F  |  W ER K  |  F AO R  |  T AH D EY  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.12.08, Block: 9, Trial: 43\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  HH AE F  |  AH V  |  M AY  |  F R EH N D Z  |  L AY V  |  K L UH K S  |  T UW  |  M IY  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.12.08, Block: 9, Trial: 44\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  Y AO R  |  S OW SH AH L  |  S IH CH UW EY SH AH N  |  IH Z  |  N AA T  |  V EH R IY  |  D IH F ER AH N T  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.12.08, Block: 9, Trial: 45\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  W IY  |  M AH S T  |  R IH K AO R D  |  EH V R IY TH IH NG  |  DH AE T  |  HH AE P AH N D  |  T AH D EY  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.12.08, Block: 9, Trial: 46\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  L EH T S  |  G OW  |  CH EH K  |  DH IH S  |  N UW  |  P L EY S  |  AW T  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.12.08, Block: 9, Trial: 47\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AY  |  AE M  |  SH UH R  |  AY  |  K AE N  |  D UW  |  DH IH S  |  W IH TH AW T  |  Y AO R  |  HH EH L P  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.12.08, Block: 9, Trial: 48\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  D UW  |  N AA T  |  P UH T  |  OY L  |  IH N  |  DH AH  |  W AO T ER  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.12.08, Block: 9, Trial: 49\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  IH T  |  IH Z  |  AH N UW ZH UW AH L  |  F AO R  |  M AY  |  P EH R AH N T  |  T UW  |  T IY M  |  AH P  |  W IH DH  |  DH EH M  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.12.10, Block: 7, Trial: 25\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  L IH V IH NG  |  AA N  |  AH  |  B AH JH IH T  |  IH Z  |  K W AY T  |  D IH F AH K AH L T  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.12.10, Block: 7, Trial: 26\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  P L IY Z  |  T EY K  |  K EH R  |  AH V  |  Y AO R  |  CH AY L D  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.12.10, Block: 7, Trial: 27\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AY  |  W AA Z  |  AH S P EH SH L IY  |  L UH K IH NG  |  F AO R W ER D  |  T UW  |  IH T  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.12.10, Block: 7, Trial: 28\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  T W EH L V  |  N IY D Z  |  T UW  |  G OW  |  F AO R  |  DH AH  |  F IH N AH L  |  G EY M  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.12.10, Block: 7, Trial: 29\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AY  |  HH AE D  |  DH IH S  |  V IH ZH AH N  |  W AH N S  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.12.10, Block: 7, Trial: 30\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AY  |  W IH L  |  G EH T  |  M AY  |  B EH S T  |  K L OW DH Z  |  AW T  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.12.10, Block: 7, Trial: 31\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  IH Z  |  DH IH S  |  DH AH  |  P L EY S  |  Y UW  |  Y UW ZH AH W AH L IY  |  V IH Z IH T  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.12.10, Block: 7, Trial: 32\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  M AY  |  P EH R AH N T S  |  G IH V  |  M IY  |  K W AA L AH T IY  |  AE N JH D AH K AE K SH AH N  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.12.10, Block: 7, Trial: 33\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  SH IY  |  S OW L D  |  M IY  |  DH IH S  |  B UH K  |  AH N D  |  AY  |  P EY D  |  F AO R  |  IH T  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.12.10, Block: 7, Trial: 34\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  DH IH S  |  W AA Z  |  AH  |  B IH Z N AH S  |  D IH S IH ZH AH N  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.12.10, Block: 7, Trial: 35\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AY  |  L AY K  |  D R AY V IH NG  |  S T IH T K  |  IH T S  |  IY Z IY  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.12.10, Block: 7, Trial: 36\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  DH IH S  |  P R OW G R AE M  |  IH Z  |  V EH R IY  |  IH N T AH R EH S T IH NG  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.12.10, Block: 7, Trial: 37\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AA R  |  Y UW  |  S ER T AH N  |  Y AO R  |  P EH R AH N T S  |  W IH L  |  L AA T  |  Y UW  |  G OW  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.12.10, Block: 7, Trial: 38\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  DH AH  |  S IH T  |  AH V  |  CH IH L D R AH N  |  IH N  |  DH IH S  |  K AH N T R IY  |  IH Z  |  AO F AH L  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.12.10, Block: 7, Trial: 39\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  K AH M P AH N IY Z  |  AA R  |  L UH K IH NG  |  F AO R  |  M AO R  |  EH M P L OY IY Z  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.12.10, Block: 7, Trial: 40\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AY  |  W UH D  |  TH AE DH ER  |  B IY  |  W IH DH  |  M AY  |  F R EH N D Z  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.12.10, Block: 7, Trial: 41\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  W IY  |  AA R  |  S AH P OW Z D  |  T UW  |  HH EH L P  |  AW ER  |  F AE M AH L IY  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.12.10, Block: 7, Trial: 42\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  DH AH  |  S IH T IY  |  HH AE Z  |  AH  |  D R AH G  |  P R AA B L AH M  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.12.10, Block: 7, Trial: 43\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AY  |  D UW  |  N AA T  |  G EH T  |  P EY D  |  IH N AH F  |  F AO R  |  DH IH S  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.12.10, Block: 7, Trial: 44\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  B IY IH NG  |  AH  |  M AH DH ER  |  IH Z  |  N AA T  |  AO L W EY Z  |  IY Z IY  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.12.10, Block: 7, Trial: 45\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  HH IY  |  D AH Z  |  N AA T  |  S IY M  |  L AY K  |  AH  |  P ER S AH N  |  HH UW  |  W UH D  |  M EY K  |  DH AE T  |  CH OY S  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.12.10, Block: 7, Trial: 46\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AY  |  D OW N T  |  B IH L IY V  |  DH AE T  |  K AH P AH L  |  W EH N T  |  ER T  |  S OW  |  L EY T  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.12.10, Block: 7, Trial: 47\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  DH IH S  |  IH Z  |  AH  |  G UH D  |  S IY Z AH N  |  F AO R  |  AW ER  |  B IH Z N AH S  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.12.10, Block: 7, Trial: 48\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AA R  |  Y UW  |  F R IY  |  T UW  |  W ER K  |  AA N  |  DH IH S  |  T AH G AY T  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.12.10, Block: 7, Trial: 49\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  L EH T S  |  CH EH K  |  W IH DH  |  IY CH  |  AH DH ER  |  EH V ER IY  |  HH AE F  |  AW ER  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.12.17, Block: 11, Trial: 30\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  D UW  |  Y UW  |  HH EH V IH N  |  N OW  |  DH AH  |  K IH F ER AH N S  |  B IH IY N  |  DH IH S  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.12.17, Block: 11, Trial: 31\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  SH IY  |  L EH F  |  HH OW M  |  F IH F T IH K  |  M IH N AH Z  |  AH G OW  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.12.17, Block: 11, Trial: 32\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AH  |  D AW L D  |  DH IH NG Z  |  DH EH R  |  R IH M L IY  |  IH N  |  DH AH  |  AH N L IH NG  |  AH S  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.12.17, Block: 11, Trial: 33\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  DH IH S  |  S IH CH UW EY SH AH N  |  IH Z  |  N AA T  |  DH AE T  |  M AY N  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.12.17, Block: 11, Trial: 34\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  W AH T  |  T AY P  |  AH V  |  P EH Z AH N  |  D UW  |  Y UW  |  W AA N T  |  T UW  |  K AO L  |  AH P  |  T UW  |  B IY  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.12.17, Block: 11, Trial: 35\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  W IY  |  G UH D  |  AH G AH V  |  F R IY  |  S T AH F  |  F AO  |  DH AH  |  S T AO R  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.12.17, Block: 11, Trial: 36\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  W IH SH  |  V ER ZH AH N  |  AH V  |  DH AH  |  S T AO R IY  |  IH Z  |  D R OW  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.12.17, Block: 11, Trial: 37\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  S AH M B AA D IY  |  M AH S T  |  AE V  |  K AA R D  |  AH  |  IH N  |  DH AH  |  IY V N IH NG  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.12.17, Block: 11, Trial: 38\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  B IH G  |  Y AO R  |  F EY V ER IH T  |  B UH G  |  F R AH M  |  S K UW L  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.12.17, Block: 11, Trial: 39\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  HH AW  |  M EH N IY  |  AW ER Z  |  D IH D  |  Y UW  |  W EY T  |  AW G S EH N D T  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.12.17, Block: 11, Trial: 40\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  W IY  |  T AA T IH D  |  DH IH S  |  W ER K  |  S EH S  |  DH AH  |  P EY B ER  |  K EY N  |  AW T  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.12.17, Block: 11, Trial: 41\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AY  |  K UH D AH N T  |  AH V OY D  |  G OW IH NG  |  T UW  |  DH AH  |  K AH N T R IY  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.12.17, Block: 11, Trial: 42\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  HH AW  |  M EH N IY  |  D AA L ER Z  |  T UW  |  Y UW  |  N IY D  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.12.17, Block: 11, Trial: 43\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  T W EH N T IY  |  F AO R  |  AW ER Z  |  W AH N  |  B AY  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.12.17, Block: 11, Trial: 44\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  B EY B IY  |  F UW D  |  F R AH M  |  DH AH  |  S T AO R  |  IH Z  |  N AA T  |  B AE D  |  IH T  |  AO L  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.12.17, Block: 11, Trial: 45\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  W AH T  |  M UW V IY Z  |  AA R  |  DH AH  |  M EY K IH NG  |  DH IH S  |  Y IH R  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.12.17, Block: 11, Trial: 46\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  IH N  |  DH AH  |  S EH K IH NG  |  S IY Z AH N  |  AH V  |  DH AE T  |  F AH N  |  SH OW  |  K AH M IH NG  |  S UW N  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.12.17, Block: 11, Trial: 47\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  DH AE T  |  CH AY L D  |  IH Z  |  L IY S T  |  L AH N CH  |  M AY N IY  |  DH AE N  |  DH AH  |  AH DH ER  |  K IH D Z  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.12.17, Block: 11, Trial: 48\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  L EH T S T  |  S T EH K  |  T UW  |  S AH M W AH T  |  IY Z IY ER  |  JH AA F  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.12.17, Block: 11, Trial: 49\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  M AY  |  D AO T ER  |  L AH V D  |  DH AH  |  CH IH Z AH Z  |  W IY  |  M EY D  |  T UW  |  DH AH  |  HH AW S  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.12.17, Block: 11, Trial: 50\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  P AH B L IH K  |  P L EY S AH Z  |  AA R  |  F AO R  |  EH V R IY W AH N T  |  T UW  |  EH N JH OY  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.12.17, Block: 11, Trial: 51\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AY  |  HH OW P  |  Y UW  |  AH N T ER S T AE N D  |  DH AH  |  K AH S T  |  AH V  |  D UW IH NG  |  DH IH S  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.12.17, Block: 11, Trial: 52\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AW ER  |  K AH M P AH N IY  |  W IH L  |  P EY  |  DH AH  |  S P AO R T S  |  G IH V  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.12.17, Block: 11, Trial: 53\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  L IH Z AH N  |  T UW  |  DH AH  |  HH EH D  |  K UH K  |  IH N  |  DH AH  |  HH AW S  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.12.17, Block: 11, Trial: 54\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  DH AE T  |  M UW Z IH K  |  IH Z  |  K AO R  |  M AY  |  AW R T  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.12.17, Block: 11, Trial: 55\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  DH AH  |  L AO  |  S EH Z  |  DH IH S  |  IH Z  |  N AA T  |  W AY T  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.12.17, Block: 11, Trial: 56\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  Y UW  |  S IY M  |  T UW  |  B IY  |  AH  |  R EH G Y AH L ER  |  IH N  |  DH IH S  |  P L EY S  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.12.17, Block: 11, Trial: 57\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  W AH T  |  IH G Z AE K T L IY  |  D IH D  |  Y AO R  |  F R EH N  |  T EH L  |  Y UW  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.12.17, Block: 11, Trial: 58\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  DH IH S  |  S IH CH UW EY SH AH N  |  IH Z  |  N AA T  |  AH N UW ZH UW AH L  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.12.17, Block: 11, Trial: 59\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  W AH T EH V ER  |  Y UW  |  S EY  |  DH AH  |  F AE N D  |  W IH L  |  N AA T  |  CH EY N JH  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.12.29, Block: 4, Trial: 25\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  DH EY V  |  N AA T  |  TH R IY  |  D AH S ER Z  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.12.29, Block: 4, Trial: 26\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  G EH T  |  AW T  |  AA N  |  DH AH  |  R UH D  |  T UW  |  B UH T D  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.12.29, Block: 4, Trial: 27\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  DH AE T S  |  HH AW  |  W IY  |  K UH N  |  S T AA R T IH D  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.12.29, Block: 4, Trial: 28\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  W IY R  |  B AE K IH NG  |  IH T  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.12.29, Block: 4, Trial: 29\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  DH EY  |  HH AE V  |  DH AH  |  N OW  |  CH OY S  |  S D IY L  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.12.29, Block: 4, Trial: 30\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  IH T S  |  N AY S  |  T UW  |  G EH T  |  AW T  |  IH N  |  DH AH  |  OW P AH N  |  HH IY R  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.12.29, Block: 4, Trial: 31\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  M AY  |  B R OW DH ER  |  K L IH V Z  |  W EH R  |  AY  |  W ER K  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.12.29, Block: 4, Trial: 32\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  DH EY  |  W ER L  |  L UH K IH NG  |  IH N AH F  |  T UW  |  HH AE V  |  S AH M  |  OY L  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.12.29, Block: 4, Trial: 33\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  DH AH  |  F AE S T  |  B IH K S  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.12.29, Block: 4, Trial: 34\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AH B AW T  |  F AO R  |  TH AW Z AH N D  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.12.29, Block: 4, Trial: 35\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  Y UW  |  HH AE V  |  W AH N  |  L IH L  |  AO L  |  T UW  |  Y ER S EH L F  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.12.29, Block: 4, Trial: 36\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  DH AH  |  T R IY  |  W ER  |  S OW  |  B OY N IH T  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.12.29, Block: 4, Trial: 37\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  D UW  |  Y UW  |  W AA CH  |  M Y UW Z IH K  |  T EH L AH V IH ZH AH N  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.12.29, Block: 4, Trial: 38\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AY  |  P L AE N D  |  DH AE T  |  M Y UW Z IH K  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.12.29, Block: 4, Trial: 39\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  DH AH  |  S T EY P IH NG  |  B AY K  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.12.29, Block: 4, Trial: 40\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  B OW TH  |  B OY Z  |  HH AE V  |  P L AE K  |  IY R  |  AH N D  |  B R AW N  |  AW S  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.12.29, Block: 4, Trial: 41\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  DH AE T S  |  IH G Z AE K T L IY  |  DH AH  |  P R AA B L AH M  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.12.29, Block: 4, Trial: 42\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  P L EY N  |  M AO R  |  T R IY Z  |  IH N  |  AH P AH N  |  EH R IY AH Z  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.12.29, Block: 4, Trial: 43\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  IH T  |  IH Z  |  N AA T  |  G OW  |  T UW  |  HH AE P AH N  |  DH AE T  |  W EY  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.12.29, Block: 4, Trial: 44\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  DH EH R  |  HH AE Z  |  AO L S OW  |  B IH N  |  AH  |  D IH V IH ZH AH N  |  AH V  |  IY V AH N B AO IY  |  T UW  |  DH AH  |  P L AE K  |  M AA R IH D  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.12.29, Block: 4, Trial: 45\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  DH AE T S  |  W UH D  |  T UW  |  HH IY R  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.12.29, Block: 4, Trial: 46\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AY  |  S T IH L  |  D IH D AH N T  |  W AA N T  |  HH ER  |  T UW  |  G OW  |  T UW  |  AH  |  D EY  |  K EH R  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.12.29, Block: 4, Trial: 47\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  DH EH N  |  IH T  |  G OW Z  |  T UW  |  DH AH  |  N EH K S T  |  P OY N T  |  AH N D  |  S OW  |  AA N  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.12.29, Block: 4, Trial: 48\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AH N D  |  AY  |  JH AH S T  |  EH N D AH N  |  AH P  |  HH AE V IH NG  |  T UW  |  D R AA B  |  DH AH  |  K L EY S  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.12.29, Block: 4, Trial: 49\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  DH AE T  |  IH Z  |  AY  |  W IH L  |  G UH D  |  N OW  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.12.29, Block: 5, Trial: 25\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AY  |  DH AE T  |  DH EY  |  AE T  |  CH EY N JH  |  DH EH R  |  P AA L AH S IY  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.12.29, Block: 5, Trial: 26\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AY  |  K AE N AA T  |  T EH L  |  K IH D Z  |  N AA T  |  T UW  |  P L EY  |  AW T S AY D  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.12.29, Block: 5, Trial: 27\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  CH IH L D R AH N  |  K AE N  |  JH OY N  |  DH AE T  |  R EH D IH NG  |  G R UW P  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.12.29, Block: 5, Trial: 28\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AY  |  W UH D  |  R AE DH ER  |  W AH N  |  DH IH S  |  B IH Z N AH S  |  W IH DH  |  DH EH M  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.12.29, Block: 5, Trial: 29\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AY  |  F AY N D  |  DH IH S  |  K AA AO R S  |  R IH L IY  |  IH N T AH R EH S T IH NG  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.12.29, Block: 5, Trial: 30\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AY  |  AH N D ER S T AE N D  |  DH AH  |  D IH V AH N S  |  F AY N T  |  W EH L  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.12.29, Block: 5, Trial: 31\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  W IY  |  AA R  |  T EH S IH NG  |  DH AH  |  L IH S T  |  G R UW  |  N AW  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.12.29, Block: 5, Trial: 32\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  G AH B AH D N IY  |  N UW  |  W AH T  |  HH AE P AH N D  |  DH EH R  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.12.29, Block: 5, Trial: 33\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  DH IH S  |  K AH M P AH N IY  |  W EH N T  |  P AH B L IH K  |  DH AE S T  |  Y IH R  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.12.29, Block: 5, Trial: 34\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  IH T  |  W IH L  |  P IY  |  AE N  |  IH M P AO R T AH N T  |  S T AO R IY  |  T UW  |  D EH L  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.12.29, Block: 5, Trial: 35\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AY  |  AE M  |  AH W EY  |  AA N  |  DH AH  |  F ER S T  |  W IY K EH N D  |  AH V  |  N EH K S T  |  M AH N TH  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.12.29, Block: 5, Trial: 36\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AY  |  HH AE V  |  B IH N  |  T UW  |  N ER S IH NG  |  S K UW L  |  ER R EH D IY  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.12.29, Block: 5, Trial: 37\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  DH EH R  |  S ER V AH N S  |  IH Z  |  B AE D  |  AH N D  |  DH AH  |  F UW D  |  IH Z AH N T  |  G UH D  |  IY DH ER  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.12.29, Block: 5, Trial: 38\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  W IY  |  S T AO R  |  DH IH S  |  S T AH F  |  IH N  |  DH AH  |  R UW M  |  AE T  |  DH AH  |  B AE K  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.12.29, Block: 5, Trial: 39\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  IH T  |  IH Z  |  AE N  |  EH M P L OY IY  |  EH JH AH K EY SH AH N  |  P R OW G R AE M  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.12.29, Block: 5, Trial: 40\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  W IY  |  D OW N T  |  W AA N T  |  EH N IY  |  T R AH B AH L  |  IH N  |  P AH B L IH K  |  P L EY S AH Z  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.12.29, Block: 5, Trial: 41\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  K UH D  |  Y UW  |  G EH T  |  W IY  |  DH AE T  |  W AY T  |  B UH K  |  P L IY Z  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.12.29, Block: 5, Trial: 42\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  DH IH S  |  M UW V IY  |  IH Z  |  M AY  |  F EY V ER IH T  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.12.29, Block: 5, Trial: 43\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  Y AE NG  |  P IY P AH L  |  G EH T  |  T UW  |  HH IY R  |  DH AE T  |  AH  |  L AA T  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.12.29, Block: 5, Trial: 44\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AY  |  EH N JH OY  |  R AH N IH NG  |  F AO R  |  M AY L Z  |  AA N  |  AH  |  K OW L D  |  M AO R N IH NG  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.12.29, Block: 5, Trial: 45\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  G UH D  |  W ER K  |  AO F AH N  |  B R IH NG Z  |  JH OY  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.12.29, Block: 5, Trial: 46\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AY  |  K AE N AA T  |  S IY  |  DH AH  |  D IH F ER AH N S  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.12.29, Block: 5, Trial: 47\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  DH AE T  |  IH Z  |  AH  |  W AH N D ER F AH L  |  K AA R D  |  TH AE NG K  |  Y UW  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.12.29, Block: 5, Trial: 48\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AY  |  W IH L  |  S P EH N D  |  DH AH  |  W IY K EH N D  |  W IH DH  |  M AY  |  P EH R AH N T S  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2023.12.29, Block: 5, Trial: 49\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  Y UW  |  G EH T  |  HH AE V  |  AH V  |  DH AH  |  K R EH D AH T  |  F AO R  |  DH IH S  |  W ER K  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.02.25, Block: 6, Trial: 23\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  DH EY  |  L IY V Z  |  AA R  |  AO L  |  D  |  AH N D  |  B R AW N  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.02.25, Block: 6, Trial: 25\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AE N  |  ER L IY  |  V ER ZH AH N  |  AH V  |  DH IH S  |  AA R T AH K AH L  |  W AA Z  |  P AH B L IH SH T  |  L AE S T  |  M AH N TH  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.02.25, Block: 6, Trial: 26\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  B IH K AO Z  |  DH EY  |  D OW N T  |  W AA N T  |  T UW  |  N OW  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.02.25, Block: 6, Trial: 27\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AY  |  TH IH NG K  |  EH V R IY W AH N  |  W UH D  |  AH G R IY  |  HH IY  |  W AA Z  |  AH  |  V IH N AH N EH R IY  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.02.25, Block: 6, Trial: 28\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AY  |  R IH M EH M B ER  |  IH T  |  T UH K  |  M IY  |  AH  |  L AO NG  |  T AY M  |  T UW  |  AH N D ER S T EH N T  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.02.25, Block: 6, Trial: 29\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AY  |  G EH S  |  IH T  |  IH Z  |  T UW  |  ER L IY  |  T UW  |  N OW  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.02.25, Block: 6, Trial: 30\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  DH IY Z  |  T AY M Z  |  AH V  |  HH IH N S T AH D AH N D Z  |  AA R  |  N AA T  |  AH N Y UW ZH UW AH L  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.02.25, Block: 6, Trial: 31\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  Y UW  |  HH AE V  |  AH  |  K AH P AH L  |  AH V  |  CH OY S AH Z  |  HH IY R  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.02.25, Block: 6, Trial: 32\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  IH T  |  IH Z  |  ER L IY  |  IH N  |  DH AH  |  M AO R N IH NG  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.02.25, Block: 6, Trial: 33\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  W EH R  |  IH N  |  B IH N S AH L EY N Y AH  |  AA R  |  Y UW  |  F R AH M  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.02.25, Block: 6, Trial: 34\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  SH IY  |  D AH Z  |  HH AE V  |  AH  |  JH AA B  |  AH N D  |  AH  |  K AH IH R  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.02.25, Block: 6, Trial: 35\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  DH AE T  |  IH N EH N S SH M AH N T  |  W AA Z  |  M IH N AH L IY  |  F AO R  |  P IY P AH L  |  IH N  |  B AH B AH L  |  HH OW M Z  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.02.25, Block: 6, Trial: 36\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AY  |  K UH D  |  P R AA B AH B L IY  |  S T AA R T  |  P L EY IH NG  |  B EY S B AO L  |  N EH K S T  |  S AH M ER  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.02.25, Block: 6, Trial: 37\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  W IY  |  L AY K  |  B IY IH NG  |  W IH DH  |  AW ER  |  K IH D Z  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.02.25, Block: 6, Trial: 38\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  IH T  |  IH Z  |  AH N Y UW ZH UW AH L  |  F AO R  |  AH S  |  T UW  |  N AA T  |  HH AE V  |  R EY N  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.02.25, Block: 6, Trial: 39\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  IH T S  |  AW ER Z  |  T UW  |  K IY P  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.02.25, Block: 6, Trial: 41\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  DH EH R  |  AA R  |  DH AE T S  |  AH V  |  S AH CH  |  D IH V IH ZH AH N Z  |  IH N  |  DH IH S  |  K AH N T R IY  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.02.25, Block: 6, Trial: 42\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  HH IY  |  IH Z  |  AH  |  P R AH D EH K SH AH N  |  P L EY N ER  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.02.25, Block: 6, Trial: 43\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  IH T S  |  JH AH S T  |  DH AH  |  EH D IY AH  |  DH AE T  |  M EY K S  |  M IY  |  S AW D  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.02.25, Block: 6, Trial: 44\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  DH EY  |  D UW  |  K AH V ER  |  AH  |  V IY AY IH D IY  |  AH V  |  T AA P IH K S  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.02.25, Block: 6, Trial: 45\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  JH OY N  |  AH S  |  N AW  |  F AO R  |  AH  |  T EH S K AE T  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.02.25, Block: 6, Trial: 46\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  DH EY  |  JH AH S T  |  N IY D  |  T UW  |  D UW  |  S AH M TH IH NG  |  W IH DH  |  HH IH M  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.02.25, Block: 6, Trial: 47\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  W AH T  |  IH Z  |  DH AH  |  S AH B JH IH K T  |  M AE T ER  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.02.25, Block: 6, Trial: 49\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  W AH T  |  AA R  |  Y UW  |  D UW IH NG  |  HH IY R  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.03.08, Block: 8, Trial: 24\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AY  |  F IY L  |  DH AE  |  S EY M  |  W EY  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.03.08, Block: 8, Trial: 25\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  DH EY  |  W IH N D IH D  |  W AO ER  |  F IH L D IY  |  F AY V  |  M IH N AH T S  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.03.08, Block: 8, Trial: 26\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AY  |  JH AH S T  |  G EH T  |  G OW AH N T  |  IH T  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.03.08, Block: 8, Trial: 27\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  W IY  |  R AY T  |  T UW  |  D UW  |  IH T  |  EH V ER IY  |  AH DH ER  |  M AH N TH  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.03.08, Block: 8, Trial: 28\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AY  |  HH AE V  |  Y UW  |  AO N S OY  |  DH EH M  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.03.08, Block: 8, Trial: 29\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AY  |  TH IH NG K  |  IH T  |  AE Z  |  DH AH  |  B EH S T  |  L IH V ER  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.03.08, Block: 8, Trial: 30\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AY  |  AE M  |  EH N JH OY IH NG  |  DH AE T  |  S AY D  |  AH V  |  IH T  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.03.08, Block: 8, Trial: 31\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  W AH T  |  AY  |  S IY  |  IH N  |  DH AH  |  K IH S T AH P AH  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.03.08, Block: 8, Trial: 32\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  W AH T  |  EH V R IY TH IH NG  |  IH Z  |  AA N  |  DH AH  |  L AY N  |  HH IY  |  D IH L IH V AH N Z  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.03.08, Block: 8, Trial: 33\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  W IY  |  D OW N T  |  HH AE V  |  AH  |  R IY L  |  S T R EH K T  |  M AH JH IH T  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.03.08, Block: 8, Trial: 34\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  DH AE T  |  B EY S AH N  |  R EH SH AH N  |  Y UW  |  T UW  |  M AH CH  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.03.08, Block: 8, Trial: 35\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  M AO R  |  P IY P AH L  |  K AO L  |  AA N  |  F R EH N T IH N Z  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.03.08, Block: 8, Trial: 36\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  W AH T  |  T UW  |  L AY N  |  S AH M TH IH NG  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.03.08, Block: 8, Trial: 37\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  W IY  |  AA R  |  P AO R  |  IH N  |  DH EH R  |  L EH V AH L  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.03.08, Block: 8, Trial: 38\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  HH AW  |  L AO NG  |  D AH S T  |  IH T  |  T EY K  |  T UW  |  G EH T  |  M AY  |  P OY N T S  |  B AE T K  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.03.08, Block: 8, Trial: 39\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AY  |  D OW N T  |  N OW  |  AW  |  L AY K  |  Y UW V  |  B IH N  |  HH IY R  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.03.08, Block: 8, Trial: 41\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  S AH M  |  HH AE V  |  DH AH  |  AH P S P IH R AH N M AH N T S  |  F EY L  |  W AH DH AW N T  |  EH K S P R IH D EY SH AH N  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.03.08, Block: 8, Trial: 42\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AY D  |  P R AA B AH B L IY  |  B AE  |  AH N AH DH ER  |  W AA N T  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.03.08, Block: 8, Trial: 43\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AY  |  TH IH NG K  |  HH IY  |  W IH L  |  P IH B L IY  |  B AE K  |  IH T  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.03.08, Block: 8, Trial: 44\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AY  |  D OW N T  |  N OW  |  IH F  |  Y UW  |  L AY K  |  DH AH  |  P EH R IY AH  |  IH N  |  DH IH S  |  T AW N  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.03.08, Block: 8, Trial: 45\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  DH AH  |  D IH S IH ZH AH N Z  |  AA R  |  N AA T  |  IH N  |  DH EH R  |  HH AW S  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.03.08, Block: 8, Trial: 46\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  P R AE K T IH Z  |  K IY P IH NG  |  Y UW  |  S IH K S AH Z  |  AH B AW T  |  Y UW  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.03.08, Block: 8, Trial: 47\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  W IY  |  L AY K  |  M EH S AH K AH N  |  M OW T  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.03.08, Block: 8, Trial: 48\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  B IY  |  CH EH N T AH L  |  T UW  |  HH EH P V R ER B AA B AH L  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.03.08, Block: 8, Trial: 49\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AY V  |  D AA N T  |  DH AE T  |  B IH F AO R  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.03.15, Block: 7, Trial: 24\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  Y UW  |  AA R  |  IH L AW N D  |  T UW  |  L EH T  |  DH AH  |  CH IH L D R AH N  |  SH OW  |  DH EH R  |  K EH R AH T ER  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.03.15, Block: 7, Trial: 25\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AY  |  W EH L K AH M  |  DH AH  |  D IH S IH ZH AH N  |  AH V  |  DH AH  |  K AA R T  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.03.15, Block: 7, Trial: 26\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  JH AH S T  |  S IH T  |  D AW N  |  AA N  |  DH AH  |  T EY K  |  AH N D  |  EH N JH OY  |  Y ER S EH L F  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.03.15, Block: 7, Trial: 28\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AY  |  B AA T  |  AH  |  K AH M P IH  |  AH V  |  HH ER  |  N UW  |  B UH K  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.03.15, Block: 7, Trial: 29\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  Y UW  |  K AE N T  |  S T AH P  |  P IY P AH L  |  F R AH M  |  D UW IH NG  |  W AH T  |  DH EY  |  W AA N T  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.03.15, Block: 7, Trial: 30\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AY  |  M UW V D  |  T UW  |  AH  |  B IH G ER  |  S IH T IY  |  L AE S T  |  Y IH R  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.03.15, Block: 7, Trial: 31\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  DH EY  |  HH AE V  |  T UW  |  S T EY  |  IH N S AY D  |  T AH D EY  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.03.15, Block: 7, Trial: 32\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  IH Z  |  DH AH  |  P R IH Z AH N  |  R IH S T IH K T AH D  |  T UW  |  S EH T AH D  |  T AE P S  |  AH V  |  K R IH M AH N AH L Z  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.03.15, Block: 7, Trial: 33\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  DH EY  |  D OW N T  |  M EY K  |  P R AA M AE N IY  |  D IH S IH ZH AH N Z  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.03.15, Block: 7, Trial: 34\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AY  |  V IH Z IH T AH T  |  AE N  |  IH G Z AE T IH NG  |  P EH T  |  SH AA P  |  AW T  |  IH N  |  K AE L AH F AO R N Y AH  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.03.15, Block: 7, Trial: 35\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  DH AE T  |  W AA Z  |  AH  |  G UH D  |  W ER K AA D  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.03.15, Block: 7, Trial: 36\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  M EY B IY  |  B AH T  |  P R AA B AH B L IY  |  N AA T  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.03.15, Block: 7, Trial: 37\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  DH AH  |  K AH M IH T IY  |  W IH L  |  D IH S AY D  |  AA N  |  W EH R  |  DH AH  |  M AH N IY  |  IH Z  |  B EH S T  |  S P EH N T  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.03.15, Block: 7, Trial: 38\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AY  |  AO L S OW  |  L AY K  |  JH AE Z  |  M Y UW Z IH K  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.03.15, Block: 7, Trial: 39\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  DH EY  |  B OW TH  |  M UW V D  |  W EY  |  AW T  |  IH N T UW  |  DH AH  |  K AH N T R IY  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.03.15, Block: 7, Trial: 40\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  IH T S  |  W AY T  |  AH  |  B IH T  |  D IH F ER AH N T  |  N AW  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.03.15, Block: 7, Trial: 41\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  M AY  |  HH EH R AH L IH NG  |  P AA R T  |  IH Z  |  P AA R T  |  AH V  |  M AY  |  HH OW M  |  D IH K AO R  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.03.15, Block: 7, Trial: 42\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  HH AE V  |  Y UW  |  EH V ER  |  HH ER D  |  AH V  |  IH T  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.03.15, Block: 7, Trial: 43\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AY  |  TH IH NG K  |  DH AE T  |  W UH D  |  B IY  |  M AO R  |  F EH R  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.03.15, Block: 7, Trial: 44\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  W IY  |  B AA T  |  S EY K AH N D  |  AH N D  |  V ER N AH S T ER  |  F AO R  |  AW ER  |  L IH V IH NG  |  R UW M  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.03.15, Block: 7, Trial: 45\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AY  |  D OW N T  |  N OW  |  W AY  |  AY  |  N EH V ER  |  R EH S IH S IH N  |  M AY  |  K AA R  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.03.15, Block: 7, Trial: 46\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AH N D  |  N AW  |  DH EY V  |  G AO N  |  AH N D  |  D AH N  |  AH  |  AO R AH B AH L  |  TH IH NG  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.03.15, Block: 7, Trial: 47\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AY  |  D OW N T  |  TH IH NG K  |  AY  |  K EY N D  |  EH N IY  |  W EH N T  |  L AE S T  |  Y IH R  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.03.15, Block: 7, Trial: 48\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AY  |  AE M  |  S AA R IY  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.03.15, Block: 7, Trial: 49\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AY  |  K AH M P L UW T AH D  |  DH AH  |  T R EY N IH NG  |  K AA S  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.03.15, Block: 9, Trial: 24\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  S OW  |  HH IY  |  AE Z  |  AO L  |  AH  |  W EY K  |  P EY S  |  DH AH  |  N EH K S T  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.03.15, Block: 9, Trial: 25\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  B IY P AH Z  |  S EY M  |  T UW  |  AH N JH OY  |  IH T  |  DH AH  |  DH AE T  |  IH Z  |  IH D  |  TH IH NG  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.03.15, Block: 9, Trial: 26\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  W IY V  |  B AE G  |  T AO K IH NG  |  AH  |  L IH T AH L  |  B IH T  |  N AW  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.03.15, Block: 9, Trial: 27\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  IH T S  |  S OW  |  F AA R  |  D AA  |  DH AH  |  R EH D  |  N AA T  |  M EY K  |  IH T  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.03.15, Block: 9, Trial: 28\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  G AA T  |  G EH T  |  K AE L  |  G UH D  |  V EH R IY  |  JH IH M  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.03.15, Block: 9, Trial: 29\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  HH UW  |  IH Z  |  DH AH  |  B EH S T  |  V EH R IY AH L AY N  |  R EY IY  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.03.15, Block: 9, Trial: 30\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  W EH N  |  W AA Z  |  K L AA L  |  D EH L AH V IH ZH AH N  |  IH V AY T AH N T  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.03.15, Block: 9, Trial: 31\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AY M  |  T AO K IH NG  |  AH B AW T  |  N AE SH ZH ER AH L  |  P IH L IH T AH L  |  K AH M EH K T S  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.03.15, Block: 9, Trial: 32\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  DH AH  |  W EY K S  |  M IY  |  Y UW S  |  R AH T  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.03.15, Block: 9, Trial: 33\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  SH IY  |  W AH T  |  R UW  |  TH R IY  |  HH AA L F IH S P ER Z  |  IH Z  |  M AH CH  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.03.15, Block: 9, Trial: 34\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  S AH M  |  AH V  |  DH EH M  |  AO R  |  F IH V AH L  |  T UW  |  Y UW  |  D R EH D IY NG  |  P R OW K ER Z S  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.03.15, Block: 9, Trial: 35\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  DH EH R  |  AA R  |  AH  |  N EH V ER  |  AH V  |  G UH D  |  M UW V IH Z  |  DH AY  |  DH AE T  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.03.15, Block: 9, Trial: 36\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  DH EY  |  SH UH D  |  JH AH S T  |  AO L  |  B IY  |  JH AH S T  |  N AY T  |  N AW  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.03.15, Block: 9, Trial: 38\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  B AH T  |  AH  |  AO L  |  T EY N  |  AO R  |  TH AH M TH  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.03.15, Block: 9, Trial: 39\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  W AH T  |  AE Z  |  DH IH S  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.03.15, Block: 9, Trial: 40\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  W IH L  |  AE K CH UW AH L IY  |  DH EY  |  M AY  |  IH B Z D AH S  |  B EH T S  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.03.15, Block: 9, Trial: 41\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  IH T  |  IH Z  |  F EY V IH NG  |  T UW  |  AE N  |  AA B V IH NG  |  K AH K L UW ZH  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.03.15, Block: 9, Trial: 42\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  IH T S  |  T UW  |  B AE K  |  DH AE T  |  HH AE P AH N  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.03.15, Block: 9, Trial: 43\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AY V  |  B IH K  |  K UH T  |  AH V  |  IH N  |  D R EH F IH  |  T W AY S  |  R EH T ER  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.03.15, Block: 9, Trial: 44\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AY V  |  N EH ER  |  S EH N S T  |  AW T  |  AH  |  Y UH R  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.03.15, Block: 9, Trial: 45\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  W IY  |  W EH R  |  W ER K S  |  IH N  |  W IY N T ER  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.03.15, Block: 9, Trial: 46\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AY  |  W EY K  |  AE T  |  DH AH  |  AH L W AW D  |  K R IH S AH Z  |  EH B AH L IY  |  HH IY R  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.03.15, Block: 9, Trial: 47\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AY  |  HH AE D  |  W AH T  |  K AE T  |  F AO R  |  AH N D IY  |  Y IH R Z  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.03.15, Block: 9, Trial: 48\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  JH AH S T  |  AH N D  |  K AH N CH ER  |  M IH Z IH K  |  AA R  |  M AY  |  F EY V ER AH T S  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.03.15, Block: 9, Trial: 49\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  SH IY  |  W AA Z  |  L IH V IH NG  |  IH N  |  AO R L AH L Z AH DH ER  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.03.17, Block: 6, Trial: 23\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  IH T  |  W AA Z  |  AH  |  D IH S IH ZH AH N  |  DH AE T  |  W UH D  |  P EY  |  AO F  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.03.17, Block: 6, Trial: 24\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  IH T  |  IH Z  |  HH AA R D  |  T UW  |  R IH M EH M B ER  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.03.17, Block: 6, Trial: 26\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AY  |  F IY L  |  S OW  |  S IH L IY  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.03.17, Block: 6, Trial: 28\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  CH EH K  |  DH AH  |  S AO V W EH R  |  V ER ZH AH N  |  B AY  |  T AY P IH NG  |  DH IH S  |  K AH M AE N D  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.03.17, Block: 6, Trial: 29\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AY  |  L AY V  |  IH N  |  AH  |  R IH L IY  |  S M AO L  |  AH P AA R T M AH N T  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.03.17, Block: 6, Trial: 30\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  M EY B IY  |  Y UW  |  L AY V  |  T UW  |  F AO R  |  AH W EY  |  F R AH M  |  Y AO R  |  F AE M AH L IY  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.03.17, Block: 6, Trial: 31\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AY  |  TH IH NG K  |  IH T  |  HH AE P AH N D  |  AH B AW T  |  T EH N  |  AO R  |  F IH F T IY N  |  Y IH R Z  |  AH G OW  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.03.17, Block: 6, Trial: 32\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AY  |  HH OW P  |  Y UW  |  EH N JH OY D  |  R EH D IH NG  |  DH IH S  |  B L AO G  |  P ER S T  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.03.17, Block: 6, Trial: 33\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  W IY  |  G OW  |  AA N  |  V EY K EY SH AH N  |  AE T  |  D IH F ER AH N T  |  P L EY S AH Z  |  EH V ER IY  |  Y IH R  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.03.17, Block: 6, Trial: 35\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AE K T ER  |  DH AE T  |  DH EY  |  W IH L  |  B IY  |  D IH S T R OY D  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.03.17, Block: 6, Trial: 36\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AY  |  L AY K  |  K L AE S IH K AH L  |  M Y UW Z IH K  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.03.17, Block: 6, Trial: 37\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  HH IY  |  IH Z  |  AH  |  TH AW AH P EH N T S  |  M AY  |  T R EY D  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.03.17, Block: 6, Trial: 38\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  L AY K  |  W EH N  |  AY  |  L AY V D  |  IH N  |  W AA SH IH NG T AH N  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.03.17, Block: 6, Trial: 39\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  DH AH  |  P L EY ER Z  |  AA R  |  P R IH T IY  |  IH N F ER K AH S T  |  AE T  |  DH IH S  |  P OY N T  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.03.17, Block: 6, Trial: 40\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AY  |  AO L W EY Z  |  G EH T  |  DH OW Z  |  S P AE M  |  F OW N  |  K AO L Z  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.03.17, Block: 6, Trial: 41\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  DH AE T  |  W AA Z  |  B IH F AO R  |  AY  |  M UW V D  |  AW T  |  HH IY R  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.03.17, Block: 6, Trial: 42\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AY  |  F ER G EH T  |  W EH R  |  SH IY  |  G AA T  |  IH T  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.03.17, Block: 6, Trial: 43\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  DH EY  |  W ER  |  IH L EH K T AH D  |  T UW  |  DH AH  |  K AH M IH T IY  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.03.17, Block: 6, Trial: 44\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AY  |  AO L S OW  |  R IH M EH M B ER  |  AH N D  |  IH L AH S T R IH T AH  |  V ER ZH AH N  |  AH V  |  DH IH S  |  S T AO R IY  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.03.17, Block: 6, Trial: 45\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  M AY  |  HH AH Z B AH N D  |  D IH D AH N T  |  L AY K  |  DH AE T  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.03.17, Block: 6, Trial: 46\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  B OW TH  |  T IY M Z  |  W AO K T  |  AH W EY  |  W IH DH  |  JH AH S T  |  W AH N  |  P OY N T  |  IY CH  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.03.17, Block: 6, Trial: 47\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  DH AH  |  T UW  |  M EY N  |  T AA R Z  |  AH V  |  DH AH  |  SH OW  |  G AA T  |  M EH R IY D  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.03.17, Block: 6, Trial: 48\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  IH T  |  W AA Z  |  AA N  |  DH AH  |  N UW Z  |  DH IH S  |  M AO R N IH NG  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.03.17, Block: 6, Trial: 49\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  HH AE Z  |  HH IY  |  EH V ER  |  B IH N  |  Y AO R  |  F EY V ER IH T  |  P L EY ER  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.03.17, Block: 7, Trial: 25\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  P AH B L IH K  |  CH IH M P AH N T EY SH AH N  |  ER AW N D  |  HH IY R  |  IH Z  |  B IH T IY  |  G UH D  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.03.17, Block: 7, Trial: 26\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  IH T  |  P EH Z AH N T  |  S IY M  |  L AY K  |  DH EY  |  AA R  |  T EH IY  |  M AH K S T  |  W IH DH  |  IH T  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.03.17, Block: 7, Trial: 27\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  DH AE T  |  N AY  |  W AA Z  |  R IH F AA R K AH B L IY  |  IH N EH P AH T AH D  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.03.17, Block: 7, Trial: 28\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AY  |  L AY K  |  T UW  |  HH AE V  |  S AH M B AA D IY  |  K AH M  |  W IH DH  |  M AH  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.03.17, Block: 7, Trial: 29\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AY D  |  L AY K  |  T UW  |  T UW  |  DH AE T  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.03.17, Block: 7, Trial: 30\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AY  |  G R UW  |  AH P  |  IH N  |  AH N L AH HH AH V AH  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.03.17, Block: 7, Trial: 31\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AY D  |  S EY  |  IH T  |  W AA Z  |  AH B AW T  |  T W EH N T IY  |  F AO R  |  IH N T AH R AH D  |  D AA L ER Z  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.03.17, Block: 7, Trial: 32\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AE V IH NG  |  P ER S IH AH B EY T ER D  |  IH N  |  JH UH R IY  |  D UW T IH NG  |  M AE S EH L F  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.03.17, Block: 7, Trial: 33\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  P EY S IH NG  |  DH AE T  |  AA T  |  T UW  |  IY CH  |  AH DH ER  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.03.17, Block: 7, Trial: 34\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  S IY M Z  |  L AY K  |  AY  |  JH AH S T  |  M AA T  |  IH T  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.03.17, Block: 7, Trial: 35\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AY  |  N OW  |  AY  |  HH AE V  |  T UW  |  D UW  |  M AY  |  ER IH B IH N S  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.03.17, Block: 7, Trial: 36\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  CH AE N S AH N  |  IH Z  |  V AW IH NG  |  T UW  |  AH P IY R L  |  DH AH  |  D AH IH S IH ZH AH N  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.03.17, Block: 7, Trial: 37\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  W AY  |  W AA Z  |  DH IH S  |  D IH S IH ZH AH N  |  M AE D  |  IH T  |  W AY  |  N AW  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.03.17, Block: 7, Trial: 38\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AE Z  |  EH N IY  |  S IH T IY  |  K W OW Z  |  IH T  |  G EH T S  |  M AO R  |  T IH CH ER AH N  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.03.17, Block: 7, Trial: 39\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  IH T  |  W AA Z  |  R IH L IY  |  P R IH T IY  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.03.17, Block: 7, Trial: 40\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  IH F  |  Y UW  |  AA R  |  G UH D  |  W IY  |  K AE N  |  G OW  |  G EH T  |  AW S  |  L AY V  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.03.17, Block: 7, Trial: 41\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  IH T  |  AH  |  T AW N  |  AH K IH S AH N T  |  T UW  |  AO L W EY Z  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.03.17, Block: 7, Trial: 42\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  EH V R IY B AA D IY  |  S IY M Z  |  T UW  |  L AY K  |  DH AE T  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.03.17, Block: 7, Trial: 43\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  B IH K AO Z  |  Y UW  |  HH ER N D  |  IH T  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.03.17, Block: 7, Trial: 44\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  W IY R  |  N AA T  |  M AY IH NG  |  EH N IY TH IH NG  |  AH N D  |  DH IH S  |  P EY N  |  IH N  |  T AY M  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.03.17, Block: 7, Trial: 45\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  DH EY  |  K UH D  |  B IY  |  SH AH S T  |  AH B AW T  |  IY K Y AH L  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.03.17, Block: 7, Trial: 46\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  DH EY  |  D IH D AH N T  |  HH AE V  |  EH N IY  |  P R AA B AH M  |  D UW IH NG  |  IH T  |  DH AH  |  W ER S T  |  T AY M  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.03.17, Block: 7, Trial: 47\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  IH T AH L  |  AH P  |  IH N  |  S AH M  |  W EH R  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.03.17, Block: 7, Trial: 48\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  DH IH S  |  V ER V IY  |  IH Z  |  R IH L IY  |  AA N  |  T EH L AH V IH ZH AH N  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.03.17, Block: 7, Trial: 49\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  EH V R IY B AA D IY  |  HH AE Z  |  DH AE T  |  S EY M  |  M AE N D  |  S AH N T  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.05.10, Block: 7, Trial: 25\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  G ER L Z  |  R EH N IH IY NG  |  S IH S T AH Z  |  L AO DH Z  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.05.10, Block: 7, Trial: 26\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  Y UW  |  P R AA B AH B L IY  |  W UH D AH N T  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.05.10, Block: 7, Trial: 27\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  IH T  |  W AA Z  |  AA N  |  DH AH  |  N UW Z  |  EH V ER IY  |  N EY T  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.05.10, Block: 7, Trial: 28\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  IH Z  |  S T AO R IY  |  IH Z  |  N AA T  |  AH K Y UW ZH AH W AH L  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.05.10, Block: 7, Trial: 29\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AH N D  |  D OW K T  |  W IH DH  |  S AH M  |  AO L IH V N Z  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.05.10, Block: 7, Trial: 30\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AY  |  HH AE D  |  F AW L D  |  AE N  |  IH N CH R IY AH  |  P OY N T  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.05.10, Block: 7, Trial: 31\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  DH EY  |  D OW N T  |  K EH L  |  DH EH M  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.05.10, Block: 7, Trial: 32\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  S OW L IH NG  |  DH AH  |  W AO T ER  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.05.10, Block: 7, Trial: 33\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  B IH Z N AH S  |  IH Z  |  R UW ZH AH W AH L  |  F AO R  |  T R EY D ER Z  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.05.10, Block: 7, Trial: 34\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  DH EY  |  G EY V  |  AH S  |  AH  |  M EH S SH AH L  |  D IY L  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.05.10, Block: 7, Trial: 35\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  DH AH  |  R IY AH L AH T IY  |  IH Z  |  IH T S  |  Y UW ZH AH W AH L IY  |  N AA T  |  DH AH  |  G K EY S  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.05.10, Block: 7, Trial: 36\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AY  |  W AO N D ER  |  W EH R  |  DH EY  |  D UW  |  DH AE T  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.05.10, Block: 7, Trial: 37\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  HH IY  |  K EH P T  |  IH Z  |  D OW N  |  L AY K T  |  AH N D  |  K AE SH AH W AH L  |  B AH T  |  F R EY M  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.05.10, Block: 7, Trial: 38\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  P EH R AH N OY T IH D  |  IH N  |  DH AH  |  P AE S T  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.05.10, Block: 7, Trial: 39\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  DH EH R  |  M UW V IY  |  T UW  |  R EH L AH T AH  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.05.10, Block: 7, Trial: 40\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AH N D  |  AY  |  AO L W EY Z  |  DH AE T  |  IH N  |  W AA Z  |  K AY N D  |  AH V  |  AW T  |  AH V  |  M EH ZH AH N  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.05.10, Block: 7, Trial: 41\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  W IY  |  D IH D  |  F AY N D  |  S IH M F AH L  |  K UH D  |  T AA K S AH Z  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.05.10, Block: 7, Trial: 42\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  W AH T  |  G R UW P  |  Y UW  |  HH AE P AH N  |  T UW  |  B IY  |  IH N  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.05.10, Block: 7, Trial: 43\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  DH EH R  |  IH Z  |  AH  |  K AH M P AH N EY SH AH N  |  AO L DH AH  |  DH AA P  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.05.10, Block: 7, Trial: 44\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  DH AE T S  |  W AH T  |  AY  |  D IH D  |  W EH N  |  AY  |  W AA Z  |  T R ER IH NG  |  AH P  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.05.10, Block: 7, Trial: 45\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AY  |  R IH L IY  |  W AO N T IH D  |  T UW  |  G OW  |  AA N  |  DH AH  |  R AE F T IH NG  |  T R AH M  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.05.10, Block: 7, Trial: 46\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  W IY  |  W EH N T  |  W IH DH  |  S AH M  |  F R EH N D Z  |  AH V  |  AW ER Z  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.05.10, Block: 7, Trial: 47\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AY  |  K AE N  |  M EY K  |  M AY  |  P AY Z  |  F R AH M  |  K R AE S  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.05.10, Block: 7, Trial: 48\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  N AA T  |  T OW T AH L  |  B AH T  |  S AH S T  |  F R AH M  |  K AA R Z  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.05.10, Block: 7, Trial: 49\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  DH AH  |  OW L D ER  |  OW L D  |  M IY T IY  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.06.14, Block: 12, Trial: 25\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AY  |  TH IH NG K  |  S UW T ER  |  AA R  |  L EY T ER  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.06.14, Block: 12, Trial: 26\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  S EH N D  |  M IY  |  S AH M  |  M AH N IY  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.06.14, Block: 12, Trial: 27\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  Y UW  |  G EH T  |  AH  |  L AA T  |  AH V  |  R EH F IH K S  |  IH N  |  DH EH R  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.06.14, Block: 12, Trial: 28\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  IH F  |  AY  |  W AA Z  |  S EY T IH NG  |  AH P  |  AH  |  D EY  |  K IH L  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.06.14, Block: 12, Trial: 29\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  HH IY  |  W AA Z  |  F AW N D  |  D EY D  |  AE F T ER  |  AE N  |  IH K S P L OW ZH AH N  |  W AA Z  |  HH ER D  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.06.14, Block: 12, Trial: 30\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  D UW  |  AH  |  Y IH R  |  L AO NG  |  P R AA JH EH N T  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.06.14, Block: 12, Trial: 31\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  W EH N  |  W UH D  |  P IY P AH L  |  T UW  |  IH T  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.06.14, Block: 12, Trial: 32\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AY M  |  N AA T  |  K W AY T  |  AE Z  |  B IH G  |  AH V  |  DH AE T  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.06.14, Block: 12, Trial: 33\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AY  |  AE V  |  N AA T  |  D AO T AH N IY  |  EH N IY  |  R IH K OY S  |  G R EH T  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.06.14, Block: 12, Trial: 34\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  B AE S AH Z  |  DH AE T  |  DH EY  |  Y UW Z  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.06.14, Block: 12, Trial: 35\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AE K CH UW AH L IY  |  DH EY  |  HH AE V  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.06.14, Block: 12, Trial: 36\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  EH N IY TH IH NG  |  R AY  |  DH AE T  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.06.14, Block: 12, Trial: 37\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  IH T  |  W AA Z  |  DH AH  |  R AY T  |  D IH S IH ZH AH N  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.06.14, Block: 12, Trial: 38\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  M OW T ER AH N T S  |  AA R  |  IH V AY S D  |  T UW  |  IH V OY D  |  DH AH  |  EH R IY AH  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.06.14, Block: 12, Trial: 39\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  CH IH K CH IH NG  |  DH AH  |  B L AA G Z  |  AH N D  |  S T AH F  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.06.14, Block: 12, Trial: 40\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  Y UW  |  HH AE V  |  DH AH  |  CH EH N S  |  T UW  |  R IH L IY  |  R IY EH N D  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.06.14, Block: 12, Trial: 41\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  B IY IH NG  |  IH N  |  IH N CH ER IH R  |  N AW  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.06.14, Block: 12, Trial: 42\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  HH IY  |  L AY K S  |  T UW  |  S IY  |  L OW Z  |  IH N  |  CH ER CH JH  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.06.14, Block: 12, Trial: 43\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AE D V AY S  |  AA N  |  S AH N  |  AO R  |  D AO T ER  |  G OW IH NG  |  T UW  |  K AA L IH JH  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.06.14, Block: 12, Trial: 44\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  Y UW  |  D OW N T  |  W UH D  |  T UW  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.06.14, Block: 12, Trial: 45\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AY M  |  IH N  |  DH AH  |  N EY V IH  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.06.14, Block: 12, Trial: 46\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  HH AE V  |  Y UW  |  HH ER D  |  DH AE T  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.06.14, Block: 12, Trial: 47\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  IH T  |  K AH N AA T  |  B IY  |  M EH ZH AH N  |  AH N D  |  Y EH T  |  IH T  |  IH G Z IH S T  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.06.14, Block: 12, Trial: 48\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AY  |  TH IH NG K  |  B IY AE N OW  |  IH Z  |  AO L W EY Z  |  G UH D  |  P OW K R AH N D  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.06.14, Block: 12, Trial: 49\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  T R AY IH NG  |  T UW  |  S T IH K  |  IH N  |  W IH DH  |  DH AE T  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.07.19, Block: 9, Trial: 26\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AH N S F AO R AH N AH T L IY  |  DH EY  |  AA R  |  N AA T  |  G UH D  |  F IH T ER Z  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.07.19, Block: 9, Trial: 27\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AY  |  TH IH NG K  |  AH  |  N AA T  |  AH  |  L AA T  |  AH V  |  P IY P AH L  |  F EH R  |  DH AE T  |  M AY  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.07.19, Block: 9, Trial: 28\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  W IY  |  JH UH N  |  HH AE V  |  AH D M AA R T IH D  |  IH T  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.07.19, Block: 9, Trial: 29\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  JH UW N  |  AO F  |  DH AH  |  T EH L AH V IH ZH AH N  |  AH N D  |  S T EY  |  AH V  |  DH AH  |  K AH M P Y UW T ER  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.07.19, Block: 9, Trial: 30\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  F IH N S  |  T W AO R D Z  |  W AH N  |  AH G EH DH ER  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.07.19, Block: 9, Trial: 31\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AH V  |  K AA R Z  |  Y UW  |  K AE N  |  B AY  |  S T AA K  |  IH N  |  DH AH  |  K AH M P AH N IY  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.07.19, Block: 9, Trial: 32\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  W AA Z  |  DH AH  |  M EY N D  |  N AA T  |  V AA SH AH M B AH L  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.07.19, Block: 9, Trial: 33\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AY  |  N IY D  |  T UW  |  M EY K  |  AH  |  F OW N  |  K AO L  |  AO R  |  T UW  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.07.19, Block: 9, Trial: 34\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AY  |  R IH L IY  |  EH N JH OY D  |  IH T  |  W AY T  |  AH  |  P EY T  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.07.19, Block: 9, Trial: 35\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  IH T  |  W IH L  |  B IY  |  AW ER  |  F ER S  |  CH EY N JH  |  T UW  |  S IY  |  IY CH  |  AH DH ER  |  IH N  |  K W AY T  |  AH W EH L  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.07.19, Block: 9, Trial: 36\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  EH K S P L AO L  |  B IH F AO R  |  Y UW  |  EH K S P L OY D T  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.07.19, Block: 9, Trial: 37\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  Y AO R  |  R EH K AH M  |  T UW  |  K AH M  |  OW V ER  |  EH N IY N AY M  |  W IH TH AW T  |  N UW T ER Z  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.07.19, Block: 9, Trial: 38\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  W AH T  |  G UH D  |  B IY  |  EH N T AH S IH NG  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.07.19, Block: 9, Trial: 39\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AY  |  TH IH NG K  |  DH AE T S  |  DH AH  |  M EY N  |  P R AA B L AH M  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.07.19, Block: 9, Trial: 40\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  W AY  |  W UH D  |  AH  |  W AH N  |  T UW  |  B AY  |  M AO R  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.07.19, Block: 9, Trial: 41\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  HH AW  |  M AH CH  |  P AH S IH ZH AH N  |  T UW  |  Y UW  |  N IY D  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.07.19, Block: 9, Trial: 42\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AY  |  HH AE V  |  N AA T  |  D AY T AH N  |  DH EH M  |  IH N  |  AH  |  L AO NG  |  T AY M  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.07.19, Block: 9, Trial: 43\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  HH IY  |  OW L D  |  IH Z  |  AE N ER S EY SH AH N T  |  JH UW IY  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.07.19, Block: 9, Trial: 44\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AY  |  P EY  |  F AO R  |  DH AH  |  AH N S T AH  |  D IH N AH L  |  IH N UW AH N S  |  P L AA S  |  V IH ZH AH N  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.07.19, Block: 9, Trial: 45\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AY  |  N OW  |  DH AE T  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.07.19, Block: 9, Trial: 46\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AY  |  R IY D  |  DH AH  |  W AY L  |  T R EY D  |  D IH T AH L  |  AH N D  |  DH AH  |  N UW  |  Y UW L  |  T AY M Z  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.07.19, Block: 9, Trial: 47\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  DH EH N  |  AY  |  W AH N T  |  AE K CH R UW  |  W IH DH  |  IH T  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.07.19, Block: 9, Trial: 48\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  W IY  |  G EH T  |  D IH S IH N EY T IH D  |  AA R  |  DH AH  |  T AY M  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.07.19, Block: 9, Trial: 49\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  D UW  |  Y UW  |  V IH L AO Z  |  W AY  |  DH AH  |  Y UW N AY T IH D  |  S T EY N S Z  |  W AA Z  |  IH N  |  DH AH  |  B IH D AH L  |  IH T S  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.07.19, Block: 10, Trial: 25\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  DH AH  |  CH IH L T R IY  |  IH Z  |  IH S P IH R IY AH S IY  |  AE N  |  EH K AH N AA M IH K  |  L OW D EY  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.07.19, Block: 10, Trial: 26\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  HH IY  |  T OW T IH T IH D  |  IH Z  |  R EH R AH L T IY Z  |  T UW  |  DH EH M  |  EH V ER IY  |  T AY M  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.07.19, Block: 10, Trial: 27\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  EH N S ER S T EY T  |  K L OW S ER Z  |  AA R  |  P R IY G EH T IH NG  |  AH  |  L AA T  |  AH V  |  T R AY V IH NG  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.07.19, Block: 10, Trial: 28\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  DH AH  |  P AH L IY S  |  G AA T  |  DH EH M  |  R AY D  |  AE N T ER D  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.07.19, Block: 10, Trial: 29\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  Y UW  |  HH AE V  |  B IH N  |  IH N V AA L V D  |  IH N  |  AE N  |  AH K AH L IH ZH AH N  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.07.19, Block: 10, Trial: 30\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  K L OW Z  |  T UW  |  S IY  |  L EH V AH L  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.07.19, Block: 10, Trial: 31\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  D OW N T  |  Y UW  |  W EY K  |  Y UW  |  AH N D  |  B IH N  |  AE P AH L  |  T UW  |  G OW  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.07.19, Block: 10, Trial: 32\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  IH T  |  T EY P S  |  Y UW  |  IH N  |  G AO N  |  K AH M P AH N IY  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.07.19, Block: 10, Trial: 33\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AY M  |  AH  |  D IH V AY ZH D  |  W AO M AH N T  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.07.19, Block: 10, Trial: 34\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  HH AW  |  M AH CH  |  M AO R  |  L AW D  |  G EH T  |  DH AH  |  G EH T  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.07.19, Block: 10, Trial: 35\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  W IY  |  AA R  |  R AY V AH L  |  F AO R  |  DH AH  |  P L EY ZH ER  |  AH V  |  S ER V IH NG  |  Y UW R  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.07.19, Block: 10, Trial: 36\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  DH EY  |  T EH N D  |  T UW  |  M EY K  |  D IH S IH ZH AH N  |  M EY K S T  |  AA N  |  DH EH R  |  M UW D  |  AE N  |  AH  |  S AA R T AH N  |  T AY M  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.07.19, Block: 10, Trial: 37\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  Y UW  |  AO L  |  G AA T  |  AH  |  P EY  |  W EY Z  |  DH IH S  |  Y IH R  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.07.19, Block: 10, Trial: 38\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  TH IH NG K  |  AH B AW T  |  DH IH S  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.07.19, Block: 10, Trial: 39\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  HH IY  |  P L AE B IH SH T  |  AH  |  P EY P ER  |  AH N  |  DH AH  |  S AA B JH R AH D  |  L AE S T  |  Y IH R  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.07.19, Block: 10, Trial: 40\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  DH AH  |  S AH P R IY M  |  K AO R T  |  W EH R  |  B IH  |  AH  |  D IH S IH ZH AH N  |  D AH D EY  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.07.19, Block: 10, Trial: 41\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AH N D  |  AO L  |  AH V  |  AH  |  S IH T IH D  |  DH EY  |  W ER  |  K G AA R D  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.07.19, Block: 10, Trial: 42\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  DH IH S  |  IH Z  |  DH EH R  |  Y IH R L IY  |  K AH M ER S EY SH AH N  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.07.19, Block: 10, Trial: 43\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  TH AH DH ER N  |  T EH L AH V F AO R JH AH  |  AH N D  |  S T IH L  |  P R IH T IY  |  L AA R JH  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.07.19, Block: 10, Trial: 44\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AY  |  W AA Z  |  IH N  |  AH  |  S IH M AH L AH IY  |  S IH N CH UW M EY SH AH N  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.07.19, Block: 10, Trial: 45\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  DH IH S  |  IH Z  |  DH AH  |  P OY N T  |  W EH R  |  Y UW  |  W AA N T  |  T UW  |  T EY S T  |  IH T  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.07.19, Block: 10, Trial: 46\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  L AE S T  |  IH  |  S AE T ER D T IY  |  W IY  |  AO L  |  W EY T  |  AW T  |  T UW  |  D IH T ER  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.07.19, Block: 10, Trial: 47\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AY  |  W AA Z  |  V EH R IY  |  OW P F AH L  |  EH N IY W EY  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.07.19, Block: 10, Trial: 48\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AY  |  G EH S  |  M AY  |  K AH N S AH N D  |  IH Z  |  AH B AW T  |  DH AH  |  AO R D AH IH NG  |  DH AE T  |  W IY  |  AA R  |  R IH D IH NG  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.07.19, Block: 10, Trial: 49\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  M AY  |  K AH M P Y UW T ER  |  HH AE Z  |  G UH D  |  S T AO R IH JH S IH NG  |  K AH M EY JH IH T IY  |  AH N D  |  IH T  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.07.21, Block: 6, Trial: 24\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AY  |  HH AE V AH N T  |  B IH N  |  B AE K  |  HH OW M  |  IH N  |  F AY V  |  Y IH R Z  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.07.21, Block: 6, Trial: 25\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  W IY V  |  G AA T  |  T UW  |  L IH V IH NG  |  R UW M Z  |  IH N  |  AW ER  |  N UW  |  HH AW S  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.07.21, Block: 6, Trial: 26\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  Y UW  |  W UH D  |  TH IH NG K  |  S OW  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.07.21, Block: 6, Trial: 27\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AY  |  D OW N T  |  W AA N T  |  T UW  |  M AE S  |  EH N IY TH IH NG  |  AH P  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.07.21, Block: 6, Trial: 28\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  B AH T  |  DH AE T S  |  DH AH  |  P OY N T  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.07.21, Block: 6, Trial: 29\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  DH AE T  |  IH Z  |  AH  |  G UH D  |  AH AY D IY AH  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.07.21, Block: 6, Trial: 30\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AY  |  D OW N T  |  F IY L  |  V EH R IY  |  G UH D  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.07.21, Block: 6, Trial: 31\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AY  |  HH AE V  |  AO L R EH D IY  |  P R AA S T AH S T  |  S AH M  |  AH V  |  DH EH M  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.07.21, Block: 6, Trial: 32\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AY  |  V AE L Y IY  |  HH ER  |  AH P IH N Y AH N  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.07.21, Block: 6, Trial: 33\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  T IY K S  |  HH ER  |  T UW  |  R AY T  |  HH ER  |  N EY M  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.07.21, Block: 6, Trial: 34\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  S IY  |  IH F  |  DH EH R  |  IH Z  |  S AH M W AH N  |  AE T  |  DH AH  |  D AO R  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.07.21, Block: 6, Trial: 37\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  IH T S  |  G UH D  |  P R AA P ER EY SH AH N  |  F AO R  |  K AA L IH JH  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.07.21, Block: 6, Trial: 39\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AY  |  L AH V  |  DH IH S  |  T IY M  |  AH N D  |  DH AH  |  N UW  |  K AH CH  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.07.21, Block: 6, Trial: 40\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  DH AH  |  AO R IH K AH N T  |  W IH L  |  IH T  |  S IH N T AH L  |  AH N D  |  S AW TH  |  AH M EH R IH K AH  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.07.21, Block: 6, Trial: 41\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  DH AE T  |  IH Z  |  R AY T  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.07.21, Block: 6, Trial: 42\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  DH EH R  |  IH Z  |  K W AY T  |  AH  |  B IH T  |  AH V  |  K R AY M  |  IH N  |  DH AE T  |  N EH B ER AO D T  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.07.21, Block: 6, Trial: 43\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AY  |  D IH D AH N T  |  M AY N D  |  D UW IH NG  |  DH AE T  |  AE T  |  AO L  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.07.21, Block: 6, Trial: 44\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  D IH D  |  Y UW  |  G EH T  |  T UW  |  T AO K  |  T UW  |  HH IH M  |  B IH F AO R  |  HH IY  |  L EH F T  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.07.21, Block: 6, Trial: 45\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  B IH K AO Z  |  DH EH R  |  D EH N D  |  W AA Z  |  AE T  |  W ER K  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.07.21, Block: 6, Trial: 46\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  DH AH  |  S UW N AE L AH T IY K S  |  AA R  |  ER R EH D IY  |  P EY D  |  F AO R  |  DH IH S  |  B OW TH  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.07.21, Block: 6, Trial: 47\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  W IY  |  Y UW ZH AH W AH L IY  |  D IH S AH S  |  B IH Z N AH S  |  OW V ER  |  L AH N CH  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.07.21, Block: 6, Trial: 48\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  HH IY  |  D AH Z AH N T  |  R IH L IY  |  P EY  |  AH T EH N SH AH N  |  IH N  |  K L AE S  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.07.21, Block: 6, Trial: 49\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  IH T S  |  W EH L  |  W ER TH  |  IH T  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.07.21, Block: 7, Trial: 24\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  W AH T  |  K AY N D  |  AH V  |  W ER K  |  D UW  |  Y UW  |  D UW  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.07.21, Block: 7, Trial: 25\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  W IY  |  W ER N T  |  SH UH R  |  HH AW  |  T UW  |  D UW  |  DH AE T  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.07.21, Block: 7, Trial: 26\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  DH EY  |  HH AE V  |  DH IY Z  |  F AH N  |  L IH T AH L  |  P AA R T IH Z S  |  AE T  |  N AY T  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.07.21, Block: 7, Trial: 27\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  DH EY  |  HH AE V  |  N AA T  |  B IH N  |  M EY D  |  AH W EH R  |  AH V  |  DH IH S  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.07.21, Block: 7, Trial: 28\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AE T  |  DH AE T  |  P OY N T  |  SH IY  |  W AA Z  |  AO L R EH D IY  |  G AO N  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.07.21, Block: 7, Trial: 29\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AY  |  D OW N T  |  W AA N T  |  T UW  |  P EY  |  HH ER  |  T UW  |  B IY  |  AH  |  P EY B IY  |  S IH T ER  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.07.21, Block: 7, Trial: 30\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  W EH N  |  D IH D  |  DH EY  |  M EY K  |  DH AE T  |  B UH K  |  IH N T UW  |  AH  |  M UW V IY  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.07.21, Block: 7, Trial: 32\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AY V  |  S IY N  |  AO L  |  AH V  |  DH IH S  |  B IH F AO R  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.07.21, Block: 7, Trial: 34\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  W IY  |  HH AE D  |  AH N D  |  HH AE P R IY NG  |  AH V  |  DH AH  |  F L UW  |  L AE S T  |  B OW TH  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.07.21, Block: 7, Trial: 35\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AO L W EY Z  |  AH  |  P L EH ZH ER  |  T UW  |  S IY  |  AH N D  |  T AO K  |  T UW  |  DH EH M  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.07.21, Block: 7, Trial: 36\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  DH EH R Z  |  AH  |  P AA N T  |  AH V  |  M IY  |  DH AE T  |  M IH S AH Z  |  DH EH M  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.07.21, Block: 7, Trial: 37\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  D UW  |  W IY  |  HH AE V  |  T UW  |  W EY T  |  AH N T IH L  |  EH V R IY W AH N  |  IH Z  |  W AO T IY  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.07.21, Block: 7, Trial: 38\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  DH EY  |  V IH Z IH T AH N T  |  DH EH R  |  R IH N M AH DH ER  |  AE T  |  DH AH  |  N ER S IH NG  |  HH OW M  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.07.21, Block: 7, Trial: 39\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  IH T S  |  G AA T  |  P IY P AH L  |  S ER M IH NG  |  F AO R  |  JH OY  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.07.21, Block: 7, Trial: 40\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  N AA T  |  EH V R IY B AA D IY  |  HH AE Z  |  AH  |  P IH CH ER  |  P ER F AH N T  |  B AA R IY  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.07.21, Block: 7, Trial: 41\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  Y UW  |  W IH L  |  B IY  |  L ER N IH NG  |  L AA T S  |  AH V  |  N UW  |  S T AH F  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.07.21, Block: 7, Trial: 42\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  DH AH  |  P IY P AH L  |  AA R  |  R IH L IY  |  N AY S  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.07.21, Block: 7, Trial: 43\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  EH V R IY B AA D IY  |  JH AH S T  |  L AH V Z  |  IH T  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.07.21, Block: 7, Trial: 44\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  Y UW  |  M AY T  |  B IY  |  L AY K  |  M IY  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.07.21, Block: 7, Trial: 45\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AY  |  G EH S  |  IH T  |  W AA Z  |  L AE S T  |  Y IH R  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.07.21, Block: 7, Trial: 46\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  IH T  |  JH AH S T  |  HH AE P AH N D  |  W IH DH IH N  |  DH AH  |  L AE S T  |  TH R IY  |  W IY K S  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.07.21, Block: 7, Trial: 47\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  IH T  |  W AA Z AH N T  |  R IH L IY  |  DH AE T  |  IH M P AO R T AH N T  |  T UW  |  M IY  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.07.21, Block: 7, Trial: 48\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AY  |  D OW N T  |  N OW  |  AH V  |  EH N IY  |  AH DH ER  |  S T EY T  |  W IH DH  |  DH IH S  |  P AA L AH S IY  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.07.21, Block: 7, Trial: 49\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AY  |  K UH D  |  HH IY R  |  DH AH  |  T EH R ER  |  IH N  |  IH Z  |  V OY S  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.07.28, Block: 6, Trial: 24\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AH N D  |  AY  |  AO L W EY Z  |  TH AO T  |  IH T  |  W AA Z  |  K AY N D  |  AH V  |  AW T  |  AH V  |  F EH AE SH AH N  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.07.28, Block: 6, Trial: 25\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  W IY  |  D IH D  |  F AY N D  |  S AE M AH L  |  G UH D  |  D AA K T ER Z  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.07.28, Block: 6, Trial: 26\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  IH T  |  D IH P EH N D Z  |  W AH T  |  G R UW P  |  Y UW  |  HH AE P AH N  |  T UW  |  B IY  |  IH N  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.07.28, Block: 6, Trial: 28\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  DH AE T S  |  W AH T  |  AY  |  D IH D  |  F AO R  |  M AH N IY  |  W EH N  |  AY  |  W AA Z  |  G R OW IH NG  |  AH P  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.07.28, Block: 6, Trial: 29\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AY  |  R IH L IY  |  W AO N T IH D  |  T UW  |  G OW  |  AA N  |  DH AH  |  W AY F IH K NG  |  T R IH M P  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.07.28, Block: 6, Trial: 30\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  W IY  |  W EH N T  |  W IH DH  |  S AH M  |  F R EH N D Z  |  AH V  |  AW ER Z  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.07.28, Block: 6, Trial: 31\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AY  |  K AE N  |  M EY K  |  M AY  |  P AY L Z  |  F R AH M  |  S K R EH S  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.07.28, Block: 6, Trial: 32\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  DH AH  |  OW L D ER  |  OW L D  |  P IY P AH L  |  AA R  |  S OW  |  OW L D  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.07.28, Block: 6, Trial: 33\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  Y UW  |  OW N L IY  |  N IY D  |  T UW  |  D UW  |  IH T  |  W AH N S  |  F AO R  |  AH  |  T OW T AH L  |  B IH N  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.07.28, Block: 6, Trial: 34\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  B AH T  |  AE T  |  W ER T  |  P OY N T  |  D IH D  |  DH AH  |  F IY R  |  R IH L IY  |  S EH T  |  IH N  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.07.28, Block: 6, Trial: 35\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AY  |  HH AE V  |  B IH N  |  IH N  |  P ER Z AH N  |  AO L  |  M AY  |  L AY F  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.07.28, Block: 6, Trial: 36\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  DH EY V  |  G AA T  |  AH  |  G UH D  |  TH IH NG  |  G OW IH NG  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.07.28, Block: 6, Trial: 37\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  DH AH  |  W EY  |  Y UW  |  HH AE N D AH L  |  Y ER S EH L F  |  IH Z  |  IH M S P EH N S IH V  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.07.28, Block: 6, Trial: 38\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  M AY  |  W AY F  |  W UH D  |  JH AH S T  |  L AH V  |  DH AE T  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.07.28, Block: 6, Trial: 39\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AW ER  |  V AE L Y ER Z  |  AH V  |  D IH V ER S AH T IY  |  AH N D  |  IH N K L UW SH AH N  |  AA R  |  D R AH G  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.07.28, Block: 6, Trial: 40\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  IH F  |  Y UW  |  P L EY  |  R EH G Y AH L ER  |  D IH F AH K AH N T IY  |  IH T  |  IH Z  |  N AA T  |  S OW  |  B AE D  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.07.28, Block: 6, Trial: 41\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  W EH R  |  L IH V IH NG  |  IH N  |  AH  |  R EH L AH N T AH L F L IY  |  N UW  |  EH R IY AH  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.07.28, Block: 6, Trial: 42\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  D AW N  |  DH EH R  |  AA N  |  DH AH  |  F IH F S IH NG  |  W AY F  |  B AY  |  DH AH  |  P IH L Z  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.07.28, Block: 6, Trial: 43\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  W EH L  |  AY L  |  B IY  |  W IH DH  |  AH DH ER  |  P IY P AH L  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.07.28, Block: 6, Trial: 44\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AY  |  G EH S  |  W IY  |  D UW  |  G EH T  |  IH T  |  F R AH M  |  P IY P AH L  |  T UW  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.07.28, Block: 6, Trial: 45\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  M EY B IY  |  W IY  |  SH UH D  |  M UW V  |  T UW  |  DH AH  |  S AW TH  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.07.28, Block: 6, Trial: 46\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  HH AW  |  M EH N IY  |  AH V  |  DH IY Z  |  K OY N Z  |  W IH L  |  W IY  |  N IY D  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.07.28, Block: 6, Trial: 47\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  IH F  |  Y UW  |  D R IH NG K  |  AH  |  L AA T  |  AH V  |  K AE N F IH N  |  Y UW L  |  S T EY  |  AH W EY  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.07.28, Block: 6, Trial: 48\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  SH OW IH NG  |  D IH T AH  |  IH Z  |  AE N  |  EH K S AH L AH N T  |  W EY  |  T UW  |  P R UW V  |  AH  |  P OY N T  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.07.28, Block: 6, Trial: 49\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  IH T  |  W AA Z  |  AH  |  K AH R D L AH N S  |  F OW N  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.07.28, Block: 7, Trial: 24\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AY  |  D UW  |  N AA T  |  CH AA R JH  |  IH K S EH P T  |  F AO R  |  AH M ER JH AH N IY Z  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.07.28, Block: 7, Trial: 25\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AY L  |  B IY  |  DH EH R  |  IH N  |  DH AH  |  AE F T ER N UW N  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.07.28, Block: 7, Trial: 26\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  DH AE T S  |  G OW  |  V IH Z IH T  |  F AO R  |  L AY K  |  AH  |  SH AO R T  |  W IY K EH N D  |  AO R  |  S AH M TH IH NG  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.07.28, Block: 7, Trial: 27\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AY  |  TH IH NG K  |  DH AE T S  |  DH AH  |  W EY  |  DH IH S  |  IH Z  |  D AH N  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.07.28, Block: 7, Trial: 28\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AH  |  P UH T  |  AH V  |  DH AH  |  S EH K S T AH M  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.07.28, Block: 7, Trial: 29\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  EH V R IY W AH N  |  N OW Z  |  HH AW  |  T UW  |  M EY K  |  AH  |  T UW N AH  |  F IH SH  |  S AW M P L IH N JH  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.07.28, Block: 7, Trial: 30\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AY  |  G EH T  |  R IH M EH M B ER  |  DH AH  |  G AY L Z  |  N EY M  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.07.28, Block: 7, Trial: 31\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  W AH T  |  D UW  |  Y UW  |  TH IH NG K  |  AH B AW T  |  DH IH S  |  R IY S ER CH  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.07.28, Block: 7, Trial: 32\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  W IY  |  L AH V  |  IY T IY  |  F R EH SH  |  V EH JH T AH B AH L Z  |  IH N  |  DH AH  |  S AH M ER  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.07.28, Block: 7, Trial: 33\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  Y UW  |  K AE N  |  S IY  |  W AH T  |  AY  |  M IY N  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.07.28, Block: 7, Trial: 34\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AY  |  AE M  |  AH N D  |  EY ZH AH N  |  W IH M AH N  |  W IH DH  |  AH  |  W AY T  |  B OY F R EH N T  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.07.28, Block: 7, Trial: 36\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  W IY  |  F EH L T  |  G OW N T IY  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.07.28, Block: 7, Trial: 37\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AY  |  R IH L IY  |  L AY K  |  IH T  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.07.28, Block: 7, Trial: 38\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  Y UW  |  K AE N  |  S IH T  |  IH N  |  DH AH  |  S AH N  |  AO L  |  D EY  |  ER AW N D  |  DH AH  |  P OY L  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.07.28, Block: 7, Trial: 39\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AY  |  R IH L IY  |  D OW N T  |  W AA N T  |  T UW  |  S IY  |  DH EH M  |  G OW  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.07.28, Block: 7, Trial: 40\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  DH AH  |  AO L  |  W AH T  |  AH  |  R IH W AO R D  |  AO R  |  W AH T EH V ER  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.07.28, Block: 7, Trial: 41\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AY V  |  K W IH T  |  D UW IH NG  |  DH AE T  |  B AH S EH L F  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.07.28, Block: 7, Trial: 42\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  DH AH  |  R EH S T ER AY T  |  M AH S T  |  B AE G Z  |  DH AH  |  IH K S P EH K SH AH N  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.07.28, Block: 7, Trial: 43\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  W EH R  |  D UW  |  Y UW  |  G OW  |  K AE M P IH NG  |  AE T  |  ER AW N D  |  HH IY R  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.07.28, Block: 7, Trial: 44\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AY  |  T R AY  |  T UW  |  S EY V  |  DH AE T  |  F AO R  |  DH AH  |  W IY K EH N D  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.07.28, Block: 7, Trial: 45\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  W EH N  |  D AH Z  |  S K UW L  |  S P AA R T  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.07.28, Block: 7, Trial: 47\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  DH AE T S  |  JH AH S T  |  DH AH  |  W EY  |  IH T  |  W AA Z  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.07.28, Block: 7, Trial: 48\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  V AE K S T AH B AH L Z  |  G R OW  |  IH N  |  DH AH  |  F IY N D Z  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2024.07.28, Block: 7, Trial: 49\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AY  |  HH AE D  |  EH N D AH D  |  AH P  |  IH T  |  AH  |  V EH R IY  |  T AH M P L IY  |  L UH T  |  EH R IY AH  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2025.01.10, Block: 8, Trial: 25\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  N AW T  |  G EH T  |  M AY  |  R AE D AH  |  AH  |  DH OW Z  |  B EY B ER  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2025.01.10, Block: 8, Trial: 26\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  SH IY  |  W AH D AH N D  |  DH EH M  |  T UW  |  K AO R L D  |  T UW  |  G EH T  |  W AH N  |  F AO R  |  HH ER  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2025.01.10, Block: 8, Trial: 27\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  DH EH N  |  AY  |  TH IH NG K  |  Y UW  |  HH AE V  |  AH  |  M AO R  |  IH P AE D AH B AH L  |  AH P R EH OW S  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2025.01.10, Block: 8, Trial: 28\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AY  |  JH AH S T  |  D OW N T  |  L AY K  |  DH AE T  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2025.01.10, Block: 8, Trial: 29\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  IH T  |  Y UW  |  S IY  |  IH T  |  P R AY IH NG  |  DH AE R Z  |  AH  |  P R EH B L AH M  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2025.01.10, Block: 8, Trial: 31\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  W AH T S  |  DH AH  |  W AH N T  |  AH V  |  DH AH T  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2025.01.10, Block: 8, Trial: 32\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AY  |  W AA Z AH N T  |  IY V IH N  |  K AH IH JH D  |  F AO R  |  IH N  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2025.01.10, Block: 8, Trial: 33\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AH N JH AH N Z  |  AH V  |  AA R T ER  |  AO R  |  P AE L ER Z  |  P AA S IH NG  |  TH R UW  |  DH AH  |  K AH N T AW L  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2025.01.10, Block: 8, Trial: 34\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AY  |  N OW  |  W EH N  |  AH  |  W AA Z  |  W ER K IH NG  |  TH IH NG Z  |  W AH  |  D EH F ER AH  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2025.01.10, Block: 8, Trial: 35\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  JH OY S T  |  TH IH NG Z  |  AH P  |  AH  |  L IH T AH L  |  B AH T  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2025.01.10, Block: 8, Trial: 36\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  IH F  |  AH  |  M OW V ER  |  IH Z  |  P R AA B Y AH L IY  |  IH T  |  N IY Z  |  IH N  |  DH EH R AH N AH Z  |  R IH G ER  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2025.01.10, Block: 8, Trial: 37\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AY  |  D OW N T  |  N OW  |  IH F  |  Y IY L  |  EH V ER  |  S IY  |  AE M  |  AH G EH N  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2025.01.10, Block: 8, Trial: 38\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  IH F  |  AY  |  L AY V D  |  IH N  |  N UW  |  Y UW  |  S IH T IY  |  AA R  |  W AA EH CH AH N AH N  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2025.01.10, Block: 8, Trial: 39\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  D UW  |  Y UW  |  W AA N T  |  T UW  |  HH OW M  |  OW V ER  |  AE F T ER  |  S K Y UW R  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2025.01.10, Block: 8, Trial: 40\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  DH EH R Z  |  R AO IH NG  |  T R AY AW L Z  |  AH N D  |  B OW TH  |  S EH S D  |  AH V  |  DH AH  |  R IH V ER  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2025.01.10, Block: 8, Trial: 41\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  IH T  |  S EY M Z  |  AH  |  P IY P AH L  |  JH AH S T  |  G OW  |  IH N  |  S OW K ER L Z  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2025.01.10, Block: 8, Trial: 42\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  S EY  |  W AH T  |  W IY  |  K AE N  |  T AH M  |  AH T  |  W EH DH  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2025.01.10, Block: 8, Trial: 43\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  K AH M P Y UW L AH ER AH S T  |  D AH S IH N Z  |  AA R  |  V EH R IY  |  K AH N P L AH T IH T AH D  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2025.01.10, Block: 8, Trial: 44\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  W EH R  |  AO L W EY Z  |  B IY  |  T AE K S AH Z  |  M AO R  |  S AH M TH IH NG  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2025.01.10, Block: 8, Trial: 45\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AY  |  TH IH NG K  |  IH Z  |  S AH B  |  K IH Z AH Z  |  N AE T  |  IH Z  |  G ER AY K T  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2025.01.10, Block: 8, Trial: 46\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  DH EY  |  W IH L  |  HH OW M  |  DH AH  |  K AH N T R IY  |  R ER AY M IH NG  |  IH N V EH N T UW AH L IY  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2025.01.10, Block: 8, Trial: 47\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  IH T  |  S AH D AH N  |  B IY  |  DH AE T  |  W EY  |  AY  |  OW N D  |  TH IH NG K  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2025.01.10, Block: 8, Trial: 48\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  HH IY  |  K AA T  |  AH V  |  AE Z  |  F AO L  |  S IH N P UH  |  AH N  |  DH AH  |  P L EY S  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2025.01.10, Block: 8, Trial: 49\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  IH T  |  IH Z  |  AO L  |  AH B AW T  |  EH V IY  |  K AA N T EY SH AH N Z  |  AH N D  |  M EH N IY  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2025.01.12, Block: 6, Trial: 25\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  IH T S  |  P AA T  |  AH V  |  DH AH  |  OW N K W EY ZH AH N  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2025.01.12, Block: 6, Trial: 26\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  DH EH R Z  |  AH N AH DH ER  |  HH AE S P AE N T  |  AH V  |  DH IH S  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2025.01.12, Block: 6, Trial: 28\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  HH IY  |  ER N D  |  AH  |  F UH L  |  V AA L AH JH AH P  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2025.01.12, Block: 6, Trial: 29\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  W IY  |  D AH Z  |  G UH D AH N T  |  S T AE N D  |  IH T  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2025.01.12, Block: 6, Trial: 30\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  DH AH  |  S T AO R IY  |  W AA Z  |  AH  |  V EH R IY  |  D IH P AO R T IH K  |  S T AO R IY  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2025.01.12, Block: 6, Trial: 31\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AH  |  P IH K Y IH K Y AH L ER  |  K AY N D  |  AH V  |  SH UW  |  F AO R  |  HH AE K IH NG  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2025.01.12, Block: 6, Trial: 32\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  D UW  |  Y UW  |  W AA N T  |  T UW  |  M AY  |  S AH M TH IH NG  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2025.01.12, Block: 6, Trial: 33\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  W AH T  |  W UH D  |  Y UW  |  D UW  |  AH B AW T  |  IH T  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2025.01.12, Block: 6, Trial: 34\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  DH IH S  |  IH Z  |  JH AH S T  |  AH  |  D AA R T IY  |  P OY N T  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2025.01.12, Block: 6, Trial: 35\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  W EH N  |  D UW  |  Y UW  |  W AA N T  |  DH AH  |  P EY M AH S IH T ER  |  T UW  |  K EY M  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2025.01.12, Block: 6, Trial: 36\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AY  |  D OW N T  |  N OW  |  W AH T  |  Y AO R  |  M AH T IY  |  P ER S IH D IH K  |  IH Z  |  AA N  |  Y AO R  |  F OW N  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2025.01.12, Block: 6, Trial: 37\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  DH EY  |  D OW N T  |  N IH T IY S  |  EH N IY  |  T AY M  |  D IH F ER AH S  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2025.01.12, Block: 6, Trial: 38\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  IH T  |  W AA Z  |  AH  |  B EH N AH S W IY T  |  JH OY R  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2025.01.12, Block: 6, Trial: 39\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AY  |  TH IH NG K  |  IH T S  |  N EH V ER AH N AH T L IY  |  G AA T AH N  |  B EH T ER  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2025.01.12, Block: 6, Trial: 40\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  DH EY  |  D UW  |  N AA T  |  P R EH V IY Z  |  EH N IY TH IH NG  |  S P AH S IH SH AH L  |  DH IY Z  |  D EY Z  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2025.01.12, Block: 6, Trial: 41\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AY  |  D OW N T  |  HH AE V  |  AH  |  P R AA B L AH M  |  AE T  |  AO L  |  W IH DH  |  EH M P L OY AH Z  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2025.01.12, Block: 6, Trial: 42\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  T EY K  |  AH  |  SH AW AH  |  AH N D  |  G EH T  |  D R EH S T  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2025.01.12, Block: 6, Trial: 43\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  B OW TH  |  AH V  |  M AY  |  K AE T S  |  AO R  |  D IH N K L AO D  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2025.01.12, Block: 6, Trial: 44\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AY  |  JH AH S T  |  L EH T  |  AW T  |  D IH D AH S T  |  S P AY D  |  EH N IY  |  M AH N IY  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2025.01.12, Block: 6, Trial: 45\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  DH EH R  |  K UH D  |  B IY  |  AH  |  L AA T  |  AH V  |  AA P SH AH Z  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2025.01.12, Block: 6, Trial: 46\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AH DH ER  |  DH AE T  |  DH AE T  |  DH EY  |  HH AE V  |  DH AH  |  Y UW ZH AH W AH L  |  S T AH F  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2025.01.12, Block: 6, Trial: 47\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  IH T  |  IH Z  |  R IH L IY  |  S T EH R IY  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2025.01.12, Block: 6, Trial: 48\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  DH EH R Z  |  AE T  |  L IY S T  |  W AH N  |  K AE T  |  IH N  |  DH AH  |  HH AW S  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2025.01.12, Block: 6, Trial: 49\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AY M  |  N AA T  |  SH UH R  |  HH AW  |  DH EH R  |  G OW IH NG  |  T UW  |  F IY L  |  AH B AW T  |  IH T  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2025.01.12, Block: 7, Trial: 26\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  SH IY  |  D IH D  |  V EH R IY  |  W IY L  |  DH EH R  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2025.01.12, Block: 7, Trial: 27\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  SH IY  |  D IH D AH N T  |  L AY V  |  W IH DH  |  AH S  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2025.01.12, Block: 7, Trial: 28\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  DH AE T S  |  R IH L IY  |  W IH N D  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2025.01.12, Block: 7, Trial: 29\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  IH T S  |  AH  |  P L EH ZH ER  |  T UW  |  M EY K  |  Y AO R  |  AH K EY N T IY Z  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2025.01.12, Block: 7, Trial: 30\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  HH OW P  |  Y UW  |  HH AE V  |  EH N JH OY D  |  DH IH S  |  D IH N AO R IY AH L  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2025.01.12, Block: 7, Trial: 31\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  DH AH  |  JH UH R IY  |  S T EH K T AH M  |  IH N S OW L  |  IH Z  |  N AA T  |  P IH P F IH K T  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2025.01.12, Block: 7, Trial: 32\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  M AY  |  P EH R AH N T S  |  AO L W EY Z  |  S EH D  |  IH F  |  W IY  |  W AO N T IH D  |  AH  |  K AA R  |  W IY  |  AE T  |  T UW  |  D EY  |  F AO R  |  IH T  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2025.01.12, Block: 7, Trial: 33\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  W IY  |  P EH N T AH N  |  DH OW Z  |  AE T  |  B AY  |  DH AH  |  S AH M T IH NG  |  T EY K  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2025.01.12, Block: 7, Trial: 34\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  IH T  |  HH AE P AH N Z  |  EH V ER IY  |  S IH NG G AH L  |  M AH N TH  |  W IH TH AW T  |  F IY L  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2025.01.12, Block: 7, Trial: 35\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AE N AH M L AH S  |  AE D  |  S AH M B AW L  |  G AA N T AH N  |  IH N T UW  |  DH AH  |  D R AE SH  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2025.01.12, Block: 7, Trial: 36\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AY V  |  D AH N  |  S AH M  |  AH DH ER  |  TH IH NG Z  |  T UW  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2025.01.12, Block: 7, Trial: 37\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  K AY N D  |  AH V  |  AH  |  P IH K T IH K  |  IH N  |  DH AH  |  W ER N S  |  T AY  |  TH IH NG  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2025.01.12, Block: 7, Trial: 38\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AE K CH UW AH L IY  |  DH IH S  |  F AO L  |  AY  |  AE M  |  G OW IH NG  |  B AE K  |  T UW  |  S K UW L  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2025.01.12, Block: 7, Trial: 39\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AW ER  |  IH N V AH S T R EY SH AH N  |  IH Z T ER IY  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2025.01.12, Block: 7, Trial: 40\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  W IY  |  Y UW Z D  |  T UW  |  AO L W EY Z  |  EH N JH OY  |  W AA N T IH NG  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2025.01.12, Block: 7, Trial: 41\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  Y UW  |  G OW  |  AW T S T AY D  |  AH N D  |  P L EY  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2025.01.12, Block: 7, Trial: 42\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  Y UW D  |  TH IH NG  |  DH AE T  |  IH T  |  W AA Z  |  AH  |  P R AY V AH N T  |  S K UW L  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2025.01.12, Block: 7, Trial: 43\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AY  |  N OW  |  T UW  |  W IH M AH N  |  HH UW  |  W EH N T  |  DH EH R  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2025.01.12, Block: 7, Trial: 44\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  DH EY V  |  D AO R T IH D  |  AH  |  JH R IH G  |  D EH S IH NG  |  P AA L AH S IY  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2025.01.12, Block: 7, Trial: 45\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AY  |  TH IH NG K  |  N EH R Z  |  AH B AW T  |  S EH V AH N T IY  |  AH V  |  DH EH M  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2025.01.12, Block: 7, Trial: 46\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  IH F  |  Y AO R  |  S AH V IH NG  |  AH N AH DH ER  |  T IY K  |  W IH DH  |  IH T  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2025.01.12, Block: 7, Trial: 47\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AY V  |  HH ER D  |  D EH F ER AH N T  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2025.01.12, Block: 7, Trial: 48\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  HH IY  |  D OW N T  |  IH N S EH L F  |  DH EH R  |  S K UW L  |  P R EY S IH K L IY  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2025.03.14, Block: 4, Trial: 12\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  DH EH N  |  AY  |  HH ER  |  AH  |  V EH R IY  |  N AA T  |  IH N S P L OW ZH AH N  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2025.03.14, Block: 4, Trial: 13\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  M AY  |  D AE S  |  IH Z  |  AH  |  P IH T EY T AH  |  F EY V ER IY  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2025.03.14, Block: 4, Trial: 14\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  DH IH S  |  AH  |  G UH N  |  AE F SH AH IH NG  |  T UW  |  K AH N D AH D T IY  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2025.03.14, Block: 4, Trial: 15\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  D UW  |  Y UW  |  W AA T  |  T UW  |  IH T  |  EH N S AY D  |  AO R  |  AO L S AY D  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2025.03.14, Block: 4, Trial: 16\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:   |  S OW  |  W IY  |  K AH L W AH L IY  |  S T EY T  |  IH N S ER T  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2025.03.14, Block: 4, Trial: 17\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  B IH S P W EY Z AH Z  |  R AH M  |  AH DH ER  |  T EH N AH V EH S AH T IY  |  W IH L  |  B IH S EH T  |  DH EH R  |  R IH S IH Z  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2025.03.14, Block: 4, Trial: 18\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  DH EY  |  AA  |  N IY L  |  S P R AA R T IH D  |  T UW  |  M AH N TH  |  DH EH M  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2025.03.14, Block: 4, Trial: 19\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AY  |  AY  |  G OW Z  |  Y EH R  |  AH  |  F Y UW TH  |  DH IH S  |  AH B AW N D  |  S T EH L  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2025.03.14, Block: 4, Trial: 20\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  DH AH  |  AA R  |  S OW  |  F AO L  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2025.03.14, Block: 4, Trial: 21\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  IH T  |  IH Z  |  AH  |  R IH L IY  |  P L AE Z  |  L AH P AH L  |  AE T K S  |  K AA L IH JH Z  |  AH V  |  W IH L  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2025.03.14, Block: 4, Trial: 22\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AE V IY  |  AH  |  JH ER M  |  W IH L  |  T IY CH  |  Y UW  |  AA T  |  AH V  |  R EY V IH  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2025.03.14, Block: 4, Trial: 23\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  IH T  |  W AA Z  |  AH  |  B IH L EY SH AH N  |  DH AH  |  AH  |  P IY  |  HH AE V  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2025.03.14, Block: 4, Trial: 24\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  IH T  |  IH Z  |  K AO N  |  T UW  |  W IH M EH M B ER  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2025.03.14, Block: 6, Trial: 12\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  DH EH N  |  AY  |  HH ER D  |  AH  |  V EH R IY  |  K AE N  |  IH S K L EY S AH N  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2025.03.14, Block: 6, Trial: 13\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  M AY  |  G EH T  |  IH Z  |  AH  |  R IH T EH T AH  |  F AA F M ER  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2025.03.14, Block: 6, Trial: 14\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  DH AE T S  |  AH  |  G UH D  |  AA P SH AH N  |  T UW  |  K AH S IH D IY  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2025.03.14, Block: 6, Trial: 15\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  D UW  |  Y UW  |  W AH N  |  IH T  |  IH N S AY N D  |  AO R  |  AO P S AY D  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2025.03.14, Block: 6, Trial: 16\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AE Z  |  S OW  |  W EY  |  F AE L IY  |  S EH T  |  AW T S T AY T  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2025.03.14, Block: 6, Trial: 17\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  B IH S EY S AH N Z  |  R AA  |  AH DH ER  |  G AH M ER IH SH AH N IY  |  W IH L  |  F ER S EH K T  |  DH EH R  |  L EY S AH JH  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2025.03.14, Block: 6, Trial: 18\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  DH EY  |  AA R  |  D IY L  |  S P EH D IH NG  |  T UW  |  B EY TH  |  DH AH M  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2025.03.14, Block: 6, Trial: 19\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AY  |  G OW Z  |  DH EH R  |  AA R  |  AH  |  F Y UW TH  |  DH IH S  |  AH F EH N D  |  S T IH L  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2025.03.14, Block: 6, Trial: 20\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  DH EY  |  AA R  |  S OW  |  S B L AO G  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2025.03.14, Block: 6, Trial: 21\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  IH T  |  IH Z  |  AH  |  F R EY L IY  |  L AA G Z  |  P L EY P ER  |  AA N S  |  R IH L ER JH  |  AH  |  F EY L  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2025.03.14, Block: 6, Trial: 22\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AE V IY  |  AH  |  D JH AA B  |  DH AA  |  T IY CH  |  Y AO  |  AA T  |  AH V  |  R EY ER  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2025.03.14, Block: 6, Trial: 23\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  IH T  |  W AA Z  |  AH  |  D AH N S IH N  |  DH AH T  |  W EY T  |  P EY  |  HH AO F S  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2025.03.14, Block: 6, Trial: 24\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  IH T  |  AH  |  AW L T  |  T UW  |  R IH M EH M B ER  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2025.03.16, Block: 5, Trial: 25\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  W IY  |  HH AE P AH N D  |  HH AE D  |  AH  |  L AA T  |  AH V  |  P R AA B L AH M Z  |  W IH DH  |  DH AH  |  N UW  |  K AH M P UW T ER  |  AE T  |  AO L  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2025.03.16, Block: 5, Trial: 26\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  D EY K  |  AH  |  S IH T  |  AH N D  |  EH N JH OY  |  DH AH  |  W AY N D  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2025.03.16, Block: 5, Trial: 27\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AY  |  TH IH NG K  |  W IY  |  F AH F EH L D  |  AW ER  |  AA B AH B EY SH AH N  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2025.03.16, Block: 5, Trial: 28\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  DH EY  |  SH UH D  |  S T AH D IY  |  DH IH S  |  N OW  |  S P IY SH AH Z  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2025.03.16, Block: 5, Trial: 29\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  M AH B L IY  |  W IY  |  K AE CH  |  K AA M P  |  AH N D  |  S AH M AH N T  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2025.03.16, Block: 5, Trial: 30\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  P IH K IH NG  |  AE T  |  D OW N T  |  IH N  |  AH  |  R IH L D EH R L  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2025.03.16, Block: 5, Trial: 31\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  S T AA D  |  B AY  |  K AE N CH AH S R EY T IH NG  |  AH N D  |  IH K EH N S IH NG  |  SH UH R  |  V IH M AH L AH L EY SH AH N  |  P AW ER  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2025.03.16, Block: 5, Trial: 33\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AY  |  G EH S  |  W EH R  |  B OW TH  |  P R IH T IY  |  R EH D ER K AH L  |  P IY P AH L  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2025.03.16, Block: 5, Trial: 34\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  IH T  |  W AA Z  |  AA N  |  IH Z  |  W EY  |  DH EH R  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2025.03.16, Block: 5, Trial: 35\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  Y UW  |  AA R  |  P R AA B AH B L IY  |  W AY T  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2025.03.16, Block: 5, Trial: 36\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AY  |  AE M  |  SH AY R D IH NG  |  T UW  |  K AH N P EH K S  |  IH N  |  T UW  |  W AH T  |  AO L  |  DH IH S  |  D AW N  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2025.03.16, Block: 5, Trial: 37\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  IH F  |  DH EY  |  W ER K  |  AE T  |  IH T  |  AH  |  L IH T AH L  |  B IH T  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2025.03.16, Block: 5, Trial: 38\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AY  |  TH IH NG K  |  DH EY  |  D IH D  |  AH  |  W IH L  |  G UH D  |  JH AA B  |  AH V  |  DH AE T  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2025.03.16, Block: 5, Trial: 39\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  DH AE T S  |  W AH T  |  DH EH R  |  D UW IH NG  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2025.03.16, Block: 5, Trial: 40\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  IH T S  |  AH  |  R IH L IY  |  G UH D  |  M UW V IH  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2025.03.16, Block: 5, Trial: 41\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  W AH S T  |  Y AO R  |  S EH S T AH D  |  F EH V ER IH T  |  F UW D  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2025.03.16, Block: 5, Trial: 42\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  P IY P AH L  |  AA R  |  F R EH S IH NG  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2025.03.16, Block: 5, Trial: 43\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  DH EH R  |  N EH V ER  |  W IH L  |  B IY  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2025.03.16, Block: 5, Trial: 44\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  W AH T  |  AH V  |  DH AH  |  L EY NG Z  |  DH AE T  |  IH Z  |  AH  |  P R AA B AH K T  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2025.03.16, Block: 5, Trial: 45\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  DH AE S  |  K AY N D  |  T UW  |  B IY  |  B IY T AH F AH L T  |  T EH R AH N T EH R IY  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2025.03.16, Block: 5, Trial: 46\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  K AE N  |  D UW  |  B AH F EH V ER  |  DH EY  |  W EY N T  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2025.03.16, Block: 5, Trial: 47\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  DH AH  |  OW N L IY  |  K AA S T S  |  AH V  |  TH IH NG Z  |  DH AE T  |  Y UW  |  K AE N  |  Y UW Z  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2025.03.16, Block: 5, Trial: 48\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  DH AE T S  |  K AY N D  |  AH V  |  AH N D ER S T AE N D AH B AH L  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2025.03.16, Block: 5, Trial: 49\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  IH T  |  DH AH  |  B EH D AH L  |  AH V  |  AH  |  R EH G IH D EH N SH AH L  |  EH R IY AH  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2025.03.30, Block: 10, Trial: 7\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AA R  |  Y UW  |  S ER V IH NG  |  AH N AH DH ER  |  D EH S  |  W IH DH  |  IH T  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2025.03.30, Block: 10, Trial: 9\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  HH IY  |  B EH S IH K L IY  |  P UH T  |  IH N S EH L TH  |  TH R UW  |  S K UW L  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2025.03.30, Block: 10, Trial: 10\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  M AY  |  K AA R  |  IH Z  |  AH  |  N AY N T AH N  |  EY T IY  |  S EH N S  |  T AY UW T ER  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2025.03.30, Block: 10, Trial: 12\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  G EH T  |  R EH D  |  AH V  |  DH AH  |  T UW  |  DH AE T  |  W IY  |  HH AE V  |  W AH T  |  N AW  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2025.03.30, Block: 10, Trial: 13\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AY  |  AE M  |  AE N  |  AH M EH R IH K AH N  |  S IH T AH S AH N  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2025.03.30, Block: 10, Trial: 14\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  DH AE T S  |  W AY  |  W IY  |  D IH S AY D IH D  |  T UW  |  B IH L D  |  AE N  |  AH G IH SH AH N  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2025.03.30, Block: 13, Trial: 25\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  W AH T S  |  DH AE T  |  M EH R IY  |  AH B AW T  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2025.03.30, Block: 13, Trial: 26\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  DH AH  |  B EH T AH F AH N T  |  AH V  |  F AE V IH NG  |  V IH Z IH T  |  IH N SH IH R AH N  |  IH Z  |  F AO R  |  DH AH  |  R IH M AH L IY  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2025.03.30, Block: 13, Trial: 27\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  Y UW  |  G EH T  |  F AY N D  |  DH EH M  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2025.03.30, Block: 13, Trial: 28\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  W AH T  |  K AY N  |  AH V  |  F AH S EH B T IH NG  |  T UW  |  Y UW  |  T UW  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2025.03.30, Block: 13, Trial: 29\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AY V  |  B IH N  |  AE T  |  K AE M P AH N AH N T S  |  W EH R  |  D IH P AH L  |  IH L IY  |  W ER NG  |  T UW  |  AA R  |  TH R IY  |  AW Z IH Z  |  AH  |  D EY  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2025.03.30, Block: 13, Trial: 30\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AY  |  W AA Z  |  L IH V IY  |  B EH T ER  |  T ER N  |  Y IH R Z  |  AH G AO L  |  DH AE T  |  AH  |  AE M  |  N AW  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2025.03.30, Block: 13, Trial: 31\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  SH IY  |  K AH M  |  AH  |  G AA T  |  T UW  |  Y UW  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2025.03.30, Block: 13, Trial: 32\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  HH ER  |  AY Z  |  AA L  |  D EY N IH NG  |  K AA L ER  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2025.03.30, Block: 13, Trial: 33\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AW ER  |  AH N OY IH NG  |  P R EH JH IH K T  |  D IH F AH L AH M AH N T  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2025.03.30, Block: 13, Trial: 34\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AY  |  TH IH NG  |  W DH IY  |  HH AE V  |  AH B AW T  |  TH ER T D  |  B EH T S  |  L EH F T  |  AO R  |  AW ER  |  TH L OW D  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2025.03.30, Block: 13, Trial: 35\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AY  |  L AY K  |  W ER S  |  CH UW Z IH K  |  JH ER ZH AH N S  |  AH T S EH P T  |  F AO R  |  K AE N T R IY  |  M Y UW Z IH K  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2025.03.30, Block: 13, Trial: 36\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AY  |  W AA Z  |  M IY N IH NG  |  AA L  |  DH AH  |  AE F  |  AH V  |  M AY  |  DH IH  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2025.03.30, Block: 13, Trial: 37\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  W AH T IY  |  L AE V Z  |  DH AH M  |  DH EH R  |  M AH CH  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2025.03.30, Block: 13, Trial: 38\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  DH IH S  |  DH AH  |  W EY T  |  AH  |  HH AE V  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2025.03.30, Block: 13, Trial: 40\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  DH EY  |  JH AH S T  |  W AH D  |  DH AH  |  W EH T ER  |  P AO R  |  AA N  |  DH AH  |  AE P  |  DH AH P EH T  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2025.03.30, Block: 13, Trial: 41\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  W AH T  |  IH N  |  DH AH  |  M IH D AH L  |  AH V  |  M AY  |  D EH K  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2025.03.30, Block: 13, Trial: 42\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AE T  |  HH AE Z  |  D AE N D  |  T UW  |  W AH T  |  M EH ZH AH Z  |  R EH D  |  AH K AW S T  |  AH G TH EH DH ER Z  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2025.03.30, Block: 13, Trial: 43\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AY  |  AW N S OY D  |  B EH T IY  |  HH AE Z  |  AH  |  G AE G AH N  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2025.03.30, Block: 13, Trial: 44\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  S OW  |  W UH D  |  T UW  |  Y UW  |  TH IH NG K  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2025.03.30, Block: 13, Trial: 45\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AA R  |  W EH N IY  |  Y UW  |  Y UW  |  HH AE V  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2025.03.30, Block: 13, Trial: 46\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  W AY  |  W AY F S  |  B AA DH ER  |  IH Z  |  DH AH  |  OW N L IY  |  R EH R P EH R T AH L  |  L AH V  |  B IH T  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2025.03.30, Block: 13, Trial: 47\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AY  |  W AA Z  |  IH N  |  IH L EH T AH  |  F AO R  |  AY  |  B AE S AH S R AE M  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2025.03.30, Block: 13, Trial: 48\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  DH AH  |  K AA R D  |  D AE L AH SH AH P  |  R EY D  |  B ER  |  AO F  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2025.03.30, Block: 13, Trial: 49\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  W EH N  |  AY  |  W AA Z  |  AH N T IY N  |  Y IH R Z  |  OW L D  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2025.04.13, Block: 8, Trial: 25\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  HH IY  |  W UH D AH N T  |  EH V ER  |  R IH L IY  |  T AO K  |  AH B AW T  |  IH T  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2025.04.13, Block: 8, Trial: 26\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AY  |  HH AE D  |  F AO R  |  B L AE DH ER Z  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2025.04.13, Block: 8, Trial: 27\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AY  |  G UH D  |  S IY  |  DH AE T  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2025.04.13, Block: 8, Trial: 28\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  IH F  |  S AH M W EY  |  K EY M  |  AH N D  |  HH ER D  |  IH T  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2025.04.13, Block: 8, Trial: 29\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AY  |  HH AE V AH N T  |  R IH L IY  |  P R EH S T  |  IH T  |  AW T  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2025.04.13, Block: 8, Trial: 30\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  DH AE T  |  W AA Z  |  V EH R IY  |  D IH S AO R T AH N T IY  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2025.04.13, Block: 8, Trial: 31\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  DH EH R  |  AE K S UW AH S L IY  |  D UW  |  DH IH NG Z  |  L AY K  |  DH IH S  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2025.04.13, Block: 8, Trial: 32\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  M AY  |  AH S B M EH K T  |  G EH T Z  |  P IH N  |  W AH N S  |  AH  |  M AH N TH S  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2025.04.13, Block: 8, Trial: 33\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AY  |  N OW  |  W IY  |  L AY V  |  IH N  |  R IY K AE N IH L  |  F AO R  |  S EH V AH N  |  Y IH R Z  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2025.04.13, Block: 8, Trial: 34\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AY  |  D OW N T  |  N OW  |  W AH T  |  TH AE NG K S  |  AH B AW T  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2025.04.13, Block: 8, Trial: 35\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  DH EH R  |  AA R  |  AO L W EY Z  |  N UW  |  K AH K F EH F ER F IH T S  |  AO R  |  P R AA B L AH M Z  |  AA R  |  R EY Z AH S IY Z  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2025.04.13, Block: 8, Trial: 36\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AY M  |  T AO K IH NG  |  AH B AW T  |  IH N K R IY L AH T L IY  |  L OY Z  |  F AO R K S  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2025.04.13, Block: 8, Trial: 37\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  DH EH R Z  |  AH  |  K AH P AH L  |  N UW  |  T EY N CH AH N Z  |  DH IH S  |  Y IH R  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2025.04.13, Block: 8, Trial: 38\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  DH AH  |  L AE S AH N T S  |  F AO R  |  K AE M W AH T S  |  AA R  |  B EH R IY  |  IH K S P EH S SH IH S  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2025.04.13, Block: 8, Trial: 39\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  W IY  |  EH N JH OY D  |  HH AE V IH NG  |  HH UW  |  HH IY R  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2025.04.13, Block: 8, Trial: 40\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AY  |  W AA Z  |  W AO N T IH NG  |  AA N  |  AH  |  F AA R M  |  L AY N S  |  S AH M IY  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2025.04.13, Block: 8, Trial: 41\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  DH IY Z  |  B OY  |  K AE T S  |  AA R  |  AH P  |  T UW  |  AO L  |  S AO R T S  |  AH V  |  TH IH NG Z  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2025.04.13, Block: 8, Trial: 42\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  DH AH  |  AA K CH SH AH N D AH D  |  IH Z  |  P EH SH AH N  |  B AY  |  IH T S  |  L UW V M AH N  |  W AY T  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2025.04.13, Block: 8, Trial: 43\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  EH N AH  |  R EH S AH N  |  P ER ZH IH N  |  AH V  |  W IH T AH N S  |  SH UH D  |  B IY  |  F AY T  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2025.04.13, Block: 8, Trial: 44\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  N  |  DH AH  |  IH N D T AH N AE T  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2025.04.13, Block: 8, Trial: 45\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  S IH N S  |  DH EY  |  D OW N T  |  HH AE V  |  DH AH  |  R IH L IY  |  F IY  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2025.04.13, Block: 8, Trial: 46\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  DH EH R Z  |  AH  |  L AA T  |  AH V  |  N UW  |  S EH CH AH N  |  IH N  |  DH AH  |  T AA K Y AH M AH N T  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2025.04.13, Block: 8, Trial: 47\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  AH N D  |  AW ER  |  AE N D  |  AH  |  HH AE V  |  AH W EY  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2025.04.13, Block: 8, Trial: 48\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  SH IY  |  B AA S  |  AE T  |  DH AH  |  AH DH ER  |  W AH N  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Session: t15.2025.04.13, Block: 8, Trial: 49\n",
      "\u001b[35mcmd2:\u001b[0m Predicted Sequence:  W EH L  |  B EY B IY  |  DH AE T  |  IH Z  |  AH N T AE S IH  |  F AE F T ER  | \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m \n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:45:58,708 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:45:58,886 INFO: Partial:  get tired with the song and dace retain\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:45:59,012 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:02,547 INFO: OPT time: 3.535\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:02,548 INFO: Final:  get tired with the song and dace routine\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:02,548 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:   0%|          | 0/1450 [00:00<?, ?trial/s]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:02,716 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:02,742 INFO: Partial:  emergency kahre\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:02,760 INFO: Augmented nbest from 100 to 112 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:03,376 INFO: OPT time: 0.616\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:03,377 INFO: Final:  emergency care\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:03,377 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:   0%|          | 1/1450 [00:03<1:36:22,  3.99s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:03,515 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:03,588 INFO: Partial:  yu create a bigger surprise\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:03,661 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:04,430 INFO: OPT time: 0.768\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:04,430 INFO: Final:  you create a bigger surprise\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:04,430 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:   0%|          | 2/1450 [00:04<51:25,  2.13s/trial]  \n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:04,622 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:04,666 INFO: Partial:  think maybe yu look at it\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:04,701 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:05,575 INFO: OPT time: 0.874\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:05,575 INFO: Final:  think maybe you look at it\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:05,576 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:   0%|          | 3/1450 [00:05<39:31,  1.64s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:05,722 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:05,761 INFO: Partial:  that they due have problems\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:05,786 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:06,569 INFO: OPT time: 0.783\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:06,569 INFO: Final:  show that they do have problems\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:06,569 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:   0%|          | 4/1450 [00:07<34:47,  1.44s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:06,724 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:06,749 INFO: Partial:  enjoy that to\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:06,770 INFO: Augmented nbest from 100 to 120 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:07,615 INFO: OPT time: 0.845\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:07,615 INFO: Final:  enjoy that to\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:07,616 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:   0%|          | 5/1450 [00:08<30:51,  1.28s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:07,725 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:07,785 INFO: Partial:  moved to kansas city\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:07,826 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:08,602 INFO: OPT time: 0.775\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:08,602 INFO: Final:  moved to kansas city\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:08,603 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:   0%|          | 6/1450 [00:09<28:55,  1.20s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:08,729 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:08,764 INFO: Partial:  maybe for times a wieck\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:08,798 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:09,658 INFO: OPT time: 0.859\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:09,658 INFO: Final:  maybe four times a week\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:09,659 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:   0%|          | 7/1450 [00:10<27:12,  1.13s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:09,830 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:09,915 INFO: Partial:  when he seeds it to his events\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:09,961 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:10,827 INFO: OPT time: 0.866\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:10,828 INFO: Final:  when he sees it to his events\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:10,828 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:   1%|          | 8/1450 [00:11<26:36,  1.11s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:10,935 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:10,967 INFO: Partial:  theirs just no won around\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:10,994 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:11,733 INFO: OPT time: 0.739\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:11,733 INFO: Final:  theirs just no one around\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:11,734 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:   1%|          | 9/1450 [00:12<27:03,  1.13s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:11,936 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:11,962 INFO: Partial:  the system write now\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:11,988 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:12,618 INFO: OPT time: 0.629\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:12,618 INFO: Final:  the system right now\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:12,619 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:   1%|          | 10/1450 [00:13<25:24,  1.06s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:12,739 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:12,833 INFO: Partial:  either won of them would be a tieszen choyce\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:12,908 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:13,992 INFO: OPT time: 1.083\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:13,992 INFO: Final:  either one of them would be a titian choice\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:13,992 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:   1%|          | 11/1450 [00:14<24:06,  1.01s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:14,144 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:14,165 INFO: Partial:  things lyke that\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:14,182 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:14,795 INFO: OPT time: 0.613\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:14,795 INFO: Final:  things like that\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:14,795 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:   1%|          | 12/1450 [00:15<26:47,  1.12s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:14,943 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:14,975 INFO: Partial:  lived in places\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:15,001 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:15,483 INFO: OPT time: 0.481\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:15,483 INFO: Final:  lived in places\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:15,484 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:   1%|          | 13/1450 [00:16<24:28,  1.02s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:15,646 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:15,682 INFO: Partial:  yu had to change it\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:15,705 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:16,462 INFO: OPT time: 0.757\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:16,462 INFO: Final:  you had to change it\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:16,463 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:   1%|          | 14/1450 [00:16<22:02,  1.09trial/s]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:16,649 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:16,707 INFO: Partial:  just sort of happens automatically\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:16,739 INFO: Augmented nbest from 100 to 112 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:17,548 INFO: OPT time: 0.808\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:17,548 INFO: Final:  it just sort of happens automatically\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:17,548 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:   1%|          | 15/1450 [00:17<22:27,  1.07trial/s]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:17,752 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:17,838 INFO: Partial:  minute your upp in the anew pottle\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:17,915 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:19,006 INFO: OPT time: 1.091\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:19,006 INFO: Final:  minute your up in the anew portal\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:19,006 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:   1%|          | 16/1450 [00:18<23:29,  1.02trial/s]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:19,157 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:19,214 INFO: Partial:  its a joking hazzard\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:19,255 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:20,054 INFO: OPT time: 0.799\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:20,054 INFO: Final:  its a choking hazard\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:20,055 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:   1%|          | 17/1450 [00:20<26:53,  1.13s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:20,258 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:20,326 INFO: Partial:  even after yu whate your than nex\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:20,376 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:21,318 INFO: OPT time: 0.941\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:21,318 INFO: Final:  even after you wait your than nex\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:21,318 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:   1%|          | 18/1450 [00:21<26:18,  1.10s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:21,462 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:21,517 INFO: Partial:  guess they mutsch be vinet\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:21,563 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:22,474 INFO: OPT time: 0.911\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:22,474 INFO: Final:  guess they must be visit\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:22,475 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:   1%|▏         | 19/1450 [00:22<27:27,  1.15s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:22,666 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:22,699 INFO: Partial:  they kaim bakke litter\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:22,731 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:23,511 INFO: OPT time: 0.780\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:23,512 INFO: Final:  they came back later\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:23,512 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:   1%|▏         | 20/1450 [00:23<27:28,  1.15s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:23,667 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:23,721 INFO: Partial:  well what due yu due on your yard\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:23,777 INFO: Augmented nbest from 100 to 116 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:24,900 INFO: OPT time: 1.124\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:24,901 INFO: Final:  well what du u du on your yard\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:24,901 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:   1%|▏         | 21/1450 [00:24<26:37,  1.12s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:25,071 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:25,131 INFO: Partial:  atz why they kaul them swimming pools\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:25,191 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:26,121 INFO: OPT time: 0.930\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:26,121 INFO: Final:  nats why they call them swimming pools\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:26,122 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:   2%|▏         | 22/1450 [00:26<28:32,  1.20s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:26,275 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:26,364 INFO: Partial:  it covers the book of the knittle expenses\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:26,422 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:27,523 INFO: OPT time: 1.101\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:27,523 INFO: Final:  it covers the book of the natal expenses\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:27,524 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:   2%|▏         | 23/1450 [00:27<28:40,  1.21s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:27,679 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:27,729 INFO: Partial:  talk to our whicker\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:27,804 INFO: Augmented nbest from 100 to 124 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:28,643 INFO: OPT time: 0.839\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:28,643 INFO: Final:  talk to our winter\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:28,644 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:   2%|▏         | 24/1450 [00:28<30:03,  1.26s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:28,780 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:28,821 INFO: Partial:  yu were just upp there then\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:28,855 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:29,658 INFO: OPT time: 0.802\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:29,658 INFO: Final:  you were just up there then\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:29,659 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:   2%|▏         | 25/1450 [00:30<29:00,  1.22s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:29,781 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:29,823 INFO: Partial:  last year or the year\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:29,852 INFO: Augmented nbest from 100 to 152 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:31,010 INFO: OPT time: 1.159\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:31,011 INFO: Final:  last year or the year before\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:31,011 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:   2%|▏         | 26/1450 [00:31<27:30,  1.16s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:31,184 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:31,254 INFO: Partial:  thing sung of your choyce frum that show\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:31,313 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:32,465 INFO: OPT time: 1.152\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:32,465 INFO: Final:  thing song of your choice from that show\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:32,466 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:   2%|▏         | 27/1450 [00:32<28:52,  1.22s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:32,589 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:32,648 INFO: Partial:  lyke black hidy and that kind of thing\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:32,705 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:33,866 INFO: OPT time: 1.161\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:33,866 INFO: Final:  like black hide bee and that kind of thing\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:33,867 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:   2%|▏         | 28/1450 [00:33<30:32,  1.29s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:33,994 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:34,026 INFO: Partial:  he did something bad\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:34,052 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:34,721 INFO: OPT time: 0.668\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:34,721 INFO: Final:  if he did something bad\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:34,721 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:   2%|▏         | 29/1450 [00:35<31:19,  1.32s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:34,895 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:34,932 INFO: Partial:  think there a good teem\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:34,962 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:35,771 INFO: OPT time: 0.810\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:35,772 INFO: Final:  think their a good team\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:35,772 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:   2%|▏         | 30/1450 [00:36<27:58,  1.18s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:35,896 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:35,943 INFO: Partial:  kant think of the name\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:35,984 INFO: Augmented nbest from 100 to 120 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:36,986 INFO: OPT time: 1.002\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:36,986 INFO: Final:  cant think of the name\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:36,987 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:   2%|▏         | 31/1450 [00:37<27:01,  1.14s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:37,099 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:37,167 INFO: Partial:  large signed kahre vicinity now\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:37,237 INFO: Augmented nbest from 100 to 106 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:38,195 INFO: OPT time: 0.958\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:38,195 INFO: Final:  large child care vicinity now\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:38,196 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:   2%|▏         | 32/1450 [00:38<27:30,  1.16s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:38,305 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:38,372 INFO: Partial:  are yu rumen comely or something else\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:38,433 INFO: Augmented nbest from 100 to 104 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:39,473 INFO: OPT time: 1.040\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:39,474 INFO: Final:  are you rumen comely or something else\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:39,474 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:   2%|▏         | 33/1450 [00:39<27:48,  1.18s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:39,606 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:39,646 INFO: Partial:  that kind move read recently\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:39,693 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:40,526 INFO: OPT time: 0.833\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:40,526 INFO: Final:  that kind you read recently\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:40,527 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:   2%|▏         | 34/1450 [00:40<28:30,  1.21s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:40,708 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:40,737 INFO: Partial:  it is really good\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:40,759 INFO: Augmented nbest from 100 to 133 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:41,779 INFO: OPT time: 1.020\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:41,779 INFO: Final:  it is really good\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:41,780 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:   2%|▏         | 35/1450 [00:41<27:23,  1.16s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:41,910 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:41,950 INFO: Partial:  due play the piano\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:41,979 INFO: Augmented nbest from 100 to 114 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:42,938 INFO: OPT time: 0.959\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:42,938 INFO: Final:  do play the piano\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:42,939 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:   2%|▏         | 36/1450 [00:43<28:01,  1.19s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:43,113 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:43,165 INFO: Partial:  comment and join the conversation\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:43,197 INFO: Augmented nbest from 100 to 178 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:44,693 INFO: OPT time: 1.495\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:44,693 INFO: Final:  comment and join the conversation\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:44,693 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:   3%|▎         | 37/1450 [00:44<27:47,  1.18s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:44,818 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:44,883 INFO: Partial:  that is the point of this article\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:44,929 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:45,935 INFO: OPT time: 1.006\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:45,935 INFO: Final:  that is the point of this article\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:45,936 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:   3%|▎         | 38/1450 [00:46<31:49,  1.35s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:46,123 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:46,168 INFO: Partial:  weave remodeled aull our units\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:46,201 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:47,226 INFO: OPT time: 1.024\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:47,226 INFO: Final:  weave remodeled all our units\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:47,227 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:   3%|▎         | 39/1450 [00:47<31:01,  1.32s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:47,426 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:47,463 INFO: Partial:  another riel good won\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:47,488 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:48,206 INFO: OPT time: 0.718\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:48,206 INFO: Final:  another real good one\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:48,206 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:   3%|▎         | 40/1450 [00:48<30:48,  1.31s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:48,329 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:48,391 INFO: Partial:  its morr efficient to due things yourself\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:48,433 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:49,466 INFO: OPT time: 1.032\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:49,466 INFO: Final:  its more efficient to do things yourself\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:49,466 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:   3%|▎         | 41/1450 [00:49<28:26,  1.21s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:49,633 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:49,692 INFO: Partial:  guess that ai really dote no that mutsch\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:49,759 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:51,214 INFO: OPT time: 1.456\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:51,215 INFO: Final:  guess that ai really doan know that much\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:51,215 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:   3%|▎         | 42/1450 [00:50<28:46,  1.23s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:51,337 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:51,425 INFO: Partial:  doanh tel that to a nettle texan no\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:51,516 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:52,795 INFO: OPT time: 1.279\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:52,795 INFO: Final:  doan tell that to a nettle texan no\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:52,795 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:   3%|▎         | 43/1450 [00:52<32:25,  1.38s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:52,943 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:52,970 INFO: Partial:  wish ai could\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:52,999 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:53,692 INFO: OPT time: 0.693\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:53,692 INFO: Final:  wish i could\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:53,693 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:   3%|▎         | 44/1450 [00:54<33:47,  1.44s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:53,842 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:53,883 INFO: Partial:  can hardly whate\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:53,910 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:54,623 INFO: OPT time: 0.713\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:54,623 INFO: Final:  can hardly wait\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:54,624 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:   3%|▎         | 45/1450 [00:55<29:56,  1.28s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:54,745 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:54,815 INFO: Partial:  there going to be in even worse sep\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:54,883 INFO: Augmented nbest from 100 to 118 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:56,105 INFO: OPT time: 1.223\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:56,105 INFO: Final:  there going to be in even worse sep\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:56,106 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:   3%|▎         | 46/1450 [00:56<27:28,  1.17s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:56,250 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:56,337 INFO: Partial:  they blowe the whistle on it other\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:56,399 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:57,394 INFO: OPT time: 0.995\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:57,394 INFO: Final:  they blow the whistle on it other\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:57,395 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:   3%|▎         | 47/1450 [00:57<29:37,  1.27s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:57,557 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:57,610 INFO: Partial:  would mutsch rather own my own home\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:57,663 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:58,901 INFO: OPT time: 1.238\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:58,901 INFO: Final:  would much rather own my own home\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:58,902 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:   3%|▎         | 48/1450 [00:58<29:45,  1.27s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:59,056 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:59,103 INFO: Partial:  nott even a dressy suk\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:46:59,153 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:00,033 INFO: OPT time: 0.879\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:00,033 INFO: Final:  not even a tracy suck\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:00,033 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:   3%|▎         | 49/1450 [01:00<31:22,  1.34s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:00,161 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:00,239 INFO: Partial:  any conclusions baste on riel intelligence\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:00,291 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:01,291 INFO: OPT time: 0.999\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:01,291 INFO: Final:  draw any conclusions based on real intelligence\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:01,291 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:   3%|▎         | 50/1450 [01:01<29:51,  1.28s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:01,466 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:01,501 INFO: Partial:  just to fought it\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:01,526 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:02,228 INFO: OPT time: 0.702\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:02,228 INFO: Final:  just to fight it\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:02,229 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:   4%|▎         | 51/1450 [01:02<29:41,  1.27s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:02,364 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:02,409 INFO: Partial:  that is just personal feeling\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:02,450 INFO: Augmented nbest from 100 to 109 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:03,309 INFO: OPT time: 0.859\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:03,309 INFO: Final:  that is just personal feeling\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:03,309 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:   4%|▎         | 52/1450 [01:03<27:19,  1.17s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:03,466 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:03,536 INFO: Partial:  they dote sci itch other very offen\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:03,598 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:04,782 INFO: OPT time: 1.183\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:04,782 INFO: Final:  they dote cie each other very offen\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:04,783 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:   4%|▎         | 53/1450 [01:04<26:39,  1.14s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:04,971 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:05,028 INFO: Partial:  it has been riel good talking to yu\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:05,105 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:06,251 INFO: OPT time: 1.146\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:06,251 INFO: Final:  it has been real good talking to you\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:06,252 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:   4%|▎         | 54/1450 [01:06<28:55,  1.24s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:06,375 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:06,415 INFO: Partial:  redding and things lyke this\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:06,452 INFO: Augmented nbest from 100 to 123 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:07,417 INFO: OPT time: 0.965\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:07,417 INFO: Final:  reading and things like this\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:07,418 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:   4%|▍         | 55/1450 [01:07<30:29,  1.31s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:07,576 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:07,629 INFO: Partial:  they try to though in good stuff\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:07,680 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:08,635 INFO: OPT time: 0.955\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:08,635 INFO: Final:  they try to low in good stuff\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:08,636 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:   4%|▍         | 56/1450 [01:08<29:27,  1.27s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:08,781 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:08,809 INFO: Partial:  if yu get place\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:08,833 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:09,642 INFO: OPT time: 0.808\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:09,642 INFO: Final:  if you get place\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:09,643 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:   4%|▍         | 57/1450 [01:10<29:05,  1.25s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:09,782 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:09,840 INFO: Partial:  think this is lyke to years ago\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:09,880 INFO: Augmented nbest from 100 to 104 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:10,846 INFO: OPT time: 0.966\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:10,846 INFO: Final:  think this is like two years ago\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:10,847 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:   4%|▍         | 58/1450 [01:11<27:21,  1.18s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:10,984 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:11,037 INFO: Partial:  the beep in the pegram\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:11,078 INFO: Augmented nbest from 100 to 125 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:12,040 INFO: OPT time: 0.962\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:12,040 INFO: Final:  the beep in the program\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:12,041 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:   4%|▍         | 59/1450 [01:12<27:30,  1.19s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:12,188 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:12,227 INFO: Partial:  he hass it really nice\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:12,266 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:13,199 INFO: OPT time: 0.933\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:13,199 INFO: Final:  he has it really nice\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:13,200 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:   4%|▍         | 60/1450 [01:13<27:32,  1.19s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:13,394 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:13,442 INFO: Partial:  he a problem tried\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:13,481 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:14,281 INFO: OPT time: 0.800\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:14,282 INFO: Final:  is he a problem tried\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:14,282 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:   4%|▍         | 61/1450 [01:14<27:18,  1.18s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:14,397 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:14,466 INFO: Partial:  to grow upp and to decide what they want to due\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:14,552 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:15,745 INFO: OPT time: 1.192\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:15,745 INFO: Final:  to grow up and to decide what they want to do\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:15,746 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:   4%|▍         | 62/1450 [01:15<26:36,  1.15s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:15,899 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:15,952 INFO: Partial:  they had no choyce butt to leve\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:16,005 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:17,102 INFO: OPT time: 1.096\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:17,102 INFO: Final:  they had no choice but to leave\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:17,103 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:   4%|▍         | 63/1450 [01:17<28:45,  1.24s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:17,302 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:17,366 INFO: Partial:  standley there has to be a collision\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:17,422 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:18,361 INFO: OPT time: 0.939\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:18,361 INFO: Final:  sadly there has to be a collision\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:18,362 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:   4%|▍         | 64/1450 [01:18<29:31,  1.28s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:18,506 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:18,532 INFO: Partial:  yu get morr stuff\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:18,562 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:19,348 INFO: OPT time: 0.786\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:19,348 INFO: Final:  you get more stuff\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:19,349 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:   4%|▍         | 65/1450 [01:19<29:22,  1.27s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:19,506 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:19,581 INFO: Partial:  said that the closures woodby prominent\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:19,616 INFO: Augmented nbest from 100 to 116 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:20,777 INFO: OPT time: 1.161\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:20,778 INFO: Final:  she said that the closures would be prominent\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:20,778 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:   5%|▍         | 66/1450 [01:20<27:22,  1.19s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:20,910 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:20,988 INFO: Partial:  they aull leapt as he jogged out to join them\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:21,053 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:22,413 INFO: OPT time: 1.360\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:22,413 INFO: Final:  they all leapt as he jogged out to join them\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:22,414 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:   5%|▍         | 67/1450 [01:22<29:02,  1.26s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:22,617 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:22,678 INFO: Partial:  think it won due something for it\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:22,722 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:23,559 INFO: OPT time: 0.836\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:23,559 INFO: Final:  think it won do something for it\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:23,559 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:   5%|▍         | 68/1450 [01:23<31:36,  1.37s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:23,717 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:23,754 INFO: Partial:  dote live in a house\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:23,794 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:24,625 INFO: OPT time: 0.831\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:24,626 INFO: Final:  doan live in a house\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:24,626 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:   5%|▍         | 69/1450 [01:25<30:01,  1.30s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:24,818 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:24,870 INFO: Partial:  so hees a phan of history\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:24,916 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:25,836 INFO: OPT time: 0.920\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:25,836 INFO: Final:  so hees a fan of history\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:25,837 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:   5%|▍         | 70/1450 [01:26<28:21,  1.23s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:26,021 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:26,088 INFO: Partial:  that was almost an example\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:26,125 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:26,951 INFO: OPT time: 0.826\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:26,951 INFO: Final:  that was almost an example\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:26,952 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:   5%|▍         | 71/1450 [01:27<28:11,  1.23s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:27,122 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:27,210 INFO: Partial:  attention is what most of them nied\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:27,257 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:28,183 INFO: OPT time: 0.926\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:28,183 INFO: Final:  attention is what most of them need\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:28,184 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:   5%|▍         | 72/1450 [01:28<27:23,  1.19s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:28,325 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:28,421 INFO: Partial:  national population\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:28,448 INFO: Augmented nbest from 100 to 106 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:29,104 INFO: OPT time: 0.656\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:29,104 INFO: Final:  in national population\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:29,104 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:   5%|▌         | 73/1450 [01:29<27:38,  1.20s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:29,228 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:29,268 INFO: Partial:  what to goh acting\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:29,299 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:29,943 INFO: OPT time: 0.644\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:29,943 INFO: Final:  what to go hunting\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:29,943 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:   5%|▌         | 74/1450 [01:30<25:40,  1.12s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:30,127 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:30,181 INFO: Partial:  immediate reports of casualties\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:30,213 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:31,001 INFO: OPT time: 0.788\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:31,001 INFO: Final:  no immediate reports of casualties\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:31,002 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:   5%|▌         | 75/1450 [01:31<23:43,  1.04s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:31,130 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:31,172 INFO: Partial:  yu have to work around it\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:31,209 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:32,166 INFO: OPT time: 0.957\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:32,166 INFO: Final:  you have to work around it\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:32,166 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:   5%|▌         | 76/1450 [01:32<23:51,  1.04s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:32,333 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:32,373 INFO: Partial:  confusion and uncertainty\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:32,395 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:33,180 INFO: OPT time: 0.785\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:33,180 INFO: Final:  confusion and uncertainty\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:33,181 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:   5%|▌         | 77/1450 [01:33<24:41,  1.08s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:33,334 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:33,380 INFO: Partial:  there is no cobe big upp\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:33,430 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:34,355 INFO: OPT time: 0.926\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:34,356 INFO: Final:  there is no cobe big up\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:34,356 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:   5%|▌         | 78/1450 [01:34<24:13,  1.06s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:34,539 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:34,592 INFO: Partial:  what happens if oui luse worse\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:34,640 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:35,592 INFO: OPT time: 0.951\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:35,592 INFO: Final:  what happens if we lose worse\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:35,592 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:   5%|▌         | 79/1450 [01:35<25:00,  1.09s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:35,741 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:35,807 INFO: Partial:  there was no point in delling with him\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:35,849 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:36,945 INFO: OPT time: 1.095\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:36,945 INFO: Final:  there was no point in delling with him\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:36,945 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:   6%|▌         | 80/1450 [01:37<25:57,  1.14s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:37,145 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:37,182 INFO: Partial:  nott quite that offen\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:37,210 INFO: Augmented nbest from 100 to 125 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:38,149 INFO: OPT time: 0.938\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:38,149 INFO: Final:  not quite that often\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:38,149 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:   6%|▌         | 81/1450 [01:38<27:24,  1.20s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:38,346 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:38,377 INFO: Partial:  doanh travel to mutsch\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:38,413 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:39,240 INFO: OPT time: 0.827\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:39,240 INFO: Final:  doan travel too much\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:39,240 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:   6%|▌         | 82/1450 [01:39<27:24,  1.20s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:39,348 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:39,424 INFO: Partial:  whats in lyke frum an artist point of vue\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:39,508 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:40,684 INFO: OPT time: 1.177\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:40,685 INFO: Final:  whats it like from an artists point of view\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:40,685 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:   6%|▌         | 83/1450 [01:40<26:38,  1.17s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:40,853 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:40,937 INFO: Partial:  looks lyke save gott a weapon\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:41,016 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:41,973 INFO: OPT time: 0.957\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:41,974 INFO: Final:  it looks like save got a weapon\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:41,974 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:   6%|▌         | 84/1450 [01:42<28:30,  1.25s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:42,158 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:42,209 INFO: Partial:  have three left in the house\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:42,252 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:43,092 INFO: OPT time: 0.840\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:43,092 INFO: Final:  have three left in the house\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:43,093 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:   6%|▌         | 85/1450 [01:43<28:43,  1.26s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:43,256 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:43,296 INFO: Partial:  that idea fix mi exactly\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:43,327 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:44,245 INFO: OPT time: 0.918\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:44,245 INFO: Final:  that idea fits me exactly\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:44,245 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:   6%|▌         | 86/1450 [01:44<27:43,  1.22s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:44,357 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:44,432 INFO: Partial:  if ai had to big a favorite teem\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:44,494 INFO: Augmented nbest from 100 to 106 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:45,636 INFO: OPT time: 1.141\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:45,636 INFO: Final:  if i had to big a favorite team\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:45,636 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:   6%|▌         | 87/1450 [01:45<27:14,  1.20s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:45,763 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:45,836 INFO: Partial:  bringing something for a public pinnock\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:45,892 INFO: Augmented nbest from 100 to 108 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:46,986 INFO: OPT time: 1.094\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:46,987 INFO: Final:  bringing something for a public picnic\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:46,987 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:   6%|▌         | 88/1450 [01:47<28:31,  1.26s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:47,164 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:47,193 INFO: Partial:  being very good\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:47,220 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:48,008 INFO: OPT time: 0.788\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:48,008 INFO: Final:  being very good\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:48,009 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:   6%|▌         | 89/1450 [01:48<29:09,  1.29s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:48,166 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:48,225 INFO: Partial:  he works on the rund\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:48,287 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:48,976 INFO: OPT time: 0.689\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:48,976 INFO: Final:  he works on the road\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:48,977 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:   6%|▌         | 90/1450 [01:49<27:20,  1.21s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:49,172 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:49,225 INFO: Partial:  goh with good intentions\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:49,265 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:49,953 INFO: OPT time: 0.688\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:49,953 INFO: Final:  go with good intentions\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:49,954 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:   6%|▋         | 91/1450 [01:50<25:42,  1.13s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:50,069 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:50,097 INFO: Partial:  no theirs no whey\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:50,141 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:50,841 INFO: OPT time: 0.700\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:50,841 INFO: Final:  no theirs no whey\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:50,842 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:   6%|▋         | 92/1450 [01:51<24:36,  1.09s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:50,971 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:51,009 INFO: Partial:  that will said wonderful\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:51,035 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:51,712 INFO: OPT time: 0.677\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:51,713 INFO: Final:  that will sound wonderful\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:51,713 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:   6%|▋         | 93/1450 [01:52<23:14,  1.03s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:51,872 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:51,911 INFO: Partial:  your carre is fein and\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:51,941 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:52,909 INFO: OPT time: 0.968\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:52,909 INFO: Final:  your car is fine and everything\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:52,909 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:   6%|▋         | 94/1450 [01:53<22:09,  1.02trial/s]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:53,076 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:53,215 INFO: Partial:  lyke second jobs that they work in the afternoons\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:53,288 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:54,732 INFO: OPT time: 1.444\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:54,732 INFO: Final:  like second jobs that they work in the afternoons\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:54,733 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:   7%|▋         | 95/1450 [01:54<23:36,  1.05s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:54,883 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:54,934 INFO: Partial:  winant that be awful if yu were\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:54,979 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:55,932 INFO: OPT time: 0.953\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:55,932 INFO: Final:  wooden that be awful if you were\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:55,932 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:   7%|▋         | 96/1450 [01:56<28:51,  1.28s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:56,084 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:56,114 INFO: Partial:  weir supposed to be\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:56,141 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:56,831 INFO: OPT time: 0.690\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:56,831 INFO: Final:  weir supposed to be\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:56,832 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:   7%|▋         | 97/1450 [01:57<28:17,  1.25s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:56,984 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:57,040 INFO: Partial:  to take a\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:57,081 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:57,773 INFO: OPT time: 0.691\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:57,773 INFO: Final:  to take a shower\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:57,773 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:   7%|▋         | 98/1450 [01:58<25:52,  1.15s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:57,888 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:57,953 INFO: Partial:  however there is no actually whey to measure this\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:57,997 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:59,163 INFO: OPT time: 1.166\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:59,164 INFO: Final:  however there is no actually way to measure this\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:59,164 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:   7%|▋         | 99/1450 [01:59<24:27,  1.09s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:59,290 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:59,322 INFO: Partial:  really well regulated\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:47:59,347 INFO: Augmented nbest from 100 to 128 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:00,072 INFO: OPT time: 0.726\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:00,072 INFO: Final:  really well regulated\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:00,073 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:   7%|▋         | 100/1450 [02:00<26:29,  1.18s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:00,191 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:00,235 INFO: Partial:  theirs nothing wrong with that\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:00,263 INFO: Augmented nbest from 100 to 128 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:01,279 INFO: OPT time: 1.016\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:01,280 INFO: Final:  theirs nothing wrong with that\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:01,280 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:   7%|▋         | 101/1450 [02:01<24:39,  1.10s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:01,393 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:01,487 INFO: Partial:  other states have taken strawder measures\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:01,545 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:02,405 INFO: OPT time: 0.860\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:02,405 INFO: Final:  other states have taken stronger measures\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:02,406 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:   7%|▋         | 102/1450 [02:02<25:23,  1.13s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:02,597 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:02,660 INFO: Partial:  which ai thought was a riel interesting crosson\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:02,722 INFO: Augmented nbest from 100 to 134 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:04,270 INFO: OPT time: 1.548\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:04,270 INFO: Final:  which i thought was a real interesting crosson\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:04,271 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:   7%|▋         | 103/1450 [02:03<25:20,  1.13s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:04,399 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:04,468 INFO: Partial:  its as mutsch research as they can possibly due\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:04,589 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:05,757 INFO: OPT time: 1.168\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:05,757 INFO: Final:  its as much research as they can possibly due\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:05,758 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:   7%|▋         | 104/1450 [02:05<30:16,  1.35s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:05,905 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:05,968 INFO: Partial:  your knowledgeable on that\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:05,990 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:06,677 INFO: OPT time: 0.687\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:06,677 INFO: Final:  your knowledgeable on that\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:06,678 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:   7%|▋         | 105/1450 [02:07<31:10,  1.39s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:06,807 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:06,842 INFO: Partial:  yu cel them\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:06,867 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:07,560 INFO: OPT time: 0.693\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:07,560 INFO: Final:  you sell them\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:07,560 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:   7%|▋         | 106/1450 [02:08<27:59,  1.25s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:07,709 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:07,761 INFO: Partial:  never bated the outside\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:07,790 INFO: Augmented nbest from 100 to 130 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:08,711 INFO: OPT time: 0.922\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:08,712 INFO: Final:  never baited the outside\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:08,712 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:   7%|▋         | 107/1450 [02:09<25:30,  1.14s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:08,910 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:08,938 INFO: Partial:  now its bakke again\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:08,961 INFO: Augmented nbest from 100 to 104 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:09,661 INFO: OPT time: 0.699\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:09,661 INFO: Final:  now its back again\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:09,661 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:   7%|▋         | 108/1450 [02:10<25:34,  1.14s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:09,812 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:09,857 INFO: Partial:  weir never going to get that bakke\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:09,902 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:11,029 INFO: OPT time: 1.126\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:11,029 INFO: Final:  weir never going to get that back\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:11,029 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:   8%|▊         | 109/1450 [02:11<24:14,  1.08s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:11,215 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:11,258 INFO: Partial:  dote sci things changing really\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:11,289 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:12,255 INFO: OPT time: 0.966\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:12,255 INFO: Final:  dint see things changing really\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:12,256 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:   8%|▊         | 110/1450 [02:12<26:07,  1.17s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:12,418 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:12,464 INFO: Partial:  who yu never expect to when\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:12,498 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:13,356 INFO: OPT time: 0.857\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:13,356 INFO: Final:  who you never expect to when\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:13,357 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:   8%|▊         | 111/1450 [02:13<26:29,  1.19s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:13,522 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:13,566 INFO: Partial:  did yu sci pacific ice\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:13,600 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:14,550 INFO: OPT time: 0.950\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:14,550 INFO: Final:  did you see pacific ice\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:14,550 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:   8%|▊         | 112/1450 [02:14<25:53,  1.16s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:14,725 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:14,802 INFO: Partial:  there was sum really nasty patronizing\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:14,846 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:15,829 INFO: OPT time: 0.982\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:15,829 INFO: Final:  there was some really nasty patronizing\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:15,830 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:   8%|▊         | 113/1450 [02:15<26:05,  1.17s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:16,028 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:16,092 INFO: Partial:  the decision append a lower cart rilling\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:16,140 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:17,126 INFO: OPT time: 0.986\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:17,126 INFO: Final:  the decision appealed a lower court rilling\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:17,126 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:   8%|▊         | 114/1450 [02:17<26:47,  1.20s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:17,331 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:17,385 INFO: Partial:  think that is an excellent program\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:17,424 INFO: Augmented nbest from 100 to 108 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:18,264 INFO: OPT time: 0.840\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:18,265 INFO: Final:  think that is an excellent program\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:18,265 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:   8%|▊         | 115/1450 [02:18<27:23,  1.23s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:18,433 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:18,483 INFO: Partial:  the political aspect\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:18,501 INFO: Augmented nbest from 100 to 112 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:19,165 INFO: OPT time: 0.664\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:19,165 INFO: Final:  the political aspect\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:19,166 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:   8%|▊         | 116/1450 [02:19<26:45,  1.20s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:19,334 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:19,383 INFO: Partial:  since ai due a lot of projects\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:19,421 INFO: Augmented nbest from 100 to 116 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:20,453 INFO: OPT time: 1.032\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:20,453 INFO: Final:  since i do a lot of projects\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:20,453 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:   8%|▊         | 117/1450 [02:20<24:43,  1.11s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:20,639 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:20,678 INFO: Partial:  they deduct kut us off\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:20,713 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:21,405 INFO: OPT time: 0.692\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:21,405 INFO: Final:  they didn't cut us off\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:21,406 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:   8%|▊         | 118/1450 [02:21<25:52,  1.17s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:21,542 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:21,606 INFO: Partial:  every major city has a thadda\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:21,655 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:22,634 INFO: OPT time: 0.979\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:22,634 INFO: Final:  every major city has a third\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:22,635 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:   8%|▊         | 119/1450 [02:22<24:25,  1.10s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:22,743 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:22,781 INFO: Partial:  the raul in the family\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:22,809 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:23,501 INFO: OPT time: 0.692\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:23,501 INFO: Final:  the role in the family\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:23,502 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:   8%|▊         | 120/1450 [02:24<25:15,  1.14s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:23,645 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:23,696 INFO: Partial:  oui doanh really it out to mutsch\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:23,745 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:24,907 INFO: OPT time: 1.162\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:24,907 INFO: Final:  we doan really it out to much\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:24,908 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:   8%|▊         | 121/1450 [02:24<23:25,  1.06s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:25,047 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:25,081 INFO: Partial:  give and incentive\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:25,108 INFO: Augmented nbest from 100 to 114 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:25,899 INFO: OPT time: 0.791\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:25,899 INFO: Final:  give an incentive\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:25,899 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:   8%|▊         | 122/1450 [02:26<25:43,  1.16s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:26,048 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:26,122 INFO: Partial:  they live it upp to yu and your jermyn\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:26,195 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:27,391 INFO: OPT time: 1.196\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:27,391 INFO: Final:  they live it up to you and your submit\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:27,392 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:   8%|▊         | 123/1450 [02:27<24:34,  1.11s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:27,554 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:27,588 INFO: Partial:  to bass displace\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:27,623 INFO: Augmented nbest from 100 to 107 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:28,305 INFO: OPT time: 0.682\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:28,305 INFO: Final:  to bass splice\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:28,306 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:   9%|▊         | 124/1450 [02:28<27:05,  1.23s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:28,456 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:28,484 INFO: Partial:  could yu have snow\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:28,510 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:29,319 INFO: OPT time: 0.809\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:29,319 INFO: Final:  could you have snow\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:29,320 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:   9%|▊         | 125/1450 [02:29<25:00,  1.13s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:29,455 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:29,487 INFO: Partial:  when they were younger\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:29,520 INFO: Augmented nbest from 100 to 183 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:30,912 INFO: OPT time: 1.392\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:30,913 INFO: Final:  when they were younger\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:30,913 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:   9%|▊         | 126/1450 [02:30<24:11,  1.10s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:31,059 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:31,101 INFO: Partial:  hope yu enjoyed this\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:31,124 INFO: Augmented nbest from 100 to 103 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:31,831 INFO: OPT time: 0.707\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:31,831 INFO: Final:  hope you enjoyed this\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:31,831 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:   9%|▉         | 127/1450 [02:32<27:28,  1.25s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:31,961 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:32,008 INFO: Partial:  was pretty shocked at that\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:32,045 INFO: Augmented nbest from 100 to 110 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:32,984 INFO: OPT time: 0.939\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:32,984 INFO: Final:  was pretty shocked at that\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:32,984 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:   9%|▉         | 128/1450 [02:33<25:16,  1.15s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:33,164 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:33,206 INFO: Partial:  nott that hive been aware of\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:33,239 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:34,092 INFO: OPT time: 0.853\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:34,092 INFO: Final:  not that i been aware of\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:34,093 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:   9%|▉         | 129/1450 [02:34<25:17,  1.15s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:34,268 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:34,338 INFO: Partial:  was going to se ai always enjoyed that\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:34,383 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:35,496 INFO: OPT time: 1.112\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:35,496 INFO: Final:  was going to say i always enjoyed that\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:35,496 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:   9%|▉         | 130/1450 [02:35<25:00,  1.14s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:35,500 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:35,539 INFO: Partial:  its nott lyke mime going home\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:35,575 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:36,532 INFO: OPT time: 0.957\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:36,532 INFO: Final:  its not like hime going home\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:36,533 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:   9%|▉         | 131/1450 [02:36<26:44,  1.22s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:36,672 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:36,722 INFO: Partial:  due they aull live in the erria\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:36,763 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:37,735 INFO: OPT time: 0.972\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:37,735 INFO: Final:  do they all live in the area\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:37,736 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:   9%|▉         | 132/1450 [02:37<25:32,  1.16s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:37,874 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:37,915 INFO: Partial:  are rohde bye there kids\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:37,955 INFO: Augmented nbest from 100 to 120 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:38,934 INFO: OPT time: 0.979\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:38,934 INFO: Final:  are rode by their kids\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:38,935 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:   9%|▉         | 133/1450 [02:39<25:47,  1.17s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:39,078 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:39,104 INFO: Partial:  its a\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:39,132 INFO: Augmented nbest from 100 to 156 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:40,125 INFO: OPT time: 0.993\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:40,125 INFO: Final:  its a mini\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:40,126 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:   9%|▉         | 134/1450 [02:40<25:55,  1.18s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:40,277 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:40,304 INFO: Partial:  they have the\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:40,332 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:41,015 INFO: OPT time: 0.682\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:41,015 INFO: Final:  they have the merit\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:41,015 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:   9%|▉         | 135/1450 [02:41<25:58,  1.18s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:41,180 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:41,250 INFO: Partial:  ultimately what yu due is your\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:41,285 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:42,268 INFO: OPT time: 0.984\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:42,268 INFO: Final:  ultimately what you do is your decision\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:42,269 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:   9%|▉         | 136/1450 [02:42<24:00,  1.10s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:42,382 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:42,422 INFO: Partial:  think they goh to\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:42,461 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:43,309 INFO: OPT time: 0.848\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:43,309 INFO: Final:  think they go to far\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:43,310 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:   9%|▉         | 137/1450 [02:43<25:01,  1.14s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:43,485 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:43,528 INFO: Partial:  the beste example\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:43,555 INFO: Augmented nbest from 100 to 111 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:44,264 INFO: OPT time: 0.709\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:44,264 INFO: Final:  the best example\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:44,265 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  10%|▉         | 138/1450 [02:44<24:19,  1.11s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:44,386 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:44,436 INFO: Partial:  soler power\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:44,486 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:45,145 INFO: OPT time: 0.659\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:45,145 INFO: Final:  solar power satellite\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:45,146 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  10%|▉         | 139/1450 [02:45<23:16,  1.07s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:45,292 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:45,337 INFO: Partial:  before ai retired\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:45,366 INFO: Augmented nbest from 100 to 111 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:46,044 INFO: OPT time: 0.678\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:46,044 INFO: Final:  before i retired\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:46,045 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  10%|▉         | 140/1450 [02:46<22:03,  1.01s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:46,191 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:46,244 INFO: Partial:  they can be selective\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:46,270 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:46,948 INFO: OPT time: 0.678\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:46,949 INFO: Final:  they can be selective\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:46,949 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  10%|▉         | 141/1450 [02:47<21:18,  1.02trial/s]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:47,095 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:47,139 INFO: Partial:  where lats of\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:47,175 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:47,972 INFO: OPT time: 0.797\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:47,972 INFO: Final:  wear lots of shorts\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:47,973 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  10%|▉         | 142/1450 [02:48<20:49,  1.05trial/s]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:48,096 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:48,143 INFO: Partial:  maybe five or six years ago\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:48,173 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:49,112 INFO: OPT time: 0.940\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:49,113 INFO: Final:  maybe five or six years ago\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:49,113 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  10%|▉         | 143/1450 [02:49<21:15,  1.02trial/s]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:49,298 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:49,333 INFO: Partial:  dunne pretty good at\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:49,359 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:50,171 INFO: OPT time: 0.812\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:50,171 INFO: Final:  i done pretty good at\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:50,172 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  10%|▉         | 144/1450 [02:50<22:18,  1.02s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:50,302 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:50,375 INFO: Partial:  morr room they nied to\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:50,446 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:51,414 INFO: OPT time: 0.968\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:51,414 INFO: Final:  more room they need to inserts\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:51,414 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  10%|█         | 145/1450 [02:51<22:30,  1.04s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:51,608 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:51,645 INFO: Partial:  oui will appeal this\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:51,663 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:52,462 INFO: OPT time: 0.799\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:52,462 INFO: Final:  we will appeal this decision\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:52,463 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  10%|█         | 146/1450 [02:52<23:51,  1.10s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:52,606 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:52,679 INFO: Partial:  and he that leeks us to our next point\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:52,754 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:53,901 INFO: OPT time: 1.148\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:53,902 INFO: Final:  and hee that leeks us to our next point\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:53,902 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  10%|█         | 147/1450 [02:53<23:30,  1.08s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:54,013 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:54,072 INFO: Partial:  especially when yu get dunne\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:54,107 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:54,912 INFO: OPT time: 0.805\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:54,912 INFO: Final:  especially when you get done\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:54,913 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  10%|█         | 148/1450 [02:55<25:48,  1.19s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:55,112 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:55,225 INFO: Partial:  new write away he sidden try to dutch the talker\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:55,338 INFO: Augmented nbest from 100 to 107 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:56,881 INFO: OPT time: 1.543\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:56,881 INFO: Final:  knew right away he sidden try to dutch the talker\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:56,882 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  10%|█         | 149/1450 [02:56<24:37,  1.14s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:57,023 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:57,053 INFO: Partial:  how should they due\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:57,079 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:57,884 INFO: OPT time: 0.804\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:57,884 INFO: Final:  how should they do\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:57,885 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  10%|█         | 150/1450 [02:58<30:01,  1.39s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:58,020 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:58,064 INFO: Partial:  my wife kind of\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:58,109 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:58,909 INFO: OPT time: 0.800\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:58,909 INFO: Final:  my wife kind of looks\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:58,910 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  10%|█         | 151/1450 [02:59<27:31,  1.27s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:59,024 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:59,051 INFO: Partial:  after five yoos\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:59,077 INFO: Augmented nbest from 100 to 127 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:59,915 INFO: OPT time: 0.839\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:59,915 INFO: Final:  after five years\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:48:59,916 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  10%|█         | 152/1450 [03:00<25:53,  1.20s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:00,025 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:00,117 INFO: Partial:  something to pitiful the school\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:00,151 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:01,258 INFO: OPT time: 1.107\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:01,258 INFO: Final:  do something to petrify the school property\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:01,259 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  11%|█         | 153/1450 [03:01<24:38,  1.14s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:01,430 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:01,501 INFO: Partial:  just to get a time that oui can both goh\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:01,586 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:02,790 INFO: OPT time: 1.204\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:02,791 INFO: Final:  just to get a time that we can both go\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:02,791 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  11%|█         | 154/1450 [03:02<25:56,  1.20s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:02,934 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:02,980 INFO: Partial:  then yu have to make a\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:03,018 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:03,999 INFO: OPT time: 0.980\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:03,999 INFO: Final:  then you have to make a salah\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:04,000 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  11%|█         | 155/1450 [03:04<28:03,  1.30s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:04,135 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:04,176 INFO: Partial:  butt its along the\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:04,220 INFO: Augmented nbest from 100 to 103 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:05,042 INFO: OPT time: 0.823\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:05,042 INFO: Final:  but its along the likes\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:05,043 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  11%|█         | 156/1450 [03:05<27:26,  1.27s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:05,238 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:05,434 INFO: Partial:  atz neet mchugh lyke worse stitching also\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:05,526 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:06,684 INFO: OPT time: 1.158\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:06,684 INFO: Final:  that neat mccue like worse stitching also\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:06,685 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  11%|█         | 157/1450 [03:06<25:56,  1.20s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:06,847 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:06,886 INFO: Partial:  already on my\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:06,918 INFO: Augmented nbest from 100 to 149 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:08,065 INFO: OPT time: 1.146\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:08,065 INFO: Final:  already on my job\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:08,066 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  11%|█         | 158/1450 [03:08<28:45,  1.34s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:08,246 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:08,292 INFO: Partial:  lyttle stricken for each\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:08,327 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:09,133 INFO: OPT time: 0.806\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:09,134 INFO: Final:  little trickle for each\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:09,134 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  11%|█         | 159/1450 [03:09<29:01,  1.35s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:09,250 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:09,276 INFO: Partial:  knowing your choices\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:09,297 INFO: Augmented nbest from 100 to 105 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:09,994 INFO: OPT time: 0.697\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:09,995 INFO: Final:  knowing your choices\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:09,995 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  11%|█         | 160/1450 [03:10<27:11,  1.26s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:10,150 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:10,200 INFO: Partial:  cried luvs hid against\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:10,269 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:11,208 INFO: OPT time: 0.939\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:11,208 INFO: Final:  cried loves hit against des\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:11,209 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  11%|█         | 161/1450 [03:11<24:34,  1.14s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:11,356 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:11,391 INFO: Partial:  gatt plein them\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:11,449 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:12,144 INFO: OPT time: 0.695\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:12,144 INFO: Final:  you get plein them\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:12,145 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  11%|█         | 162/1450 [03:12<25:00,  1.16s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:12,259 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:12,291 INFO: Partial:  probably millets of\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:12,316 INFO: Augmented nbest from 100 to 107 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:13,144 INFO: OPT time: 0.828\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:13,144 INFO: Final:  probably millions of dollars\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:13,145 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  11%|█         | 163/1450 [03:13<23:30,  1.10s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:13,256 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:13,325 INFO: Partial:  so ai gott under there and mest with the\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:13,381 INFO: Augmented nbest from 100 to 104 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:14,558 INFO: OPT time: 1.177\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:14,558 INFO: Final:  so i got under there and messed with the\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:14,559 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  11%|█▏        | 164/1450 [03:14<22:52,  1.07s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:14,763 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:14,825 INFO: Partial:  for as just having huddles around\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:14,861 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:15,979 INFO: OPT time: 1.118\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:15,980 INFO: Final:  as far as just having huddles around\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:15,980 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  11%|█▏        | 165/1450 [03:16<25:04,  1.17s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:16,165 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:16,217 INFO: Partial:  it would depend ubben which won yu\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:16,275 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:17,272 INFO: OPT time: 0.996\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:17,272 INFO: Final:  it would depend about which one you juan\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:17,272 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  11%|█▏        | 166/1450 [03:17<26:40,  1.25s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:17,468 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:17,513 INFO: Partial:  that won wahlert really well\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:17,563 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:18,536 INFO: OPT time: 0.973\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:18,536 INFO: Final:  that one wasn't really well trade\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:18,537 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  12%|█▏        | 167/1450 [03:18<26:56,  1.26s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:18,671 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:18,749 INFO: Partial:  he also whats to sci morr school setty\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:18,816 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:19,977 INFO: OPT time: 1.161\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:19,977 INFO: Final:  he also whats to cie more school safety\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:19,978 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  12%|█▏        | 168/1450 [03:19<26:57,  1.26s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:20,175 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:20,201 INFO: Partial:  les se typical\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:20,229 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:20,886 INFO: OPT time: 0.657\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:20,886 INFO: Final:  lets say typical\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:20,887 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  12%|█▏        | 169/1450 [03:21<28:04,  1.32s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:21,075 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:21,104 INFO: Partial:  yu continue\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:21,122 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:21,783 INFO: OPT time: 0.661\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:21,783 INFO: Final:  do you continue\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:21,784 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  12%|█▏        | 170/1450 [03:22<25:27,  1.19s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:21,977 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:22,040 INFO: Partial:  put aull the money into\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:22,078 INFO: Augmented nbest from 100 to 122 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:23,079 INFO: OPT time: 1.001\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:23,079 INFO: Final:  put all the money into it\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:23,079 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  12%|█▏        | 171/1450 [03:23<23:32,  1.10s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:23,280 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:23,336 INFO: Partial:  pundits just inedible\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:23,389 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:24,190 INFO: OPT time: 0.801\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:24,191 INFO: Final:  and its just india\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:24,191 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  12%|█▏        | 172/1450 [03:24<24:44,  1.16s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:24,384 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:24,422 INFO: Partial:  its funny ai was\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:24,464 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:25,272 INFO: OPT time: 0.807\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:25,272 INFO: Final:  its funny i was read\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:25,272 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  12%|█▏        | 173/1450 [03:25<24:24,  1.15s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:25,385 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:25,459 INFO: Partial:  stil gott a couple of years on in to goh\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:25,546 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:26,751 INFO: OPT time: 1.204\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:26,751 INFO: Final:  still got a couple of years on it to go\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:26,751 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  12%|█▏        | 174/1450 [03:26<23:58,  1.13s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:26,891 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:26,934 INFO: Partial:  oui doanh have anywhere to goh\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:26,975 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:28,097 INFO: OPT time: 1.122\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:28,097 INFO: Final:  we doan have anywhere to go\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:28,098 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  12%|█▏        | 175/1450 [03:28<26:11,  1.23s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:28,292 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:28,355 INFO: Partial:  and its decision can lien to a different\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:28,433 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:29,603 INFO: OPT time: 1.170\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:29,603 INFO: Final:  and its decision can lean to a different reas\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:29,604 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  12%|█▏        | 176/1450 [03:29<26:53,  1.27s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:29,797 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:29,866 INFO: Partial:  won in the mourning and won in the evening\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:29,909 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:30,865 INFO: OPT time: 0.956\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:30,865 INFO: Final:  one in the morning and one in the evening\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:30,866 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  12%|█▏        | 177/1450 [03:31<28:23,  1.34s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:30,998 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:31,033 INFO: Partial:  can yu\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:31,068 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:31,593 INFO: OPT time: 0.525\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:31,593 INFO: Final:  can you imagine\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:31,594 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  12%|█▏        | 178/1450 [03:32<27:53,  1.32s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:31,703 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:31,760 INFO: Partial:  its about thirty since miles away\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:31,804 INFO: Augmented nbest from 100 to 133 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:32,989 INFO: OPT time: 1.185\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:32,989 INFO: Final:  its about thirty six miles away\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:32,989 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  12%|█▏        | 179/1450 [03:33<24:08,  1.14s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:33,104 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:33,166 INFO: Partial:  can gott that mutsch off the end\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:33,216 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:34,168 INFO: OPT time: 0.951\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:34,168 INFO: Final:  can got that much off the n\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:34,168 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  12%|█▏        | 180/1450 [03:34<25:44,  1.22s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:34,307 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:34,398 INFO: Partial:  as long as he pus in the ours he needs to due\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:34,513 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:35,956 INFO: OPT time: 1.443\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:35,956 INFO: Final:  as long as he pus in the hours he needs to due\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:35,957 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  12%|█▏        | 181/1450 [03:35<25:29,  1.21s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:36,112 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:36,147 INFO: Partial:  that won that yu had\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:36,179 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:36,879 INFO: OPT time: 0.700\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:36,879 INFO: Final:  that one that you had\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:36,880 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  13%|█▎        | 182/1450 [03:37<29:10,  1.38s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:37,010 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:37,070 INFO: Partial:  both of the children were in college\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:37,122 INFO: Augmented nbest from 100 to 128 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:38,326 INFO: OPT time: 1.203\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:38,326 INFO: Final:  both of the children were in college\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:38,326 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  13%|█▎        | 183/1450 [03:38<26:14,  1.24s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:38,514 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:38,591 INFO: Partial:  yu can get the information to sette it upp\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:38,651 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:39,817 INFO: OPT time: 1.165\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:39,817 INFO: Final:  you can get the information to set it up\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:39,817 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  13%|█▎        | 184/1450 [03:39<27:30,  1.30s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:40,019 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:40,075 INFO: Partial:  fined a place that has a nice job\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:40,127 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:41,274 INFO: OPT time: 1.147\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:41,274 INFO: Final:  find a place that has a nice job\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:41,275 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  13%|█▎        | 185/1450 [03:41<28:40,  1.36s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:41,421 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:41,455 INFO: Partial:  bick the write persson\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:41,519 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:42,325 INFO: OPT time: 0.806\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:42,325 INFO: Final:  back the right person\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:42,325 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  13%|█▎        | 186/1450 [03:42<29:16,  1.39s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:42,529 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:42,557 INFO: Partial:  get calls at home\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:42,585 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:43,385 INFO: OPT time: 0.799\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:43,385 INFO: Final:  get calls at home\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:43,385 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  13%|█▎        | 187/1450 [03:43<27:06,  1.29s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:43,526 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:43,565 INFO: Partial:  somebody was telling mi\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:43,593 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:44,444 INFO: OPT time: 0.850\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:44,444 INFO: Final:  somebody was telling me\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:44,445 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  13%|█▎        | 188/1450 [03:44<25:38,  1.22s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:44,629 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:44,656 INFO: Partial:  couple of problems\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:44,677 INFO: Augmented nbest from 100 to 108 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:45,371 INFO: OPT time: 0.694\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:45,371 INFO: Final:  couple of problems\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:45,372 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  13%|█▎        | 189/1450 [03:45<24:37,  1.17s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:45,530 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:45,570 INFO: Partial:  butt that was a really fun\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:45,602 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:46,571 INFO: OPT time: 0.968\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:46,571 INFO: Final:  but that was a really fun\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:46,572 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  13%|█▎        | 190/1450 [03:46<23:03,  1.10s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:46,735 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:46,775 INFO: Partial:  it sums lyke its good\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:46,814 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:47,658 INFO: OPT time: 0.843\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:47,658 INFO: Final:  it sounds like its good\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:47,658 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  13%|█▎        | 191/1450 [03:48<23:40,  1.13s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:47,840 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:47,874 INFO: Partial:  vote religiously\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:47,900 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:48,324 INFO: OPT time: 0.424\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:48,324 INFO: Final:  vote religiously\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:48,325 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  13%|█▎        | 192/1450 [03:49<23:24,  1.12s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:48,441 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:48,465 INFO: Partial:  there excellent\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:48,477 INFO: Augmented nbest from 20 to 20 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:48,583 INFO: OPT time: 0.106\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:48,583 INFO: Final:  their excellent\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:48,584 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  13%|█▎        | 193/1450 [03:49<20:33,  1.02trial/s]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:48,585 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:48,617 INFO: Partial:  nec has great vision\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:48,645 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:49,309 INFO: OPT time: 0.663\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:49,309 INFO: Final:  nick has great vision\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:49,309 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  13%|█▎        | 194/1450 [03:50<15:59,  1.31trial/s]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:49,443 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:49,490 INFO: Partial:  that just an extreme example\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:49,529 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:50,336 INFO: OPT time: 0.807\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:50,336 INFO: Final:  that's just an extreme example\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:50,337 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  13%|█▎        | 195/1450 [03:50<15:44,  1.33trial/s]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:50,445 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:50,512 INFO: Partial:  lot of things are really valent type movies\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:50,558 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:51,741 INFO: OPT time: 1.183\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:51,741 INFO: Final:  lot of things are really violent type movies\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:51,742 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  14%|█▎        | 196/1450 [03:51<17:27,  1.20trial/s]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:51,848 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:51,931 INFO: Partial:  think that be neet\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:52,003 INFO: Augmented nbest from 100 to 101 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:52,680 INFO: OPT time: 0.677\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:52,680 INFO: Final:  think that be neat\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:52,681 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  14%|█▎        | 197/1450 [03:53<21:00,  1.01s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:52,855 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:52,911 INFO: Partial:  put aull your recyclables in that won\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:52,952 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:54,075 INFO: OPT time: 1.123\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:54,075 INFO: Final:  put all your recyclables in that one\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:54,076 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  14%|█▎        | 198/1450 [03:54<20:34,  1.01trial/s]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:54,253 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:54,282 INFO: Partial:  your present location\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:54,304 INFO: Augmented nbest from 100 to 119 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:54,970 INFO: OPT time: 0.666\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:54,970 INFO: Final:  your present location\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:54,971 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  14%|█▎        | 199/1450 [03:55<23:07,  1.11s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:55,153 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:55,186 INFO: Partial:  aisle take it out\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:55,216 INFO: Augmented nbest from 100 to 139 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:56,165 INFO: OPT time: 0.948\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:56,165 INFO: Final:  aisle take it out\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:56,166 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  14%|█▍        | 200/1450 [03:56<21:45,  1.04s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:56,358 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:56,398 INFO: Partial:  people going into different fields\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:56,430 INFO: Augmented nbest from 100 to 126 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:57,429 INFO: OPT time: 0.999\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:57,429 INFO: Final:  people going into different fields\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:57,429 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  14%|█▍        | 201/1450 [03:57<22:41,  1.09s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:57,558 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:57,615 INFO: Partial:  guess the question is in my mined\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:57,667 INFO: Augmented nbest from 100 to 104 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:58,634 INFO: OPT time: 0.967\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:58,635 INFO: Final:  guess the question is in my mind\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:58,635 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  14%|█▍        | 202/1450 [03:58<23:45,  1.14s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:58,763 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:58,811 INFO: Partial:  letz talk about here pollution\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:58,845 INFO: Augmented nbest from 100 to 105 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:59,681 INFO: OPT time: 0.837\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:59,682 INFO: Final:  lets talk about here pollution\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:59,682 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  14%|█▍        | 203/1450 [04:00<24:07,  1.16s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:59,865 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:59,901 INFO: Partial:  wont be driving\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:49:59,918 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:00,591 INFO: OPT time: 0.673\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:00,591 INFO: Final:  wont be driving\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:00,592 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  14%|█▍        | 204/1450 [04:01<23:24,  1.13s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:00,765 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:00,803 INFO: Partial:  which is a good diel\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:00,834 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:01,651 INFO: OPT time: 0.816\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:01,651 INFO: Final:  which is a good deal\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:01,651 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  14%|█▍        | 205/1450 [04:02<22:01,  1.06s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:01,768 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:01,841 INFO: Partial:  no lats of women would due it aull the time\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:01,915 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:03,119 INFO: OPT time: 1.203\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:03,119 INFO: Final:  know lats of women would due it all the time\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:03,119 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  14%|█▍        | 206/1450 [04:03<22:00,  1.06s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:03,273 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:03,321 INFO: Partial:  this is my dax parte\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:03,367 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:04,214 INFO: OPT time: 0.847\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:04,214 INFO: Final:  this is my dads part\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:04,215 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  14%|█▍        | 207/1450 [04:04<24:30,  1.18s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:04,375 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:04,408 INFO: Partial:  yu could stick to that\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:04,435 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:05,127 INFO: OPT time: 0.692\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:05,127 INFO: Final:  you could stick to that\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:05,128 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  14%|█▍        | 208/1450 [04:05<23:56,  1.16s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:05,275 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:05,302 INFO: Partial:  enjoy the inventor\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:05,321 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:05,997 INFO: OPT time: 0.676\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:05,997 INFO: Final:  enjoy the inventor\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:05,998 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  14%|█▍        | 209/1450 [04:06<22:24,  1.08s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:06,177 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:06,220 INFO: Partial:  dote have access other\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:06,251 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:07,056 INFO: OPT time: 0.804\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:07,056 INFO: Final:  dint have access either\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:07,057 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  14%|█▍        | 210/1450 [04:07<21:04,  1.02s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:07,180 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:07,244 INFO: Partial:  certainly if yu watch it any amount of time\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:07,283 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:08,420 INFO: OPT time: 1.136\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:08,420 INFO: Final:  certainly if you watch it any amount of time\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:08,421 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  15%|█▍        | 211/1450 [04:08<21:17,  1.03s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:08,586 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:08,633 INFO: Partial:  no income taxes in taxes\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:08,670 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:09,468 INFO: OPT time: 0.798\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:09,468 INFO: Final:  no income taxes in texas\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:09,469 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  15%|█▍        | 212/1450 [04:09<23:20,  1.13s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:09,588 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:09,635 INFO: Partial:  dote no if yu have won\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:09,686 INFO: Augmented nbest from 100 to 133 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:10,876 INFO: OPT time: 1.190\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:10,876 INFO: Final:  dote know if you have won\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:10,877 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  15%|█▍        | 213/1450 [04:10<22:48,  1.11s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:10,992 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:11,045 INFO: Partial:  are our prisons overcrowded\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:11,070 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:11,914 INFO: OPT time: 0.844\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:11,914 INFO: Final:  why are our prisons overcrowded\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:11,915 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  15%|█▍        | 214/1450 [04:12<24:39,  1.20s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:12,093 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:12,129 INFO: Partial:  they would vote true choyce\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:12,168 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:13,138 INFO: OPT time: 0.970\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:13,138 INFO: Final:  they would vote true choice\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:13,138 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  15%|█▍        | 215/1450 [04:13<23:39,  1.15s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:13,296 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:13,332 INFO: Partial:  when he gose to school\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:13,362 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:14,298 INFO: OPT time: 0.935\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:14,298 INFO: Final:  when he goes to school\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:14,298 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  15%|█▍        | 216/1450 [04:14<24:05,  1.17s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:14,497 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:14,543 INFO: Partial:  it was lyke five or six dollars\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:14,581 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:15,526 INFO: OPT time: 0.946\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:15,526 INFO: Final:  it was like five or six dollars\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:15,527 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  15%|█▍        | 217/1450 [04:15<24:00,  1.17s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:15,700 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:15,746 INFO: Partial:  just thought that they drug upp\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:15,789 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:16,641 INFO: OPT time: 0.851\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:16,641 INFO: Final:  just thought that they broke up\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:16,641 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  15%|█▌        | 218/1450 [04:16<24:21,  1.19s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:16,802 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:16,859 INFO: Partial:  its only lyke eleven hundred square feet\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:16,965 INFO: Augmented nbest from 100 to 108 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:17,943 INFO: OPT time: 0.978\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:17,944 INFO: Final:  its only like eleven hundred square feet\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:17,944 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  15%|█▌        | 219/1450 [04:18<23:53,  1.16s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:18,105 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:18,147 INFO: Partial:  dote blowe there hand of\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:18,191 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:19,007 INFO: OPT time: 0.816\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:19,007 INFO: Final:  daunt blow their hand of\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:19,008 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  15%|█▌        | 220/1450 [04:19<24:43,  1.21s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:19,210 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:19,282 INFO: Partial:  when he comes the final decision will be\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:19,358 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:20,510 INFO: OPT time: 1.152\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:20,510 INFO: Final:  when he comes the final decision will be made\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:20,511 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  15%|█▌        | 221/1450 [04:20<23:49,  1.16s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:20,712 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:20,746 INFO: Partial:  the carpeting is grows\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:20,777 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:21,468 INFO: OPT time: 0.692\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:21,469 INFO: Final:  the carpeting is gross\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:21,469 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  15%|█▌        | 222/1450 [04:21<25:53,  1.27s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:21,613 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:21,667 INFO: Partial:  points frum the maynes report\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:21,699 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:22,549 INFO: OPT time: 0.850\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:22,550 INFO: Final:  key points from the mains report\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:22,550 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  15%|█▌        | 223/1450 [04:22<23:59,  1.17s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:22,716 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:22,758 INFO: Partial:  there out our buseman\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:22,794 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:23,633 INFO: OPT time: 0.839\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:23,633 INFO: Final:  their out our basement\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:23,633 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  15%|█▌        | 224/1450 [04:23<23:24,  1.15s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:23,818 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:23,843 INFO: Partial:  compean and everything\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:23,862 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:24,547 INFO: OPT time: 0.685\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:24,548 INFO: Final:  new carpet and everything\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:24,548 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  16%|█▌        | 225/1450 [04:25<23:00,  1.13s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:24,719 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:24,792 INFO: Partial:  they would have had kids running around bye then\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:24,851 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:25,982 INFO: OPT time: 1.130\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:25,982 INFO: Final:  they would have had kids running around by then\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:25,982 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  16%|█▌        | 226/1450 [04:25<21:41,  1.06s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:26,124 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:26,160 INFO: Partial:  think our next carre\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:26,183 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:26,869 INFO: OPT time: 0.686\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:26,870 INFO: Final:  think our next car\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:26,870 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  16%|█▌        | 227/1450 [04:27<23:56,  1.17s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:27,025 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:27,099 INFO: Partial:  think its there whey of saying how well yu due\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:27,184 INFO: Augmented nbest from 100 to 160 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:29,142 INFO: OPT time: 1.958\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:29,142 INFO: Final:  think its their whey of saying how well u due\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:29,143 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  16%|█▌        | 228/1450 [04:28<22:10,  1.09s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:29,331 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:29,397 INFO: Partial:  aull of a sighted yu look and theirs three\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:29,455 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:30,612 INFO: OPT time: 1.156\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:30,612 INFO: Final:  all of a cited you look and theirs three\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:30,612 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  16%|█▌        | 229/1450 [04:30<29:22,  1.44s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:30,734 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:30,769 INFO: Partial:  he bettor nott be mine\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:30,803 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:31,604 INFO: OPT time: 0.801\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:31,604 INFO: Final:  he better not be mine\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:31,605 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  16%|█▌        | 230/1450 [04:32<29:30,  1.45s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:31,737 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:31,784 INFO: Partial:  mayde dish and a dysert\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:31,844 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:32,690 INFO: OPT time: 0.846\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:32,690 INFO: Final:  made dish and a dysart\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:32,691 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  16%|█▌        | 231/1450 [04:33<26:41,  1.31s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:32,841 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:32,886 INFO: Partial:  how many divisions does he have\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:32,926 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:33,873 INFO: OPT time: 0.946\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:33,873 INFO: Final:  how many divisions does he have\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:33,874 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  16%|█▌        | 232/1450 [04:34<25:16,  1.25s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:34,041 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:34,067 INFO: Partial:  long term consequences\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:34,096 INFO: Augmented nbest from 100 to 110 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:34,755 INFO: OPT time: 0.659\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:34,756 INFO: Final:  long term consequences\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:34,756 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  16%|█▌        | 233/1450 [04:35<24:52,  1.23s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:34,944 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:34,972 INFO: Partial:  no a girl\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:34,998 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:35,655 INFO: OPT time: 0.658\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:35,656 INFO: Final:  know a girl\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:35,656 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  16%|█▌        | 234/1450 [04:36<22:45,  1.12s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:35,845 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:35,914 INFO: Partial:  oui sette a rehder nested\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:36,008 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:36,949 INFO: OPT time: 0.942\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:36,950 INFO: Final:  we set a reder nested\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:36,950 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  16%|█▌        | 235/1450 [04:37<21:23,  1.06s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:37,149 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:37,184 INFO: Partial:  dote have any problem\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:37,209 INFO: Augmented nbest from 100 to 103 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:37,922 INFO: OPT time: 0.712\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:37,922 INFO: Final:  don't have any problem\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:37,922 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  16%|█▋        | 236/1450 [04:38<22:49,  1.13s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:38,048 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:38,121 INFO: Partial:  had a hard time getting city on a jury\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:38,190 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:39,347 INFO: OPT time: 1.156\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:39,347 INFO: Final:  had a hard time getting city on a jury\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:39,347 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  16%|█▋        | 237/1450 [04:39<21:51,  1.08s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:39,553 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:39,624 INFO: Partial:  doanh it the walk at aull\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:39,720 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:40,700 INFO: OPT time: 0.979\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:40,700 INFO: Final:  doan it the walk at all\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:40,700 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  16%|█▋        | 238/1450 [04:40<23:55,  1.18s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:40,861 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:40,947 INFO: Partial:  hast us to bundle our newspapers\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:41,004 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:41,867 INFO: OPT time: 0.863\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:41,867 INFO: Final:  they asked us to bundle our newspapers\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:41,868 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  16%|█▋        | 239/1450 [04:42<24:55,  1.23s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:42,060 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:42,131 INFO: Partial:  make a collection on monday for yard\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:42,190 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:43,348 INFO: OPT time: 1.157\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:43,348 INFO: Final:  they make a collection on monday for yard weights\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:43,349 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  17%|█▋        | 240/1450 [04:43<24:29,  1.21s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:43,461 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:43,518 INFO: Partial:  goulden tkach won to sejm your life\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:43,562 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:44,747 INFO: OPT time: 1.185\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:44,747 INFO: Final:  gooden catch one to save your life\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:44,748 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  17%|█▋        | 241/1450 [04:44<26:04,  1.29s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:44,863 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:44,931 INFO: Partial:  was a great pleasure speaking with yu\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:45,039 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:45,998 INFO: OPT time: 0.958\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:45,998 INFO: Final:  was a great pleasure speaking with you\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:45,999 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  17%|█▋        | 242/1450 [04:46<26:41,  1.33s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:46,170 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:46,203 INFO: Partial:  due oui just goh ahead\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:46,237 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:47,180 INFO: OPT time: 0.943\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:47,180 INFO: Final:  du we just go ahead\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:47,181 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  17%|█▋        | 243/1450 [04:47<26:13,  1.30s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:47,370 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:47,416 INFO: Partial:  felt kind of stubborn\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:47,458 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:48,268 INFO: OPT time: 0.809\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:48,268 INFO: Final:  felt kind of stupid\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:48,268 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  17%|█▋        | 244/1450 [04:48<25:28,  1.27s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:48,473 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:48,498 INFO: Partial:  things its grade\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:48,524 INFO: Augmented nbest from 100 to 118 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:49,188 INFO: OPT time: 0.664\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:49,188 INFO: Final:  think its great\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:49,188 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  17%|█▋        | 245/1450 [04:49<24:21,  1.21s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:49,372 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:49,485 INFO: Partial:  mineral of the jury\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:49,571 INFO: Augmented nbest from 100 to 165 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:50,774 INFO: OPT time: 1.203\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:50,774 INFO: Final:  perjury of the jury\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:50,775 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  17%|█▋        | 246/1450 [04:50<22:34,  1.13s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:50,985 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:51,022 INFO: Partial:  yu no what ai am saying\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:51,051 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:51,913 INFO: OPT time: 0.861\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:51,913 INFO: Final:  you know what eye am saying\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:51,913 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  17%|█▋        | 247/1450 [04:52<25:20,  1.26s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:52,078 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:52,107 INFO: Partial:  they turn them\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:52,131 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:52,810 INFO: OPT time: 0.679\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:52,810 INFO: Final:  they turn them loose\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:52,811 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  17%|█▋        | 248/1450 [04:53<24:33,  1.23s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:52,981 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:53,063 INFO: Partial:  he went to venal won mine an kaim bakke another\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:53,144 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:54,595 INFO: OPT time: 1.451\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:54,595 INFO: Final:  he went to venal one mine an came back another\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:54,595 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  17%|█▋        | 249/1450 [04:54<22:34,  1.13s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:54,787 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:54,815 INFO: Partial:  morr or les at home\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:54,847 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:55,690 INFO: OPT time: 0.843\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:55,690 INFO: Final:  more or less at home\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:55,691 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  17%|█▋        | 250/1450 [04:56<26:29,  1.32s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:55,888 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:55,939 INFO: Partial:  yu can avoid this problem in to\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:55,974 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:56,832 INFO: OPT time: 0.858\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:56,832 INFO: Final:  you can avoid this problem in two\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:56,833 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  17%|█▋        | 251/1450 [04:57<25:05,  1.26s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:56,991 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:57,060 INFO: Partial:  whats the specialty that your looking\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:57,109 INFO: Augmented nbest from 100 to 104 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:58,106 INFO: OPT time: 0.997\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:58,106 INFO: Final:  whats the specialty that your looking for\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:58,106 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  17%|█▋        | 252/1450 [04:58<24:23,  1.22s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:58,293 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:58,389 INFO: Partial:  germany is a gets in point\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:58,455 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:59,400 INFO: OPT time: 0.945\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:59,400 INFO: Final:  germany is a case in point\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:59,400 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  17%|█▋        | 253/1450 [04:59<24:40,  1.24s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:59,599 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:59,631 INFO: Partial:  sumter it was easy\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:50:59,659 INFO: Augmented nbest from 100 to 151 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:00,805 INFO: OPT time: 1.146\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:00,805 INFO: Final:  sometime it was easy\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:00,806 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  18%|█▊        | 254/1450 [05:00<25:00,  1.25s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:01,000 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:01,031 INFO: Partial:  dunne those to\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:01,060 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:01,711 INFO: OPT time: 0.651\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:01,711 INFO: Final:  done those too\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:01,712 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  18%|█▊        | 255/1450 [05:02<25:53,  1.30s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:01,904 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:01,942 INFO: Partial:  its a whole experience\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:01,971 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:02,658 INFO: OPT time: 0.687\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:02,658 INFO: Final:  its a whole experience\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:02,658 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  18%|█▊        | 256/1450 [05:03<23:30,  1.18s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:02,804 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:02,895 INFO: Partial:  order to bolick the divison the schools mutsch be splat\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:02,992 INFO: Augmented nbest from 100 to 112 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:04,453 INFO: OPT time: 1.461\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:04,453 INFO: Final:  order to bolich the division the schools much be splat\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:04,454 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  18%|█▊        | 257/1450 [05:04<22:05,  1.11s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:04,613 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:04,708 INFO: Partial:  tradeable disposition\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:04,740 INFO: Augmented nbest from 100 to 101 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:05,553 INFO: OPT time: 0.813\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:05,553 INFO: Final:  tradable disposition\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:05,554 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  18%|█▊        | 258/1450 [05:05<26:09,  1.32s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:05,711 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:05,752 INFO: Partial:  its aull rohde upp into won\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:05,794 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:06,742 INFO: OPT time: 0.947\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:06,742 INFO: Final:  its all rode up into one\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:06,742 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  18%|█▊        | 259/1450 [05:06<24:50,  1.25s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:06,915 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:06,957 INFO: Partial:  yu due have a separate erria\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:06,998 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:07,947 INFO: OPT time: 0.949\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:07,947 INFO: Final:  you due have a separate area\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:07,948 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  18%|█▊        | 260/1450 [05:08<24:26,  1.23s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:08,117 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:08,189 INFO: Partial:  think about how many automobiles there are\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:08,237 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:09,097 INFO: OPT time: 0.860\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:09,097 INFO: Final:  think about how many automobiles there are\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:09,098 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  18%|█▊        | 261/1450 [05:09<24:15,  1.22s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:09,219 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:09,247 INFO: Partial:  what are the others\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:09,275 INFO: Augmented nbest from 100 to 162 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:10,407 INFO: OPT time: 1.132\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:10,408 INFO: Final:  what are the others\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:10,408 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  18%|█▊        | 262/1450 [05:10<23:48,  1.20s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:10,522 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:10,561 INFO: Partial:  its really kind of\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:10,601 INFO: Augmented nbest from 100 to 200 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:12,458 INFO: OPT time: 1.857\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:12,458 INFO: Final:  its really kind of crazy\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:12,459 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  18%|█▊        | 263/1450 [05:11<24:25,  1.23s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:12,628 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:12,692 INFO: Partial:  the latest android foulds for\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:12,733 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:13,673 INFO: OPT time: 0.939\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:13,673 INFO: Final:  the latest android phones for less\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:13,674 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  18%|█▊        | 264/1450 [05:13<29:14,  1.48s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:13,830 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:13,896 INFO: Partial:  again our choices are nott mayde in a vacuum\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:13,945 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:14,937 INFO: OPT time: 0.992\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:14,938 INFO: Final:  again our choices are not made in a vacuum\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:14,938 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  18%|█▊        | 265/1450 [05:15<27:38,  1.40s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:15,134 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:15,194 INFO: Partial:  babers of contras should have no illusions\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:15,250 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:16,447 INFO: OPT time: 1.197\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:16,447 INFO: Final:  babies of contras should have no illusions\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:16,448 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  18%|█▊        | 266/1450 [05:16<26:49,  1.36s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:16,639 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:16,687 INFO: Partial:  they aside yu a topic\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:16,717 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:17,417 INFO: OPT time: 0.699\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:17,417 INFO: Final:  they assign you a topic\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:17,417 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  18%|█▊        | 267/1450 [05:17<27:41,  1.40s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:17,538 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:17,590 INFO: Partial:  theirs this won akhtar everyone lykes\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:17,629 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:18,576 INFO: OPT time: 0.946\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:18,576 INFO: Final:  theirs this one actor everyone likes\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:18,576 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  18%|█▊        | 268/1450 [05:18<25:05,  1.27s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:18,740 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:18,852 INFO: Partial:  as he gott to be a tennyson\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:18,921 INFO: Augmented nbest from 100 to 123 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:20,305 INFO: OPT time: 1.383\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:20,305 INFO: Final:  as he got to be a tennyson\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:20,306 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  19%|█▊        | 269/1450 [05:20<24:23,  1.24s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:20,446 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:20,488 INFO: Partial:  when love to\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:20,523 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:21,178 INFO: OPT time: 0.654\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:21,178 INFO: Final:  wed love to\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:21,179 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  19%|█▊        | 270/1450 [05:21<27:16,  1.39s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:21,345 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:21,424 INFO: Partial:  these other people are out running around\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:21,470 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:22,440 INFO: OPT time: 0.971\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:22,441 INFO: Final:  all these other people are out running around\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:22,441 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  19%|█▊        | 271/1450 [05:22<24:12,  1.23s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:22,549 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:22,605 INFO: Partial:  lot of mover\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:22,640 INFO: Augmented nbest from 100 to 129 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:23,459 INFO: OPT time: 0.819\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:23,459 INFO: Final:  lot of mover\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:23,460 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  19%|█▉        | 272/1450 [05:23<24:22,  1.24s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:23,653 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:23,691 INFO: Partial:  oui had an oken\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:23,720 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:24,568 INFO: OPT time: 0.848\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:24,568 INFO: Final:  we had an occasion\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:24,569 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  19%|█▉        | 273/1450 [05:24<23:02,  1.17s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:24,754 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:24,896 INFO: Partial:  that is true in alertly and across this nation\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:25,026 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:26,155 INFO: OPT time: 1.128\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:26,155 INFO: Final:  that is true in illinois and across this nation\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:26,155 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  19%|█▉        | 274/1450 [05:26<22:38,  1.15s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:26,365 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:26,437 INFO: Partial:  eason that funny\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:26,483 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:26,998 INFO: OPT time: 0.515\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:26,999 INFO: Final:  even that funny\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:26,999 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  19%|█▉        | 275/1450 [05:27<25:09,  1.28s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:27,164 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:27,205 INFO: Partial:  with stems kandel\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:27,242 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:27,899 INFO: OPT time: 0.657\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:27,899 INFO: Final:  with tims scandal\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:27,900 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  19%|█▉        | 276/1450 [05:28<22:32,  1.15s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:28,061 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:28,110 INFO: Partial:  erly republic\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:28,162 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:28,833 INFO: OPT time: 0.671\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:28,833 INFO: Final:  the only republic\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:28,833 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  19%|█▉        | 277/1450 [05:29<21:03,  1.08s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:28,965 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:29,060 INFO: Partial:  yu goh for long vacating\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:29,173 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:29,987 INFO: OPT time: 0.814\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:29,987 INFO: Final:  you goe for long vacation\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:29,987 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  19%|█▉        | 278/1450 [05:30<20:11,  1.03s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:30,168 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:30,217 INFO: Partial:  and unjust amount of time\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:30,247 INFO: Augmented nbest from 100 to 105 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:31,166 INFO: OPT time: 0.919\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:31,166 INFO: Final:  and unjust amount of time\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:31,167 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  19%|█▉        | 279/1450 [05:31<20:52,  1.07s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:31,368 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:31,438 INFO: Partial:  breaking morr often than usual\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:31,472 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:32,319 INFO: OPT time: 0.847\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:32,319 INFO: Final:  breaking more often than usual\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:32,320 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  19%|█▉        | 280/1450 [05:32<21:30,  1.10s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:32,471 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:32,518 INFO: Partial:  thought it was pretty good\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:32,552 INFO: Augmented nbest from 100 to 115 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:33,508 INFO: OPT time: 0.956\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:33,508 INFO: Final:  thought it was pretty good\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:33,509 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  19%|█▉        | 281/1450 [05:33<21:46,  1.12s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:33,671 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:33,786 INFO: Partial:  rais aerien rather than changer base\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:33,938 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:34,920 INFO: OPT time: 0.982\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:34,920 INFO: Final:  race area rather than changer base\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:34,921 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  19%|█▉        | 282/1450 [05:34<22:10,  1.14s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:35,082 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:35,144 INFO: Partial:  there needs to be a lon jun somewhere\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:35,214 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:36,197 INFO: OPT time: 0.983\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:36,197 INFO: Final:  there needs to be a lon run somewhere\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:36,198 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  20%|█▉        | 283/1450 [05:36<23:44,  1.22s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:36,380 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:36,408 INFO: Partial:  how strung is it\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:36,431 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:37,117 INFO: OPT time: 0.686\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:37,117 INFO: Final:  how strong is it\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:37,118 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  20%|█▉        | 284/1450 [05:37<24:03,  1.24s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:37,280 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:37,325 INFO: Partial:  will agree to that\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:37,349 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:38,010 INFO: OPT time: 0.661\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:38,010 INFO: Final:  will agree to that\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:38,011 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  20%|█▉        | 285/1450 [05:38<22:11,  1.14s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:38,181 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:38,221 INFO: Partial:  if your involved yourself\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:38,252 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:38,911 INFO: OPT time: 0.658\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:38,911 INFO: Final:  if your involved yourself\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:38,912 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  20%|█▉        | 286/1450 [05:39<20:42,  1.07s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:39,085 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:39,159 INFO: Partial:  they can always maybe get somebody house to cook\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:39,229 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:40,436 INFO: OPT time: 1.206\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:40,436 INFO: Final:  they can always maybe get somebody house to cook\n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  20%|█▉        | 287/1450 [05:40<19:43,  1.02s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:40,438 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:40,444 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:40,482 INFO: Partial:  could due it now\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:40,508 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:41,197 INFO: OPT time: 0.689\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:41,197 INFO: Final:  could do it now\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:41,198 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  20%|█▉        | 288/1450 [05:41<22:39,  1.17s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:41,388 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:41,452 INFO: Partial:  due yu have a roto deller\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:41,514 INFO: Augmented nbest from 100 to 125 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:42,678 INFO: OPT time: 1.164\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:42,679 INFO: Final:  du u have a rhoto deller\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:42,680 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  20%|█▉        | 289/1450 [05:42<20:15,  1.05s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:42,795 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:42,864 INFO: Partial:  they due kumm bakke this year\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:42,925 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:43,898 INFO: OPT time: 0.973\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:43,898 INFO: Final:  if they due come back this year\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:43,899 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  20%|██        | 290/1450 [05:44<22:46,  1.18s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:44,098 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:44,146 INFO: Partial:  think sze has problems with that\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:44,173 INFO: Augmented nbest from 100 to 121 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:45,172 INFO: OPT time: 0.999\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:45,172 INFO: Final:  think she has problems with that\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:45,173 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  20%|██        | 291/1450 [05:45<22:59,  1.19s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:45,297 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:45,343 INFO: Partial:  its site a trouble here\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:45,391 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:46,079 INFO: OPT time: 0.688\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:46,079 INFO: Final:  its such a trouble here\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:46,079 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  20%|██        | 292/1450 [05:46<23:27,  1.22s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:46,201 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:46,317 INFO: Partial:  they trait the nuclear of there power write now\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:46,420 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:47,579 INFO: OPT time: 1.159\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:47,579 INFO: Final:  they trait the nucleus of their power right now\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:47,580 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  20%|██        | 293/1450 [05:47<21:38,  1.12s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:47,706 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:47,793 INFO: Partial:  after that season ahlers had a decision to make\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:47,876 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:49,041 INFO: OPT time: 1.165\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:49,041 INFO: Final:  after that season ahlers had a decision to make\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:49,042 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  20%|██        | 294/1450 [05:49<23:48,  1.24s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:49,206 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:49,282 INFO: Partial:  hees dunne a bunche of baltimore movies\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:49,320 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:50,493 INFO: OPT time: 1.172\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:50,493 INFO: Final:  hees done a bunch of baltimore movies\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:50,494 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  20%|██        | 295/1450 [05:50<25:05,  1.30s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:50,608 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:50,671 INFO: Partial:  and what was the point of it aull\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:50,729 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:51,853 INFO: OPT time: 1.124\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:51,853 INFO: Final:  and what was the point of it all\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:51,854 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  20%|██        | 296/1450 [05:51<25:55,  1.35s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:52,011 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:52,080 INFO: Partial:  people get very upset\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:52,114 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:52,919 INFO: OPT time: 0.804\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:52,919 INFO: Final:  people get very upset\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:52,919 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  20%|██        | 297/1450 [05:53<25:58,  1.35s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:53,113 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:53,172 INFO: Partial:  its doing a lot of demmon\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:53,235 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:54,178 INFO: OPT time: 0.943\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:54,178 INFO: Final:  its doing a lot of devon\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:54,179 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  21%|██        | 298/1450 [05:54<24:18,  1.27s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:54,318 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:54,361 INFO: Partial:  have yu ever had of hur\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:54,405 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:55,259 INFO: OPT time: 0.854\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:55,259 INFO: Final:  have you ever had of her\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:55,260 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  21%|██        | 299/1450 [05:55<24:14,  1.26s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:55,419 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:55,484 INFO: Partial:  there pretty forgiving\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:55,506 INFO: Augmented nbest from 100 to 113 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:56,152 INFO: OPT time: 0.646\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:56,152 INFO: Final:  their pretty forgiving\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:56,153 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  21%|██        | 300/1450 [05:56<23:10,  1.21s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:56,319 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:56,358 INFO: Partial:  where yu frum originally\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:56,385 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:57,188 INFO: OPT time: 0.803\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:57,188 INFO: Final:  where you from originally\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:57,189 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  21%|██        | 301/1450 [05:57<21:20,  1.11s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:57,322 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:57,384 INFO: Partial:  oui manage to get to won\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:57,437 INFO: Augmented nbest from 100 to 120 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:58,563 INFO: OPT time: 1.126\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:58,563 INFO: Final:  we manage to get to one\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:58,563 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  21%|██        | 302/1450 [05:58<20:52,  1.09s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:58,727 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:58,772 INFO: Partial:  when yu watch them goh upp\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:58,810 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:59,667 INFO: OPT time: 0.857\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:59,667 INFO: Final:  when you watch them go up\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:59,667 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  21%|██        | 303/1450 [06:00<22:28,  1.18s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:59,828 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:59,898 INFO: Partial:  the green tax above is a matter of choyce\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:51:59,965 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:52:01,158 INFO: OPT time: 1.193\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:52:01,158 INFO: Final:  the green tax above is a matter of choice\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:52:01,159 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  21%|██        | 304/1450 [06:01<22:02,  1.15s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:52:01,332 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:52:01,383 INFO: Partial:  lot of philosophical content\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:52:01,411 INFO: Augmented nbest from 100 to 108 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:52:02,106 INFO: OPT time: 0.696\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:52:02,107 INFO: Final:  lot of philosophical content\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:52:02,107 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  21%|██        | 305/1450 [06:02<23:57,  1.26s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:52:02,234 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:52:02,273 INFO: Partial:  letz than have the trials\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:52:02,299 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:52:03,108 INFO: OPT time: 0.809\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:52:03,108 INFO: Final:  less than half the trials\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:52:03,109 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  21%|██        | 306/1450 [06:03<22:10,  1.16s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:52:03,236 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:52:03,274 INFO: Partial:  even if its smoking\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:52:03,301 INFO: Augmented nbest from 100 to 178 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:52:04,457 INFO: OPT time: 1.156\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:52:04,457 INFO: Final:  even if its smoking\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:52:04,458 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  21%|██        | 307/1450 [06:04<21:14,  1.11s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:52:04,639 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:52:04,687 INFO: Partial:  get things dunne founder\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:52:04,725 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:52:05,413 INFO: OPT time: 0.687\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:52:05,413 INFO: Final:  get things done faster\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:52:05,414 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  21%|██        | 308/1450 [06:05<22:33,  1.19s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:52:05,543 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:52:05,598 INFO: Partial:  it was fun to work with him\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:52:05,642 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:52:06,760 INFO: OPT time: 1.117\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:52:06,760 INFO: Final:  it was fun to work with him\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:52:06,760 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  21%|██▏       | 309/1450 [06:06<21:13,  1.12s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:52:06,946 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:52:06,999 INFO: Partial:  think most people won to be\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:52:07,044 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:52:07,897 INFO: OPT time: 0.852\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:52:07,897 INFO: Final:  think most people one to be\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:52:07,897 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  21%|██▏       | 310/1450 [06:08<22:31,  1.19s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:52:08,047 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:52:08,096 INFO: Partial:  driving a carre for longer\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:52:08,129 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:52:08,981 INFO: OPT time: 0.851\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:52:08,981 INFO: Final:  driving a car for longer\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:52:08,982 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  21%|██▏       | 311/1450 [06:09<22:13,  1.17s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:52:09,149 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:52:09,214 INFO: Partial:  the classical think that yu sci on tv\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:52:09,265 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:52:10,257 INFO: OPT time: 0.992\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:52:10,257 INFO: Final:  the classical think that you see on tv\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:52:10,257 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  22%|██▏       | 312/1450 [06:10<21:42,  1.14s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:52:10,454 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:52:10,509 INFO: Partial:  is therefore disappointing\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:52:10,532 INFO: Augmented nbest from 100 to 112 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:52:11,224 INFO: OPT time: 0.692\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:52:11,224 INFO: Final:  it is therefore disappointing\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:52:11,225 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  22%|██▏       | 313/1450 [06:11<22:26,  1.18s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:52:11,356 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:52:11,415 INFO: Partial:  doanh get to mutsch money for them\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:52:11,450 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:52:12,439 INFO: OPT time: 0.988\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:52:12,439 INFO: Final:  doan get too much money for them\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:52:12,440 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  22%|██▏       | 314/1450 [06:12<21:11,  1.12s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:52:12,560 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:52:12,608 INFO: Partial:  been here sense seventy for\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:52:12,645 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:52:13,450 INFO: OPT time: 0.805\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:52:13,451 INFO: Final:  been here since seventy four\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:52:13,451 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  22%|██▏       | 315/1450 [06:13<21:42,  1.15s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:52:13,562 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:52:13,622 INFO: Partial:  heaven had to replace the thing yet\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:52:13,666 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:52:14,794 INFO: OPT time: 1.128\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:52:14,795 INFO: Final:  haven't had to replace the thing yet\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:52:14,795 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  22%|██▏       | 316/1450 [06:14<20:55,  1.11s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:52:14,965 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:52:15,018 INFO: Partial:  halley recommend it\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:52:15,058 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:52:15,718 INFO: OPT time: 0.661\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:52:15,719 INFO: Final:  highly recommend it\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:52:15,719 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  22%|██▏       | 317/1450 [06:16<22:14,  1.18s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:52:15,871 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:52:15,918 INFO: Partial:  least traditionally\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:52:15,947 INFO: Augmented nbest from 100 to 103 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:52:16,602 INFO: OPT time: 0.655\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:52:16,602 INFO: Final:  at least traditionally\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:52:16,603 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  22%|██▏       | 318/1450 [06:17<20:47,  1.10s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:52:16,771 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:52:16,838 INFO: Partial:  weir kind of at the end of that trill\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:52:16,915 INFO: Augmented nbest from 100 to 126 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:52:18,337 INFO: OPT time: 1.421\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:52:18,337 INFO: Final:  weir kind of at the end of that trail\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:52:18,338 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  22%|██▏       | 319/1450 [06:18<19:32,  1.04s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:52:18,475 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:52:18,530 INFO: Partial:  can get this yard in shape\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:52:18,576 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:52:19,526 INFO: OPT time: 0.950\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:52:19,526 INFO: Final:  can get this yard in shape\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:52:19,527 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  22%|██▏       | 320/1450 [06:19<23:27,  1.25s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:52:19,678 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:52:19,743 INFO: Partial:  cheese really a good fissure woman\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:52:19,796 INFO: Augmented nbest from 100 to 102 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:52:20,947 INFO: OPT time: 1.151\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:52:20,947 INFO: Final:  seas really a good fisher woman\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:52:20,947 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  22%|██▏       | 321/1450 [06:20<23:07,  1.23s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:52:21,083 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:52:21,134 INFO: Partial:  our particular situation\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:52:21,158 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:52:21,822 INFO: OPT time: 0.664\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:52:21,822 INFO: Final:  in our particular situation\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:52:21,823 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  22%|██▏       | 322/1450 [06:22<24:10,  1.29s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:52:21,982 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:52:22,076 INFO: Partial:  usually want my dog in the park nir my home\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:52:22,221 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:52:23,608 INFO: OPT time: 1.387\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:52:23,608 INFO: Final:  usually want my dog in the park near my home\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:52:23,609 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  22%|██▏       | 323/1450 [06:23<21:50,  1.16s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:52:23,787 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:52:23,859 INFO: Partial:  did that with the section baby\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:52:23,914 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:52:24,766 INFO: OPT time: 0.851\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:52:24,766 INFO: Final:  did that with the second baby\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:52:24,766 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  22%|██▏       | 324/1450 [06:25<25:20,  1.35s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:52:24,890 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:52:24,943 INFO: Partial:  its disappointing how this was handled\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:52:24,982 INFO: Augmented nbest from 100 to 102 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:52:25,934 INFO: OPT time: 0.952\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:52:25,934 INFO: Final:  its disappointing how this was handled\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:52:25,935 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  22%|██▏       | 325/1450 [06:26<24:13,  1.29s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:52:26,092 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:52:26,153 INFO: Partial:  he tolled us to get inside our carre\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:52:26,204 INFO: Augmented nbest from 100 to 101 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:52:27,336 INFO: OPT time: 1.132\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:52:27,336 INFO: Final:  he told us to get inside our car\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:52:27,337 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  22%|██▏       | 326/1450 [06:27<23:30,  1.26s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:52:27,495 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:52:27,567 INFO: Partial:  guess when your filling defeated dote give upp\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:52:27,630 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:52:28,839 INFO: OPT time: 1.209\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:52:28,839 INFO: Final:  guess when your feeling defeated doan give up\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:52:28,840 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  23%|██▎       | 327/1450 [06:28<24:19,  1.30s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:52:28,998 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:52:29,030 INFO: Partial:  that would be aull\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:52:29,057 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:52:29,725 INFO: OPT time: 0.667\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:52:29,725 INFO: Final:  that would be all\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:52:29,725 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  23%|██▎       | 328/1450 [06:30<25:26,  1.36s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:52:29,897 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:52:29,995 INFO: Partial:  love is energy beautiful energy\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:52:30,027 INFO: Augmented nbest from 100 to 113 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:52:30,896 INFO: OPT time: 0.869\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:52:30,896 INFO: Final:  love is energy beautiful energy\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:52:30,897 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  23%|██▎       | 329/1450 [06:31<22:45,  1.22s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:52:31,101 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:52:31,252 INFO: Partial:  maybe the kamp wreak mayde was between him and the unemployment lysne\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:52:31,366 INFO: Augmented nbest from 100 to 156 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:52:33,389 ERROR: Error during OPT rescore: CUDA out of memory. Tried to allocate 114.00 MiB (GPU 0; 14.74 GiB total capacity; 13.94 GiB already allocated; 4.19 MiB free; 14.45 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:52:33,432 ERROR: Error during OPT rescore: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 14.74 GiB total capacity; 13.98 GiB already allocated; 2.19 MiB free; 14.45 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:52:33,433 INFO: OPT time: 2.067\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:52:33,433 INFO: Final:  maybe the kampe reek mayde was between him and the unemployment lysne\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:52:33,434 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  23%|██▎       | 330/1450 [06:32<22:28,  1.20s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:52:33,610 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:52:33,684 INFO: Partial:  he tried to hyde in the bakke of the room room\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:52:33,795 INFO: Augmented nbest from 100 to 187 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:52:35,734 ERROR: Error during OPT rescore: CUDA out of memory. Tried to allocate 112.00 MiB (GPU 0; 14.74 GiB total capacity; 13.97 GiB already allocated; 4.19 MiB free; 14.45 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:52:35,754 ERROR: Error during OPT rescore: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 14.74 GiB total capacity; 14.03 GiB already allocated; 2.19 MiB free; 14.45 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:52:35,756 INFO: OPT time: 1.961\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:52:35,756 INFO: Final:  hee tried to hide in the bak of the roome reaume\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:52:35,756 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  23%|██▎       | 331/1450 [06:34<29:54,  1.60s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:52:35,912 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:52:36,008 INFO: Partial:  is also close to the trap ministration\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:52:36,073 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:52:37,093 INFO: OPT time: 1.020\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:52:37,093 INFO: Final:  is also close to the trump ministration\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:52:37,094 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  23%|██▎       | 332/1450 [06:37<33:54,  1.82s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:52:37,217 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:52:37,329 INFO: Partial:  tutorial on applying the principles of anybody could stil\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:52:37,408 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:52:38,573 INFO: OPT time: 1.165\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:52:38,573 INFO: Final:  tutorial on applying the principles of anybody code style\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:52:38,574 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  23%|██▎       | 333/1450 [06:38<31:10,  1.67s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:52:38,718 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:52:38,783 INFO: Partial:  get bringing news allers and special report\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:52:38,835 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:52:39,793 INFO: OPT time: 0.958\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:52:39,793 INFO: Final:  get breaking news allows and special report\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:52:39,793 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  23%|██▎       | 334/1450 [06:40<30:03,  1.62s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:52:39,920 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:52:40,015 INFO: Partial:  the time for jovial fines is behind us\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:52:40,044 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:52:41,172 INFO: OPT time: 1.127\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:52:41,172 INFO: Final:  the time for trivial fines is behind us\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:52:41,173 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  23%|██▎       | 335/1450 [06:41<27:49,  1.50s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:52:41,324 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:52:41,452 INFO: Partial:  there was talk at the sitter on wresting of the trupp tragedy\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:52:41,565 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:52:43,003 INFO: OPT time: 1.438\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:52:43,003 INFO: Final:  there was talk at the sitter on wresting of the trump tragedy\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:52:43,004 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  23%|██▎       | 336/1450 [06:42<27:08,  1.46s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:52:43,132 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:52:43,215 INFO: Partial:  is the only girl who comes to our school\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:52:43,276 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:52:44,440 INFO: OPT time: 1.164\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:52:44,440 INFO: Final:  she is the only girl who comes to our school\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:52:44,441 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  23%|██▎       | 337/1450 [06:44<29:10,  1.57s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:52:44,636 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:52:44,686 INFO: Partial:  there new house cost just as mutsch\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:52:44,731 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:52:45,679 INFO: OPT time: 0.948\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:52:45,679 INFO: Final:  their new house cost just as much\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:52:45,679 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  23%|██▎       | 338/1450 [06:45<28:23,  1.53s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:52:45,836 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:52:45,912 INFO: Partial:  that parte its hyun lever on reckard\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:52:45,966 INFO: Augmented nbest from 100 to 119 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:52:47,319 INFO: OPT time: 1.353\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:52:47,319 INFO: Final:  that part its highest lever on reckard\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:52:47,320 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  23%|██▎       | 339/1450 [06:47<26:44,  1.44s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:52:47,440 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:52:47,593 INFO: Partial:  plese sci our privacy daughters for details of your data protection writes\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:52:47,711 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:52:49,161 INFO: OPT time: 1.449\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:52:49,161 INFO: Final:  please cie our privacy daughters for details of your data protection rights\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:52:49,161 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  23%|██▎       | 340/1450 [06:48<27:48,  1.50s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:52:49,347 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:52:49,411 INFO: Partial:  the end the workers turned around\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:52:49,444 INFO: Augmented nbest from 100 to 124 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:52:50,410 INFO: OPT time: 0.966\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:52:50,410 INFO: Final:  at the end the workers turned around\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:52:50,411 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  24%|██▎       | 341/1450 [06:50<29:39,  1.60s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:52:50,546 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:52:50,655 INFO: Partial:  stil only lats of cheddars and sum adversity\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:52:50,716 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:52:52,095 INFO: OPT time: 1.379\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:52:52,095 INFO: Final:  still only lots of cheddars and some diversity\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:52:52,096 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  24%|██▎       | 342/1450 [06:51<27:39,  1.50s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:52:52,250 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:52:52,336 INFO: Partial:  just coven this with your fender\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:52:52,408 INFO: Augmented nbest from 100 to 107 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:52:53,375 INFO: OPT time: 0.966\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:52:53,375 INFO: Final:  just cover this with your fender\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:52:53,375 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  24%|██▎       | 343/1450 [06:53<28:40,  1.55s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:52:53,555 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:52:53,601 INFO: Partial:  stil miles yoos whiter\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:52:53,634 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:52:54,594 INFO: OPT time: 0.960\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:52:54,594 INFO: Final:  still miles ewes water\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:52:54,595 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  24%|██▎       | 344/1450 [06:54<27:07,  1.47s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:52:54,754 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:52:54,833 INFO: Partial:  bettor together have serious questions to exar\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:52:54,880 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:52:56,023 INFO: OPT time: 1.143\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:52:56,023 INFO: Final:  better together have serious questions to answer\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:52:56,024 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  24%|██▍       | 345/1450 [06:56<25:42,  1.40s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:52:56,157 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:52:56,241 INFO: Partial:  said a report that this book long contends spam\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:52:56,315 INFO: Augmented nbest from 100 to 136 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:52:57,782 INFO: OPT time: 1.467\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:52:57,782 INFO: Final:  send a report that this book long contains spam\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:52:57,783 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  24%|██▍       | 346/1450 [06:57<25:51,  1.41s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:52:57,963 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:52:58,077 INFO: Partial:  this is a very important cayce frum our point of vue he haddad\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:52:58,211 INFO: Augmented nbest from 100 to 168 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:53:00,022 ERROR: Error during OPT rescore: CUDA out of memory. Tried to allocate 116.00 MiB (GPU 0; 14.74 GiB total capacity; 13.93 GiB already allocated; 74.19 MiB free; 14.38 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:53:00,589 ERROR: Error during OPT rescore: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 14.74 GiB total capacity; 14.30 GiB already allocated; 2.19 MiB free; 14.45 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:53:00,590 INFO: OPT time: 2.379\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:53:00,590 INFO: Final:  this is a vary important caisse from our pointe of vue he hadad\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:53:00,591 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  24%|██▍       | 347/1450 [06:59<27:47,  1.51s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:53:00,767 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:53:00,946 INFO: Partial:  oui bought yu books and toys to feed your appetite for space exploration\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:53:01,075 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:53:02,630 INFO: OPT time: 1.556\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:53:02,631 INFO: Final:  oui bought you books and toys to feed your appetite for space exploration\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:53:02,631 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  24%|██▍       | 348/1450 [07:02<34:54,  1.90s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:53:02,774 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:53:02,861 INFO: Partial:  kant put it downe and ai could luk at it for daze\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:53:02,970 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:53:04,492 INFO: OPT time: 1.522\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:53:04,492 INFO: Final:  cant put it down and ai could luk at it for days\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:53:04,493 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  24%|██▍       | 349/1450 [07:04<35:38,  1.94s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:53:04,676 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:53:04,830 INFO: Partial:  the only thing leff to due is to had over the controls to ezzo\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:53:04,958 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:53:06,536 INFO: OPT time: 1.579\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:53:06,537 INFO: Final:  the only thing left to do is to had over the controls to ezoe\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:53:06,537 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  24%|██▍       | 350/1450 [07:05<35:10,  1.92s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:53:06,681 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:53:06,779 INFO: Partial:  and he wont take it fairly elect yu gave it to him\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:53:06,880 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:53:08,321 INFO: OPT time: 1.441\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:53:08,321 INFO: Final:  and he wont take it fairly elect you gave it to him\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:53:08,322 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  24%|██▍       | 351/1450 [07:07<35:49,  1.96s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:53:08,487 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:53:08,559 INFO: Partial:  and yu sci what happened recently\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:53:08,596 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:53:09,443 INFO: OPT time: 0.847\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:53:09,443 INFO: Final:  and you see what happened recently\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:53:09,444 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  24%|██▍       | 352/1450 [07:09<34:51,  1.90s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:53:09,586 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:53:09,629 INFO: Partial:  weave gott sum guys here\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:53:09,671 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:53:10,523 INFO: OPT time: 0.852\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:53:10,523 INFO: Final:  weave got some guys here\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:53:10,524 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  24%|██▍       | 353/1450 [07:10<30:31,  1.67s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:53:10,687 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:53:10,721 INFO: Partial:  he guess home frum work leight\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:53:10,763 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:53:11,863 INFO: OPT time: 1.100\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:53:11,863 INFO: Final:  he gets home from work late\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:53:11,864 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  24%|██▍       | 354/1450 [07:11<27:16,  1.49s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:53:11,989 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:53:12,030 INFO: Partial:  my taxes have gone upp\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:53:12,063 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:53:13,002 INFO: OPT time: 0.939\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:53:13,002 INFO: Final:  my taxes have gone up\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:53:13,003 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  24%|██▍       | 355/1450 [07:13<26:24,  1.45s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:53:13,191 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:53:13,225 INFO: Partial:  its once important to yu\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:53:13,261 INFO: Augmented nbest from 100 to 107 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:53:13,965 INFO: OPT time: 0.704\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:53:13,966 INFO: Final:  its whats important to you\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:53:13,966 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  25%|██▍       | 356/1450 [07:14<24:42,  1.35s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:53:14,094 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:53:14,124 INFO: Partial:  oui enjoy doing it\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:53:14,150 INFO: Augmented nbest from 100 to 112 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:53:14,999 INFO: OPT time: 0.849\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:53:14,999 INFO: Final:  we enjoy doing it\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:53:14,999 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  25%|██▍       | 357/1450 [07:15<22:32,  1.24s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:53:15,195 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:53:15,247 INFO: Partial:  did percent or thirteen percent\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:53:15,278 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:53:16,087 INFO: OPT time: 0.808\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:53:16,087 INFO: Final:  dead percent or thirteen percent\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:53:16,088 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  25%|██▍       | 358/1450 [07:16<21:24,  1.18s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:53:16,201 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:53:16,228 INFO: Partial:  the detroit news\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:53:16,250 INFO: Augmented nbest from 100 to 107 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:53:17,077 INFO: OPT time: 0.827\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:53:17,077 INFO: Final:  the detroit news\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:53:17,077 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  25%|██▍       | 359/1450 [07:17<20:54,  1.15s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:53:17,199 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:53:17,228 INFO: Partial:  has will as yu due\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:53:17,266 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:53:17,968 INFO: OPT time: 0.702\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:53:17,968 INFO: Final:  has will as you do\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:53:17,968 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  25%|██▍       | 360/1450 [07:18<20:00,  1.10s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:53:18,103 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:53:18,134 INFO: Partial:  who did yu vote for\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:53:18,166 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:53:19,106 INFO: OPT time: 0.940\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:53:19,106 INFO: Final:  who did you vote for\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:53:19,107 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  25%|██▍       | 361/1450 [07:19<18:50,  1.04s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:53:19,306 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:53:19,329 INFO: Partial:  really love it\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:53:19,352 INFO: Augmented nbest from 100 to 143 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:53:20,300 INFO: OPT time: 0.948\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:53:20,300 INFO: Final:  i really love it\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:53:20,301 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  25%|██▍       | 362/1450 [07:20<19:22,  1.07s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:53:20,409 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:53:20,471 INFO: Partial:  they have this whirled football lynk\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:53:20,518 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:53:21,462 INFO: OPT time: 0.944\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:53:21,462 INFO: Final:  they have this world football thing\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:53:21,463 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  25%|██▌       | 363/1450 [07:21<20:02,  1.11s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:53:21,613 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:53:21,644 INFO: Partial:  voice frum the ground\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:53:21,671 INFO: Augmented nbest from 100 to 104 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:53:22,368 INFO: OPT time: 0.697\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:53:22,368 INFO: Final:  voice from the crowd\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:53:22,369 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  25%|██▌       | 364/1450 [07:22<20:19,  1.12s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:53:22,515 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:53:22,547 INFO: Partial:  the ones that killed\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:53:22,572 INFO: Augmented nbest from 100 to 120 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:53:23,399 INFO: OPT time: 0.826\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:53:23,399 INFO: Final:  the ones that killed\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:53:23,399 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  25%|██▌       | 365/1450 [07:23<19:07,  1.06s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:53:23,518 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:53:23,553 INFO: Partial:  lyke the whey that\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:53:23,574 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:53:24,276 INFO: OPT time: 0.702\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:53:24,276 INFO: Final:  like the way that\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:53:24,277 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  25%|██▌       | 366/1450 [07:24<18:57,  1.05s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:53:24,420 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:53:24,566 INFO: Partial:  vision is won of the foundational plagues for any untroubled\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:53:24,654 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:53:25,862 INFO: OPT time: 1.208\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:53:25,862 INFO: Final:  vision is one of the foundational plans for any contributory\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:53:25,863 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  25%|██▌       | 367/1450 [07:25<18:00,  1.00trial/s]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:53:26,028 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:53:26,059 INFO: Partial:  that wayson a standard\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:53:26,090 INFO: Augmented nbest from 100 to 102 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:53:26,906 INFO: OPT time: 0.816\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:53:26,906 INFO: Final:  that wasn't a standard\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:53:26,906 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  25%|██▌       | 368/1450 [07:27<21:10,  1.17s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:53:27,027 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:53:27,065 INFO: Partial:  the planed and aull that\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:53:27,105 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:53:27,803 INFO: OPT time: 0.698\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:53:27,803 INFO: Final:  the planes and all that\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:53:27,804 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  25%|██▌       | 369/1450 [07:28<20:27,  1.14s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:53:27,931 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:53:27,967 INFO: Partial:  oui moved to hiway\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:53:27,994 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:53:28,803 INFO: OPT time: 0.810\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:53:28,803 INFO: Final:  we moved to highway\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:53:28,804 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  26%|██▌       | 370/1450 [07:29<19:08,  1.06s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:53:28,932 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:53:28,991 INFO: Partial:  decisions have been mayde at this time\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:53:29,030 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:53:30,019 INFO: OPT time: 0.989\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:53:30,019 INFO: Final:  no decisions have been made at this time\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:53:30,020 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  26%|██▌       | 371/1450 [07:30<18:47,  1.04s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:53:30,138 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:53:30,159 INFO: Partial:  because your write\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:53:30,180 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:53:30,840 INFO: OPT time: 0.660\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:53:30,841 INFO: Final:  because your right\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:53:30,841 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  26%|██▌       | 372/1450 [07:31<19:41,  1.10s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:53:31,037 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:53:31,064 INFO: Partial:  nott dunne anything\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:53:31,083 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:53:31,751 INFO: OPT time: 0.667\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:53:31,751 INFO: Final:  not done anything\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:53:31,751 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  26%|██▌       | 373/1450 [07:32<18:11,  1.01s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:53:31,940 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:53:31,972 INFO: Partial:  what due they kaul it\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:53:31,998 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:53:32,697 INFO: OPT time: 0.698\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:53:32,697 INFO: Final:  what do they call it\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:53:32,697 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  26%|██▌       | 374/1450 [07:33<17:37,  1.02trial/s]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:53:32,842 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:53:32,908 INFO: Partial:  left ana farm for sisti years\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:53:32,978 INFO: Augmented nbest from 100 to 113 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:53:33,981 INFO: OPT time: 1.002\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:53:33,981 INFO: Final:  lived on a farm for sitting years\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:53:33,982 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  26%|██▌       | 375/1450 [07:34<17:24,  1.03trial/s]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:53:34,150 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:53:34,186 INFO: Partial:  other signed of the coyne\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:53:34,222 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:53:35,072 INFO: OPT time: 0.850\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:53:35,072 INFO: Final:  other side of the coin\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:53:35,073 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  26%|██▌       | 376/1450 [07:35<19:04,  1.07s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:53:35,249 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:53:35,297 INFO: Partial:  butt ai think its salad and this point\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:53:35,402 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:53:36,386 INFO: OPT time: 0.984\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:53:36,386 INFO: Final:  but i think its solid and this point\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:53:36,387 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  26%|██▌       | 377/1450 [07:36<19:11,  1.07s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:53:36,553 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:53:36,718 INFO: Partial:  plies he used to deliver pigeons before the believes\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:53:36,810 INFO: Augmented nbest from 100 to 106 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:53:38,237 INFO: OPT time: 1.427\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:53:38,237 INFO: Final:  plies he used to deliver pigeons before the abilities\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:53:38,238 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  26%|██▌       | 378/1450 [07:37<20:27,  1.15s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:53:38,361 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:53:38,400 INFO: Partial:  nott campy words\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:53:38,450 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:53:39,144 INFO: OPT time: 0.693\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:53:39,144 INFO: Final:  not campy words\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:53:39,144 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  26%|██▌       | 379/1450 [07:39<24:13,  1.36s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:53:39,261 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:53:39,384 INFO: Partial:  and there are other fissures in the drabik to note\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:53:39,477 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:53:40,860 INFO: OPT time: 1.382\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:53:40,860 INFO: Final:  and there are other features in the drabik to not\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:53:40,860 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  26%|██▌       | 380/1450 [07:40<21:47,  1.22s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:53:41,066 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:53:41,242 INFO: Partial:  lawmakers in both parties have called for stabilizing the fireplaces\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:53:41,330 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:53:42,776 INFO: OPT time: 1.446\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:53:42,776 INFO: Final:  lawmakers in both parties have called for stabilizing the marketplaces\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:53:42,777 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  26%|██▋       | 381/1450 [07:42<24:24,  1.37s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:53:42,970 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:53:43,064 INFO: Partial:  sze klans oliver never should sines of the infection\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:53:43,133 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:53:44,571 INFO: OPT time: 1.438\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:53:44,571 INFO: Final:  she clans oliver never should signs of the infection\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:53:44,572 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  26%|██▋       | 382/1450 [07:44<27:18,  1.53s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:53:44,774 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:53:44,882 INFO: Partial:  here is the video of the charlie rows summitt\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:53:45,020 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:53:46,170 INFO: OPT time: 1.150\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:53:46,171 INFO: Final:  here is the video of the charlie rose summitt\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:53:46,171 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  26%|██▋       | 383/1450 [07:46<28:40,  1.61s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:53:46,381 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:53:46,409 INFO: Partial:  this is so beautiful\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:53:46,433 INFO: Augmented nbest from 100 to 116 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:53:47,089 INFO: OPT time: 0.656\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:53:47,089 INFO: Final:  this is so beautiful\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:53:47,090 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  26%|██▋       | 384/1450 [07:47<28:34,  1.61s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:53:47,275 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:53:47,384 INFO: Partial:  golz wishon to speed upp the whale\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:53:47,475 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:53:48,622 INFO: OPT time: 1.147\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:53:48,623 INFO: Final:  goals mission to speed up the whale\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:53:48,623 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  27%|██▋       | 385/1450 [07:48<24:52,  1.40s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:53:48,785 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:53:48,930 INFO: Partial:  said bilious responded swilley to that incident for the drivers sifting\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:53:49,070 INFO: Augmented nbest from 100 to 175 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:53:51,046 ERROR: Error during OPT rescore: CUDA out of memory. Tried to allocate 100.00 MiB (GPU 0; 14.74 GiB total capacity; 13.99 GiB already allocated; 26.19 MiB free; 14.43 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:53:51,546 ERROR: Error during OPT rescore: CUDA out of memory. Tried to allocate 62.00 MiB (GPU 0; 14.74 GiB total capacity; 14.37 GiB already allocated; 26.19 MiB free; 14.43 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:53:51,548 INFO: OPT time: 2.477\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:53:51,548 INFO: Final:  hee said bilious responded swilley to that incident for the drivers sifting\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:53:51,548 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  27%|██▋       | 386/1450 [07:50<25:33,  1.44s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:53:51,691 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:53:51,803 INFO: Partial:  witthuhn murders they se the fire was under control\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:53:51,872 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:53:53,233 INFO: OPT time: 1.361\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:53:53,233 INFO: Final:  without murders they say the fire was under control\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:53:53,234 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  27%|██▋       | 387/1450 [07:52<33:25,  1.89s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:53:53,391 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:53:53,520 INFO: Partial:  he looked upp to fined the throng fleeing into the virus of both\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:53:53,600 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:53:55,053 INFO: OPT time: 1.453\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:53:55,054 INFO: Final:  he looked up to find the throng fleeing into the variance of both\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:53:55,054 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  27%|██▋       | 388/1450 [07:54<32:19,  1.83s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:53:55,196 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:53:55,287 INFO: Partial:  the to of them attend to make a bring for in\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:53:55,387 INFO: Augmented nbest from 100 to 129 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:53:56,811 INFO: OPT time: 1.425\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:53:56,812 INFO: Final:  the to of them intend to make a bring for it\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:53:56,812 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  27%|██▋       | 389/1450 [07:56<32:15,  1.82s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:53:56,997 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:53:57,050 INFO: Partial:  oui brought great news for yu\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:53:57,110 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:53:58,048 INFO: OPT time: 0.938\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:53:58,048 INFO: Final:  we brought great news for you\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:53:58,049 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  27%|██▋       | 390/1450 [07:58<31:52,  1.80s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:53:58,200 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:53:58,352 INFO: Partial:  intimate and tender driver about caring on against lykes hundreds\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:53:58,483 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:53:59,851 INFO: OPT time: 1.368\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:53:59,851 INFO: Final:  intimate and tender driver about caring on against likes hundreds\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:53:59,852 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  27%|██▋       | 391/1450 [07:59<28:50,  1.63s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:54:00,007 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:54:00,190 INFO: Partial:  sowing east kansas another special vallance in the town of sunderland\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:54:00,295 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:54:01,879 INFO: OPT time: 1.583\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:54:01,879 INFO: Final:  sewing east kansas another special village in the town of sunderland\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:54:01,879 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  27%|██▋       | 392/1450 [08:01<29:42,  1.68s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:54:02,011 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:54:02,149 INFO: Partial:  moved to landed in search of basile butt friends were hard to kumm my\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:54:02,317 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:54:03,897 INFO: OPT time: 1.580\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:54:03,897 INFO: Final:  moved to landed in search of bustle but friends were hard to come my\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:54:03,898 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  27%|██▋       | 393/1450 [08:03<31:29,  1.79s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:54:04,015 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:54:04,152 INFO: Partial:  scholey the sound of sallies was the only opprobrium won here\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:54:04,270 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:54:05,794 INFO: OPT time: 1.524\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:54:05,794 INFO: Final:  shelly the sound of sallies was the only opprobrium one here\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:54:05,795 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  27%|██▋       | 394/1450 [08:05<32:40,  1.86s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:54:05,923 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:54:06,054 INFO: Partial:  so the whirled can celebrate dither here he added\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:54:06,134 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:54:07,334 INFO: OPT time: 1.199\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:54:07,334 INFO: Final:  so the world can celebrate dither hear he added\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:54:07,334 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  27%|██▋       | 395/1450 [08:07<32:51,  1.87s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:54:07,523 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:54:07,579 INFO: Partial:  critcher in the hice\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:54:07,616 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:54:08,314 INFO: OPT time: 0.698\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:54:08,314 INFO: Final:  creature in the house\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:54:08,315 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  27%|██▋       | 396/1450 [08:08<31:05,  1.77s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:54:08,422 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:54:08,527 INFO: Partial:  the live and the prayers gond willing heel be fein suen\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:54:08,654 INFO: Augmented nbest from 100 to 127 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:54:10,422 INFO: OPT time: 1.768\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:54:10,422 INFO: Final:  the live and the prayers god willing heel be fein soon\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:54:10,423 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  27%|██▋       | 397/1450 [08:09<26:54,  1.53s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:54:10,630 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:54:10,687 INFO: Partial:  it mi be in the fissure\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:54:10,733 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:54:11,675 INFO: OPT time: 0.941\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:54:11,675 INFO: Final:  it me be in the future\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:54:11,676 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  27%|██▋       | 398/1450 [08:11<29:54,  1.71s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:54:11,832 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:54:11,869 INFO: Partial:  earning is money\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:54:11,900 INFO: Augmented nbest from 100 to 116 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:54:12,706 INFO: OPT time: 0.806\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:54:12,706 INFO: Final:  earning his money\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:54:12,707 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  28%|██▊       | 399/1450 [08:13<27:29,  1.57s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:54:12,833 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:54:12,919 INFO: Partial:  and there ardor to get read of for the weekend\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:54:12,981 INFO: Augmented nbest from 100 to 149 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:54:14,697 INFO: OPT time: 1.715\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:54:14,697 INFO: Final:  and their order to get read of for the weekend\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:54:14,698 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  28%|██▊       | 400/1450 [08:14<24:38,  1.41s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:54:14,838 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:54:14,888 INFO: Partial:  think its justa crying sejm\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:54:14,920 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:54:15,886 INFO: OPT time: 0.965\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:54:15,886 INFO: Final:  think its just a crying same\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:54:15,886 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  28%|██▊       | 401/1450 [08:16<27:40,  1.58s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:54:16,039 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:54:16,114 INFO: Partial:  cel products aboard as mutsch as oui bring in\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:54:16,170 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:54:17,334 INFO: OPT time: 1.164\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:54:17,334 INFO: Final:  sell products aboard as much as we bring in\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:54:17,334 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  28%|██▊       | 402/1450 [08:17<25:34,  1.46s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:54:17,443 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:54:17,481 INFO: Partial:  this year and last year\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:54:17,517 INFO: Augmented nbest from 100 to 159 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:54:18,535 INFO: OPT time: 1.017\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:54:18,535 INFO: Final:  this year and last year\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:54:18,535 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  28%|██▊       | 403/1450 [08:18<25:28,  1.46s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:54:18,644 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:54:18,691 INFO: Partial:  dote hone my home\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:54:18,730 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:54:19,693 INFO: OPT time: 0.962\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:54:19,693 INFO: Final:  dote home my home\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:54:19,693 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  28%|██▊       | 404/1450 [08:19<24:05,  1.38s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:54:19,848 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:54:19,932 INFO: Partial:  there due fein in there studies\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:54:20,013 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:54:20,825 INFO: OPT time: 0.811\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:54:20,825 INFO: Final:  their due find in their studies\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:54:20,825 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  28%|██▊       | 405/1450 [08:21<22:53,  1.31s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:54:20,955 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:54:20,999 INFO: Partial:  atz the beste whey to due it\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:54:21,044 INFO: Augmented nbest from 100 to 110 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:54:22,039 INFO: OPT time: 0.994\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:54:22,039 INFO: Final:  that the best way to due it\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:54:22,040 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  28%|██▊       | 406/1450 [08:22<21:55,  1.26s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:54:22,152 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:54:22,207 INFO: Partial:  was hard to except that\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:54:22,237 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:54:23,086 INFO: OPT time: 0.849\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:54:23,086 INFO: Final:  it was hard to except that\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:54:23,086 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  28%|██▊       | 407/1450 [08:23<21:39,  1.25s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:54:23,254 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:54:23,358 INFO: Partial:  my father drinas mi about combing cocking\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:54:23,423 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:54:24,574 INFO: OPT time: 1.151\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:54:24,574 INFO: Final:  my father teaches me about combing caulking\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:54:24,575 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  28%|██▊       | 408/1450 [08:24<20:36,  1.19s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:54:24,760 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:54:24,804 INFO: Partial:  yu no its so exciting\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:54:24,837 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:54:25,544 INFO: OPT time: 0.706\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:54:25,544 INFO: Final:  you know its so exciting\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:54:25,545 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  28%|██▊       | 409/1450 [08:26<22:09,  1.28s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:54:25,661 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:54:25,724 INFO: Partial:  it was pretty simler\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:54:25,766 INFO: Augmented nbest from 100 to 118 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:54:26,694 INFO: OPT time: 0.928\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:54:26,694 INFO: Final:  it was pretty similar\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:54:26,695 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  28%|██▊       | 410/1450 [08:26<20:32,  1.18s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:54:26,866 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:54:26,905 INFO: Partial:  it was when ai was a child\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:54:26,947 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:54:28,061 INFO: OPT time: 1.114\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:54:28,061 INFO: Final:  it was when i was a child\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:54:28,062 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  28%|██▊       | 411/1450 [08:28<20:20,  1.17s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:54:28,266 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:54:28,299 INFO: Partial:  heaven had a change\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:54:28,329 INFO: Augmented nbest from 100 to 114 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:54:29,257 INFO: OPT time: 0.927\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:54:29,257 INFO: Final:  heaven had a change\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:54:29,257 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  28%|██▊       | 412/1450 [08:29<21:18,  1.23s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:54:29,368 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:54:29,408 INFO: Partial:  have yu seen gose yet\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:54:29,451 INFO: Augmented nbest from 100 to 152 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:54:30,883 INFO: OPT time: 1.432\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:54:30,884 INFO: Final:  have you seen gose yet\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:54:30,884 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  28%|██▊       | 413/1450 [08:30<21:06,  1.22s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:54:31,072 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:54:31,106 INFO: Partial:  he mayde mi laugh\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:54:31,138 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:54:31,831 INFO: OPT time: 0.693\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:54:31,831 INFO: Final:  he made me laugh\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:54:31,832 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  29%|██▊       | 414/1450 [08:32<23:11,  1.34s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:54:31,974 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:54:32,016 INFO: Partial:  where oui went frum there\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:54:32,049 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:54:32,992 INFO: OPT time: 0.943\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:54:32,992 INFO: Final:  where we went from there\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:54:32,992 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  29%|██▊       | 415/1450 [08:33<21:07,  1.22s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:54:33,175 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:54:33,230 INFO: Partial:  the moderate choyce\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:54:33,251 INFO: Augmented nbest from 100 to 105 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:54:33,940 INFO: OPT time: 0.688\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:54:33,940 INFO: Final:  the moderate choice\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:54:33,940 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  29%|██▊       | 416/1450 [08:34<20:46,  1.21s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:54:34,075 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:54:34,175 INFO: Partial:  was inaugurated in generally\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:54:34,213 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:54:35,311 INFO: OPT time: 1.098\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:54:35,311 INFO: Final:  she was inaugurated in generally\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:54:35,312 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  29%|██▉       | 417/1450 [08:35<19:25,  1.13s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:54:35,480 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:54:35,566 INFO: Partial:  well weir really overburden\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:54:35,605 INFO: Augmented nbest from 100 to 112 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:54:36,770 INFO: OPT time: 1.165\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:54:36,770 INFO: Final:  well weir really potent\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:54:36,771 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  29%|██▉       | 418/1450 [08:36<20:39,  1.20s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:54:36,883 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:54:36,920 INFO: Partial:  believe it is to\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:54:36,949 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:54:37,749 INFO: OPT time: 0.800\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:54:37,749 INFO: Final:  believe it is to\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:54:37,749 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  29%|██▉       | 419/1450 [08:38<21:58,  1.28s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:54:37,883 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:54:37,937 INFO: Partial:  gave yu a run for your money\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:54:37,983 INFO: Augmented nbest from 100 to 104 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:54:38,980 INFO: OPT time: 0.997\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:54:38,980 INFO: Final:  gave you a run for your money\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:54:38,980 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  29%|██▉       | 420/1450 [08:39<20:24,  1.19s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:54:39,088 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:54:39,174 INFO: Partial:  noticed that is voice troubled\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:54:39,217 INFO: Augmented nbest from 100 to 125 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:54:40,185 INFO: OPT time: 0.968\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:54:40,185 INFO: Final:  noticed that his voice troubled\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:54:40,186 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  29%|██▉       | 421/1450 [08:40<20:36,  1.20s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:54:40,390 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:54:40,489 INFO: Partial:  ai can goh out and goh to the baur this leight\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:54:40,570 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:54:42,013 INFO: OPT time: 1.443\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:54:42,014 INFO: Final:  ai can go out and go to the baur this late\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:54:42,014 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  29%|██▉       | 422/1450 [08:41<20:36,  1.20s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:54:42,197 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:54:42,240 INFO: Partial:  my rayment signed mi upp\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:54:42,283 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:54:43,133 INFO: OPT time: 0.850\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:54:43,133 INFO: Final:  my crewman signed me up\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:54:43,133 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  29%|██▉       | 423/1450 [08:43<23:47,  1.39s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:54:43,296 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:54:43,390 INFO: Partial:  was land to get read of littered consulate\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:54:43,457 INFO: Augmented nbest from 100 to 129 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:54:44,817 INFO: OPT time: 1.360\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:54:44,817 INFO: Final:  was gland to get read of littered consulate\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:54:44,817 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  29%|██▉       | 424/1450 [08:44<22:22,  1.31s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:54:45,002 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:54:45,067 INFO: Partial:  they were showing sum and ai was watching\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:54:45,124 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:54:46,235 INFO: OPT time: 1.111\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:54:46,235 INFO: Final:  they were showing some and i was watching\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:54:46,236 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  29%|██▉       | 425/1450 [08:46<24:17,  1.42s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:54:46,403 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:54:46,455 INFO: Partial:  how will yu measure your life\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:54:46,488 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:54:47,339 INFO: OPT time: 0.851\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:54:47,339 INFO: Final:  how will you measure your life\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:54:47,340 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  29%|██▉       | 426/1450 [08:47<24:14,  1.42s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:54:47,506 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:54:47,566 INFO: Partial:  lyke orange muzik to\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:54:47,605 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:54:48,535 INFO: OPT time: 0.930\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:54:48,535 INFO: Final:  like organ music to\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:54:48,536 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  29%|██▉       | 427/1450 [08:48<22:36,  1.33s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:54:48,710 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:54:48,761 INFO: Partial:  there gutting sum of that\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:54:48,787 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:54:49,486 INFO: OPT time: 0.699\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:54:49,486 INFO: Final:  their getting some of that\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:54:49,487 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  30%|██▉       | 428/1450 [08:49<21:54,  1.29s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:54:49,611 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:54:49,657 INFO: Partial:  dote no if your lyke mi\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:54:49,706 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:54:50,688 INFO: OPT time: 0.982\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:54:50,688 INFO: Final:  dint noe if your like me\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:54:50,689 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  30%|██▉       | 429/1450 [08:50<20:10,  1.19s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:54:50,816 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:54:50,945 INFO: Partial:  oui result the write to make the final decision on aull name kisses\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:54:51,101 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:54:52,590 INFO: OPT time: 1.489\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:54:52,590 INFO: Final:  oui reserve the right to make the final decision on all name kisses\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:54:52,591 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  30%|██▉       | 430/1450 [08:52<20:14,  1.19s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:54:52,727 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:54:52,772 INFO: Partial:  every time something new kaim upp\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:54:52,814 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:54:53,664 INFO: OPT time: 0.850\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:54:53,664 INFO: Final:  every time something new came up\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:54:53,665 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  30%|██▉       | 431/1450 [08:54<23:50,  1.40s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:54:53,824 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:54:53,905 INFO: Partial:  and he does it aull with a smile and a quiet joy\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:54:54,062 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:54:55,512 INFO: OPT time: 1.449\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:54:55,512 INFO: Final:  and he does it all with a smile and a quiet joy\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:54:55,513 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  30%|██▉       | 432/1450 [08:55<22:08,  1.31s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:54:55,629 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:54:55,666 INFO: Partial:  it is a used place\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:54:55,706 INFO: Augmented nbest from 100 to 122 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:54:56,655 INFO: OPT time: 0.949\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:54:56,655 INFO: Final:  it is a used place\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:54:56,655 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  30%|██▉       | 433/1450 [08:56<24:52,  1.47s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:54:56,832 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:54:56,865 INFO: Partial:  it letz a long time\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:54:56,896 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:54:57,700 INFO: OPT time: 0.804\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:54:57,700 INFO: Final:  it lasts a long time\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:54:57,701 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  30%|██▉       | 434/1450 [08:58<23:12,  1.37s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:54:57,835 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:54:57,940 INFO: Partial:  just has to be koffler in itself and ai think a is\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:54:58,099 INFO: Augmented nbest from 100 to 119 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:54:59,710 INFO: OPT time: 1.611\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:54:59,710 INFO: Final:  just has to be confident in himself and ai think a is\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:54:59,710 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  30%|███       | 435/1450 [08:59<21:32,  1.27s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:54:59,844 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:54:59,937 INFO: Partial:  for these reasons a fact is the beste continuation\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:54:59,998 INFO: Augmented nbest from 100 to 108 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:55:01,184 INFO: OPT time: 1.186\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:55:01,184 INFO: Final:  for these reasons a fact is the best continuation\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:55:01,185 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  30%|███       | 436/1450 [09:01<25:14,  1.49s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:55:01,343 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:55:01,389 INFO: Partial:  have they retort it\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:55:01,429 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:55:02,227 INFO: OPT time: 0.798\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:55:02,228 INFO: Final:  have they ripped it\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:55:02,228 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  30%|███       | 437/1450 [09:02<25:07,  1.49s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:55:02,345 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:55:02,414 INFO: Partial:  what did the supreme kort decide about whitton college\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:55:02,486 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:55:03,648 INFO: OPT time: 1.162\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:55:03,648 INFO: Final:  what did the supreme court decide about wheaton college\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:55:03,649 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  30%|███       | 438/1450 [09:03<22:50,  1.35s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:55:03,850 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:55:03,903 INFO: Partial:  yu get to learn and res your kids\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:55:03,954 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:55:04,939 INFO: OPT time: 0.985\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:55:04,939 INFO: Final:  you get to learn and raise your kids\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:55:04,940 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  30%|███       | 439/1450 [09:05<23:09,  1.37s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:55:05,053 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:55:05,197 INFO: Partial:  they have no original ideas curiosity or aspirations\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:55:05,232 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:55:06,221 INFO: OPT time: 0.989\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:55:06,221 INFO: Final:  they have no original ideas curiosity or aspirations\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:55:06,222 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  30%|███       | 440/1450 [09:06<22:43,  1.35s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:55:06,355 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:55:06,424 INFO: Partial:  basically he just mead fools of yu\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:55:06,487 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:55:07,615 INFO: OPT time: 1.128\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:55:07,615 INFO: Final:  basically he just made fools of you\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:55:07,616 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  30%|███       | 441/1450 [09:07<22:21,  1.33s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:55:07,759 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:55:07,800 INFO: Partial:  thousand miles away\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:55:07,822 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:55:08,481 INFO: OPT time: 0.659\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:55:08,482 INFO: Final:  a thousand miles away\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:55:08,482 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  30%|███       | 442/1450 [09:09<22:39,  1.35s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:55:08,658 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:55:08,750 INFO: Partial:  in this form sze was litter sette out to event hur father\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:55:08,849 INFO: Augmented nbest from 100 to 106 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:55:10,292 INFO: OPT time: 1.443\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:55:10,293 INFO: Final:  in this form she was later set out to event her father\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:55:10,293 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  31%|███       | 443/1450 [09:09<20:12,  1.20s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:55:10,465 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:55:10,577 INFO: Partial:  this would include quips just as paternity suits for instance\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:55:10,655 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:55:11,813 INFO: OPT time: 1.158\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:55:11,813 INFO: Final:  this would include clips such as paternity suits for instance\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:55:11,814 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  31%|███       | 444/1450 [09:11<23:14,  1.39s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:55:11,970 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:55:12,034 INFO: Partial:  factors artsy of axes farm\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:55:12,070 INFO: Augmented nbest from 100 to 166 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:55:13,480 INFO: OPT time: 1.410\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:55:13,480 INFO: Final:  factors artist of axes farm\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:55:13,480 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  31%|███       | 445/1450 [09:13<23:53,  1.43s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:55:13,671 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:55:13,812 INFO: Partial:  manned was attacked and stapp puttable times the family member elect\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:55:13,892 INFO: Augmented nbest from 100 to 124 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:55:15,475 INFO: OPT time: 1.583\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:55:15,475 INFO: Final:  man was attacked and stapp multiple times the family member elect\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:55:15,476 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  31%|███       | 446/1450 [09:14<25:04,  1.50s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:55:15,683 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:55:15,729 INFO: Partial:  what be a shame if that changed\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:55:15,764 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:55:16,621 INFO: OPT time: 0.857\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:55:16,621 INFO: Final:  would be a shame if that changed\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:55:16,622 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  31%|███       | 447/1450 [09:16<27:32,  1.65s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:55:16,780 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:55:16,920 INFO: Partial:  ministration of justice because a state faction\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:55:17,004 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:55:18,124 INFO: OPT time: 1.120\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:55:18,124 INFO: Final:  ministration of justice becomes a state faction\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:55:18,125 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  31%|███       | 448/1450 [09:18<25:00,  1.50s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:55:18,288 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:55:18,367 INFO: Partial:  the idea is fein in principle butt the decide is aull wrong\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:55:18,466 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:55:19,914 INFO: OPT time: 1.448\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:55:19,914 INFO: Final:  the idea is fine in principle but the decide is all wrong\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:55:19,915 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  31%|███       | 449/1450 [09:19<25:00,  1.50s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:55:20,088 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:55:20,173 INFO: Partial:  yu fined this article useful that plays sherr it with others\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:55:20,237 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:55:21,443 INFO: OPT time: 1.205\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:55:21,443 INFO: Final:  you find this article useful that plays share it with others\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:55:21,444 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  31%|███       | 450/1450 [09:21<26:26,  1.59s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:55:21,592 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:55:21,678 INFO: Partial:  butt behind the scenes the whitehouse took a les friendly approached\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:55:21,727 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:55:23,179 INFO: OPT time: 1.452\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:55:23,179 INFO: Final:  but behind the scenes the white house took a les friendly approached\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:55:23,179 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  31%|███       | 451/1450 [09:22<26:07,  1.57s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:55:23,296 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:55:23,357 INFO: Partial:  was there anything pacific yu said to them\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:55:23,402 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:55:24,396 INFO: OPT time: 0.994\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:55:24,397 INFO: Final:  was there anything specific you said to them\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:55:24,397 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  31%|███       | 452/1450 [09:24<26:55,  1.62s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:55:24,597 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:55:24,676 INFO: Partial:  had aull the vegetables in it\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:55:24,710 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:55:25,568 INFO: OPT time: 0.858\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:55:25,568 INFO: Final:  it had all the vegetables in it\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:55:25,569 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  31%|███       | 453/1450 [09:25<24:54,  1.50s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:55:25,701 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:55:25,788 INFO: Partial:  he had choices to make the cancer tolled him\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:55:25,858 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:55:27,055 INFO: OPT time: 1.197\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:55:27,056 INFO: Final:  he had choices to make the cancer told him\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:55:27,056 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  31%|███▏      | 454/1450 [09:27<23:14,  1.40s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:55:27,206 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:55:27,298 INFO: Partial:  getting pledge cheese for the boye scouts\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:55:27,420 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:55:28,402 INFO: OPT time: 0.982\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:55:28,403 INFO: Final:  getting plain cheese for the boy scouts\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:55:28,403 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  31%|███▏      | 455/1450 [09:28<23:39,  1.43s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:55:28,514 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:55:28,551 INFO: Partial:  downed the problem downe\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:55:28,581 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:55:29,392 INFO: OPT time: 0.811\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:55:29,392 INFO: Final:  dive down the problem down\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:55:29,393 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  31%|███▏      | 456/1450 [09:29<23:14,  1.40s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:55:29,512 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:55:29,570 INFO: Partial:  frum hates to sixteens\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:55:29,624 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:55:30,488 INFO: OPT time: 0.864\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:55:30,488 INFO: Final:  from eights to sixteens\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:55:30,489 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  32%|███▏      | 457/1450 [09:30<21:09,  1.28s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:55:30,616 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:55:30,664 INFO: Partial:  now that the grantors are here\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:55:30,707 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:55:31,565 INFO: OPT time: 0.858\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:55:31,565 INFO: Final:  now that the ratings are here\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:55:31,566 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  32%|███▏      | 458/1450 [09:31<20:14,  1.22s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:55:31,715 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:55:31,747 INFO: Partial:  due yu watch star truck\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:55:31,778 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:55:32,586 INFO: OPT time: 0.808\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:55:32,586 INFO: Final:  du u watch star track\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:55:32,587 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  32%|███▏      | 459/1450 [09:33<19:29,  1.18s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:55:32,717 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:55:32,777 INFO: Partial:  oui sette around and it popken\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:55:32,815 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:55:33,799 INFO: OPT time: 0.983\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:55:33,799 INFO: Final:  we sit around and eat popken\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:55:33,799 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  32%|███▏      | 460/1450 [09:34<18:40,  1.13s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:55:33,919 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:55:33,966 INFO: Partial:  of office every dey\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:55:34,003 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:55:34,696 INFO: OPT time: 0.693\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:55:34,696 INFO: Final:  out of office every day\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:55:34,697 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  32%|███▏      | 461/1450 [09:35<19:03,  1.16s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:55:34,822 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:55:34,878 INFO: Partial:  so that leaves mi with a choyce to make\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:55:34,931 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:55:36,129 INFO: OPT time: 1.198\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:55:36,129 INFO: Final:  so that leaves me with a choice to make\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:55:36,129 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  32%|███▏      | 462/1450 [09:36<17:45,  1.08s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:55:36,324 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:55:36,405 INFO: Partial:  yu no that been advertising that\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:55:36,440 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:55:37,251 INFO: OPT time: 0.810\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:55:37,251 INFO: Final:  you know that been advertising that\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:55:37,252 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  32%|███▏      | 463/1450 [09:37<19:29,  1.18s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:55:37,427 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:55:37,448 INFO: Partial:  would yu consider\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:55:37,468 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:55:38,123 INFO: OPT time: 0.654\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:55:38,123 INFO: Final:  would you consider\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:55:38,123 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  32%|███▏      | 464/1450 [09:38<19:09,  1.17s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:55:38,326 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:55:38,356 INFO: Partial:  due everything well\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:55:38,376 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:55:39,038 INFO: OPT time: 0.662\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:55:39,039 INFO: Final:  they do everything well\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:55:39,039 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  32%|███▏      | 465/1450 [09:39<17:41,  1.08s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:55:39,230 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:55:39,285 INFO: Partial:  they have a lyttle curriculum\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:55:39,309 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:55:40,155 INFO: OPT time: 0.845\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:55:40,155 INFO: Final:  they have a little curriculum\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:55:40,156 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  32%|███▏      | 466/1450 [09:40<16:52,  1.03s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:55:40,332 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:55:40,398 INFO: Partial:  that was impression ai gott when ai was there\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:55:40,473 INFO: Augmented nbest from 100 to 137 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:55:42,161 INFO: OPT time: 1.688\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:55:42,161 INFO: Final:  that was impression i got when i was there\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:55:42,162 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  32%|███▏      | 467/1450 [09:41<17:17,  1.06s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:55:42,338 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:55:42,390 INFO: Partial:  ostin is so pretty\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:55:42,418 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:55:43,098 INFO: OPT time: 0.680\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:55:43,098 INFO: Final:  austin is so pretty\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:55:43,099 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  32%|███▏      | 468/1450 [09:43<21:56,  1.34s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:55:43,239 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:55:43,281 INFO: Partial:  due sum every now at then\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:55:43,318 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:55:44,168 INFO: OPT time: 0.849\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:55:44,168 INFO: Final:  do some every now at then\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:55:44,169 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  32%|███▏      | 469/1450 [09:44<19:56,  1.22s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:55:44,341 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:55:44,378 INFO: Partial:  that what ai needed\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:55:44,403 INFO: Augmented nbest from 100 to 138 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:55:45,401 INFO: OPT time: 0.998\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:55:45,401 INFO: Final:  that's what i needed\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:55:45,401 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  32%|███▏      | 470/1450 [09:45<19:11,  1.17s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:55:45,545 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:55:45,592 INFO: Partial:  doing sum other movie\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:55:45,618 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:55:46,306 INFO: OPT time: 0.687\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:55:46,306 INFO: Final:  is doing some other movie\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:55:46,307 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  32%|███▏      | 471/1450 [09:46<19:27,  1.19s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:55:46,448 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:55:46,499 INFO: Partial:  really daunt want to stay in news\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:55:46,541 INFO: Augmented nbest from 100 to 101 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:55:47,493 INFO: OPT time: 0.952\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:55:47,494 INFO: Final:  really doan want to stay in news\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:55:47,494 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  33%|███▎      | 472/1450 [09:47<18:01,  1.11s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:55:47,649 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:55:47,709 INFO: Partial:  where putting upp with aull hur accident\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:55:47,754 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:55:48,698 INFO: OPT time: 0.945\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:55:48,699 INFO: Final:  where putting up with all her accident\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:55:48,699 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  33%|███▎      | 473/1450 [09:48<18:24,  1.13s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:55:48,852 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:55:48,900 INFO: Partial:  farrelly new to it\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:55:48,929 INFO: Augmented nbest from 100 to 108 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:55:49,760 INFO: OPT time: 0.830\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:55:49,760 INFO: Final:  fairly new to it\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:55:49,761 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  33%|███▎      | 474/1450 [09:50<18:45,  1.15s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:55:49,955 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:55:50,022 INFO: Partial:  no theirs nott any food that yu can get\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:55:50,092 INFO: Augmented nbest from 100 to 168 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:55:51,993 INFO: OPT time: 1.901\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:55:51,993 INFO: Final:  no theirs not any food that you can get\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:55:51,993 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  33%|███▎      | 475/1450 [09:51<18:17,  1.13s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:55:52,161 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:55:52,224 INFO: Partial:  have your career and your home life\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:55:52,259 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:55:53,370 INFO: OPT time: 1.111\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:55:53,371 INFO: Final:  you have your career and your home life\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:55:53,371 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  33%|███▎      | 476/1450 [09:53<23:39,  1.46s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:55:53,564 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:55:53,603 INFO: Partial:  orabelle stuff lyke that\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:55:53,627 INFO: Augmented nbest from 100 to 106 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:55:54,586 INFO: OPT time: 0.959\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:55:54,587 INFO: Final:  horrible stuff like that\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:55:54,587 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  33%|███▎      | 477/1450 [09:54<23:14,  1.43s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:55:54,766 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:55:54,890 INFO: Partial:  pc invaded counsell stalls fantastically\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:55:54,937 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:55:55,874 INFO: OPT time: 0.937\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:55:55,874 INFO: Final:  pc invaded council stalls fantastically\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:55:55,875 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  33%|███▎      | 478/1450 [09:56<22:10,  1.37s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:55:56,073 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:55:56,155 INFO: Partial:  cyst been affect calmest intuition\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:55:56,228 INFO: Augmented nbest from 100 to 111 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:55:57,088 INFO: OPT time: 0.860\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:55:57,089 INFO: Final:  cyst been affect commerce intuition\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:55:57,089 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  33%|███▎      | 479/1450 [09:57<21:45,  1.34s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:55:57,277 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:55:57,391 INFO: Partial:  dominoes disheartening star where tears treasurys\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:55:57,446 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:55:58,936 INFO: OPT time: 1.489\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:55:58,936 INFO: Final:  dominoes disheartening star where dares treasuries\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:55:58,936 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  33%|███▎      | 480/1450 [09:58<21:05,  1.31s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:55:59,076 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:55:59,194 INFO: Partial:  intelligent grandparents visions prided stick\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:55:59,247 INFO: Augmented nbest from 100 to 102 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:00,188 INFO: OPT time: 0.941\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:00,188 INFO: Final:  intelligent grandparents visions credit stick\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:00,188 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  33%|███▎      | 481/1450 [10:00<23:42,  1.47s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:00,378 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:00,541 INFO: Partial:  mascot began keating whet at shana\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:00,697 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:01,815 INFO: OPT time: 1.117\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:01,815 INFO: Final:  mascot began keating weight at china\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:01,815 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  33%|███▎      | 482/1450 [10:01<22:38,  1.40s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:01,993 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:02,118 INFO: Partial:  conveyed les hallway obviously minister\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:02,173 INFO: Augmented nbest from 100 to 125 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:03,338 INFO: OPT time: 1.165\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:03,338 INFO: Final:  conveyed this hallway obviously minister\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:03,339 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  33%|███▎      | 483/1450 [10:03<23:41,  1.47s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:03,484 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:03,567 INFO: Partial:  pony paper vise psychiatry\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:03,616 INFO: Augmented nbest from 100 to 117 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:04,583 INFO: OPT time: 0.968\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:04,584 INFO: Final:  pony paper vice psychiatry\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:04,584 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  33%|███▎      | 484/1450 [10:04<23:55,  1.49s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:04,789 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:04,917 INFO: Partial:  thoroughly uprooting nott croston\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:04,988 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:05,935 INFO: OPT time: 0.948\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:05,936 INFO: Final:  thoroughly uprooting not christian\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:05,937 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  33%|███▎      | 485/1450 [10:06<22:44,  1.41s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:06,093 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:06,268 INFO: Partial:  make disease whatever temples characters relatively\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:06,335 INFO: Augmented nbest from 100 to 120 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:07,483 INFO: OPT time: 1.148\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:07,483 INFO: Final:  make disease whatever temples characters relatively\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:07,484 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  34%|███▎      | 486/1450 [10:07<22:25,  1.40s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:07,595 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:07,690 INFO: Partial:  talkers rehabilitation loss stiehl directory\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:07,757 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:08,693 INFO: OPT time: 0.935\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:08,693 INFO: Final:  talkers rehabilitation laws deal directory\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:08,693 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  34%|███▎      | 487/1450 [10:08<23:07,  1.44s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:08,900 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:09,074 INFO: Partial:  election fissure mothers briere ours dedication\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:09,208 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:10,312 INFO: OPT time: 1.104\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:10,312 INFO: Final:  election fisher mothers briere hours dedication\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:10,312 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  34%|███▎      | 488/1450 [10:10<21:59,  1.37s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:10,505 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:10,616 INFO: Partial:  occasionally flooding signing wiens\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:10,658 INFO: Augmented nbest from 100 to 111 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:11,605 INFO: OPT time: 0.947\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:11,605 INFO: Final:  occasionally flooding signing wins\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:11,606 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  34%|███▎      | 489/1450 [10:11<23:09,  1.45s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:11,802 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:11,921 INFO: Partial:  anyways over hundred override\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:11,969 INFO: Augmented nbest from 100 to 124 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:12,955 INFO: OPT time: 0.986\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:12,955 INFO: Final:  anyways over hundred override\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:12,956 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  34%|███▍      | 490/1450 [10:13<22:24,  1.40s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:13,107 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:13,205 INFO: Partial:  intelligent simler fee persis at stil\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:13,267 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:14,393 INFO: OPT time: 1.125\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:14,393 INFO: Final:  intelligent similar fee persists at still\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:14,393 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  34%|███▍      | 491/1450 [10:14<22:08,  1.39s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:14,511 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:14,567 INFO: Partial:  enough course suitt aloud\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:14,604 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:15,287 INFO: OPT time: 0.683\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:15,287 INFO: Final:  enough course suit allowed\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:15,288 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  34%|███▍      | 492/1450 [10:15<22:21,  1.40s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:15,411 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:15,482 INFO: Partial:  bandel decesaris delusion brink\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:15,526 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:16,492 INFO: OPT time: 0.966\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:16,492 INFO: Final:  bandel decesaris delusion break\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:16,493 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  34%|███▍      | 493/1450 [10:16<19:55,  1.25s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:16,614 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:16,709 INFO: Partial:  beginning express flexible precisely shoes\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:16,758 INFO: Augmented nbest from 100 to 171 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:18,249 INFO: OPT time: 1.491\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:18,249 INFO: Final:  beginning expressed flexible precisely shoes\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:18,249 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  34%|███▍      | 494/1450 [10:17<19:41,  1.24s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:18,418 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:18,499 INFO: Partial:  immigration launching comport abuse\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:18,535 INFO: Augmented nbest from 100 to 153 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:19,526 INFO: OPT time: 0.991\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:19,526 INFO: Final:  immigration launching compete abuse\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:19,527 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  34%|███▍      | 495/1450 [10:19<22:09,  1.39s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:19,720 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:19,817 INFO: Partial:  cued excel chilly consuming attacking sort\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:19,895 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:20,838 INFO: OPT time: 0.943\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:20,838 INFO: Final:  used excel chile consuming attacking sort\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:20,838 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  34%|███▍      | 496/1450 [10:20<21:35,  1.36s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:21,026 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:21,103 INFO: Partial:  lot innocent howled commendation embarrassed\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:21,169 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:21,978 INFO: OPT time: 0.809\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:21,978 INFO: Final:  lot innocent old combination embarrassed\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:21,978 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  34%|███▍      | 497/1450 [10:22<21:20,  1.34s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:22,126 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:22,167 INFO: Partial:  they are lovely\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:22,186 INFO: Augmented nbest from 100 to 107 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:22,864 INFO: OPT time: 0.678\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:22,864 INFO: Final:  they are lovely\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:22,865 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  34%|███▍      | 498/1450 [10:23<20:21,  1.28s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:23,023 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:23,058 INFO: Partial:  hiers what yu have gott\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:23,089 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:23,943 INFO: OPT time: 0.854\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:23,943 INFO: Final:  hears what you have got\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:23,944 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  34%|███▍      | 499/1450 [10:24<18:26,  1.16s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:24,126 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:24,180 INFO: Partial:  won that ai yoos just for emergencies\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:24,217 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:25,203 INFO: OPT time: 0.986\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:25,203 INFO: Final:  one that i ewes just for emergencies\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:25,204 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  34%|███▍      | 500/1450 [10:25<18:01,  1.14s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:25,329 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:25,372 INFO: Partial:  there in tune with that\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:25,401 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:26,092 INFO: OPT time: 0.691\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:26,092 INFO: Final:  their in tune with that\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:26,093 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  35%|███▍      | 501/1450 [10:26<18:34,  1.17s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:26,231 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:26,263 INFO: Partial:  yu really nott remember\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:26,290 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:26,989 INFO: OPT time: 0.699\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:26,989 INFO: Final:  du you really not remember\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:26,989 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  35%|███▍      | 502/1450 [10:27<17:12,  1.09s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:27,133 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:27,178 INFO: Partial:  oui dote hachtel them very well\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:27,219 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:28,415 INFO: OPT time: 1.195\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:28,415 INFO: Final:  we doan hachtel them verry well\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:28,416 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  35%|███▍      | 503/1450 [10:28<16:16,  1.03s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:28,536 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:28,591 INFO: Partial:  atz another thing ai dote understand\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:28,637 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:29,586 INFO: OPT time: 0.949\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:29,586 INFO: Final:  that's another thing i dote understand\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:29,587 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  35%|███▍      | 504/1450 [10:29<18:07,  1.15s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:29,739 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:29,785 INFO: Partial:  before a swimming poul\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:29,823 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:30,514 INFO: OPT time: 0.691\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:30,514 INFO: Final:  before a swimming pool\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:30,515 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  35%|███▍      | 505/1450 [10:31<18:12,  1.16s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:30,641 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:30,685 INFO: Partial:  aull write mime redi to goh\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:30,746 INFO: Augmented nbest from 100 to 176 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:32,460 INFO: OPT time: 1.714\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:32,460 INFO: Final:  all right mime ready to go\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:32,461 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  35%|███▍      | 506/1450 [10:31<17:06,  1.09s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:32,647 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:32,682 INFO: Partial:  can relate to that\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:32,704 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:33,506 INFO: OPT time: 0.801\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:33,506 INFO: Final:  can relate to that\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:33,506 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  35%|███▍      | 507/1450 [10:33<21:08,  1.35s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:33,647 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:33,687 INFO: Partial:  yu goh to work every weekend\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:33,716 INFO: Augmented nbest from 100 to 112 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:34,724 INFO: OPT time: 1.007\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:34,724 INFO: Final:  you go to work every weekend\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:34,724 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  35%|███▌      | 508/1450 [10:34<19:42,  1.26s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:34,849 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:34,906 INFO: Partial:  nott for controlling how mutsch is spent\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:34,947 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:35,940 INFO: OPT time: 0.993\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:35,941 INFO: Final:  not for controlling how much is spent\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:35,941 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  35%|███▌      | 509/1450 [10:36<19:30,  1.24s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:36,053 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:36,117 INFO: Partial:  the united states an canada are so different\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:36,174 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:37,164 INFO: OPT time: 0.990\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:37,164 INFO: Final:  the united states and canada are so different\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:37,165 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  35%|███▌      | 510/1450 [10:37<19:21,  1.24s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:37,355 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:37,389 INFO: Partial:  well to yu no something\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:37,432 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:38,247 INFO: OPT time: 0.815\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:38,248 INFO: Final:  well to you know something\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:38,248 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  35%|███▌      | 511/1450 [10:38<19:17,  1.23s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:38,355 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:38,421 INFO: Partial:  nott every game sets out to make a point\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:38,492 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:39,646 INFO: OPT time: 1.154\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:39,646 INFO: Final:  not every game sets out to make a point\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:39,647 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  35%|███▌      | 512/1450 [10:39<18:33,  1.19s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:39,760 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:39,823 INFO: Partial:  nice eason the word ide tews\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:39,894 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:41,015 INFO: OPT time: 1.121\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:41,015 INFO: Final:  nice eason the word ide choose\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:41,016 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  35%|███▌      | 513/1450 [10:41<19:32,  1.25s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:41,165 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:41,227 INFO: Partial:  three or for nays and that woodby it\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:41,274 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:42,275 INFO: OPT time: 1.001\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:42,275 INFO: Final:  three or for days and that would be it\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:42,276 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  35%|███▌      | 514/1450 [10:42<20:04,  1.29s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:42,466 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:42,505 INFO: Partial:  its a basal occasion\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:42,532 INFO: Augmented nbest from 100 to 106 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:43,241 INFO: OPT time: 0.709\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:43,241 INFO: Final:  its a basal occasion\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:43,242 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  36%|███▌      | 515/1450 [10:43<19:55,  1.28s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:43,367 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:43,424 INFO: Partial:  what level of kahre to yu nied\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:43,482 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:44,622 INFO: OPT time: 1.140\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:44,622 INFO: Final:  what level of kahre to you need\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:44,622 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  36%|███▌      | 516/1450 [10:44<18:26,  1.18s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:44,770 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:44,801 INFO: Partial:  your customer\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:44,820 INFO: Augmented nbest from 100 to 104 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:45,498 INFO: OPT time: 0.678\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:45,498 INFO: Final:  your customer\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:45,498 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  36%|███▌      | 517/1450 [10:46<19:20,  1.24s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:45,671 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:45,731 INFO: Partial:  did they have sum pretty good special effects\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:45,785 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:46,774 INFO: OPT time: 0.989\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:46,774 INFO: Final:  did they have some pretty good special effects\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:46,775 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  36%|███▌      | 518/1450 [10:46<17:36,  1.13s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:46,974 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:47,011 INFO: Partial:  sze gets write into it\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:47,044 INFO: Augmented nbest from 100 to 129 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:48,173 INFO: OPT time: 1.129\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:48,173 INFO: Final:  she gets right into it\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:48,174 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  36%|███▌      | 519/1450 [10:48<18:15,  1.18s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:48,378 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:48,428 INFO: Partial:  butt oui haven't seen that won either\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:48,469 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:49,422 INFO: OPT time: 0.952\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:49,422 INFO: Final:  but we haven't seen that one either\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:49,423 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  36%|███▌      | 520/1450 [10:49<19:16,  1.24s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:49,579 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:49,631 INFO: Partial:  after oui had them for several years\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:49,663 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:50,649 INFO: OPT time: 0.985\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:50,649 INFO: Final:  after we had them for several years\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:50,650 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  36%|███▌      | 521/1450 [10:50<19:16,  1.24s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:50,781 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:50,835 INFO: Partial:  have a dog that guide give us\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:50,878 INFO: Augmented nbest from 100 to 120 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:52,023 INFO: OPT time: 1.145\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:52,023 INFO: Final:  have a dog that god give us\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:52,024 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  36%|███▌      | 522/1450 [10:52<19:10,  1.24s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:52,186 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:52,234 INFO: Partial:  trane your dog for confidence\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:52,325 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:53,174 INFO: OPT time: 0.850\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:53,175 INFO: Final:  train your dog for confidence\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:53,175 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  36%|███▌      | 523/1450 [10:53<19:46,  1.28s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:53,289 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:53,331 INFO: Partial:  fined the missing klu\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:53,358 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:54,159 INFO: OPT time: 0.801\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:54,159 INFO: Final:  find the missing clue\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:54,159 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  36%|███▌      | 524/1450 [10:54<19:09,  1.24s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:54,290 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:54,513 INFO: Partial:  as is now well known kanady had numerous extramarital avoids\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:54,578 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:56,099 INFO: OPT time: 1.520\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:56,099 INFO: Final:  as is now well known kennedy had numerous extramarital avoids\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:56,099 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  36%|███▌      | 525/1450 [10:55<17:56,  1.16s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:56,296 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:56,448 INFO: Partial:  recorded and edited bye been willens for plosive production\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:56,530 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:57,733 INFO: OPT time: 1.203\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:57,734 INFO: Final:  recorded and edited by bin willens for plosive production\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:57,734 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  36%|███▋      | 526/1450 [10:57<21:30,  1.40s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:57,901 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:57,973 INFO: Partial:  hire your franchise stuff in invent\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:58,039 INFO: Augmented nbest from 100 to 102 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:58,987 INFO: OPT time: 0.948\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:58,987 INFO: Final:  hire your franchise staff in invent\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:58,988 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  36%|███▋      | 527/1450 [10:59<22:35,  1.47s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:59,103 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:59,209 INFO: Partial:  so ai was supposed when ai gott this mason out of the blue\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:56:59,325 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:57:01,049 INFO: OPT time: 1.723\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:57:01,049 INFO: Final:  so ai was surprised when ai got this mason out of the blue\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:57:01,049 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  36%|███▋      | 528/1450 [11:00<21:34,  1.40s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:57:01,209 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:57:01,340 INFO: Partial:  economic haitiens pater shiff is bought on\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:57:01,440 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:57:02,587 INFO: OPT time: 1.147\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:57:02,587 INFO: Final:  economic issues pater schiff is bought on\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:57:02,588 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  36%|███▋      | 529/1450 [11:02<24:34,  1.60s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:57:02,713 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:57:02,798 INFO: Partial:  yu nott away of it that here is a really in shortt\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:57:02,931 INFO: Augmented nbest from 100 to 143 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:57:04,839 INFO: OPT time: 1.907\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:57:04,839 INFO: Final:  you not away of it that hear is a really in short\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:57:04,839 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  37%|███▋      | 530/1450 [11:04<24:15,  1.58s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:57:05,019 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:57:05,065 INFO: Partial:  redi to it bakke\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:57:05,105 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:57:05,911 INFO: OPT time: 0.806\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:57:05,911 INFO: Final:  ready to hit back\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:57:05,911 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  37%|███▋      | 531/1450 [11:06<27:18,  1.78s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:57:06,019 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:57:06,207 INFO: Partial:  despite that swore says it was audible to edify or contact the family\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:57:06,346 INFO: Augmented nbest from 100 to 135 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:57:08,292 INFO: OPT time: 1.945\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:57:08,292 INFO: Final:  despite that swan says it was unable to edify or contact the family\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:57:08,292 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  37%|███▋      | 532/1450 [11:07<24:00,  1.57s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:57:08,427 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:57:08,502 INFO: Partial:  surety is no looking so easy\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:57:08,542 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:57:09,393 INFO: OPT time: 0.851\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:57:09,393 INFO: Final:  charity is no looking so easy\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:57:09,393 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  37%|███▋      | 533/1450 [11:09<27:42,  1.81s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:57:09,524 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:57:09,589 INFO: Partial:  the size over amerika the swings is on\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:57:09,642 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:57:10,795 INFO: OPT time: 1.153\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:57:10,795 INFO: Final:  in the skies over america the squeeze is on\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:57:10,796 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  37%|███▋      | 534/1450 [11:10<24:25,  1.60s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:57:10,931 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:57:11,020 INFO: Partial:  yu are redding own the fact that yu are redi and get to work\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:57:11,152 INFO: Augmented nbest from 100 to 172 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:57:13,178 ERROR: Error during OPT rescore: CUDA out of memory. Tried to allocate 120.00 MiB (GPU 0; 14.74 GiB total capacity; 14.09 GiB already allocated; 120.19 MiB free; 14.34 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:57:13,558 ERROR: Error during OPT rescore: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.74 GiB total capacity; 14.36 GiB already allocated; 24.19 MiB free; 14.43 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:57:13,559 INFO: OPT time: 2.407\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:57:13,559 INFO: Final:  yoo are redding own the fact that uwe are reddy and get to work\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:57:13,560 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  37%|███▋      | 535/1450 [11:12<23:29,  1.54s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:57:13,737 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:57:13,812 INFO: Partial:  winans deprives bawl of plates\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:57:13,874 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:57:14,989 INFO: OPT time: 1.115\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:57:14,990 INFO: Final:  winans deprives ball of place\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:57:14,990 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  37%|███▋      | 536/1450 [11:15<29:03,  1.91s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:57:15,141 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:57:15,230 INFO: Partial:  public hearing is planned for remember\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:57:15,270 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:57:16,206 INFO: OPT time: 0.936\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:57:16,206 INFO: Final:  public hearing is planned for november\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:57:16,207 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  37%|███▋      | 537/1450 [11:16<26:50,  1.76s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:57:16,340 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:57:16,447 INFO: Partial:  oui want to support our local punishes support each other\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:57:16,513 INFO: Augmented nbest from 100 to 130 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:57:18,076 INFO: OPT time: 1.563\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:57:18,076 INFO: Final:  we want to support our local produces support each other\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:57:18,077 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  37%|███▋      | 538/1450 [11:17<24:19,  1.60s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:57:18,247 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:57:18,367 INFO: Partial:  the fading history is especially relevant today\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:57:18,400 INFO: Augmented nbest from 100 to 133 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:57:19,551 INFO: OPT time: 1.151\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:57:19,551 INFO: Final:  the fading history is especially relevant today\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:57:19,552 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  37%|███▋      | 539/1450 [11:19<25:31,  1.68s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:57:19,750 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:57:19,869 INFO: Partial:  comedians are already familiar with this system\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:57:19,910 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:57:21,021 INFO: OPT time: 1.111\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:57:21,021 INFO: Final:  canadians are already familiar with this system\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:57:21,022 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  37%|███▋      | 540/1450 [11:20<24:33,  1.62s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:57:21,155 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:57:21,255 INFO: Partial:  or bierer images of that ngai\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:57:21,343 INFO: Augmented nbest from 100 to 109 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:57:22,323 INFO: OPT time: 0.980\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:57:22,323 INFO: Final:  or bury images of that guy\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:57:22,323 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  37%|███▋      | 541/1450 [11:22<23:51,  1.57s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:57:22,462 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:57:22,573 INFO: Partial:  opened a law cancelling office at home after graduating\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:57:22,650 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:57:23,807 INFO: OPT time: 1.157\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:57:23,807 INFO: Final:  ann opened a law cancelling office at home after graduating\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:57:23,808 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  37%|███▋      | 542/1450 [11:23<22:35,  1.49s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:57:23,965 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:57:24,039 INFO: Partial:  large size in stockings is hard to cel\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:57:24,110 INFO: Augmented nbest from 100 to 106 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:57:25,290 INFO: OPT time: 1.180\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:57:25,291 INFO: Final:  large size in stockings is hard to sell\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:57:25,291 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  37%|███▋      | 543/1450 [11:25<22:31,  1.49s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:57:25,465 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:57:25,531 INFO: Partial:  rind is used to tkach pik seven\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:57:25,604 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:57:26,720 INFO: OPT time: 1.116\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:57:26,721 INFO: Final:  rod is used to catch pick seven\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:57:26,721 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  38%|███▊      | 544/1450 [11:26<22:28,  1.49s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:57:26,870 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:57:26,920 INFO: Partial:  kick the bawl streett and follow thru\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:57:26,987 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:57:27,967 INFO: OPT time: 0.979\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:57:27,967 INFO: Final:  kick the ball straight and follow through\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:57:27,968 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  38%|███▊      | 545/1450 [11:28<22:10,  1.47s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:57:28,173 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:57:28,241 INFO: Partial:  help the woman get bakke to hur feet\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:57:28,309 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:57:29,293 INFO: OPT time: 0.984\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:57:29,293 INFO: Final:  help the woman get back to her feet\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:57:29,294 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  38%|███▊      | 546/1450 [11:29<21:08,  1.40s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:57:29,475 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:57:29,551 INFO: Partial:  parte of t helps to pass the evening\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:57:29,601 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:57:30,543 INFO: OPT time: 0.942\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:57:30,544 INFO: Final:  pot of tea helps to pass the evening\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:57:30,544 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  38%|███▊      | 547/1450 [11:30<20:46,  1.38s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:57:30,678 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:57:30,765 INFO: Partial:  murky fires lyke flame and eat\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:57:30,851 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:57:31,795 INFO: OPT time: 0.944\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:57:31,795 INFO: Final:  murky fires like flame and heat\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:57:31,796 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  38%|███▊      | 548/1450 [11:31<20:09,  1.34s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:57:31,983 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:57:32,074 INFO: Partial:  the soft cusson broke the maynes fall\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:57:32,201 INFO: Augmented nbest from 100 to 103 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:57:33,342 INFO: OPT time: 1.140\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:57:33,342 INFO: Final:  the soft cousin broke the mains fall\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:57:33,343 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  38%|███▊      | 549/1450 [11:33<19:44,  1.31s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:57:33,487 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:57:33,552 INFO: Partial:  the sault brings kaim across frum the sci\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:57:33,615 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:57:34,791 INFO: OPT time: 1.176\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:57:34,791 INFO: Final:  the salt brings came across from the c\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:57:34,792 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  38%|███▊      | 550/1450 [11:34<20:45,  1.38s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:57:34,986 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:57:35,060 INFO: Partial:  the girl and the both sold fifty points\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:57:35,129 INFO: Augmented nbest from 100 to 114 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:57:36,320 INFO: OPT time: 1.190\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:57:36,320 INFO: Final:  the girl and the books sold fifty points\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:57:36,320 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  38%|███▊      | 551/1450 [11:36<21:01,  1.40s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:57:36,490 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:57:36,584 INFO: Partial:  take the winding bath to which the lyke\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:57:36,667 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:57:37,777 INFO: OPT time: 1.110\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:57:37,777 INFO: Final:  take the winding bath to which the lake\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:57:37,777 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  38%|███▊      | 552/1450 [11:37<21:34,  1.44s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:57:37,896 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:57:37,975 INFO: Partial:  note closely the size of the guess take\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:57:38,038 INFO: Augmented nbest from 100 to 101 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:57:39,027 INFO: OPT time: 0.988\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:57:39,027 INFO: Final:  note closely the size of the guess tick\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:57:39,027 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  38%|███▊      | 553/1450 [11:39<21:36,  1.45s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:57:39,199 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:57:39,277 INFO: Partial:  wipe the rais of is doughty fiss\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:57:39,373 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:57:40,533 INFO: OPT time: 1.160\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:57:40,534 INFO: Final:  wipe the race of is dirty fis\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:57:40,534 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  38%|███▊      | 554/1450 [11:40<20:42,  1.39s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:57:40,703 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:57:40,761 INFO: Partial:  med the could before yu goh out\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:57:40,818 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:57:41,764 INFO: OPT time: 0.946\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:57:41,764 INFO: Final:  med the could before you go out\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:57:41,765 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  38%|███▊      | 555/1450 [11:41<21:13,  1.42s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:57:41,903 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:57:41,994 INFO: Partial:  the raced was bubbly strayed and whole lipp\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:57:42,137 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:57:43,298 INFO: OPT time: 1.161\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:57:43,298 INFO: Final:  the raced was bubbly trade and whole lip\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:57:43,299 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  38%|███▊      | 556/1450 [11:43<20:20,  1.37s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:57:43,411 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:57:43,480 INFO: Partial:  tree katt give both to kittens\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:57:43,519 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:57:44,461 INFO: OPT time: 0.942\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:57:44,461 INFO: Final:  the stray cat give both to kittens\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:57:44,462 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  38%|███▊      | 557/1450 [11:44<21:04,  1.42s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:57:44,610 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:57:44,674 INFO: Partial:  the yung girl give no kleer response\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:57:44,738 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:57:45,718 INFO: OPT time: 0.980\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:57:45,718 INFO: Final:  the young girl give no clear response\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:57:45,718 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  38%|███▊      | 558/1450 [11:45<19:55,  1.34s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:57:45,913 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:57:45,981 INFO: Partial:  miele was cooked before the bille rague\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:57:46,052 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:57:47,037 INFO: OPT time: 0.985\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:57:47,037 INFO: Final:  meal was cooked before the bill rang\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:57:47,038 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  39%|███▊      | 559/1450 [11:47<19:31,  1.31s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:57:47,216 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:57:47,299 INFO: Partial:  the rupe will bind the seven books at once\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:57:47,363 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:57:48,493 INFO: OPT time: 1.130\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:57:48,493 INFO: Final:  the group will bind the seven books at once\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:57:48,494 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  39%|███▊      | 560/1450 [11:48<19:31,  1.32s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:57:48,617 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:57:48,684 INFO: Partial:  happ over the fix and plauche in\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:57:48,763 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:57:49,922 INFO: OPT time: 1.158\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:57:49,922 INFO: Final:  hap over the fence and lauch in\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:57:49,922 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  39%|███▊      | 561/1450 [11:49<20:07,  1.36s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:57:50,126 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:57:50,201 INFO: Partial:  the friendly gig leff the drug storr\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:57:50,278 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:57:51,255 INFO: OPT time: 0.977\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:57:51,255 INFO: Final:  the friendly gang left the drug store\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:57:51,256 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  39%|███▉      | 562/1450 [11:51<20:24,  1.38s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:57:51,424 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:57:51,504 INFO: Partial:  meche wire kippes tess inside\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:57:51,620 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:57:52,595 INFO: OPT time: 0.975\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:57:52,595 INFO: Final:  much wire keeps techs inside\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:57:52,595 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  39%|███▉      | 563/1450 [11:52<20:11,  1.37s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:57:52,731 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:57:52,812 INFO: Partial:  sowed familiar\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:57:52,842 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:57:53,494 INFO: OPT time: 0.651\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:57:53,494 INFO: Final:  they sound familiar\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:57:53,495 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  39%|███▉      | 564/1450 [11:54<20:02,  1.36s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:57:53,629 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:57:53,727 INFO: Partial:  in this whey every decision yu make mutsch be carefully considerate\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:57:53,806 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:57:55,211 INFO: OPT time: 1.405\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:57:55,212 INFO: Final:  in this way every decision u make much be carefully considerate\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:57:55,212 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  39%|███▉      | 565/1450 [11:54<17:59,  1.22s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:57:55,332 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:57:55,416 INFO: Partial:  those can cresses work well\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:57:55,466 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:57:56,413 INFO: OPT time: 0.947\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:57:56,413 INFO: Final:  those can cresses work well\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:57:56,413 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  39%|███▉      | 566/1450 [11:56<20:10,  1.37s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:57:56,534 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:57:56,606 INFO: Partial:  dote really kahre what it takes to qualify\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:57:56,662 INFO: Augmented nbest from 100 to 119 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:57:58,117 INFO: OPT time: 1.454\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:57:58,117 INFO: Final:  dint really care what it takes to qualify\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:57:58,117 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  39%|███▉      | 567/1450 [11:57<19:24,  1.32s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:57:58,236 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:57:58,285 INFO: Partial:  its the texas here\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:57:58,328 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:57:59,011 INFO: OPT time: 0.682\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:57:59,011 INFO: Final:  its the taxes here\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:57:59,012 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  39%|███▉      | 568/1450 [11:59<21:05,  1.43s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:57:59,139 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:57:59,199 INFO: Partial:  its people it will probably shred\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:57:59,244 INFO: Augmented nbest from 100 to 112 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:58:00,206 INFO: OPT time: 0.962\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:58:00,206 INFO: Final:  if its people it will probably shred\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:58:00,207 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  39%|███▉      | 569/1450 [12:00<18:40,  1.27s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:58:00,342 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:58:00,401 INFO: Partial:  whats the word haim looking for\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:58:00,458 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:58:01,431 INFO: OPT time: 0.973\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:58:01,431 INFO: Final:  whats the word i looking for\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:58:01,432 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  39%|███▉      | 570/1450 [12:01<18:19,  1.25s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:58:01,544 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:58:01,584 INFO: Partial:  this about where ai stead\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:58:01,619 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:58:02,465 INFO: OPT time: 0.845\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:58:02,465 INFO: Final:  this about where i said\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:58:02,466 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  39%|███▉      | 571/1450 [12:02<18:11,  1.24s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:58:02,647 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:58:02,690 INFO: Partial:  just dutt feet the carre\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:58:02,730 INFO: Augmented nbest from 100 to 109 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:58:03,679 INFO: OPT time: 0.949\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:58:03,679 INFO: Final:  just didn't feet the carre\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:58:03,679 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  39%|███▉      | 572/1450 [12:03<17:15,  1.18s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:58:03,849 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:58:03,903 INFO: Partial:  what to yu think canby dunne about that\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:58:03,950 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:58:04,939 INFO: OPT time: 0.989\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:58:04,939 INFO: Final:  what to you think canby done about that\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:58:04,940 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  40%|███▉      | 573/1450 [12:05<17:23,  1.19s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:58:05,052 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:58:05,138 INFO: Partial:  oui usually order our tickets whey in events\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:58:05,191 INFO: Augmented nbest from 100 to 113 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:58:06,345 INFO: OPT time: 1.154\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:58:06,345 INFO: Final:  we usually order our tickets way in events\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:58:06,345 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  40%|███▉      | 574/1450 [12:06<17:40,  1.21s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:58:06,456 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:58:06,507 INFO: Partial:  love to run in the read\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:58:06,562 INFO: Augmented nbest from 100 to 118 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:58:07,544 INFO: OPT time: 0.982\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:58:07,544 INFO: Final:  love to run in the red\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:58:07,545 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  40%|███▉      | 575/1450 [12:07<18:30,  1.27s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:58:07,659 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:58:07,797 INFO: Partial:  my level of expertise is increasing almost dayley\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:58:07,868 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:58:08,996 INFO: OPT time: 1.128\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:58:08,996 INFO: Final:  my level of expertise is increasing almost daily\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:58:08,997 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  40%|███▉      | 576/1450 [12:08<18:11,  1.25s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:58:09,161 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:58:09,257 INFO: Partial:  yu saw the bason of the civil writes hatt\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:58:09,333 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:58:10,508 INFO: OPT time: 1.175\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:58:10,509 INFO: Final:  you saw the bason of the civil rights hat\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:58:10,509 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  40%|███▉      | 577/1450 [12:10<19:03,  1.31s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:58:10,666 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:58:10,710 INFO: Partial:  rather be doing that\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:58:10,734 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:58:11,585 INFO: OPT time: 0.850\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:58:11,585 INFO: Final:  ide rather be doing that\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:58:11,585 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  40%|███▉      | 578/1450 [12:11<19:54,  1.37s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:58:11,766 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:58:11,841 INFO: Partial:  going bakke to the bases in the erly greats\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:58:11,913 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:58:13,114 INFO: OPT time: 1.201\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:58:13,114 INFO: Final:  going back to the bases in the early greats\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:58:13,115 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  40%|███▉      | 579/1450 [12:13<18:36,  1.28s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:58:13,269 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:58:13,323 INFO: Partial:  whatever pup oui trick\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:58:13,361 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:58:14,162 INFO: OPT time: 0.801\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:58:14,162 INFO: Final:  whatever pup we trick\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:58:14,163 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  40%|████      | 580/1450 [12:14<19:40,  1.36s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:58:14,272 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:58:14,395 INFO: Partial:  reports on the occasion of the six animation\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:58:14,462 INFO: Augmented nbest from 100 to 137 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:58:15,846 INFO: OPT time: 1.384\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:58:15,846 INFO: Final:  reports on the occasion of the six anniversary\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:58:15,847 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  40%|████      | 581/1450 [12:15<18:18,  1.26s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:58:15,975 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:58:16,022 INFO: Partial:  have to think about sum morr now\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:58:16,081 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:58:17,190 INFO: OPT time: 1.109\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:58:17,190 INFO: Final:  have to think about it some more now\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:58:17,191 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  40%|████      | 582/1450 [12:17<20:06,  1.39s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:58:17,380 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:58:17,424 INFO: Partial:  a sowing machine\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:58:17,449 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:58:18,133 INFO: OPT time: 0.684\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:58:18,133 INFO: Final:  buy a sewing machine\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:58:18,134 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  40%|████      | 583/1450 [12:18<19:53,  1.38s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:58:18,281 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:58:18,352 INFO: Partial:  yu take away a basins freedom\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:58:18,390 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:58:19,242 INFO: OPT time: 0.852\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:58:19,242 INFO: Final:  you take away a persons freedom\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:58:19,242 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  40%|████      | 584/1450 [12:19<17:59,  1.25s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:58:19,384 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:58:19,471 INFO: Partial:  my employee feels that he was to control us\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:58:19,578 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:58:20,743 INFO: OPT time: 1.165\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:58:20,743 INFO: Final:  my employee feels that he want to control us\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:58:20,744 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  40%|████      | 585/1450 [12:20<17:22,  1.20s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:58:20,888 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:58:20,961 INFO: Partial:  found that aull ai talked about was my baby\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:58:21,016 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:58:22,214 INFO: OPT time: 1.198\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:58:22,214 INFO: Final:  found that all i talked about was my baby\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:58:22,214 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  40%|████      | 586/1450 [12:22<18:37,  1.29s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:58:22,393 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:58:22,464 INFO: Partial:  tame school makes a nice bit\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:58:22,536 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:58:23,508 INFO: OPT time: 0.972\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:58:23,508 INFO: Final:  team school makes a nice bit\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:58:23,508 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  40%|████      | 587/1450 [12:23<19:22,  1.35s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:58:23,699 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:58:23,804 INFO: Partial:  the hard of the carre work the leaping kump\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:58:23,891 INFO: Augmented nbest from 100 to 109 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:58:25,338 INFO: OPT time: 1.446\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:58:25,338 INFO: Final:  the hard of the car work the leaping cup\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:58:25,338 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  41%|████      | 588/1450 [12:24<19:07,  1.33s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:58:25,503 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:58:25,618 INFO: Partial:  the heart beet cranley and with foam trus\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:58:25,772 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:58:26,935 INFO: OPT time: 1.163\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:58:26,935 INFO: Final:  the heart beat rally and with foam truss\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:58:26,936 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  41%|████      | 589/1450 [12:26<21:14,  1.48s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:58:27,117 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:58:27,208 INFO: Partial:  the biel was ward it then sever wreak\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:58:27,325 INFO: Augmented nbest from 100 to 103 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:58:28,505 INFO: OPT time: 1.180\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:58:28,506 INFO: Final:  the beel was ward it then sever reek\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:58:28,506 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  41%|████      | 590/1450 [12:28<21:43,  1.52s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:58:28,619 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:58:28,698 INFO: Partial:  the frett biel was gott in think slices\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:58:28,756 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:58:29,906 INFO: OPT time: 1.150\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:58:29,906 INFO: Final:  the fret beel was got in think slices\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:58:29,906 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  41%|████      | 591/1450 [12:29<21:55,  1.53s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:58:30,018 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:58:30,107 INFO: Partial:  the navy attend the big taxed fauss\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:58:30,211 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:58:31,155 INFO: OPT time: 0.944\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:58:31,155 INFO: Final:  the navy attend the big test voice\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:58:31,155 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  41%|████      | 592/1450 [12:31<21:20,  1.49s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:58:31,323 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:58:31,399 INFO: Partial:  the get lowing un scared muhs\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:58:31,486 INFO: Augmented nbest from 100 to 103 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:58:32,467 INFO: OPT time: 0.981\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:58:32,467 INFO: Final:  the get lowing of scared much\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:58:32,468 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  41%|████      | 593/1450 [12:32<20:16,  1.42s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:58:32,626 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:58:32,678 INFO: Partial:  there are morr that due filtered here\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:58:32,736 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:58:33,686 INFO: OPT time: 0.951\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:58:33,687 INFO: Final:  there are more that do filtered here\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:58:33,687 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  41%|████      | 594/1450 [12:33<19:47,  1.39s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:58:33,825 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:58:33,902 INFO: Partial:  hatt prim was wind and to trooping\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:58:33,966 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:58:35,078 INFO: OPT time: 1.112\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:58:35,078 INFO: Final:  the head prim was wind and to trooping\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:58:35,079 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  41%|████      | 595/1450 [12:35<19:03,  1.34s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:58:35,232 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:58:35,323 INFO: Partial:  the longer chide to luse is guess\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:58:35,402 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:58:36,516 INFO: OPT time: 1.114\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:58:36,516 INFO: Final:  the longer tide to lose is guess\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:58:36,517 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  41%|████      | 596/1450 [12:36<19:15,  1.35s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:58:36,635 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:58:36,710 INFO: Partial:  dress curled around the fist post\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:58:36,776 INFO: Augmented nbest from 100 to 102 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:58:37,736 INFO: OPT time: 0.959\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:58:37,736 INFO: Final:  the dress curled around the fence post\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:58:37,736 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  41%|████      | 597/1450 [12:37<19:36,  1.38s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:58:37,938 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:58:38,003 INFO: Partial:  kut the pye into large ponts\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:58:38,048 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:58:38,893 INFO: OPT time: 0.846\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:58:38,894 INFO: Final:  cut the pie into large parts\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:58:38,894 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  41%|████      | 598/1450 [12:39<18:54,  1.33s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:58:39,040 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:58:39,121 INFO: Partial:  when dr what summum get which\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:58:39,182 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:58:40,123 INFO: OPT time: 0.941\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:58:40,123 INFO: Final:  men drive what summum get which\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:58:40,124 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  41%|████▏     | 599/1450 [12:40<18:08,  1.28s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:58:40,242 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:58:40,307 INFO: Partial:  always close apart nor tate\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:58:40,383 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:58:41,188 INFO: OPT time: 0.805\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:58:41,188 INFO: Final:  always close apart nor tight\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:58:41,189 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  41%|████▏     | 600/1450 [12:41<17:54,  1.26s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:58:41,346 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:58:41,421 INFO: Partial:  he li prone and only moved a live\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:58:41,491 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:58:42,470 INFO: OPT time: 0.978\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:58:42,470 INFO: Final:  he lay prone and only moved a lime\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:58:42,470 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  41%|████▏     | 601/1450 [12:42<17:02,  1.20s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:58:42,651 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:58:42,718 INFO: Partial:  klus lyke keep along the treat\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:58:42,791 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:58:43,731 INFO: OPT time: 0.940\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:58:43,731 INFO: Final:  close like keep along the treat\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:58:43,732 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  42%|████▏     | 602/1450 [12:43<17:20,  1.23s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:58:43,854 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:58:43,929 INFO: Partial:  wix of loud hoang in the bill herre\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:58:44,016 INFO: Augmented nbest from 100 to 106 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:58:45,183 INFO: OPT time: 1.166\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:58:45,183 INFO: Final:  wicks of loud hoang in the bil here\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:58:45,183 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  42%|████▏     | 603/1450 [12:45<17:28,  1.24s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:58:45,357 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:58:45,461 INFO: Partial:  pound of sooter costs morr than enge\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:58:45,561 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:58:46,544 INFO: OPT time: 0.982\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:58:46,544 INFO: Final:  pound of sitter costs more than age\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:58:46,544 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  42%|████▏     | 604/1450 [12:46<18:21,  1.30s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:58:46,660 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:58:46,742 INFO: Partial:  fiene was shop and gott the kleer water\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:58:46,812 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:58:48,179 INFO: OPT time: 1.367\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:58:48,179 INFO: Final:  fiene was shop and got the clear water\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:58:48,180 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  42%|████▏     | 605/1450 [12:47<18:35,  1.32s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:58:48,361 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:58:48,433 INFO: Partial:  play siems tel and quite supan\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:58:48,488 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:58:49,435 INFO: OPT time: 0.946\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:58:49,435 INFO: Final:  the play seems tel and quite supan\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:58:49,435 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  42%|████▏     | 606/1450 [12:49<19:53,  1.41s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:58:49,565 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:58:49,640 INFO: Partial:  belle the put to sum it frum sinking\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:58:49,708 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:58:50,695 INFO: OPT time: 0.987\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:58:50,696 INFO: Final:  bell the put to some it from sinking\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:58:50,696 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  42%|████▏     | 607/1450 [12:50<19:12,  1.37s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:58:50,870 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:58:50,947 INFO: Partial:  the kumm interred in lett schul that here\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:58:51,031 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:58:52,162 INFO: OPT time: 1.131\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:58:52,162 INFO: Final:  the cum interred in let sure that here\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:58:52,163 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  42%|████▏     | 608/1450 [12:52<18:44,  1.33s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:58:52,274 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:58:52,398 INFO: Partial:  just is yoos to make connely gives\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:58:52,501 INFO: Augmented nbest from 100 to 123 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:58:53,883 INFO: OPT time: 1.382\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:58:53,883 INFO: Final:  just is use to make conley gives\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:58:53,884 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  42%|████▏     | 609/1450 [12:53<19:15,  1.37s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:58:54,079 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:58:54,162 INFO: Partial:  did menz were said inning order\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:58:54,304 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:58:55,154 INFO: OPT time: 0.850\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:58:55,154 INFO: Final:  did means were said in in order\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:58:55,155 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  42%|████▏     | 610/1450 [12:55<20:41,  1.48s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:58:55,284 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:58:55,337 INFO: Partial:  the bill was paid every third wieck\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:58:55,401 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:58:56,523 INFO: OPT time: 1.122\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:58:56,523 INFO: Final:  the bill was paid every third week\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:58:56,523 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  42%|████▏     | 611/1450 [12:56<19:48,  1.42s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:58:56,682 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:58:56,776 INFO: Partial:  that what ai had the operating to due\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:58:56,867 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:58:57,856 INFO: OPT time: 0.989\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:58:57,856 INFO: Final:  that what i had the operating to do\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:58:57,857 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  42%|████▏     | 612/1450 [12:57<19:34,  1.40s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:58:57,985 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:58:58,076 INFO: Partial:  because it actually dozen bettor who shows upp\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:58:58,138 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:58:59,270 INFO: OPT time: 1.131\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:58:59,270 INFO: Final:  because it actually dozen better who shows up\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:58:59,271 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  42%|████▏     | 613/1450 [12:59<19:16,  1.38s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:58:59,385 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:58:59,446 INFO: Partial:  they have the beste of both words\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:58:59,492 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:00,476 INFO: OPT time: 0.984\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:00,477 INFO: Final:  they have the best of both words\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:00,477 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  42%|████▏     | 614/1450 [13:00<19:22,  1.39s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:00,589 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:00,695 INFO: Partial:  oui fined it easier to divide the measure boylls hupp\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:00,770 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:02,163 INFO: OPT time: 1.392\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:02,163 INFO: Final:  we find it easier to divide the measure boyles hupp\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:02,163 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  42%|████▏     | 615/1450 [13:01<18:35,  1.34s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:02,293 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:02,364 INFO: Partial:  prominently attest\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:02,380 INFO: Augmented nbest from 55 to 55 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:02,798 INFO: OPT time: 0.418\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:02,798 INFO: Final:  prominently attached\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:02,799 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  42%|████▏     | 616/1450 [13:03<20:01,  1.44s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:02,991 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:03,053 INFO: Partial:  dote no about ninety\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:03,091 INFO: Augmented nbest from 100 to 124 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:04,054 INFO: OPT time: 0.963\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:04,055 INFO: Final:  dint know about ninety\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:04,055 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  43%|████▎     | 617/1450 [13:04<16:38,  1.20s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:04,194 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:04,279 INFO: Partial:  good rather sci it harder to commit somebody\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:04,336 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:05,325 INFO: OPT time: 0.989\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:05,325 INFO: Final:  good rather see it harder to commit somebody\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:05,325 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  43%|████▎     | 618/1450 [13:05<16:52,  1.22s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:05,499 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:05,568 INFO: Partial:  morr activity on our parte\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:05,615 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:06,551 INFO: OPT time: 0.936\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:06,551 INFO: Final:  more activity on our part\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:06,552 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  43%|████▎     | 619/1450 [13:06<17:04,  1.23s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:06,702 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:06,792 INFO: Partial:  keep chickens in a garage\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:06,849 INFO: Augmented nbest from 100 to 110 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:07,823 INFO: OPT time: 0.974\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:07,823 INFO: Final:  keep chickens in a garage\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:07,824 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  43%|████▎     | 620/1450 [13:07<17:01,  1.23s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:08,006 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:08,083 INFO: Partial:  sheens live with us for lyke five years\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:08,147 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:09,139 INFO: OPT time: 0.991\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:09,139 INFO: Final:  cedes live with us for like five years\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:09,140 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  43%|████▎     | 621/1450 [13:09<17:10,  1.24s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:09,312 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:09,409 INFO: Partial:  its lyke seventy decrease here write now\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:09,483 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:10,602 INFO: OPT time: 1.119\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:10,602 INFO: Final:  its like seventy degrees here right now\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:10,603 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  43%|████▎     | 622/1450 [13:10<17:27,  1.26s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:10,713 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:10,756 INFO: Partial:  bick that carre out\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:10,794 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:11,635 INFO: OPT time: 0.841\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:11,636 INFO: Final:  back that car out\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:11,636 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  43%|████▎     | 623/1450 [13:12<18:15,  1.32s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:11,816 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:11,888 INFO: Partial:  oui had to give him a tomato\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:11,941 INFO: Augmented nbest from 100 to 128 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:13,349 INFO: OPT time: 1.408\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:13,349 INFO: Final:  we had to give him a tomato\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:13,350 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  43%|████▎     | 624/1450 [13:13<17:01,  1.24s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:13,517 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:13,565 INFO: Partial:  its riel hard to make them\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:13,597 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:14,571 INFO: OPT time: 0.974\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:14,571 INFO: Final:  its real hard to make them\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:14,572 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  43%|████▎     | 625/1450 [13:14<18:58,  1.38s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:14,718 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:14,783 INFO: Partial:  when ai furst dotted working\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:14,835 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:15,804 INFO: OPT time: 0.969\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:15,804 INFO: Final:  when i first started working\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:15,804 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  43%|████▎     | 626/1450 [13:16<18:18,  1.33s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:15,923 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:15,983 INFO: Partial:  think that a family intimately\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:16,016 INFO: Augmented nbest from 100 to 110 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:16,962 INFO: OPT time: 0.946\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:16,962 INFO: Final:  they think that a family activity\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:16,962 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  43%|████▎     | 627/1450 [13:17<17:51,  1.30s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:17,125 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:17,206 INFO: Partial:  it siems lyke they think the no what they want\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:17,269 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:18,431 INFO: OPT time: 1.162\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:18,431 INFO: Final:  it seems like they think the know what they want\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:18,432 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  43%|████▎     | 628/1450 [13:18<17:15,  1.26s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:18,632 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:18,683 INFO: Partial:  he pretty mutsch job out of public love\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:18,735 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:19,723 INFO: OPT time: 0.987\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:19,723 INFO: Final:  he pretty much job out of public life\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:19,723 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  43%|████▎     | 629/1450 [13:19<18:05,  1.32s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:19,831 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:19,894 INFO: Partial:  lot of good as kumm frum this won\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:19,943 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:21,067 INFO: OPT time: 1.123\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:21,067 INFO: Final:  lot of good as come from this one\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:21,067 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  43%|████▎     | 630/1450 [13:21<17:56,  1.31s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:21,234 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:21,274 INFO: Partial:  nats what they se\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:21,307 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:21,997 INFO: OPT time: 0.690\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:21,997 INFO: Final:  that what they say\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:21,998 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  44%|████▎     | 631/1450 [13:22<18:03,  1.32s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:22,137 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:22,181 INFO: Partial:  nott without your permission\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:22,205 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:23,008 INFO: OPT time: 0.803\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:23,009 INFO: Final:  not without your permission\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:23,009 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  44%|████▎     | 632/1450 [13:23<16:25,  1.20s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:23,137 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:23,232 INFO: Partial:  nice just something about that totalling\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:23,289 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:24,229 INFO: OPT time: 0.939\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:24,229 INFO: Final:  nice just something about that tunneling\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:24,229 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  44%|████▎     | 633/1450 [13:24<15:36,  1.15s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:24,343 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:24,404 INFO: Partial:  how due yu foell about sport test\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:24,465 INFO: Augmented nbest from 100 to 158 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:25,920 INFO: OPT time: 1.455\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:25,920 INFO: Final:  how du you feel about sport test\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:25,920 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  44%|████▎     | 634/1450 [13:25<15:53,  1.17s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:26,047 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:26,117 INFO: Partial:  nott because ai heaven gott the desire\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:26,171 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:27,154 INFO: OPT time: 0.982\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:27,154 INFO: Final:  not because i heaven got the desire\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:27,155 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  44%|████▍     | 635/1450 [13:27<18:00,  1.33s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:27,349 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:27,406 INFO: Partial:  remember make decisions and stick to them\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:27,450 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:28,306 INFO: OPT time: 0.856\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:28,307 INFO: Final:  remember make decisions and stick to them\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:28,307 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  44%|████▍     | 636/1450 [13:28<17:36,  1.30s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:28,449 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:28,504 INFO: Partial:  nats just nott our think\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:28,555 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:29,359 INFO: OPT time: 0.804\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:29,359 INFO: Final:  nats just not our thing\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:29,359 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  44%|████▍     | 637/1450 [13:29<16:59,  1.25s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:29,555 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:29,577 INFO: Partial:  love it\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:29,597 INFO: Augmented nbest from 100 to 139 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:30,305 INFO: OPT time: 0.708\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:30,305 INFO: Final:  love it\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:30,306 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  44%|████▍     | 638/1450 [13:30<16:09,  1.19s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:30,452 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:30,501 INFO: Partial:  just what to tel yu this\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:30,542 INFO: Augmented nbest from 100 to 107 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:31,386 INFO: OPT time: 0.844\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:31,386 INFO: Final:  just what to tell you this\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:31,387 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  44%|████▍     | 639/1450 [13:31<15:07,  1.12s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:31,556 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:31,599 INFO: Partial:  oui should goh different whey\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:31,628 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:32,574 INFO: OPT time: 0.946\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:32,574 INFO: Final:  we should go different whey\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:32,575 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  44%|████▍     | 640/1450 [13:32<14:57,  1.11s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:32,759 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:32,816 INFO: Partial:  hope yu hurd what they said\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:32,850 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:33,706 INFO: OPT time: 0.856\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:33,706 INFO: Final:  hope you heard what they said\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:33,706 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  44%|████▍     | 641/1450 [13:34<15:15,  1.13s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:33,862 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:33,918 INFO: Partial:  are yu sure yu saw it there\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:33,973 INFO: Augmented nbest from 100 to 161 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:35,518 INFO: OPT time: 1.545\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:35,518 INFO: Final:  are you sure you saw it their\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:35,518 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  44%|████▍     | 642/1450 [13:35<15:14,  1.13s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:35,668 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:35,711 INFO: Partial:  what sort of work to yu due\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:35,762 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:36,709 INFO: OPT time: 0.947\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:36,709 INFO: Final:  what sort of work to you due\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:36,710 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  44%|████▍     | 643/1450 [13:36<17:58,  1.34s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:36,871 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:36,941 INFO: Partial:  would lyke to bye a carre next year\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:36,983 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:38,106 INFO: OPT time: 1.123\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:38,106 INFO: Final:  would like to buy a kahr next year\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:38,107 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  44%|████▍     | 644/1450 [13:38<17:21,  1.29s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:38,275 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:38,334 INFO: Partial:  anything old is nott always good\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:38,375 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:39,223 INFO: OPT time: 0.848\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:39,224 INFO: Final:  anything old is not always good\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:39,224 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  44%|████▍     | 645/1450 [13:39<17:45,  1.32s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:39,377 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:39,441 INFO: Partial:  just said no to due my work\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:39,506 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:40,614 INFO: OPT time: 1.109\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:40,614 INFO: Final:  just said no to due my work\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:40,615 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  45%|████▍     | 646/1450 [13:40<16:54,  1.26s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:40,782 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:40,836 INFO: Partial:  the end everything was nice\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:40,866 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:41,709 INFO: OPT time: 0.843\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:41,709 INFO: Final:  at the end everything was nice\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:41,710 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  45%|████▍     | 647/1450 [13:42<17:24,  1.30s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:41,882 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:41,947 INFO: Partial:  this is a hard problem to work on\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:41,999 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:43,108 INFO: OPT time: 1.109\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:43,108 INFO: Final:  this is a hard problem to work on\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:43,109 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  45%|████▍     | 648/1450 [13:43<16:33,  1.24s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:43,284 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:43,346 INFO: Partial:  was nott able to work very pharr\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:43,409 INFO: Augmented nbest from 100 to 225 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:45,419 ERROR: Error during OPT rescore: CUDA out of memory. Tried to allocate 100.00 MiB (GPU 0; 14.74 GiB total capacity; 14.04 GiB already allocated; 20.19 MiB free; 14.43 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:45,880 ERROR: Error during OPT rescore: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.74 GiB total capacity; 14.39 GiB already allocated; 20.19 MiB free; 14.43 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:45,882 INFO: OPT time: 2.472\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:45,882 INFO: Final:  was notte abel to werke vary pharr\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:45,882 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  45%|████▍     | 649/1450 [13:44<17:10,  1.29s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:45,992 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:46,050 INFO: Partial:  your name is easy to remember\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:46,086 INFO: Augmented nbest from 100 to 121 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:47,080 INFO: OPT time: 0.994\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:47,080 INFO: Final:  your name is easy to remember\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:47,081 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  45%|████▍     | 650/1450 [13:47<23:06,  1.73s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:47,193 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:47,236 INFO: Partial:  someone must tel hur that\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:47,266 INFO: Augmented nbest from 100 to 112 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:48,116 INFO: OPT time: 0.849\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:48,116 INFO: Final:  someone must tell her that\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:48,116 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  45%|████▍     | 651/1450 [13:48<20:56,  1.57s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:48,295 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:48,355 INFO: Partial:  what makes yu think that is true\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:48,404 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:49,348 INFO: OPT time: 0.943\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:49,348 INFO: Final:  what makes you think that is true\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:49,348 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  45%|████▍     | 652/1450 [13:49<18:46,  1.41s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:49,498 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:49,539 INFO: Partial:  nott talking to yu\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:49,576 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:50,282 INFO: OPT time: 0.705\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:50,282 INFO: Final:  not talking to you\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:50,282 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  45%|████▌     | 653/1450 [13:50<18:01,  1.36s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:50,401 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:50,460 INFO: Partial:  had to goh furst with them\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:50,496 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:51,436 INFO: OPT time: 0.940\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:51,436 INFO: Final:  had to go first with them\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:51,437 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  45%|████▌     | 654/1450 [13:51<16:19,  1.23s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:51,604 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:51,661 INFO: Partial:  yu should take sum brink frum work\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:51,707 INFO: Augmented nbest from 100 to 121 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:53,068 INFO: OPT time: 1.361\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:53,068 INFO: Final:  you should take some brink from work\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:53,069 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  45%|████▌     | 655/1450 [13:52<16:00,  1.21s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:53,207 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:53,260 INFO: Partial:  what parte of this is really true\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:53,311 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:54,280 INFO: OPT time: 0.969\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:54,280 INFO: Final:  what part of this is really true\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:54,281 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  45%|████▌     | 656/1450 [13:54<17:39,  1.33s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:54,408 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:54,480 INFO: Partial:  would yu lyke to join mi next wieck\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:54,549 INFO: Augmented nbest from 100 to 127 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:56,001 INFO: OPT time: 1.452\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:56,002 INFO: Final:  would you like to join mee next week\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:56,002 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  45%|████▌     | 657/1450 [13:55<17:09,  1.30s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:56,113 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:56,164 INFO: Partial:  are things over there\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:56,193 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:56,883 INFO: OPT time: 0.690\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:56,883 INFO: Final:  how are things over there\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:56,883 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  45%|████▌     | 658/1450 [13:57<18:48,  1.43s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:57,013 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:57,097 INFO: Partial:  this is what ai winded to no\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:57,176 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:58,158 INFO: OPT time: 0.982\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:58,158 INFO: Final:  this is what i wooded to know\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:58,159 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  45%|████▌     | 659/1450 [13:58<16:38,  1.26s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:58,318 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:58,372 INFO: Partial:  any new news on this\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:58,407 INFO: Augmented nbest from 100 to 130 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:59,382 INFO: OPT time: 0.975\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:59,382 INFO: Final:  any new news on this\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:59,383 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  46%|████▌     | 660/1450 [13:59<16:40,  1.27s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:59,518 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:59,556 INFO: Partial:  tel mi your decision\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 07:59:59,581 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:00,384 INFO: OPT time: 0.803\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:00,384 INFO: Final:  tell me your decision\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:00,385 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  46%|████▌     | 661/1450 [14:00<16:28,  1.25s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:00,521 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:00,573 INFO: Partial:  can kumm pih home with kids\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:00,611 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:01,558 INFO: OPT time: 0.946\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:01,558 INFO: Final:  can come pay home with kids\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:01,558 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  46%|████▌     | 662/1450 [14:01<15:28,  1.18s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:01,724 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:01,810 INFO: Partial:  this is so interesting to mi\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:01,868 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:02,711 INFO: OPT time: 0.843\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:02,711 INFO: Final:  this is so interesting to me\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:02,712 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  46%|████▌     | 663/1450 [14:03<15:26,  1.18s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:02,826 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:02,893 INFO: Partial:  love to to work of hind problems\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:02,951 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:03,923 INFO: OPT time: 0.971\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:03,923 INFO: Final:  love to to work of hard problems\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:03,923 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  46%|████▌     | 664/1450 [14:04<15:19,  1.17s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:04,129 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:04,176 INFO: Partial:  that makes it morr interesting\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:04,208 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:05,047 INFO: OPT time: 0.839\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:05,047 INFO: Final:  that makes it more interesting\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:05,048 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  46%|████▌     | 665/1450 [14:05<15:28,  1.18s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:05,229 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:05,285 INFO: Partial:  think this will kumm around\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:05,317 INFO: Augmented nbest from 100 to 115 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:06,248 INFO: OPT time: 0.930\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:06,248 INFO: Final:  think this will come around\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:06,248 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  46%|████▌     | 666/1450 [14:06<15:13,  1.16s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:06,431 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:06,554 INFO: Partial:  have never hurn of this before\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:06,592 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:07,533 INFO: OPT time: 0.941\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:07,533 INFO: Final:  have never heard of this before\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:07,534 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  46%|████▌     | 667/1450 [14:07<15:20,  1.18s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:07,735 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:07,797 INFO: Partial:  hope yu look it the whole house\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:07,858 INFO: Augmented nbest from 100 to 140 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:09,286 INFO: OPT time: 1.428\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:09,287 INFO: Final:  hope you look it the whole house\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:09,287 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  46%|████▌     | 668/1450 [14:08<15:45,  1.21s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:09,438 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:09,480 INFO: Partial:  enjoy your time away\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:09,507 INFO: Augmented nbest from 100 to 143 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:10,639 INFO: OPT time: 1.132\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:10,639 INFO: Final:  enjoy your time away\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:10,640 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  46%|████▌     | 669/1450 [14:10<17:51,  1.37s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:10,839 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:10,909 INFO: Partial:  what is the make of your carre\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:10,971 INFO: Augmented nbest from 100 to 114 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:11,980 INFO: OPT time: 1.009\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:11,980 INFO: Final:  what is the make of your car\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:11,980 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  46%|████▌     | 670/1450 [14:12<17:45,  1.37s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:12,145 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:12,185 INFO: Partial:  something is wrong here\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:12,216 INFO: Augmented nbest from 100 to 124 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:13,166 INFO: OPT time: 0.950\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:13,166 INFO: Final:  something is wrong here\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:13,167 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  46%|████▋     | 671/1450 [14:13<17:38,  1.36s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:13,346 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:13,402 INFO: Partial:  did yu get everything ai said\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:13,448 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:14,399 INFO: OPT time: 0.951\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:14,399 INFO: Final:  did you get everything i said\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:14,399 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  46%|████▋     | 672/1450 [14:14<16:56,  1.31s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:14,550 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:14,584 INFO: Partial:  what a fun place\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:14,615 INFO: Augmented nbest from 100 to 107 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:15,317 INFO: OPT time: 0.703\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:15,317 INFO: Final:  what a fun place\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:15,318 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  46%|████▋     | 673/1450 [14:15<16:38,  1.28s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:15,451 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:15,524 INFO: Partial:  sum of us will pei the money\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:15,584 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:16,537 INFO: OPT time: 0.953\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:16,537 INFO: Final:  some of us will pay the money\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:16,538 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  46%|████▋     | 674/1450 [14:16<15:11,  1.17s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:16,656 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:16,719 INFO: Partial:  that is looking very easy to mi\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:16,772 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:17,722 INFO: OPT time: 0.950\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:17,722 INFO: Final:  that is looking very easy to me\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:17,723 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  47%|████▋     | 675/1450 [14:17<15:20,  1.19s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:17,856 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:17,918 INFO: Partial:  will yu join the college next year\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:17,956 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:18,907 INFO: OPT time: 0.951\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:18,907 INFO: Final:  will you join the college next year\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:18,908 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  47%|████▋     | 676/1450 [14:19<15:19,  1.19s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:19,060 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:19,089 INFO: Partial:  are yu stil there\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:19,122 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:19,926 INFO: OPT time: 0.804\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:19,927 INFO: Final:  are you still there\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:19,927 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  47%|████▋     | 677/1450 [14:20<15:17,  1.19s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:20,062 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:20,125 INFO: Partial:  will whate for a couple of daze\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:20,179 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:21,130 INFO: OPT time: 0.951\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:21,130 INFO: Final:  will wait for a couple of days\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:21,131 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  47%|████▋     | 678/1450 [14:21<14:37,  1.14s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:21,265 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:21,308 INFO: Partial:  they kaim thru just now\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:21,334 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:22,145 INFO: OPT time: 0.810\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:22,145 INFO: Final:  they came through just now\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:22,146 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  47%|████▋     | 679/1450 [14:22<14:51,  1.16s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:22,268 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:22,304 INFO: Partial:  due whoever goh there\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:22,337 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:23,029 INFO: OPT time: 0.692\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:23,030 INFO: Final:  do whoever go there\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:23,030 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  47%|████▋     | 680/1450 [14:23<14:17,  1.11s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:23,169 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:23,209 INFO: Partial:  hope this will look good\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:23,244 INFO: Augmented nbest from 100 to 113 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:24,241 INFO: OPT time: 0.997\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:24,241 INFO: Final:  hope this will look good\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:24,242 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  47%|████▋     | 681/1450 [14:24<13:23,  1.05s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:24,371 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:24,432 INFO: Partial:  ness morr about this than yu\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:24,497 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:25,606 INFO: OPT time: 1.109\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:25,607 INFO: Final:  ness more about this than you\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:25,607 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  47%|████▋     | 682/1450 [14:25<14:01,  1.10s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:25,777 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:25,827 INFO: Partial:  no this will aull wieck out\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:25,869 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:26,820 INFO: OPT time: 0.951\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:26,820 INFO: Final:  no this will all weak out\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:26,820 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  47%|████▋     | 683/1450 [14:27<15:02,  1.18s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:26,978 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:27,023 INFO: Partial:  how many people are cumming here\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:27,061 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:27,914 INFO: OPT time: 0.852\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:27,914 INFO: Final:  how many people are coming here\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:27,915 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  47%|████▋     | 684/1450 [14:28<15:09,  1.19s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:28,080 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:28,137 INFO: Partial:  the end it was looking very good\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:28,236 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:29,212 INFO: OPT time: 0.976\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:29,212 INFO: Final:  at the end it was looking very good\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:29,213 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  47%|████▋     | 685/1450 [14:29<14:46,  1.16s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:29,383 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:29,443 INFO: Partial:  will only lett this couple in\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:29,476 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:30,336 INFO: OPT time: 0.861\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:30,337 INFO: Final:  they will only let this couple in\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:30,337 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  47%|████▋     | 686/1450 [14:30<15:17,  1.20s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:30,485 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:30,528 INFO: Partial:  whats next for yu\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:30,560 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:31,366 INFO: OPT time: 0.806\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:31,366 INFO: Final:  so whats next for you\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:31,367 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  47%|████▋     | 687/1450 [14:31<14:58,  1.18s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:31,487 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:31,534 INFO: Partial:  its a pleasure working with yu\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:31,580 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:32,701 INFO: OPT time: 1.121\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:32,701 INFO: Final:  its a pleasure working with you\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:32,701 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  47%|████▋     | 688/1450 [14:32<14:23,  1.13s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:32,890 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:32,941 INFO: Partial:  think its about the sejm\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:32,967 INFO: Augmented nbest from 100 to 110 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:33,914 INFO: OPT time: 0.947\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:33,914 INFO: Final:  think its about the same\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:33,915 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  48%|████▊     | 689/1450 [14:34<15:08,  1.19s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:34,092 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:34,140 INFO: Partial:  called mi the other dey\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:34,168 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:35,112 INFO: OPT time: 0.944\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:35,112 INFO: Final:  she called me the other day\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:35,112 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  48%|████▊     | 690/1450 [14:35<15:11,  1.20s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:35,296 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:35,350 INFO: Partial:  guess what oui are doing next year\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:35,389 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:36,507 INFO: OPT time: 1.118\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:36,507 INFO: Final:  guess what we are doing next year\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:36,508 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  48%|████▊     | 691/1450 [14:36<15:10,  1.20s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:36,700 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:36,743 INFO: Partial:  yu believe that boye\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:36,775 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:37,622 INFO: OPT time: 0.847\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:37,622 INFO: Final:  do you believe that boy\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:37,623 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  48%|████▊     | 692/1450 [14:37<15:53,  1.26s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:37,804 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:37,867 INFO: Partial:  nott want to goh there again\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:37,951 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:38,811 INFO: OPT time: 0.860\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:38,812 INFO: Final:  not want to go there again\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:38,812 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  48%|████▊     | 693/1450 [14:39<15:19,  1.22s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:39,010 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:39,066 INFO: Partial:  having children around is fun\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:39,099 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:39,945 INFO: OPT time: 0.846\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:39,945 INFO: Final:  having children around is fun\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:39,946 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  48%|████▊     | 694/1450 [14:40<15:12,  1.21s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:40,109 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:40,169 INFO: Partial:  this is sutch a great idea\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:40,214 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:41,159 INFO: OPT time: 0.944\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:41,159 INFO: Final:  this is such a great idea\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:41,160 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  48%|████▊     | 695/1450 [14:41<14:54,  1.19s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:41,312 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:41,366 INFO: Partial:  both of yu are doing so well\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:41,412 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:42,365 INFO: OPT time: 0.952\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:42,365 INFO: Final:  both of you are doing so well\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:42,365 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  48%|████▊     | 696/1450 [14:42<15:00,  1.19s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:42,516 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:42,606 INFO: Partial:  social grupe experience supposed sine\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:42,670 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:43,365 INFO: OPT time: 0.695\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:43,366 INFO: Final:  social group experience supposed sign\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:43,366 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  48%|████▊     | 697/1450 [14:43<15:01,  1.20s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:43,520 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:43,601 INFO: Partial:  katt neu capek basically kahre\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:43,706 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:44,649 INFO: OPT time: 0.943\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:44,649 INFO: Final:  cat neu topic basically care\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:44,650 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  48%|████▊     | 698/1450 [14:44<14:16,  1.14s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:44,829 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:44,914 INFO: Partial:  jury nursing depends ley whatever usual\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:44,968 INFO: Augmented nbest from 100 to 108 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:45,942 INFO: OPT time: 0.975\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:45,943 INFO: Final:  jury nursing depends lay whatever usual\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:45,943 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  48%|████▊     | 699/1450 [14:46<14:47,  1.18s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:46,127 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:46,195 INFO: Partial:  middle ours north wanted seven large\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:46,241 INFO: Augmented nbest from 100 to 150 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:47,629 INFO: OPT time: 1.388\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:47,629 INFO: Final:  middle ours north wanted seven large\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:47,629 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  48%|████▊     | 700/1450 [14:47<15:11,  1.22s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:47,827 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:47,894 INFO: Partial:  crime benefits lives ngai cumming\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:47,937 INFO: Augmented nbest from 100 to 136 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:49,091 INFO: OPT time: 1.154\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:49,091 INFO: Final:  crime benefits lives guy coming\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:49,091 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  48%|████▊     | 701/1450 [14:49<16:56,  1.36s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:49,230 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:49,330 INFO: Partial:  happened least husband comes without\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:49,368 INFO: Augmented nbest from 100 to 104 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:50,318 INFO: OPT time: 0.950\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:50,318 INFO: Final:  happened least husband comes without\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:50,319 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  48%|████▊     | 702/1450 [14:50<17:18,  1.39s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:50,433 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:50,556 INFO: Partial:  baseball budget husband vigor boyz\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:50,627 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:51,571 INFO: OPT time: 0.944\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:51,571 INFO: Final:  baseball budget husband major boys\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:51,572 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  48%|████▊     | 703/1450 [14:51<16:40,  1.34s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:51,740 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:51,814 INFO: Partial:  thru whatever super sounds cook wirt\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:51,875 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:52,818 INFO: OPT time: 0.943\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:52,818 INFO: Final:  through whatever super sounds cook what\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:52,819 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  49%|████▊     | 704/1450 [14:53<16:20,  1.31s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:52,941 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:53,034 INFO: Partial:  think anymore usual sound than recessing\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:53,092 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:53,905 INFO: OPT time: 0.812\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:53,905 INFO: Final:  think anymore usual sound than recessing\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:53,905 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  49%|████▊     | 705/1450 [14:54<16:03,  1.29s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:54,041 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:54,116 INFO: Partial:  married visual bigots noyes report experience\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:54,156 INFO: Augmented nbest from 100 to 132 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:55,335 INFO: OPT time: 1.179\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:55,335 INFO: Final:  married visual bigot noise report experience\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:55,336 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  49%|████▊     | 706/1450 [14:55<15:16,  1.23s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:55,443 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:55,488 INFO: Partial:  sit seven mine second dallas\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:55,519 INFO: Augmented nbest from 100 to 142 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:56,688 INFO: OPT time: 1.168\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:56,688 INFO: Final:  sit seven my second dallas\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:56,688 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  49%|████▉     | 707/1450 [14:56<15:59,  1.29s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:56,848 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:56,923 INFO: Partial:  look reckard topic policy girl\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:56,982 INFO: Augmented nbest from 100 to 169 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:58,465 INFO: OPT time: 1.483\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:58,465 INFO: Final:  look recurred topic policy girl\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:58,466 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  49%|████▉     | 708/1450 [14:58<16:11,  1.31s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:58,654 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:58,735 INFO: Partial:  agree casualties employees snow helps woman\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:58,787 INFO: Augmented nbest from 100 to 150 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:59,995 INFO: OPT time: 1.208\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:59,995 INFO: Final:  agree casualties employees snow helps woman\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:00:59,995 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  49%|████▉     | 709/1450 [14:59<17:54,  1.45s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:00,156 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:00,214 INFO: Partial:  says power baby course miles\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:00,274 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:01,210 INFO: OPT time: 0.935\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:01,210 INFO: Final:  these power baby course miles\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:01,211 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  49%|████▉     | 710/1450 [15:01<18:10,  1.47s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:01,363 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:01,422 INFO: Partial:  wife teems weighs living sense ngai\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:01,477 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:02,421 INFO: OPT time: 0.944\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:02,421 INFO: Final:  wife teams ways living sex guy\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:02,422 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  49%|████▉     | 711/1450 [15:02<17:11,  1.40s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:02,564 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:02,659 INFO: Partial:  evening wording years death thinking fat\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:02,718 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:03,671 INFO: OPT time: 0.953\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:03,672 INFO: Final:  evening thirty years death thinking fat\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:03,672 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  49%|████▉     | 712/1450 [15:03<16:29,  1.34s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:03,867 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:03,968 INFO: Partial:  benefits vote today future forward experience\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:04,017 INFO: Augmented nbest from 100 to 114 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:05,164 INFO: OPT time: 1.147\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:05,164 INFO: Final:  benefits vote today future forward experience\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:05,165 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  49%|████▉     | 713/1450 [15:05<16:08,  1.31s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:05,370 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:05,436 INFO: Partial:  yoos tax government teel grew\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:05,500 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:06,356 INFO: OPT time: 0.856\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:06,356 INFO: Final:  ewes tax government deal grew\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:06,357 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  49%|████▉     | 714/1450 [15:06<16:46,  1.37s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:06,475 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:06,550 INFO: Partial:  choices whose whatever mother henne regular\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:06,597 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:07,545 INFO: OPT time: 0.948\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:07,545 INFO: Final:  choices whose whatever mother end regular\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:07,546 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  49%|████▉     | 715/1450 [15:07<16:06,  1.31s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:07,675 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:07,779 INFO: Partial:  tucked lives social punishment trouble las\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:07,844 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:08,793 INFO: OPT time: 0.948\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:08,793 INFO: Final:  talked lives social punishment trouble las\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:08,794 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  49%|████▉     | 716/1450 [15:08<15:37,  1.28s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:08,980 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:09,040 INFO: Partial:  basically this is low in my books\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:09,084 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:10,070 INFO: OPT time: 0.987\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:10,071 INFO: Final:  basically this is low in my books\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:10,071 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  49%|████▉     | 717/1450 [15:10<15:29,  1.27s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:10,180 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:10,270 INFO: Partial:  as usual our turn comes when oui were about to leve\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:10,364 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:11,744 INFO: OPT time: 1.380\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:11,745 INFO: Final:  as usual our turn comes when we were about to leave\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:11,745 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  50%|████▉     | 718/1450 [15:11<15:30,  1.27s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:11,885 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:11,934 INFO: Partial:  sometimes ai enjoy funny movies\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:11,966 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:12,777 INFO: OPT time: 0.811\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:12,777 INFO: Final:  sometimes i enjoy funny movies\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:12,777 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  50%|████▉     | 719/1450 [15:13<16:57,  1.39s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:12,885 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:12,951 INFO: Partial:  dote measure yourself against this yard stick\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:12,986 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:13,965 INFO: OPT time: 0.979\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:13,966 INFO: Final:  don't measure yourself against this yard stick\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:13,966 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  50%|████▉     | 720/1450 [15:14<15:37,  1.28s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:14,088 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:14,165 INFO: Partial:  tolled yu to cel that pott of the company\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:14,225 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:15,595 INFO: OPT time: 1.369\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:15,595 INFO: Final:  told you to cel that put of the company\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:15,595 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  50%|████▉     | 721/1450 [15:15<15:15,  1.26s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:15,792 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:15,853 INFO: Partial:  theirs alot of snow under my carre\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:15,901 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:17,061 INFO: OPT time: 1.160\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:17,061 INFO: Final:  theirs alot of snow under my car\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:17,061 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  50%|████▉     | 722/1450 [15:17<16:35,  1.37s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:17,194 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:17,278 INFO: Partial:  courant whate for this version of the game\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:17,308 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:18,436 INFO: OPT time: 1.127\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:18,436 INFO: Final:  couldn't wait for this version of the game\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:18,436 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  50%|████▉     | 723/1450 [15:18<16:55,  1.40s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:18,597 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:18,644 INFO: Partial:  expected yu here won our ago\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:18,675 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:19,486 INFO: OPT time: 0.810\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:19,486 INFO: Final:  expected you here one hour ago\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:19,486 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  50%|████▉     | 724/1450 [15:19<16:49,  1.39s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:19,599 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:19,651 INFO: Partial:  can yu czech the redding on the computer\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:19,687 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:20,817 INFO: OPT time: 1.130\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:20,817 INFO: Final:  can you check the redding on the computer\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:20,818 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  50%|█████     | 725/1450 [15:20<15:34,  1.29s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:21,005 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:21,055 INFO: Partial:  our situation is nott very different\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:21,096 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:21,952 INFO: OPT time: 0.856\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:21,952 INFO: Final:  our situation is not very different\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:21,953 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  50%|█████     | 726/1450 [15:22<15:42,  1.30s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:22,106 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:22,156 INFO: Partial:  yu no how to read muzik\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:22,208 INFO: Augmented nbest from 100 to 175 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:23,904 INFO: OPT time: 1.696\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:23,904 INFO: Final:  you know how to read music\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:23,904 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  50%|█████     | 727/1450 [15:23<15:04,  1.25s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:24,011 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:24,066 INFO: Partial:  just wanted our usual food to eat\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:24,112 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:24,971 INFO: OPT time: 0.859\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:24,972 INFO: Final:  just wanted our usual food to eat\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:24,972 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  50%|█████     | 728/1450 [15:25<17:35,  1.46s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:25,113 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:25,166 INFO: Partial:  many casualties were there\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:25,194 INFO: Augmented nbest from 100 to 108 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:25,904 INFO: OPT time: 0.710\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:25,904 INFO: Final:  how many casualties were there\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:25,905 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  50%|█████     | 729/1450 [15:26<16:08,  1.34s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:26,016 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:26,098 INFO: Partial:  living with this grupe of friends felt wonderful\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:26,155 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:27,300 INFO: OPT time: 1.145\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:27,300 INFO: Final:  living with this group of friends felt wonderful\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:27,300 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  50%|█████     | 730/1450 [15:27<14:38,  1.22s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:27,419 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:27,466 INFO: Partial:  what brings yu to our home\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:27,506 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:28,359 INFO: OPT time: 0.854\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:28,360 INFO: Final:  what brings you to our home\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:28,360 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  50%|█████     | 731/1450 [15:28<15:15,  1.27s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:28,520 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:28,605 INFO: Partial:  sze sette sze especially wooden to talk to yu\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:28,691 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:29,888 INFO: OPT time: 1.197\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:29,889 INFO: Final:  sze said sze especially wooden to talk to you\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:29,889 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  50%|█████     | 732/1450 [15:29<14:27,  1.21s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:30,026 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:30,073 INFO: Partial:  bring mi the noyes report plese\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:30,117 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:31,086 INFO: OPT time: 0.969\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:31,086 INFO: Final:  bring me the noise report please\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:31,087 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  51%|█████     | 733/1450 [15:31<15:35,  1.31s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:31,226 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:31,282 INFO: Partial:  yu understand that recycle is important\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:31,305 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:32,247 INFO: OPT time: 0.942\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:32,248 INFO: Final:  do you understand that recycle is important\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:32,248 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  51%|█████     | 734/1450 [15:32<15:11,  1.27s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:32,429 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:32,473 INFO: Partial:  my computer is quite expensive\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:32,501 INFO: Augmented nbest from 100 to 123 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:33,455 INFO: OPT time: 0.954\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:33,455 INFO: Final:  my computer is quite expensive\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:33,455 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  51%|█████     | 735/1450 [15:33<14:46,  1.24s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:33,630 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:33,673 INFO: Partial:  everyone should read newspaper\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:33,699 INFO: Augmented nbest from 100 to 105 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:34,524 INFO: OPT time: 0.825\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:34,524 INFO: Final:  everyone should read newspaper\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:34,525 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  51%|█████     | 736/1450 [15:34<14:38,  1.23s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:34,634 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:34,677 INFO: Partial:  have certainly mayde friends here\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:34,707 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:35,514 INFO: OPT time: 0.807\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:35,514 INFO: Final:  have certainly made friends here\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:35,514 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  51%|█████     | 737/1450 [15:35<14:02,  1.18s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:35,637 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:35,674 INFO: Partial:  nothing to expensive plese\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:35,700 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:36,382 INFO: OPT time: 0.681\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:36,382 INFO: Final:  nothing too expensive please\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:36,382 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  51%|█████     | 738/1450 [15:36<13:20,  1.12s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:36,538 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:36,601 INFO: Partial:  many local people worked at this company\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:36,652 INFO: Augmented nbest from 100 to 164 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:38,201 INFO: OPT time: 1.549\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:38,201 INFO: Final:  many local people worked at this company\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:38,201 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  51%|█████     | 739/1450 [15:37<12:24,  1.05s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:38,343 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:38,394 INFO: Partial:  pik upp your biggest book\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:38,429 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:39,278 INFO: OPT time: 0.849\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:39,278 INFO: Final:  pick up your biggest book\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:39,279 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  51%|█████     | 740/1450 [15:39<15:08,  1.28s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:39,446 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:39,483 INFO: Partial:  what difference does this make\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:39,518 INFO: Augmented nbest from 100 to 186 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:40,937 INFO: OPT time: 1.419\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:40,937 INFO: Final:  what difference does this make\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:40,938 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  51%|█████     | 741/1450 [15:40<14:23,  1.22s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:41,048 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:41,107 INFO: Partial:  tattle be nice\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:41,147 INFO: Augmented nbest from 100 to 143 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:42,256 INFO: OPT time: 1.109\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:42,256 INFO: Final:  little be nice\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:42,256 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  51%|█████     | 742/1450 [15:42<15:56,  1.35s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:42,455 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:42,529 INFO: Partial:  pastes the furst tariff game\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:42,570 INFO: Augmented nbest from 100 to 108 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:43,495 INFO: OPT time: 0.925\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:43,495 INFO: Final:  paste the first tariff game\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:43,496 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  51%|█████     | 743/1450 [15:43<15:48,  1.34s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:43,658 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:43,699 INFO: Partial:  were yu here last summer\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:43,740 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:44,442 INFO: OPT time: 0.702\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:44,442 INFO: Final:  were you here last summer\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:44,443 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  51%|█████▏    | 744/1450 [15:44<15:25,  1.31s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:44,558 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:44,629 INFO: Partial:  that virulence\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:44,670 INFO: Augmented nbest from 100 to 112 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:45,344 INFO: OPT time: 0.673\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:45,344 INFO: Final:  that violence\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:45,344 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  51%|█████▏    | 745/1450 [15:45<14:06,  1.20s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:45,461 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:45,507 INFO: Partial:  tried to have a compass\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:45,537 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:46,478 INFO: OPT time: 0.941\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:46,478 INFO: Final:  tried to have a compass\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:46,479 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  51%|█████▏    | 746/1450 [15:46<13:02,  1.11s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:46,661 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:46,694 INFO: Partial:  and drop those off\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:46,721 INFO: Augmented nbest from 100 to 145 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:47,685 INFO: OPT time: 0.963\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:47,685 INFO: Final:  and drop those off\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:47,685 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  52%|█████▏    | 747/1450 [15:47<13:06,  1.12s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:47,864 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:47,918 INFO: Partial:  oui have a lot of people who work on the lite\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:47,993 INFO: Augmented nbest from 100 to 114 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:49,693 INFO: OPT time: 1.700\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:49,693 INFO: Final:  oui have a lot of people who work on the light\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:49,693 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  52%|█████▏    | 748/1450 [15:49<13:23,  1.14s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:49,870 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:49,904 INFO: Partial:  that really important\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:49,930 INFO: Augmented nbest from 100 to 108 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:50,630 INFO: OPT time: 0.700\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:50,630 INFO: Final:  that's really important\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:50,630 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  52%|█████▏    | 749/1450 [15:51<16:23,  1.40s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:50,771 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:50,902 INFO: Partial:  usually sze will addict to said of the minter upp\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:51,070 INFO: Augmented nbest from 100 to 118 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:52,565 INFO: OPT time: 1.495\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:52,565 INFO: Final:  usually she will addict to said of the victor up\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:52,566 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  52%|█████▏    | 750/1450 [15:52<14:44,  1.26s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:52,686 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:52,731 INFO: Partial:  it mayde a pig difference\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:52,767 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:53,561 INFO: OPT time: 0.794\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:53,561 INFO: Final:  it made a big difference\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:53,562 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  52%|█████▏    | 751/1450 [15:54<17:04,  1.47s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:53,678 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:53,818 INFO: Partial:  this origin can sette of new depression\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:53,881 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:54,855 INFO: OPT time: 0.973\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:54,855 INFO: Final:  this origin can set of new depression\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:54,856 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  52%|█████▏    | 752/1450 [15:55<15:24,  1.32s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:54,981 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:55,062 INFO: Partial:  yu really can count thaws of storz\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:55,156 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:56,276 INFO: OPT time: 1.120\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:56,276 INFO: Final:  you really can count thumbs of stores\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:56,277 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  52%|█████▏    | 753/1450 [15:56<15:16,  1.32s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:56,386 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:56,424 INFO: Partial:  our crime write has increased\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:56,453 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:57,147 INFO: OPT time: 0.694\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:57,147 INFO: Final:  our crime rate has increased\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:57,148 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  52%|█████▏    | 754/1450 [15:57<15:37,  1.35s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:57,286 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:57,390 INFO: Partial:  on top of the fidder das on casually\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:57,510 INFO: Augmented nbest from 100 to 134 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:58,950 INFO: OPT time: 1.440\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:58,950 INFO: Final:  on top of the federal tax on casually\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:58,951 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  52%|█████▏    | 755/1450 [15:58<13:56,  1.20s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:59,097 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:59,139 INFO: Partial:  its going to be hard to\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:01:59,179 INFO: Augmented nbest from 100 to 123 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:00,178 INFO: OPT time: 0.999\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:00,178 INFO: Final:  its going to be hard to\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:00,179 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  52%|█████▏    | 756/1450 [16:00<16:00,  1.38s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:00,294 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:00,371 INFO: Partial:  tress are built xtra study\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:00,455 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:01,419 INFO: OPT time: 0.964\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:01,419 INFO: Final:  tress are built extra sturdy\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:01,420 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  52%|█████▏    | 757/1450 [16:01<15:26,  1.34s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:01,603 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:01,635 INFO: Partial:  somebody would sci it\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:01,658 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:02,347 INFO: OPT time: 0.688\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:02,347 INFO: Final:  somebody would see it\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:02,348 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  52%|█████▏    | 758/1450 [16:02<15:05,  1.31s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:02,501 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:02,560 INFO: Partial:  is collisional been for yu\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:02,592 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:03,399 INFO: OPT time: 0.808\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:03,400 INFO: Final:  is collisional been for you\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:03,400 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  52%|█████▏    | 759/1450 [16:03<13:45,  1.19s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:03,604 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:03,716 INFO: Partial:  morr of the volunteer neikirk service\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:03,839 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:04,780 INFO: OPT time: 0.941\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:04,781 INFO: Final:  more of the volunteer knitter service\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:04,781 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  52%|█████▏    | 760/1450 [16:04<13:14,  1.15s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:04,914 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:04,960 INFO: Partial:  yu lyke it\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:05,013 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:05,666 INFO: OPT time: 0.653\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:05,666 INFO: Final:  you like it\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:05,667 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  52%|█████▏    | 761/1450 [16:06<14:00,  1.22s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:05,811 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:05,912 INFO: Partial:  that provided where oui work\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:05,959 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:06,919 INFO: OPT time: 0.960\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:06,919 INFO: Final:  that provided where we work\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:06,920 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  53%|█████▎    | 762/1450 [16:07<12:50,  1.12s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:07,113 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:07,196 INFO: Partial:  butt the think was that ai could due the job myself\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:07,264 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:08,470 INFO: OPT time: 1.205\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:08,470 INFO: Final:  but the think was that i could do the job myself\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:08,470 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  53%|█████▎    | 763/1450 [16:08<13:16,  1.16s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:08,617 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:08,657 INFO: Partial:  oui were sitting there wondering\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:08,687 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:09,492 INFO: OPT time: 0.805\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:09,492 INFO: Final:  we were sitting there wondering\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:09,493 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  53%|█████▎    | 764/1450 [16:09<14:36,  1.28s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:09,618 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:09,663 INFO: Partial:  them kumm a long whey\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:09,717 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:10,566 INFO: OPT time: 0.848\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:10,566 INFO: Final:  them come a long way\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:10,567 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  53%|█████▎    | 765/1450 [16:10<13:42,  1.20s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:10,723 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:10,784 INFO: Partial:  they will order everyone to goh along\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:10,828 INFO: Augmented nbest from 100 to 103 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:11,792 INFO: OPT time: 0.964\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:11,793 INFO: Final:  they will order everyone to go along\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:11,793 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  53%|█████▎    | 766/1450 [16:12<13:15,  1.16s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:11,924 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:11,982 INFO: Partial:  basically ai will just stick around\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:12,018 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:12,967 INFO: OPT time: 0.949\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:12,967 INFO: Final:  basically i will just stick around\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:12,968 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  53%|█████▎    | 767/1450 [16:13<13:27,  1.18s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:13,127 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:13,177 INFO: Partial:  this camping space is expensive\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:13,211 INFO: Augmented nbest from 100 to 172 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:14,652 INFO: OPT time: 1.441\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:14,652 INFO: Final:  this camping space is expensive\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:14,653 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  53%|█████▎    | 768/1450 [16:14<13:24,  1.18s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:14,831 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:14,898 INFO: Partial:  what was in the local newspaper today\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:14,937 INFO: Augmented nbest from 100 to 147 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:16,330 INFO: OPT time: 1.393\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:16,330 INFO: Final:  what was in the local newspaper today\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:16,331 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  53%|█████▎    | 769/1450 [16:16<15:06,  1.33s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:16,436 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:16,495 INFO: Partial:  this season will bring morr sun\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:16,544 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:17,401 INFO: OPT time: 0.857\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:17,401 INFO: Final:  this season will bring more sun\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:17,401 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  53%|█████▎    | 770/1450 [16:17<16:16,  1.44s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:17,539 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:17,593 INFO: Partial:  what are yu watching this season\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:17,624 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:18,449 INFO: OPT time: 0.825\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:18,449 INFO: Final:  what are you watching this season\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:18,450 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  53%|█████▎    | 771/1450 [16:18<15:00,  1.33s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:18,641 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:18,709 INFO: Partial:  whats the diel with everyone in this company\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:18,761 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:19,904 INFO: OPT time: 1.143\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:19,904 INFO: Final:  whats the deal with everyone in this company\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:19,904 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  53%|█████▎    | 772/1450 [16:19<14:02,  1.24s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:20,045 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:20,130 INFO: Partial:  mourning ours with sun are quite wonderful\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:20,174 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:21,133 INFO: OPT time: 0.959\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:21,133 INFO: Final:  morning hours with sun are quite wonderful\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:21,134 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  53%|█████▎    | 773/1450 [16:21<14:44,  1.31s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:21,246 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:21,305 INFO: Partial:  people used whyte clothes for this game\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:21,344 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:22,321 INFO: OPT time: 0.978\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:22,322 INFO: Final:  people used white clothes for this game\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:22,322 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  53%|█████▎    | 774/1450 [16:22<14:27,  1.28s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:22,449 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:22,508 INFO: Partial:  social situation here is getting bettor\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:22,549 INFO: Augmented nbest from 100 to 117 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:23,536 INFO: OPT time: 0.987\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:23,537 INFO: Final:  social situation here is getting better\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:23,537 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  53%|█████▎    | 775/1450 [16:23<14:06,  1.25s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:23,651 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:23,716 INFO: Partial:  that old muzik reckard is stil very good\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:23,768 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:25,142 INFO: OPT time: 1.374\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:25,143 INFO: Final:  that old music reckard is still very good\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:25,143 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  54%|█████▎    | 776/1450 [16:24<13:57,  1.24s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:25,254 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:25,312 INFO: Partial:  ten guys kaim in for cards\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:25,369 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:26,319 INFO: OPT time: 0.950\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:26,319 INFO: Final:  ten guys came in for cards\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:26,320 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  54%|█████▎    | 777/1450 [16:26<15:09,  1.35s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:26,459 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:26,533 INFO: Partial:  this policy will change the law in many states\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:26,606 INFO: Augmented nbest from 100 to 129 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:28,098 INFO: OPT time: 1.492\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:28,098 INFO: Final:  this policy will change the law in many states\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:28,099 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  54%|█████▎    | 778/1450 [16:27<14:32,  1.30s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:28,261 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:28,323 INFO: Partial:  it is a great caucasian to start rowing\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:28,394 INFO: Augmented nbest from 100 to 106 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:29,765 INFO: OPT time: 1.372\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:29,766 INFO: Final:  it is a great occasion to start rowing\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:29,766 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  54%|█████▎    | 779/1450 [16:29<16:08,  1.44s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:29,966 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:30,055 INFO: Partial:  this situation is nott necessarily special\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:30,100 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:31,074 INFO: OPT time: 0.973\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:31,074 INFO: Final:  this situation is not necessarily special\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:31,074 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  54%|█████▍    | 780/1450 [16:31<16:52,  1.51s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:31,268 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:31,321 INFO: Partial:  there is a big camping space over here\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:31,366 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:32,347 INFO: OPT time: 0.981\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:32,347 INFO: Final:  there is a big camping space over here\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:32,348 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  54%|█████▍    | 781/1450 [16:32<16:09,  1.45s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:32,472 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:32,517 INFO: Partial:  my word is final\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:32,547 INFO: Augmented nbest from 100 to 114 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:33,502 INFO: OPT time: 0.954\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:33,502 INFO: Final:  my word is final\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:33,502 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  54%|█████▍    | 782/1450 [16:33<15:33,  1.40s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:33,673 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:33,733 INFO: Partial:  public education is getting bettor\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:33,770 INFO: Augmented nbest from 100 to 148 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:34,962 INFO: OPT time: 1.192\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:34,962 INFO: Final:  public education is getting better\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:34,963 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  54%|█████▍    | 783/1450 [16:34<14:43,  1.32s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:35,076 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:35,164 INFO: Partial:  this is certainly nott with thousand dollars\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:35,212 INFO: Augmented nbest from 100 to 110 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:36,201 INFO: OPT time: 0.989\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:36,201 INFO: Final:  this is certainly not with thousand dollars\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:36,202 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  54%|█████▍    | 784/1450 [16:36<15:09,  1.37s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:36,379 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:36,434 INFO: Partial:  this looks super expensive butt its nott\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:36,538 INFO: Augmented nbest from 100 to 103 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:37,501 INFO: OPT time: 0.963\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:37,501 INFO: Final:  this looks super expensive but its not\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:37,502 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  54%|█████▍    | 785/1450 [16:37<14:42,  1.33s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:37,682 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:37,749 INFO: Partial:  think there is stil sum confusion about this\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:37,787 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:38,896 INFO: OPT time: 1.109\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:38,896 INFO: Final:  think there is still some confusion about this\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:38,897 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  54%|█████▍    | 786/1450 [16:38<14:35,  1.32s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:39,086 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:39,162 INFO: Partial:  will nott miss another game this season\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:39,207 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:40,156 INFO: OPT time: 0.948\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:40,156 INFO: Final:  will not miss another game this season\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:40,157 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  54%|█████▍    | 787/1450 [16:40<14:49,  1.34s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:40,289 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:40,326 INFO: Partial:  it felt quite unusual\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:40,348 INFO: Augmented nbest from 100 to 133 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:41,470 INFO: OPT time: 1.122\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:41,470 INFO: Final:  it felt quite unusual\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:41,471 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  54%|█████▍    | 788/1450 [16:41<14:32,  1.32s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:41,590 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:41,674 INFO: Partial:  whats between my homen this new city\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:41,729 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:42,871 INFO: OPT time: 1.141\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:42,871 INFO: Final:  whats between my home un this new city\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:42,871 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  54%|█████▍    | 789/1450 [16:42<14:30,  1.32s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:42,996 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:43,066 INFO: Partial:  recycling morr will certainly help\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:43,097 INFO: Augmented nbest from 100 to 103 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:44,050 INFO: OPT time: 0.953\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:44,050 INFO: Final:  recycling more will certainly help\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:44,051 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  54%|█████▍    | 790/1450 [16:44<14:45,  1.34s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:44,198 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:44,241 INFO: Partial:  five viles north of here\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:44,273 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:45,074 INFO: OPT time: 0.801\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:45,075 INFO: Final:  five miles north of here\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:45,075 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  55%|█████▍    | 791/1450 [16:45<14:12,  1.29s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:45,200 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:45,259 INFO: Partial:  avoid whyte clothes for this game\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:45,294 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:46,135 INFO: OPT time: 0.841\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:46,135 INFO: Final:  avoid white clothes for this game\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:46,136 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  55%|█████▍    | 792/1450 [16:46<13:17,  1.21s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:46,302 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:46,374 INFO: Partial:  which areas of the city are good for living\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:46,430 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:47,543 INFO: OPT time: 1.112\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:47,543 INFO: Final:  which areas of the city are good for living\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:47,544 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  55%|█████▍    | 793/1450 [16:47<12:46,  1.17s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:47,705 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:47,763 INFO: Partial:  he is been a good chilled so for\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:47,819 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:48,763 INFO: OPT time: 0.944\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:48,763 INFO: Final:  he is been a good child so for\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:48,763 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  55%|█████▍    | 794/1450 [16:48<13:32,  1.24s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:48,909 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:48,981 INFO: Partial:  yu have to be quite social to make friends\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:49,018 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:50,142 INFO: OPT time: 1.124\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:50,142 INFO: Final:  you have to be quite social to make friends\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:50,142 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  55%|█████▍    | 795/1450 [16:50<13:27,  1.23s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:50,313 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:50,354 INFO: Partial:  it is bettor that yu are home\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:50,422 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:51,396 INFO: OPT time: 0.974\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:51,396 INFO: Final:  it is better that you are home\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:51,396 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  55%|█████▍    | 796/1450 [16:51<13:55,  1.28s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:51,515 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:51,563 INFO: Partial:  social countries are wonderful\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:51,586 INFO: Augmented nbest from 100 to 103 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:52,273 INFO: OPT time: 0.688\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:52,273 INFO: Final:  social countries are wonderful\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:52,274 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  55%|█████▍    | 797/1450 [16:52<13:49,  1.27s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:52,416 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:52,484 INFO: Partial:  are yu working this full game season\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:52,513 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:53,479 INFO: OPT time: 0.966\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:53,479 INFO: Final:  are you working this full game season\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:53,479 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  55%|█████▌    | 798/1450 [16:53<12:31,  1.15s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:53,619 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:53,675 INFO: Partial:  plese play my favorite muzik\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:53,704 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:54,548 INFO: OPT time: 0.844\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:54,549 INFO: Final:  please play my favorite music\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:54,549 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  55%|█████▌    | 799/1450 [16:54<12:40,  1.17s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:54,719 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:54,774 INFO: Partial:  the sun should point us to the north\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:54,819 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:55,789 INFO: OPT time: 0.971\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:55,790 INFO: Final:  the sun should point us to the north\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:55,790 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  55%|█████▌    | 800/1450 [16:55<12:20,  1.14s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:55,923 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:55,969 INFO: Partial:  was saying exactly this\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:55,994 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:56,668 INFO: OPT time: 0.674\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:56,668 INFO: Final:  was saying exactly this\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:56,668 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  55%|█████▌    | 801/1450 [16:57<12:38,  1.17s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:56,825 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:56,896 INFO: Partial:  sze loved nothing morr than hur favorite book\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:56,943 INFO: Augmented nbest from 100 to 109 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:58,092 INFO: OPT time: 1.149\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:58,092 INFO: Final:  she loved nothing more than her favorite book\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:58,093 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  55%|█████▌    | 802/1450 [16:58<11:41,  1.08s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:58,230 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:58,261 INFO: Partial:  testing is important\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:58,282 INFO: Augmented nbest from 100 to 115 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:58,936 INFO: OPT time: 0.654\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:58,937 INFO: Final:  testing is important\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:58,937 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  55%|█████▌    | 803/1450 [16:59<12:46,  1.18s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:59,131 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:59,200 INFO: Partial:  they record muzik in small room\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:02:59,246 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:00,212 INFO: OPT time: 0.966\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:00,212 INFO: Final:  they record music in small room\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:00,212 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  55%|█████▌    | 804/1450 [17:00<11:39,  1.08s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:00,337 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:00,400 INFO: Partial:  they are future husband and wife\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:00,567 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:01,405 INFO: OPT time: 0.838\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:01,405 INFO: Final:  they are future husband and wife\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:01,406 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  56%|█████▌    | 805/1450 [17:01<12:15,  1.14s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:01,536 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:01,611 INFO: Partial:  luxury clothes are expensive\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:01,641 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:02,432 INFO: OPT time: 0.791\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:02,433 INFO: Final:  luxury clothes are expensive\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:02,433 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  56%|█████▌    | 806/1450 [17:02<12:24,  1.16s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:02,639 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:02,695 INFO: Partial:  tel mi about nice places nir yu\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:02,753 INFO: Augmented nbest from 100 to 145 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:04,121 INFO: OPT time: 1.368\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:04,121 INFO: Final:  tell me about nice places near you\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:04,122 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  56%|█████▌    | 807/1450 [17:03<11:58,  1.12s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:04,243 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:04,354 INFO: Partial:  this is nott necessarily true\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:04,393 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:05,193 INFO: OPT time: 0.800\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:05,193 INFO: Final:  this is not necessarily true\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:05,193 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  56%|█████▌    | 808/1450 [17:05<13:47,  1.29s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:05,346 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:05,396 INFO: Partial:  dote understand what yu are saying\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:05,433 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:06,283 INFO: OPT time: 0.850\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:06,283 INFO: Final:  doan understand what you are saying\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:06,283 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  56%|█████▌    | 809/1450 [17:06<13:04,  1.22s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:06,450 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:06,509 INFO: Partial:  paid with my usual credit card\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:06,543 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:07,383 INFO: OPT time: 0.840\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:07,383 INFO: Final:  paid with my usual credit card\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:07,384 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  56%|█████▌    | 810/1450 [17:07<12:37,  1.18s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:07,555 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:07,612 INFO: Partial:  what is your next lysne in the play\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:07,661 INFO: Augmented nbest from 100 to 105 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:08,828 INFO: OPT time: 1.166\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:08,828 INFO: Final:  what is your next line in the play\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:08,829 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  56%|█████▌    | 811/1450 [17:08<12:20,  1.16s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:08,958 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:09,006 INFO: Partial:  my father was thanking about it\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:09,036 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:09,878 INFO: OPT time: 0.842\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:09,878 INFO: Final:  my father was thinking about it\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:09,879 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  56%|█████▌    | 812/1450 [17:10<13:14,  1.24s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:10,058 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:10,109 INFO: Partial:  butt that across the room\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:10,150 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:10,952 INFO: OPT time: 0.801\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:10,952 INFO: Final:  put that across the room\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:10,953 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  56%|█████▌    | 813/1450 [17:11<12:35,  1.19s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:11,063 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:11,095 INFO: Partial:  my heart is with yu\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:11,129 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:11,975 INFO: OPT time: 0.846\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:11,976 INFO: Final:  my heart is with you\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:11,976 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  56%|█████▌    | 814/1450 [17:12<12:12,  1.15s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:12,164 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:12,206 INFO: Partial:  what exactly due yu no\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:12,242 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:12,936 INFO: OPT time: 0.693\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:12,936 INFO: Final:  what exactly due you know\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:12,936 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  56%|█████▌    | 815/1450 [17:13<11:47,  1.11s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:13,066 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:13,120 INFO: Partial:  weave already talked enough\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:13,164 INFO: Augmented nbest from 100 to 112 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:13,841 INFO: OPT time: 0.676\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:13,841 INFO: Final:  you already talked enough\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:13,842 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  56%|█████▋    | 816/1450 [17:14<11:16,  1.07s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:13,971 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:14,011 INFO: Partial:  my daughter lex hur carre\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:14,050 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:14,895 INFO: OPT time: 0.844\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:14,895 INFO: Final:  my daughter lets her car\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:14,896 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  56%|█████▋    | 817/1450 [17:15<10:45,  1.02s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:15,071 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:15,146 INFO: Partial:  that siems lyke enough work for today\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:15,195 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:16,303 INFO: OPT time: 1.107\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:16,303 INFO: Final:  that seems like enough work for today\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:16,304 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  56%|█████▋    | 818/1450 [17:16<10:50,  1.03s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:16,475 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:16,530 INFO: Partial:  half of my friends live clocks to mi\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:16,588 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:17,708 INFO: OPT time: 1.120\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:17,708 INFO: Final:  half of my friends live clocks to me\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:17,709 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  56%|█████▋    | 819/1450 [17:17<12:01,  1.14s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:17,879 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:17,952 INFO: Partial:  your social situation is nott very different\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:18,004 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:18,949 INFO: OPT time: 0.945\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:18,949 INFO: Final:  your social situation is not very different\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:18,950 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  57%|█████▋    | 820/1450 [17:19<12:49,  1.22s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:19,082 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:19,144 INFO: Partial:  must record everything that happened today\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:19,172 INFO: Augmented nbest from 100 to 104 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:20,151 INFO: OPT time: 0.979\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:20,151 INFO: Final:  we must record everything that happened today\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:20,152 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  57%|█████▋    | 821/1450 [17:20<12:52,  1.23s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:20,284 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:20,335 INFO: Partial:  les goh czech this new place out\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:20,376 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:21,336 INFO: OPT time: 0.960\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:21,336 INFO: Final:  lets go check this new place out\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:21,337 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  57%|█████▋    | 822/1450 [17:21<12:46,  1.22s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:21,487 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:21,553 INFO: Partial:  am sure ai can due this without your help\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:21,598 INFO: Augmented nbest from 100 to 108 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:22,979 INFO: OPT time: 1.381\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:22,979 INFO: Final:  am sure ai can do this without your help\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:22,980 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  57%|█████▋    | 823/1450 [17:22<12:38,  1.21s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:23,089 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:23,140 INFO: Partial:  nott put oil in the water\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:23,172 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:24,114 INFO: OPT time: 0.941\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:24,114 INFO: Final:  do not put oil in the water\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:24,114 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  57%|█████▋    | 824/1450 [17:24<13:58,  1.34s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:24,292 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:24,390 INFO: Partial:  is unusual for my parent to teem upp with them\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:24,472 INFO: Augmented nbest from 100 to 129 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:26,159 INFO: OPT time: 1.686\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:26,159 INFO: Final:  is unusual for my parents to team up with them\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:26,159 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  57%|█████▋    | 825/1450 [17:25<13:18,  1.28s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:26,296 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:26,371 INFO: Partial:  living on a budget is quite difficult\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:26,422 INFO: Augmented nbest from 100 to 118 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:27,581 INFO: OPT time: 1.159\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:27,581 INFO: Final:  living on a budget is quite difficult\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:27,581 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  57%|█████▋    | 826/1450 [17:27<15:41,  1.51s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:27,697 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:27,752 INFO: Partial:  plese take kahre of your child\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:27,787 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:28,744 INFO: OPT time: 0.956\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:28,744 INFO: Final:  please take care of your child\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:28,745 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  57%|█████▋    | 827/1450 [17:29<15:23,  1.48s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:28,899 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:28,976 INFO: Partial:  was especially looking forward to it\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:29,020 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:29,875 INFO: OPT time: 0.855\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:29,876 INFO: Final:  was especially looking forward to it\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:29,876 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  57%|█████▋    | 828/1450 [17:30<14:22,  1.39s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:30,001 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:30,092 INFO: Partial:  twelve needs to goh for the finnell game\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:30,153 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:31,315 INFO: OPT time: 1.162\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:31,315 INFO: Final:  twelve needs to go for the final game\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:31,316 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  57%|█████▋    | 829/1450 [17:31<13:33,  1.31s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:31,508 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:31,565 INFO: Partial:  had this vision once\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:31,597 INFO: Augmented nbest from 100 to 136 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:32,591 INFO: OPT time: 0.993\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:32,591 INFO: Final:  i had this vision once\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:32,591 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  57%|█████▋    | 830/1450 [17:32<13:56,  1.35s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:32,708 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:32,764 INFO: Partial:  will get my beste clothes out\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:32,801 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:33,777 INFO: OPT time: 0.976\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:33,777 INFO: Final:  will get my best clothes out\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:33,778 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  57%|█████▋    | 831/1450 [17:34<13:41,  1.33s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:33,911 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:34,015 INFO: Partial:  is this the place yu usually visit\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:34,053 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:34,915 INFO: OPT time: 0.862\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:34,915 INFO: Final:  is this the place you usually visit\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:34,915 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  57%|█████▋    | 832/1450 [17:35<13:13,  1.28s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:35,112 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:35,204 INFO: Partial:  my parents give mi quality education\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:35,259 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:36,099 INFO: OPT time: 0.840\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:36,099 INFO: Final:  my parents gave me quality education\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:36,099 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  57%|█████▋    | 833/1450 [17:36<12:45,  1.24s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:36,214 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:36,290 INFO: Partial:  sze sold mi this book and ai paid for it\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:36,362 INFO: Augmented nbest from 100 to 140 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:38,076 INFO: OPT time: 1.714\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:38,076 INFO: Final:  she sold me this book and i paid for it\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:38,077 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  58%|█████▊    | 834/1450 [17:37<12:33,  1.22s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:38,219 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:38,271 INFO: Partial:  this was a business decision\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:38,308 INFO: Augmented nbest from 100 to 127 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:39,319 INFO: OPT time: 1.012\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:39,320 INFO: Final:  this was a business decision\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:39,320 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  58%|█████▊    | 835/1450 [17:39<14:51,  1.45s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:39,518 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:39,575 INFO: Partial:  lyke driving stick its easy\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:39,612 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:40,430 INFO: OPT time: 0.818\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:40,430 INFO: Final:  like driving stick its easy\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:40,431 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  58%|█████▊    | 836/1450 [17:40<14:12,  1.39s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:40,622 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:40,674 INFO: Partial:  this program is very interesting\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:40,706 INFO: Augmented nbest from 100 to 104 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:41,411 INFO: OPT time: 0.705\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:41,411 INFO: Final:  this program is very interesting\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:41,412 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  58%|█████▊    | 837/1450 [17:41<13:19,  1.30s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:41,522 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:41,599 INFO: Partial:  are yu certain your parents will lot yu goh\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:41,698 INFO: Augmented nbest from 100 to 180 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:43,606 INFO: OPT time: 1.907\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:43,606 INFO: Final:  are you certain your parents will lot you go\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:43,606 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  58%|█████▊    | 838/1450 [17:42<12:18,  1.21s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:43,729 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:43,804 INFO: Partial:  the sit of children in this country is hoefle\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:43,859 INFO: Augmented nbest from 100 to 108 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:45,058 INFO: OPT time: 1.198\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:45,058 INFO: Final:  the sit of children in this country is awful\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:45,058 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  58%|█████▊    | 839/1450 [17:45<15:18,  1.50s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:45,230 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:45,291 INFO: Partial:  companies are looking for morr employees\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:45,334 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:46,304 INFO: OPT time: 0.970\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:46,304 INFO: Final:  companies are looking for more employees\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:46,305 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  58%|█████▊    | 840/1450 [17:46<15:07,  1.49s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:46,431 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:46,500 INFO: Partial:  would rather be with my friends\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:46,537 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:47,393 INFO: OPT time: 0.856\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:47,393 INFO: Final:  would rather be with my friends\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:47,394 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  58%|█████▊    | 841/1450 [17:47<14:22,  1.42s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:47,534 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:47,603 INFO: Partial:  oui are supposed to help our family\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:47,643 INFO: Augmented nbest from 100 to 134 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:48,837 INFO: OPT time: 1.194\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:48,837 INFO: Final:  we are supposed to help our family\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:48,838 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  58%|█████▊    | 842/1450 [17:48<13:21,  1.32s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:49,037 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:49,092 INFO: Partial:  the city has a drug problem\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:49,122 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:49,964 INFO: OPT time: 0.842\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:49,964 INFO: Final:  the city has a drug problem\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:49,965 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  58%|█████▊    | 843/1450 [17:50<13:42,  1.36s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:50,140 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:50,215 INFO: Partial:  due nott get paid enough for this\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:50,247 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:51,218 INFO: OPT time: 0.971\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:51,218 INFO: Final:  do not get paid enough for this\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:51,219 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  58%|█████▊    | 844/1450 [17:51<12:59,  1.29s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:51,342 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:51,411 INFO: Partial:  being a mother is nott always easy\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:51,451 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:52,397 INFO: OPT time: 0.946\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:52,397 INFO: Final:  being a mother is not always easy\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:52,398 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  58%|█████▊    | 845/1450 [17:52<12:52,  1.28s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:52,546 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:52,649 INFO: Partial:  he does nott siem lyke a persson who would make that choyce\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:52,766 INFO: Augmented nbest from 100 to 271 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:54,239 ERROR: Error during OPT rescore: CUDA out of memory. Tried to allocate 170.00 MiB (GPU 0; 14.74 GiB total capacity; 13.81 GiB already allocated; 20.19 MiB free; 14.43 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:54,937 ERROR: Error during OPT rescore: CUDA out of memory. Tried to allocate 36.00 MiB (GPU 0; 14.74 GiB total capacity; 14.34 GiB already allocated; 20.19 MiB free; 14.43 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:54,938 INFO: OPT time: 2.172\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:54,939 INFO: Final:  hee does knot seam lyke a person houx wood make that choice\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:54,939 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  58%|█████▊    | 846/1450 [17:53<12:33,  1.25s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:55,054 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:55,149 INFO: Partial:  dote believe that couple went hurtt so leight\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:55,227 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:56,383 INFO: OPT time: 1.155\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:56,383 INFO: Final:  dote believe that couple went hurt so late\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:56,384 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  58%|█████▊    | 847/1450 [17:56<16:26,  1.64s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:56,557 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:56,632 INFO: Partial:  this is a good season for our business\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:56,685 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:57,811 INFO: OPT time: 1.126\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:57,811 INFO: Final:  this is a good season for our business\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:57,812 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  58%|█████▊    | 848/1450 [17:57<15:50,  1.58s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:57,958 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:58,041 INFO: Partial:  are yu freeh to work on this tonight\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:58,091 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:59,242 INFO: OPT time: 1.152\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:59,243 INFO: Final:  are you free to work on this tonight\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:59,243 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  59%|█████▊    | 849/1450 [17:59<15:21,  1.53s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:59,364 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:59,440 INFO: Partial:  letz czech with each other every half our\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:03:59,501 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:04:00,626 INFO: OPT time: 1.124\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:04:00,626 INFO: Final:  lets check with each other every half hour\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:04:00,626 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  59%|█████▊    | 850/1450 [18:00<15:01,  1.50s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:04:00,768 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:04:00,847 INFO: Partial:  due yu heavin no the difference between this\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:04:00,903 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:04:02,030 INFO: OPT time: 1.127\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:04:02,030 INFO: Final:  do you heavin know the difference between this\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:04:02,031 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  59%|█████▊    | 851/1450 [18:02<14:38,  1.47s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:04:02,171 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:04:02,276 INFO: Partial:  sze leapt home fifteen minute ago\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:04:02,420 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:04:03,529 INFO: OPT time: 1.109\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:04:03,530 INFO: Final:  sze left home fifteen minute ago\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:04:03,530 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  59%|█████▉    | 852/1450 [18:03<14:25,  1.45s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:04:03,677 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:04:03,818 INFO: Partial:  downed things there rumley in the allee nuss\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:04:04,642 INFO: Augmented nbest from 100 to 106 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:04:05,831 INFO: OPT time: 1.188\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:04:05,831 INFO: Final:  down things there rumley in the allee us\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:04:05,831 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  59%|█████▉    | 853/1450 [18:04<14:33,  1.46s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:04:06,022 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:04:06,118 INFO: Partial:  this situation is nott that mine\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:04:06,204 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:04:07,011 INFO: OPT time: 0.807\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:04:07,011 INFO: Final:  this situation is not that mine\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:04:07,012 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  59%|█████▉    | 854/1450 [18:07<17:01,  1.71s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:04:07,187 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:04:07,297 INFO: Partial:  what type of pessin to yu want to cullop to be\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:04:07,426 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:04:08,876 INFO: OPT time: 1.450\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:04:08,876 INFO: Final:  what type of presson to you want to cullop to be\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:04:08,877 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  59%|█████▉    | 855/1450 [18:08<15:24,  1.55s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:04:08,990 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:04:09,062 INFO: Partial:  good ago freeh stuff for the storr\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:04:09,150 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:04:10,295 INFO: OPT time: 1.145\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:04:10,295 INFO: Final:  good ago free stuff for the store\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:04:10,295 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  59%|█████▉    | 856/1450 [18:10<16:18,  1.65s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:04:10,490 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:04:10,559 INFO: Partial:  which version of the story is dru\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:04:10,648 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:04:11,591 INFO: OPT time: 0.943\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:04:11,591 INFO: Final:  which version of the story is ro\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:04:11,592 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  59%|█████▉    | 857/1450 [18:11<15:36,  1.58s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:04:11,795 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:04:11,860 INFO: Partial:  somebody must as carda in the evening\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:04:11,913 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:04:13,051 INFO: OPT time: 1.138\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:04:13,051 INFO: Final:  somebody must have carda in the evening\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:04:13,052 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  59%|█████▉    | 858/1450 [18:13<14:44,  1.49s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:04:13,194 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:04:13,262 INFO: Partial:  big your favorite book frum school\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:04:13,320 INFO: Augmented nbest from 100 to 112 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:04:14,310 INFO: OPT time: 0.990\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:04:14,310 INFO: Final:  big your favorite book from school\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:04:14,310 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  59%|█████▉    | 859/1450 [18:14<14:36,  1.48s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:04:14,500 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:04:14,587 INFO: Partial:  many ours did yu whyte accent\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:04:14,731 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:04:15,543 INFO: OPT time: 0.812\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:04:15,543 INFO: Final:  many hours did you white accent\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:04:15,544 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  59%|█████▉    | 860/1450 [18:15<13:55,  1.42s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:04:15,709 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:04:15,796 INFO: Partial:  oui tidd this work says the paper can out\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:04:15,945 INFO: Augmented nbest from 100 to 106 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:04:17,379 INFO: OPT time: 1.434\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:04:17,379 INFO: Final:  oui started this work says the paper can out\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:04:17,380 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  59%|█████▉    | 861/1450 [18:16<13:21,  1.36s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:04:17,514 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:04:17,561 INFO: Partial:  goulden avoid going to the country\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:04:17,593 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:04:18,447 INFO: OPT time: 0.854\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:04:18,447 INFO: Final:  couldn't avoid going to the country\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:04:18,448 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  59%|█████▉    | 862/1450 [18:18<14:44,  1.50s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:04:18,608 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:04:18,662 INFO: Partial:  how many dollars to yu nied\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:04:18,718 INFO: Augmented nbest from 100 to 101 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:04:19,578 INFO: OPT time: 0.859\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:04:19,578 INFO: Final:  how many dollars to you nead\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:04:19,579 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  60%|█████▉    | 863/1450 [18:19<13:25,  1.37s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:04:19,712 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:04:19,774 INFO: Partial:  twenty for ours when bye\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:04:19,817 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:04:20,619 INFO: OPT time: 0.802\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:04:20,619 INFO: Final:  twenty four ours one by\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:04:20,620 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  60%|█████▉    | 864/1450 [18:21<12:41,  1.30s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:04:20,812 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:04:20,872 INFO: Partial:  baby food frum the storr is nott bad it aull\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:04:20,960 INFO: Augmented nbest from 100 to 115 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:04:22,445 INFO: OPT time: 1.484\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:04:22,445 INFO: Final:  baby food from the store is nott bad it all\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:04:22,446 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  60%|█████▉    | 865/1450 [18:22<11:55,  1.22s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:04:22,618 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:04:22,678 INFO: Partial:  what movies are the making this year\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:04:22,724 INFO: Augmented nbest from 100 to 141 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:04:24,086 INFO: OPT time: 1.362\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:04:24,086 INFO: Final:  what movies are the making this year\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:04:24,087 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  60%|█████▉    | 866/1450 [18:23<13:39,  1.40s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:04:24,219 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:04:24,310 INFO: Partial:  the seckinger season of that fun show cumming suen\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:04:24,379 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:04:25,754 INFO: OPT time: 1.375\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:04:25,754 INFO: Final:  is the second season of that fun show coming soon\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:04:25,755 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  60%|█████▉    | 867/1450 [18:25<14:19,  1.48s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:04:25,926 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:04:26,035 INFO: Partial:  that child is least lunch money than the other kids\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:04:26,109 INFO: Augmented nbest from 100 to 106 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:04:27,277 INFO: OPT time: 1.169\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:04:27,278 INFO: Final:  that child is least lunch money than the other kids\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:04:27,278 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  60%|█████▉    | 868/1450 [18:27<14:51,  1.53s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:04:27,432 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:04:27,504 INFO: Partial:  lett stec to somewhat easier joffe\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:04:27,568 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:04:28,514 INFO: OPT time: 0.946\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:04:28,514 INFO: Final:  let stick to somewhat easier job\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:04:28,515 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  60%|█████▉    | 869/1450 [18:28<14:48,  1.53s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:04:28,636 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:04:28,736 INFO: Partial:  daughter loved the chooses oui mayde to the house\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:04:28,821 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:04:29,980 INFO: OPT time: 1.159\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:04:29,980 INFO: Final:  daughter loved the chooses we made to the house\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:04:29,981 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  60%|██████    | 870/1450 [18:29<13:56,  1.44s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:04:30,138 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:04:30,196 INFO: Partial:  public places are for everyone to enjoy\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:04:30,238 INFO: Augmented nbest from 100 to 111 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:04:31,239 INFO: OPT time: 1.001\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:04:31,239 INFO: Final:  public places are for everyone to enjoy\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:04:31,239 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  60%|██████    | 871/1450 [18:31<13:59,  1.45s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:04:31,439 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:04:31,522 INFO: Partial:  hope yu understand the cost of doing this\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:04:31,569 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:04:32,706 INFO: OPT time: 1.137\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:04:32,706 INFO: Final:  hope you understand the cost of doing this\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:04:32,706 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  60%|██████    | 872/1450 [18:32<13:24,  1.39s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:04:32,843 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:04:32,904 INFO: Partial:  our company will pei the sports give\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:04:32,957 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:04:33,941 INFO: OPT time: 0.984\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:04:33,941 INFO: Final:  our company will pay the sports give\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:04:33,942 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  60%|██████    | 873/1450 [18:34<13:36,  1.41s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:04:34,148 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:04:34,212 INFO: Partial:  listen to the head cook in the house\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:04:34,284 INFO: Augmented nbest from 100 to 116 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:04:35,494 INFO: OPT time: 1.210\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:04:35,495 INFO: Final:  listen to the head cook in the house\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:04:35,495 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  60%|██████    | 874/1450 [18:35<13:03,  1.36s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:04:35,650 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:04:35,699 INFO: Partial:  that muzik is corps my art\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:04:35,782 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:04:36,759 INFO: OPT time: 0.977\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:04:36,759 INFO: Final:  that music is corps my heart\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:04:36,760 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  60%|██████    | 875/1450 [18:36<13:35,  1.42s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:04:36,956 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:04:37,001 INFO: Partial:  the law says this is nott whyte\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:04:37,062 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:04:37,917 INFO: OPT time: 0.855\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:04:37,917 INFO: Final:  the law says this is not what\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:04:37,918 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  60%|██████    | 876/1450 [18:38<13:07,  1.37s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:04:38,056 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:04:38,110 INFO: Partial:  yu siem to be a regular in this place\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:04:38,155 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:04:39,280 INFO: OPT time: 1.125\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:04:39,280 INFO: Final:  you seem to be a regular in this place\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:04:39,280 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  60%|██████    | 877/1450 [18:39<12:29,  1.31s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:04:39,461 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:04:39,525 INFO: Partial:  what exactly did your phen tel yu\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:04:39,648 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:04:40,512 INFO: OPT time: 0.863\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:04:40,512 INFO: Final:  what exactly did your phen tell you\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:04:40,513 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  61%|██████    | 878/1450 [18:40<12:37,  1.32s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:04:40,664 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:04:40,789 INFO: Partial:  this situation is nott unusual\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:04:40,818 INFO: Augmented nbest from 100 to 101 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:04:41,636 INFO: OPT time: 0.819\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:04:41,637 INFO: Final:  this situation is not unusual\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:04:41,637 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  61%|██████    | 879/1450 [18:41<12:20,  1.30s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:04:41,766 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:04:41,838 INFO: Partial:  whatever yu se the fanned will nott change\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:04:41,896 INFO: Augmented nbest from 100 to 102 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:04:43,052 INFO: OPT time: 1.156\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:04:43,053 INFO: Final:  whatever you say the fanned will nott change\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:04:43,053 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  61%|██████    | 880/1450 [18:43<11:49,  1.25s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:04:43,171 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:04:43,262 INFO: Partial:  these nott three debtors\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:04:43,383 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:04:44,007 INFO: OPT time: 0.623\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:04:44,007 INFO: Final:  these not three doses\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:04:44,007 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  61%|██████    | 881/1450 [18:44<12:17,  1.30s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:04:44,179 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:04:44,234 INFO: Partial:  get out on the rohde to boutte\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:04:44,324 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:04:45,301 INFO: OPT time: 0.977\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:04:45,301 INFO: Final:  get out on the road to boot\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:04:45,301 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  61%|██████    | 882/1450 [18:45<11:18,  1.19s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:04:45,480 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:04:45,517 INFO: Partial:  that how oui can started\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:04:45,567 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:04:46,421 INFO: OPT time: 0.853\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:04:46,421 INFO: Final:  that how we can started\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:04:46,422 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  61%|██████    | 883/1450 [18:46<11:33,  1.22s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:04:46,580 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:04:46,612 INFO: Partial:  where backing it\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:04:46,636 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:04:47,114 INFO: OPT time: 0.478\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:04:47,114 INFO: Final:  where backing it\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:04:47,115 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  61%|██████    | 884/1450 [18:47<11:15,  1.19s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:04:47,279 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:04:47,343 INFO: Partial:  they have the no choyce stiehl\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:04:47,403 INFO: Augmented nbest from 100 to 116 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:04:48,595 INFO: OPT time: 1.191\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:04:48,595 INFO: Final:  they have the no choice steal\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:04:48,595 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  61%|██████    | 885/1450 [18:48<09:49,  1.04s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:04:48,784 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:04:48,850 INFO: Partial:  its nice to get out in the open here\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:04:48,920 INFO: Augmented nbest from 100 to 108 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:04:50,089 INFO: OPT time: 1.169\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:04:50,090 INFO: Final:  its nice to get out in the open here\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:04:50,090 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  61%|██████    | 886/1450 [18:50<11:02,  1.17s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:04:50,288 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:04:50,352 INFO: Partial:  my brother cleaves where ai work\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:04:50,457 INFO: Augmented nbest from 100 to 112 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:04:51,807 INFO: OPT time: 1.350\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:04:51,807 INFO: Final:  my brother lives where ai work\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:04:51,807 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  61%|██████    | 887/1450 [18:51<11:55,  1.27s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:04:51,996 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:04:52,067 INFO: Partial:  they whorl looking enough to have sum oil\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:04:52,125 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:04:53,248 INFO: OPT time: 1.123\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:04:53,248 INFO: Final:  they were looking enough to have some oil\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:04:53,249 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  61%|██████    | 888/1450 [18:53<13:09,  1.40s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:04:53,398 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:04:53,429 INFO: Partial:  the fast bix\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:04:53,462 INFO: Augmented nbest from 100 to 133 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:04:54,170 INFO: OPT time: 0.707\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:04:54,170 INFO: Final:  the first book\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:04:54,170 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  61%|██████▏   | 889/1450 [18:54<13:14,  1.42s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:04:54,296 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:04:54,336 INFO: Partial:  about for thousand\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:04:54,357 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:04:55,047 INFO: OPT time: 0.690\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:04:55,047 INFO: Final:  about four thousand\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:04:55,048 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  61%|██████▏   | 890/1450 [18:55<11:49,  1.27s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:04:55,197 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:04:55,253 INFO: Partial:  yu have won lille aull to yourself\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:04:55,297 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:04:56,288 INFO: OPT time: 0.991\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:04:56,288 INFO: Final:  you have won lille all to yourself\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:04:56,289 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  61%|██████▏   | 891/1450 [18:56<10:43,  1.15s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:04:56,403 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:04:56,477 INFO: Partial:  the tree were so pinot\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:04:56,553 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:04:57,401 INFO: OPT time: 0.847\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:04:57,401 INFO: Final:  the tree were so poignant\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:04:57,402 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  62%|██████▏   | 892/1450 [18:57<10:57,  1.18s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:04:57,608 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:04:57,651 INFO: Partial:  due yu watch muzik television\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:04:57,678 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:04:58,621 INFO: OPT time: 0.944\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:04:58,622 INFO: Final:  do you watch music television\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:04:58,622 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  62%|██████▏   | 893/1450 [18:58<10:45,  1.16s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:04:58,808 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:04:58,833 INFO: Partial:  planned that muzik\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:04:58,855 INFO: Augmented nbest from 100 to 107 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:04:59,560 INFO: OPT time: 0.705\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:04:59,560 INFO: Final:  planned that music\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:04:59,561 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  62%|██████▏   | 894/1450 [19:00<10:54,  1.18s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:04:59,709 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:04:59,754 INFO: Partial:  the stepping bike\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:04:59,789 INFO: Augmented nbest from 100 to 110 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:05:00,470 INFO: OPT time: 0.681\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:05:00,470 INFO: Final:  the stepping back\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:05:00,470 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  62%|██████▏   | 895/1450 [19:01<10:13,  1.11s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:05:00,612 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:05:00,679 INFO: Partial:  both boyz have plaque herre and browne house\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:05:00,778 INFO: Augmented nbest from 100 to 138 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:05:02,485 INFO: OPT time: 1.707\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:05:02,486 INFO: Final:  both boys have plack herre and brown haus\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:05:02,486 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  62%|██████▏   | 896/1450 [19:01<09:39,  1.05s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:05:02,620 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:05:02,660 INFO: Partial:  that exactly the problem\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:05:02,685 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:05:03,297 INFO: OPT time: 0.612\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:05:03,297 INFO: Final:  that's exactly the problem\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:05:03,297 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  62%|██████▏   | 897/1450 [19:03<12:19,  1.34s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:05:03,419 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:05:03,487 INFO: Partial:  plane morr trees in open areas\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:05:03,537 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:05:04,506 INFO: OPT time: 0.968\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:05:04,506 INFO: Final:  plane more trees in open areas\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:05:04,506 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  62%|██████▏   | 898/1450 [19:04<10:51,  1.18s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:05:04,625 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:05:04,683 INFO: Partial:  is nott goto happen that whey\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:05:04,728 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:05:05,590 INFO: OPT time: 0.862\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:05:05,590 INFO: Final:  is not going to happen that way\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:05:05,591 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  62%|██████▏   | 899/1450 [19:05<10:54,  1.19s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:05:05,725 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:05:05,851 INFO: Partial:  there has also been a divison of vinny to the plaque marring\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:05:05,980 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:05:07,558 INFO: OPT time: 1.578\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:05:07,558 INFO: Final:  there has also been a divison of inventory to the plaque marring\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:05:07,559 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  62%|██████▏   | 900/1450 [19:07<10:36,  1.16s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:05:07,736 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:05:07,763 INFO: Partial:  atz would to here\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:05:07,795 INFO: Augmented nbest from 100 to 120 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:05:08,510 INFO: OPT time: 0.715\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:05:08,510 INFO: Final:  that good to hear\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:05:08,510 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  62%|██████▏   | 901/1450 [19:09<12:48,  1.40s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:05:08,634 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:05:08,683 INFO: Partial:  stil didn't want hur to goto a dey kahre\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:05:08,741 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:05:10,132 INFO: OPT time: 1.391\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:05:10,132 INFO: Final:  still didn't want her to goto a day kahre\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:05:10,133 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  62%|██████▏   | 902/1450 [19:09<11:33,  1.27s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:05:10,238 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:05:10,312 INFO: Partial:  then it gose to the next point and so on\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:05:10,420 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:05:11,624 INFO: OPT time: 1.204\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:05:11,624 INFO: Final:  then it goes to the next point and so on\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:05:11,625 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  62%|██████▏   | 903/1450 [19:11<12:30,  1.37s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:05:11,745 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:05:11,808 INFO: Partial:  ai just ended upp having to rob the klass\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:05:11,886 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:05:13,259 INFO: OPT time: 1.372\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:05:13,259 INFO: Final:  and ai just ended up having to rob the klass\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:05:13,260 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  62%|██████▏   | 904/1450 [19:13<12:49,  1.41s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:05:13,449 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:05:13,505 INFO: Partial:  that is ai will good no\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:05:13,574 INFO: Augmented nbest from 100 to 110 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:05:14,566 INFO: OPT time: 0.991\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:05:14,566 INFO: Final:  that is a will good no\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:05:14,566 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  62%|██████▏   | 905/1450 [19:14<13:24,  1.48s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:05:14,752 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:05:14,810 INFO: Partial:  that they at change there policy\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:05:14,851 INFO: Augmented nbest from 100 to 108 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:05:15,691 INFO: OPT time: 0.840\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:05:15,691 INFO: Final:  that they at change their policy\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:05:15,692 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  62%|██████▏   | 906/1450 [19:16<12:55,  1.43s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:05:15,854 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:05:15,929 INFO: Partial:  cannot tel kids nott to play outside\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:05:15,978 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:05:16,932 INFO: OPT time: 0.953\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:05:16,932 INFO: Final:  cannot tell kids not to play outside\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:05:16,933 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  63%|██████▎   | 907/1450 [19:17<12:05,  1.34s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:05:17,057 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:05:17,118 INFO: Partial:  children can join that redding grupe\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:05:17,160 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:05:18,018 INFO: OPT time: 0.858\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:05:18,018 INFO: Final:  children can join that reading group\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:05:18,019 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  63%|██████▎   | 908/1450 [19:18<11:48,  1.31s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:05:18,158 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:05:18,234 INFO: Partial:  would rather won this business with them\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:05:18,267 INFO: Augmented nbest from 100 to 102 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:05:19,251 INFO: OPT time: 0.984\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:05:19,251 INFO: Final:  would rather one this business with them\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:05:19,252 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  63%|██████▎   | 909/1450 [19:19<11:11,  1.24s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:05:19,360 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:05:19,430 INFO: Partial:  fined this carse really interesting\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:05:19,501 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:05:20,452 INFO: OPT time: 0.951\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:05:20,453 INFO: Final:  find this course really interesting\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:05:20,453 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  63%|██████▎   | 910/1450 [19:20<11:08,  1.24s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:05:20,566 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:05:20,671 INFO: Partial:  understand the difference font well\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:05:20,745 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:05:21,688 INFO: OPT time: 0.943\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:05:21,688 INFO: Final:  understand the difference fight well\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:05:21,689 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  63%|██████▎   | 911/1450 [19:21<11:01,  1.23s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:05:21,868 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:05:21,928 INFO: Partial:  oui are testing the liszt grew now\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:05:21,989 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:05:23,172 INFO: OPT time: 1.182\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:05:23,172 INFO: Final:  we are testing the list grew now\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:05:23,173 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  63%|██████▎   | 912/1450 [19:23<11:01,  1.23s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:05:23,371 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:05:23,464 INFO: Partial:  kabbani new what happened there\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:05:23,507 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:05:24,317 INFO: OPT time: 0.810\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:05:24,317 INFO: Final:  company knew what happened there\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:05:24,318 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  63%|██████▎   | 913/1450 [19:24<11:41,  1.31s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:05:24,474 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:05:24,531 INFO: Partial:  this company went public that year\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:05:24,567 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:05:25,697 INFO: OPT time: 1.130\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:05:25,697 INFO: Final:  this company went public last year\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:05:25,698 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  63%|██████▎   | 914/1450 [19:25<11:14,  1.26s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:05:25,876 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:05:25,942 INFO: Partial:  will p an important story to delle\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:05:26,015 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:05:26,997 INFO: OPT time: 0.982\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:05:26,997 INFO: Final:  will be an important story to del\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:05:26,998 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  63%|██████▎   | 915/1450 [19:27<11:32,  1.29s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:05:27,184 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:05:27,266 INFO: Partial:  am away on the furst weekend of next month\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:05:27,326 INFO: Augmented nbest from 100 to 109 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:05:28,528 INFO: OPT time: 1.201\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:05:28,528 INFO: Final:  am away on the first weekend of next month\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:05:28,528 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  63%|██████▎   | 916/1450 [19:28<11:32,  1.30s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:05:28,685 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:05:28,769 INFO: Partial:  have been to nursing school already\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:05:28,800 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:05:29,648 INFO: OPT time: 0.848\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:05:29,648 INFO: Final:  have been to nursing school already\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:05:29,649 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  63%|██████▎   | 917/1450 [19:29<12:08,  1.37s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:05:29,786 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:05:29,875 INFO: Partial:  there service is bad and the food eason good either\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:05:29,935 INFO: Augmented nbest from 100 to 128 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:05:31,403 INFO: OPT time: 1.468\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:05:31,403 INFO: Final:  their service is bad and the food eason good either\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:05:31,403 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  63%|██████▎   | 918/1450 [19:31<11:27,  1.29s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:05:31,592 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:05:31,661 INFO: Partial:  oui storr this stuff in the room at the bakke\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:05:31,747 INFO: Augmented nbest from 100 to 123 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:05:33,672 INFO: OPT time: 1.925\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:05:33,672 INFO: Final:  oui store this stuff in the room at the back\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:05:33,672 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  63%|██████▎   | 919/1450 [19:32<12:40,  1.43s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:05:33,798 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:05:33,861 INFO: Partial:  it is an employee education program\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:05:33,887 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:05:34,695 INFO: OPT time: 0.807\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:05:34,695 INFO: Final:  it is an employee education program\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:05:34,696 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  63%|██████▎   | 920/1450 [19:35<14:51,  1.68s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:05:34,899 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:05:34,974 INFO: Partial:  oui dote want any trouble in public places\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:05:35,022 INFO: Augmented nbest from 100 to 102 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:05:36,158 INFO: OPT time: 1.136\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:05:36,158 INFO: Final:  we doan want any trouble in public places\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:05:36,159 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  64%|██████▎   | 921/1450 [19:36<13:05,  1.48s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:05:36,303 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:05:36,354 INFO: Partial:  could yu get oui that whyte book plese\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:05:36,412 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:05:37,566 INFO: OPT time: 1.155\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:05:37,567 INFO: Final:  could you get oui that white book please\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:05:37,567 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  64%|██████▎   | 922/1450 [19:37<13:00,  1.48s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:05:37,706 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:05:37,774 INFO: Partial:  this movie is my favorite\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:05:37,804 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:05:38,613 INFO: OPT time: 0.809\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:05:38,613 INFO: Final:  this movie is my favorite\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:05:38,614 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  64%|██████▎   | 923/1450 [19:39<12:47,  1.46s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:05:38,808 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:05:38,869 INFO: Partial:  yang people get to here that a lot\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:05:39,073 INFO: Augmented nbest from 100 to 104 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:05:40,040 INFO: OPT time: 0.966\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:05:40,040 INFO: Final:  young people get to hear that a lot\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:05:40,040 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  64%|██████▎   | 924/1450 [19:40<11:41,  1.33s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:05:40,215 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:05:40,295 INFO: Partial:  enjoy running for miles ana cold mourning\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:05:40,345 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:05:41,326 INFO: OPT time: 0.981\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:05:41,326 INFO: Final:  enjoy running for miles on a cold morning\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:05:41,326 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  64%|██████▍   | 925/1450 [19:41<11:54,  1.36s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:05:41,517 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:05:41,565 INFO: Partial:  good work offen brings joy\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:05:41,596 INFO: Augmented nbest from 100 to 106 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:05:42,583 INFO: OPT time: 0.987\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:05:42,583 INFO: Final:  good work often brings joy\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:05:42,584 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  64%|██████▍   | 926/1450 [19:42<11:41,  1.34s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:05:42,719 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:05:42,804 INFO: Partial:  cannot sci the difference\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:05:42,839 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:05:43,641 INFO: OPT time: 0.802\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:05:43,641 INFO: Final:  cannot see the difference\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:05:43,641 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  64%|██████▍   | 927/1450 [19:44<11:27,  1.31s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:05:43,824 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:05:43,875 INFO: Partial:  that is a wonderful card thankyou\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:05:43,917 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:05:44,864 INFO: OPT time: 0.947\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:05:44,864 INFO: Final:  that is a wonderful card thank you\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:05:44,865 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  64%|██████▍   | 928/1450 [19:45<10:45,  1.24s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:05:45,025 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:05:45,077 INFO: Partial:  will spend the weekend with my parents\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:05:45,118 INFO: Augmented nbest from 100 to 112 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:05:46,119 INFO: OPT time: 1.001\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:05:46,119 INFO: Final:  will spend the weekend with my parents\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:05:46,120 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  64%|██████▍   | 929/1450 [19:46<10:42,  1.23s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:05:46,226 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:05:46,289 INFO: Partial:  yu get have of the credit for this work\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:05:46,346 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:05:47,532 INFO: OPT time: 1.186\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:05:47,532 INFO: Final:  you get halve of the credit for this work\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:05:47,533 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  64%|██████▍   | 930/1450 [19:47<10:44,  1.24s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:05:47,732 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:05:47,782 INFO: Partial:  leaves are aull dead and browne\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:05:47,847 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:05:48,792 INFO: OPT time: 0.946\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:05:48,793 INFO: Final:  leaves are all dead and brown\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:05:48,793 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  64%|██████▍   | 931/1450 [19:48<11:10,  1.29s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:05:48,936 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:05:49,081 INFO: Partial:  erly version of this article was published last month\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:05:49,146 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:05:50,302 INFO: OPT time: 1.156\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:05:50,303 INFO: Final:  an earlier version of this article was published last month\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:05:50,303 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  64%|██████▍   | 932/1450 [19:50<11:04,  1.28s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:05:50,443 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:05:50,493 INFO: Partial:  because they dote want to no\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:05:50,543 INFO: Augmented nbest from 100 to 102 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:05:51,495 INFO: OPT time: 0.952\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:05:51,495 INFO: Final:  because they daunt want to know\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:05:51,496 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  64%|██████▍   | 933/1450 [19:51<11:38,  1.35s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:05:51,640 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:05:51,720 INFO: Partial:  think everyone would agree he was a missionary\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:05:51,778 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:05:52,760 INFO: OPT time: 0.983\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:05:52,761 INFO: Final:  think everyone would agree he was a visionary\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:05:52,761 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  64%|██████▍   | 934/1450 [19:52<11:12,  1.30s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:05:52,943 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:05:53,005 INFO: Partial:  remember it took mi a long time to understate\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:05:53,055 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:05:54,217 INFO: OPT time: 1.162\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:05:54,217 INFO: Final:  remember it took me a long time to understand\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:05:54,217 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  64%|██████▍   | 935/1450 [19:54<11:05,  1.29s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:05:54,345 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:05:54,403 INFO: Partial:  guess it is to erly to no\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:05:54,462 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:05:55,449 INFO: OPT time: 0.986\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:05:55,449 INFO: Final:  guess it is too early to know\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:05:55,449 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  65%|██████▍   | 936/1450 [19:55<11:29,  1.34s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:05:55,649 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:05:55,728 INFO: Partial:  these times of incidence are nott unusual\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:05:55,785 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:05:56,729 INFO: OPT time: 0.944\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:05:56,729 INFO: Final:  these times of incidence are not unusual\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:05:56,730 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  65%|██████▍   | 937/1450 [19:56<11:11,  1.31s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:05:56,853 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:05:56,909 INFO: Partial:  yu have a couple of choices here\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:05:56,957 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:05:57,900 INFO: OPT time: 0.943\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:05:57,901 INFO: Final:  you have a couple of choices here\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:05:57,901 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  65%|██████▍   | 938/1450 [19:58<11:05,  1.30s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:05:58,056 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:05:58,113 INFO: Partial:  it is erly in the mourning\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:05:58,169 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:05:58,975 INFO: OPT time: 0.805\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:05:58,975 INFO: Final:  it is early in the morning\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:05:58,975 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  65%|██████▍   | 939/1450 [19:59<10:44,  1.26s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:05:59,159 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:05:59,243 INFO: Partial:  where in pennsylvania are yu frum\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:05:59,287 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:00,236 INFO: OPT time: 0.949\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:00,237 INFO: Final:  where in pennsylvania are you from\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:00,237 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  65%|██████▍   | 940/1450 [20:00<10:14,  1.21s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:00,360 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:00,450 INFO: Partial:  sze does have a job and a kamir\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:00,506 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:01,698 INFO: OPT time: 1.192\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:01,698 INFO: Final:  she does have a job and a career\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:01,698 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  65%|██████▍   | 941/1450 [20:01<10:22,  1.22s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:01,863 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:01,974 INFO: Partial:  that investment was milly for people in bubble holmes\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:02,050 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:03,208 INFO: OPT time: 1.158\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:03,208 INFO: Final:  that investment was mainly for people in bubble homes\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:03,209 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  65%|██████▍   | 942/1450 [20:03<10:57,  1.29s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:03,367 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:03,443 INFO: Partial:  could probably start playing baseball next summer\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:03,498 INFO: Augmented nbest from 100 to 110 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:04,487 INFO: OPT time: 0.989\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:04,487 INFO: Final:  could probably start playing baseball next summer\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:04,488 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  65%|██████▌   | 943/1450 [20:04<11:29,  1.36s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:04,668 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:04,719 INFO: Partial:  oui lyke being with our kids\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:04,755 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:05,703 INFO: OPT time: 0.948\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:05,703 INFO: Final:  we like being with our kids\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:05,704 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  65%|██████▌   | 944/1450 [20:05<11:15,  1.34s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:05,870 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:05,946 INFO: Partial:  it is unusual for us to nott have rein\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:06,036 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:07,162 INFO: OPT time: 1.126\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:07,163 INFO: Final:  it is unusual for us to not have rain\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:07,163 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  65%|██████▌   | 945/1450 [20:07<10:56,  1.30s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:07,276 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:07,313 INFO: Partial:  its ours to keep\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:07,344 INFO: Augmented nbest from 100 to 135 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:08,282 INFO: OPT time: 0.938\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:08,282 INFO: Final:  its ours to keep\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:08,282 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  65%|██████▌   | 946/1450 [20:08<11:19,  1.35s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:08,475 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:08,579 INFO: Partial:  there are nats of sutch divisions in this country\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:08,639 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:09,770 INFO: OPT time: 1.130\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:09,770 INFO: Final:  there are thoughts of such divisions in this country\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:09,771 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  65%|██████▌   | 947/1450 [20:09<10:43,  1.28s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:09,881 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:09,933 INFO: Partial:  is a production planer\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:09,965 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:10,666 INFO: OPT time: 0.700\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:10,666 INFO: Final:  he is a production planner\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:10,666 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  65%|██████▌   | 948/1450 [20:11<11:13,  1.34s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:10,780 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:10,858 INFO: Partial:  its just the idea that makes mi sowed\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:10,930 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:12,059 INFO: OPT time: 1.129\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:12,059 INFO: Final:  its just the idea that makes me sad\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:12,060 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  65%|██████▌   | 949/1450 [20:12<10:05,  1.21s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:12,185 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:12,333 INFO: Partial:  due cover a variety of topics\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:12,384 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:13,326 INFO: OPT time: 0.942\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:13,326 INFO: Final:  they do cover a variety of topics\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:13,327 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  66%|██████▌   | 950/1450 [20:13<10:31,  1.26s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:13,488 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:13,556 INFO: Partial:  join us now for a knesset\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:13,621 INFO: Augmented nbest from 100 to 102 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:14,595 INFO: OPT time: 0.974\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:14,595 INFO: Final:  join us now for a test\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:14,596 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  66%|██████▌   | 951/1450 [20:14<10:31,  1.26s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:14,790 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:14,852 INFO: Partial:  they just nied to due something with him\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:14,894 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:15,845 INFO: OPT time: 0.951\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:15,846 INFO: Final:  they just need to do something with him\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:15,846 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  66%|██████▌   | 952/1450 [20:16<10:30,  1.27s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:15,990 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:16,031 INFO: Partial:  what is the subjects matter\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:16,067 INFO: Augmented nbest from 100 to 122 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:17,010 INFO: OPT time: 0.943\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:17,010 INFO: Final:  what is the subject matter\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:17,011 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  66%|██████▌   | 953/1450 [20:17<10:26,  1.26s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:17,194 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:17,239 INFO: Partial:  what are yu doing here\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:17,277 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:18,081 INFO: OPT time: 0.804\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:18,081 INFO: Final:  what are you doing here\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:18,082 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  66%|██████▌   | 954/1450 [20:18<10:11,  1.23s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:18,197 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:18,231 INFO: Partial:  foell the sejm whey\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:18,261 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:19,075 INFO: OPT time: 0.813\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:19,075 INFO: Final:  feel the same way\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:19,075 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  66%|██████▌   | 955/1450 [20:19<09:45,  1.18s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:19,200 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:19,292 INFO: Partial:  they winded wor feldene five minutes\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:19,384 INFO: Augmented nbest from 100 to 130 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:20,723 INFO: OPT time: 1.340\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:20,724 INFO: Final:  they winded were folded five minutes\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:20,724 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  66%|██████▌   | 956/1450 [20:20<09:16,  1.13s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:20,907 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:20,966 INFO: Partial:  just get kohen it\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:21,042 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:21,727 INFO: OPT time: 0.685\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:21,728 INFO: Final:  just get current it\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:21,728 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  66%|██████▌   | 957/1450 [20:22<10:32,  1.28s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:21,912 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:21,972 INFO: Partial:  oui write to due it every other month\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:22,015 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:23,002 INFO: OPT time: 0.987\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:23,002 INFO: Final:  we write to due it every other month\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:23,003 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  66%|██████▌   | 958/1450 [20:23<09:50,  1.20s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:23,110 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:23,172 INFO: Partial:  have yu enjoy them\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:23,254 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:23,952 INFO: OPT time: 0.697\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:23,952 INFO: Final:  have you enjoy them\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:23,952 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  66%|██████▌   | 959/1450 [20:24<10:00,  1.22s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:24,111 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:24,182 INFO: Partial:  thinkin as the beste liver\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:24,252 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:25,104 INFO: OPT time: 0.852\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:25,104 INFO: Final:  thinkin is the best liver\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:25,105 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  66%|██████▌   | 960/1450 [20:25<09:18,  1.14s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:25,217 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:25,253 INFO: Partial:  am enjoying that syed of it\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:25,285 INFO: Augmented nbest from 100 to 113 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:26,240 INFO: OPT time: 0.955\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:26,240 INFO: Final:  am enjoying that side of it\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:26,240 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  66%|██████▋   | 961/1450 [20:26<09:19,  1.14s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:26,415 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:26,513 INFO: Partial:  what ai sci in the constanta\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:26,575 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:27,538 INFO: OPT time: 0.963\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:27,539 INFO: Final:  what i see in the constanta\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:27,539 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  66%|██████▋   | 962/1450 [20:27<09:17,  1.14s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:27,722 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:27,788 INFO: Partial:  what everything is on the lysne he deliverance\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:27,850 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:28,972 INFO: OPT time: 1.122\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:28,972 INFO: Final:  what everything is on the line he deliverance\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:28,972 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  66%|██████▋   | 963/1450 [20:28<09:38,  1.19s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:29,123 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:29,186 INFO: Partial:  dote have a riel streck mudgett\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:29,240 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:30,605 INFO: OPT time: 1.365\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:30,606 INFO: Final:  dote have a real streck budget\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:30,606 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  66%|██████▋   | 964/1450 [20:30<10:13,  1.26s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:30,728 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:30,817 INFO: Partial:  that basin resin yu to mutsch\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:30,897 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:31,754 INFO: OPT time: 0.857\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:31,754 INFO: Final:  that basin resin you to much\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:31,755 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  67%|██████▋   | 965/1450 [20:32<11:06,  1.37s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:31,931 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:31,979 INFO: Partial:  morr people kaul on phantoms\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:32,023 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:32,990 INFO: OPT time: 0.966\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:32,990 INFO: Final:  more people call on phantoms\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:32,990 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  67%|██████▋   | 966/1450 [20:33<10:32,  1.31s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:33,134 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:33,168 INFO: Partial:  what to lysne something\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:33,198 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:33,879 INFO: OPT time: 0.682\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:33,879 INFO: Final:  what to learn something\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:33,880 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  67%|██████▋   | 967/1450 [20:34<10:20,  1.28s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:34,035 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:34,078 INFO: Partial:  oui are pour in there level\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:34,127 INFO: Augmented nbest from 100 to 102 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:34,986 INFO: OPT time: 0.859\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:34,986 INFO: Final:  we are pour in their level\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:34,987 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  67%|██████▋   | 968/1450 [20:35<09:22,  1.17s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:35,138 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:35,196 INFO: Partial:  law just it take to get my points bhatt\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:35,293 INFO: Augmented nbest from 100 to 112 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:36,645 INFO: OPT time: 1.351\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:36,645 INFO: Final:  long just it take to get my points bank\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:36,645 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  67%|██████▋   | 969/1450 [20:36<09:12,  1.15s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:36,844 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:36,899 INFO: Partial:  dentino how lyke give been here\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:36,979 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:37,970 INFO: OPT time: 0.992\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:37,970 INFO: Final:  dint no how like give been hear\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:37,971 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  67%|██████▋   | 970/1450 [20:38<10:24,  1.30s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:38,145 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:38,259 INFO: Partial:  sum have the experiments fail without expedition\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:38,312 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:39,287 INFO: OPT time: 0.975\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:39,288 INFO: Final:  some of the experiments fail without expedition\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:39,288 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  67%|██████▋   | 971/1450 [20:39<10:26,  1.31s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:39,448 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:39,492 INFO: Partial:  probably bakke another want\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:39,522 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:40,197 INFO: OPT time: 0.675\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:40,197 INFO: Final:  probably by another white\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:40,198 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  67%|██████▋   | 972/1450 [20:40<10:26,  1.31s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:40,349 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:40,442 INFO: Partial:  think he will pilley packett\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:40,504 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:41,448 INFO: OPT time: 0.944\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:41,448 INFO: Final:  think he will piggly packett\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:41,449 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  67%|██████▋   | 973/1450 [20:41<09:28,  1.19s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:41,652 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:41,725 INFO: Partial:  dote no if yu lyke the peria in this town\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:41,800 INFO: Augmented nbest from 100 to 153 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:43,739 ERROR: Error during OPT rescore: CUDA out of memory. Tried to allocate 250.00 MiB (GPU 0; 14.74 GiB total capacity; 13.92 GiB already allocated; 56.19 MiB free; 14.40 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:44,261 ERROR: Error during OPT rescore: CUDA out of memory. Tried to allocate 52.00 MiB (GPU 0; 14.74 GiB total capacity; 14.22 GiB already allocated; 4.19 MiB free; 14.45 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:44,262 INFO: OPT time: 2.461\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:44,262 INFO: Final:  dote noh if ewe like the peria in this town\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:44,262 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  67%|██████▋   | 974/1450 [20:42<09:35,  1.21s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:44,459 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:44,500 INFO: Partial:  the decisions are nott in there house\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:44,549 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:45,529 INFO: OPT time: 0.980\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:45,529 INFO: Final:  the decisions are not in their house\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:45,530 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  67%|██████▋   | 975/1450 [20:45<13:22,  1.69s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:45,658 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:45,734 INFO: Partial:  practise keeping yu sixes about yu\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:45,796 INFO: Augmented nbest from 100 to 126 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:46,971 INFO: OPT time: 1.175\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:46,972 INFO: Final:  practice keeping you sixes about you\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:46,972 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  67%|██████▋   | 976/1450 [20:46<12:20,  1.56s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:47,163 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:47,233 INFO: Partial:  lyke mexican mote\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:47,270 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:48,240 INFO: OPT time: 0.970\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:48,240 INFO: Final:  we like mexican vote\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:48,241 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  67%|██████▋   | 977/1450 [20:48<12:02,  1.53s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:48,366 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:48,459 INFO: Partial:  gentle to everybody\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:48,489 INFO: Augmented nbest from 100 to 104 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:49,185 INFO: OPT time: 0.696\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:49,185 INFO: Final:  be gentle to everybody\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:49,186 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  67%|██████▋   | 978/1450 [20:49<11:24,  1.45s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:49,366 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:49,412 INFO: Partial:  donn that before\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:49,441 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:49,920 INFO: OPT time: 0.479\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:49,920 INFO: Final:  done that before\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:49,921 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  68%|██████▊   | 979/1450 [20:50<10:11,  1.30s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:50,068 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:50,177 INFO: Partial:  are aloud to lett the children show there carrot\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:50,247 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:51,375 INFO: OPT time: 1.128\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:51,375 INFO: Final:  you are allowed to let the children show there carrot\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:51,376 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  68%|██████▊   | 980/1450 [20:51<08:50,  1.13s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:51,572 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:51,635 INFO: Partial:  wellcome the decision of the cart\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:51,675 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:52,537 INFO: OPT time: 0.861\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:52,537 INFO: Final:  welcome the decision of the court\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:52,537 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  68%|██████▊   | 981/1450 [20:52<09:35,  1.23s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:52,672 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:52,743 INFO: Partial:  just sit downe on the take and enjoy yourself\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:52,795 INFO: Augmented nbest from 100 to 112 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:53,980 INFO: OPT time: 1.185\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:53,980 INFO: Final:  just sit down on the take and enjoy yourself\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:53,981 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  68%|██████▊   | 982/1450 [20:53<09:25,  1.21s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:54,177 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:54,238 INFO: Partial:  botta cuppy of hur new book\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:54,291 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:55,236 INFO: OPT time: 0.945\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:55,236 INFO: Final:  bought a copy of her new book\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:55,237 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  68%|██████▊   | 983/1450 [20:55<09:56,  1.28s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:55,381 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:55,445 INFO: Partial:  yu kant stupp people frum doing what they want\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:55,494 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:56,879 INFO: OPT time: 1.384\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:56,879 INFO: Final:  you cant stupp people from doing what they want\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:56,879 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  68%|██████▊   | 984/1450 [20:56<09:52,  1.27s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:57,084 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:57,163 INFO: Partial:  moved to a bigger city last year\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:57,221 INFO: Augmented nbest from 100 to 114 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:58,417 INFO: OPT time: 1.195\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:58,417 INFO: Final:  moved to a bigger city last year\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:58,418 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  68%|██████▊   | 985/1450 [20:58<10:43,  1.38s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:58,587 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:58,634 INFO: Partial:  they have to stay inside today\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:58,666 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:59,603 INFO: OPT time: 0.937\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:59,603 INFO: Final:  they have to stay inside today\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:59,603 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  68%|██████▊   | 986/1450 [20:59<11:03,  1.43s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:59,787 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:59,880 INFO: Partial:  is the prison restricted to sighted taps of criminals\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:06:59,942 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:07:00,925 INFO: OPT time: 0.983\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:07:00,925 INFO: Final:  is the prison restricted to certain types of criminals\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:07:00,926 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  68%|██████▊   | 987/1450 [21:01<10:27,  1.36s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:07:01,092 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:07:01,153 INFO: Partial:  they dote make pragmatic decisions\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:07:01,200 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:07:02,008 INFO: OPT time: 0.808\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:07:02,008 INFO: Final:  they don't make pragmatic decisions\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:07:02,009 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  68%|██████▊   | 988/1450 [21:02<10:21,  1.35s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:07:02,194 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:07:02,327 INFO: Partial:  visited an exciting pett shop out in california\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:07:02,392 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:07:03,765 INFO: OPT time: 1.373\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:07:03,765 INFO: Final:  visited an exotic pet shop out in california\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:07:03,766 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  68%|██████▊   | 989/1450 [21:03<09:44,  1.27s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:07:03,899 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:07:03,939 INFO: Partial:  that was a good weekend\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:07:03,979 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:07:04,914 INFO: OPT time: 0.935\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:07:04,915 INFO: Final:  that was a good weekend\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:07:04,915 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  68%|██████▊   | 990/1450 [21:05<10:50,  1.41s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:07:05,101 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:07:05,135 INFO: Partial:  maybe butt probably nott\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:07:05,162 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:07:05,969 INFO: OPT time: 0.806\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:07:05,969 INFO: Final:  maybe but probably not\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:07:05,969 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  68%|██████▊   | 991/1450 [21:06<10:12,  1.33s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:07:06,103 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:07:06,194 INFO: Partial:  the committee will decide on where the money is beste spent\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:07:06,268 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:07:07,745 INFO: OPT time: 1.476\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:07:07,745 INFO: Final:  the committee will decide on where the money is best spent\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:07:07,745 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  68%|██████▊   | 992/1450 [21:07<09:32,  1.25s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:07:07,910 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:07:07,969 INFO: Partial:  also lyke jazz muzik\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:07:08,017 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:07:08,831 INFO: OPT time: 0.814\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:07:08,831 INFO: Final:  also like jazz music\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:07:08,832 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  68%|██████▊   | 993/1450 [21:09<10:43,  1.41s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:07:09,016 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:07:09,085 INFO: Partial:  both moved whey out into the country\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:07:09,117 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:07:10,066 INFO: OPT time: 0.949\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:07:10,066 INFO: Final:  they both moved way out into the country\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:07:10,067 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  69%|██████▊   | 994/1450 [21:10<09:58,  1.31s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:07:10,216 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:07:10,263 INFO: Partial:  its whyte a bit different now\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:07:10,302 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:07:11,244 INFO: OPT time: 0.942\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:07:11,244 INFO: Final:  its quite a bit different now\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:07:11,245 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  69%|██████▊   | 995/1450 [21:11<09:46,  1.29s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:07:11,421 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:07:11,537 INFO: Partial:  my heralding parte is parte of my home decor\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:07:11,619 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:07:12,994 INFO: OPT time: 1.374\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:07:12,994 INFO: Final:  my heralding part is part of my home decor\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:07:12,995 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  69%|██████▊   | 996/1450 [21:12<09:29,  1.26s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:07:13,126 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:07:13,168 INFO: Partial:  have yu ever hurd of it\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:07:13,204 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:07:14,150 INFO: OPT time: 0.947\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:07:14,151 INFO: Final:  have you ever heard of it\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:07:14,151 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  69%|██████▉   | 997/1450 [21:14<10:35,  1.40s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:07:14,327 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:07:14,377 INFO: Partial:  think that would be morr phair\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:07:14,422 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:07:15,366 INFO: OPT time: 0.943\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:07:15,366 INFO: Final:  think that would be more fair\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:07:15,366 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  69%|██████▉   | 998/1450 [21:15<10:00,  1.33s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:07:15,529 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:07:15,657 INFO: Partial:  oui bought second and vinocur for our living room\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:07:15,749 INFO: Augmented nbest from 100 to 127 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:07:17,456 ERROR: Error during OPT rescore: CUDA out of memory. Tried to allocate 232.00 MiB (GPU 0; 14.74 GiB total capacity; 13.81 GiB already allocated; 116.19 MiB free; 14.34 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:07:19,607 INFO: OPT time: 3.857\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:07:19,607 INFO: Final:  we bought second and vinocur for our living room\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:07:19,607 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  69%|██████▉   | 999/1450 [21:16<09:44,  1.30s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:07:19,743 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:07:19,825 INFO: Partial:  dote no why ai never renison my carre\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:07:19,883 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:07:21,272 INFO: OPT time: 1.388\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:07:21,272 INFO: Final:  dote know why ai never resisted my carre\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:07:21,273 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  69%|██████▉   | 1000/1450 [21:21<16:20,  2.18s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:07:21,445 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:07:21,528 INFO: Partial:  and now nave gone and dunne a orabelle thing\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:07:21,608 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:07:23,060 INFO: OPT time: 1.452\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:07:23,060 INFO: Final:  and now nave gone and done a orabelle thing\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:07:23,061 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  69%|██████▉   | 1001/1450 [21:22<15:09,  2.03s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:07:23,250 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:07:23,349 INFO: Partial:  dote think ai caned any went last year\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:07:23,475 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:07:24,639 INFO: OPT time: 1.163\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:07:24,639 INFO: Final:  dote think i caned any went last year\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:07:24,639 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  69%|██████▉   | 1002/1450 [21:24<14:35,  1.95s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:07:24,756 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:07:24,779 INFO: Partial:  am sorry\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:07:24,801 INFO: Augmented nbest from 100 to 116 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:07:25,404 INFO: OPT time: 0.603\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:07:25,404 INFO: Final:  am sorry\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:07:25,405 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  69%|██████▉   | 1003/1450 [21:26<13:43,  1.84s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:07:25,554 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:07:25,600 INFO: Partial:  completed the training costs\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:07:25,635 INFO: Augmented nbest from 100 to 106 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:07:26,459 INFO: OPT time: 0.824\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:07:26,460 INFO: Final:  completed the training course\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:07:26,460 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  69%|██████▉   | 1004/1450 [21:26<11:17,  1.52s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:07:26,659 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:07:26,732 INFO: Partial:  he as aull the wake pace the next\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:07:26,822 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:07:27,799 INFO: OPT time: 0.977\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:07:27,800 INFO: Final:  he as all the work pace the next\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:07:27,800 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  69%|██████▉   | 1005/1450 [21:27<10:13,  1.38s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:07:27,965 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:07:28,078 INFO: Partial:  biebel sejm to annoy it the that is ged thing\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:07:28,202 INFO: Augmented nbest from 100 to 112 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:07:29,654 INFO: OPT time: 1.452\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:07:29,654 INFO: Final:  biebel same to enjoy it the that is good thing\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:07:29,655 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  69%|██████▉   | 1006/1450 [21:29<10:07,  1.37s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:07:29,772 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:07:29,838 INFO: Partial:  weave bagge talking lyttle bit tao\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:07:29,935 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:07:30,910 INFO: OPT time: 0.975\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:07:30,910 INFO: Final:  weave bag talking little bit to\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:07:30,911 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  69%|██████▉   | 1007/1450 [21:31<11:10,  1.51s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:07:31,075 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:07:31,130 INFO: Partial:  its so pharr da the read nott make it\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:07:31,210 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:07:32,400 INFO: OPT time: 1.189\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:07:32,400 INFO: Final:  its so far da the read not make it\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:07:32,401 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  70%|██████▉   | 1008/1450 [21:32<10:34,  1.44s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:07:32,576 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:07:32,653 INFO: Partial:  caught get kal goody jim\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:07:32,966 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:07:33,905 INFO: OPT time: 0.939\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:07:33,905 INFO: Final:  got get kal good very gym\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:07:33,906 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  70%|██████▉   | 1009/1450 [21:33<10:40,  1.45s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:07:34,091 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:07:34,148 INFO: Partial:  is the beste karoline re\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:07:34,270 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:07:35,118 INFO: OPT time: 0.847\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:07:35,118 INFO: Final:  is the best caroline re\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:07:35,118 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  70%|██████▉   | 1010/1450 [21:35<10:46,  1.47s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:07:35,288 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:07:35,379 INFO: Partial:  when was caul television invited\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:07:35,453 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:07:36,298 INFO: OPT time: 0.845\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:07:36,298 INFO: Final:  when was lol television invited\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:07:36,299 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  70%|██████▉   | 1011/1450 [21:36<10:10,  1.39s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:07:36,489 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:07:36,579 INFO: Partial:  talking about natural belittle cmx\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:07:36,652 INFO: Augmented nbest from 100 to 112 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:07:37,775 INFO: OPT time: 1.123\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:07:37,775 INFO: Final:  talking about natural belittle comics\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:07:37,775 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  70%|██████▉   | 1012/1450 [21:37<09:41,  1.33s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:07:37,889 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:07:37,945 INFO: Partial:  wakes mi use rutt\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:07:38,045 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:07:38,858 INFO: OPT time: 0.813\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:07:38,858 INFO: Final:  the wakes me use rut\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:07:38,859 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  70%|██████▉   | 1013/1450 [21:39<09:59,  1.37s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:07:38,996 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:07:39,140 INFO: Partial:  what thru three clippers is mutsch\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:07:39,271 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:07:40,211 INFO: OPT time: 0.939\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:07:40,211 INFO: Final:  what through three clippers is much\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:07:40,211 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  70%|██████▉   | 1014/1450 [21:40<09:20,  1.29s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:07:40,404 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:07:40,538 INFO: Partial:  sum of them or fearful to yu grady brokers\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:07:40,749 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:07:41,867 INFO: OPT time: 1.118\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:07:41,868 INFO: Final:  some of them are fearful to u grady brokers\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:07:41,868 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  70%|███████   | 1015/1450 [21:41<09:28,  1.31s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:07:42,007 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:07:42,071 INFO: Partial:  there ruh never of good movies thy that\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:07:42,133 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:07:43,106 INFO: OPT time: 0.973\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:07:43,106 INFO: Final:  there are a never of good movies thy that\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:07:43,107 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  70%|███████   | 1016/1450 [21:43<10:12,  1.41s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:07:43,304 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:07:43,378 INFO: Partial:  should just allbee just nite now\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:07:43,538 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:07:44,478 INFO: OPT time: 0.939\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:07:44,478 INFO: Final:  should just albie just right now\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:07:44,478 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  70%|███████   | 1017/1450 [21:44<09:48,  1.36s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:07:44,619 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:07:44,690 INFO: Partial:  butt ul ten or thum\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:07:44,940 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:07:45,779 INFO: OPT time: 0.839\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:07:45,779 INFO: Final:  but ul ten or lum\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:07:45,779 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  70%|███████   | 1018/1450 [21:45<09:48,  1.36s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:07:45,924 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:07:45,943 INFO: Partial:  what is this\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:07:45,963 INFO: Augmented nbest from 100 to 134 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:07:46,773 INFO: OPT time: 0.810\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:07:46,773 INFO: Final:  what is this\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:07:46,774 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  70%|███████   | 1019/1450 [21:47<09:39,  1.34s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:07:46,909 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:07:47,035 INFO: Partial:  will actually they my indus betz\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:07:47,214 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:07:48,157 INFO: OPT time: 0.943\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:07:48,157 INFO: Final:  well actually the my indus bets\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:07:48,158 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  70%|███████   | 1020/1450 [21:48<08:53,  1.24s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:07:48,322 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:07:48,425 INFO: Partial:  is waving to involving kloos\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:07:48,593 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:07:49,433 INFO: OPT time: 0.840\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:07:49,433 INFO: Final:  it is waving to involving clues\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:07:49,434 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  70%|███████   | 1021/1450 [21:49<09:10,  1.28s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:07:49,625 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:07:49,662 INFO: Partial:  its to bakke that happen\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:07:49,696 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:07:50,506 INFO: OPT time: 0.811\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:07:50,507 INFO: Final:  its to back that happen\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:07:50,507 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  70%|███████   | 1022/1450 [21:50<09:08,  1.28s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:07:50,620 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:07:50,735 INFO: Partial:  bick kut of in driving twice retter\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:07:50,996 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:07:52,110 INFO: OPT time: 1.114\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:07:52,110 INFO: Final:  bic kut of in traffic twice rater\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:07:52,111 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  71%|███████   | 1023/1450 [21:51<08:40,  1.22s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:07:52,243 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:07:52,328 INFO: Partial:  nether sensed outten jure\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:07:53,027 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:07:53,868 INFO: OPT time: 0.841\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:07:53,868 INFO: Final:  leather sensed outen your\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:07:53,869 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  71%|███████   | 1024/1450 [21:53<09:28,  1.33s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:07:54,051 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:07:54,116 INFO: Partial:  oui where works in wynter\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:07:54,199 INFO: Augmented nbest from 100 to 102 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:07:55,168 INFO: OPT time: 0.969\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:07:55,168 INFO: Final:  we wear works in winter\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:07:55,169 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  71%|███████   | 1025/1450 [21:55<10:21,  1.46s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:07:55,336 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:07:55,452 INFO: Partial:  wake an the allied chryseis eberly here\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:07:55,548 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:07:56,746 INFO: OPT time: 1.198\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:07:56,746 INFO: Final:  work at the allied chryseis eberly here\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:07:56,747 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  71%|███████   | 1026/1450 [21:56<09:59,  1.41s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:07:56,942 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:07:57,000 INFO: Partial:  had what katt for indy years\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:07:57,058 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:07:58,000 INFO: OPT time: 0.941\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:07:58,000 INFO: Final:  had what cat for indie years\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:07:58,000 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  71%|███████   | 1027/1450 [21:58<10:18,  1.46s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:07:58,141 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:07:58,279 INFO: Partial:  justin kutscher busick army favorites\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:07:58,388 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:07:59,531 INFO: OPT time: 1.143\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:07:59,531 INFO: Final:  just and culture mythic army favorites\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:07:59,532 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  71%|███████   | 1028/1450 [21:59<09:50,  1.40s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:07:59,648 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:07:59,733 INFO: Partial:  sze was living in orelon\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:07:59,796 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:08:00,738 INFO: OPT time: 0.942\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:08:00,738 INFO: Final:  she was living in oregon\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:08:00,739 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  71%|███████   | 1029/1450 [22:00<10:05,  1.44s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:08:00,848 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:08:00,915 INFO: Partial:  it was a decision that would pei off\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:08:00,958 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:08:01,937 INFO: OPT time: 0.979\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:08:01,938 INFO: Final:  it was a decision that would pay off\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:08:01,938 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  71%|███████   | 1030/1450 [22:02<09:35,  1.37s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:08:02,050 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:08:02,091 INFO: Partial:  it is hard to remember\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:08:02,116 INFO: Augmented nbest from 100 to 108 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:08:02,825 INFO: OPT time: 0.709\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:08:02,825 INFO: Final:  it is hard to remember\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:08:02,826 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  71%|███████   | 1031/1450 [22:03<09:12,  1.32s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:08:02,951 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:08:02,995 INFO: Partial:  foell so silly\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:08:03,028 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:08:03,682 INFO: OPT time: 0.653\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:08:03,682 INFO: Final:  feel so silly\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:08:03,682 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  71%|███████   | 1032/1450 [22:04<08:17,  1.19s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:08:03,855 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:08:03,954 INFO: Partial:  czech the somewhere version bye typing this command\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:08:03,999 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:08:04,949 INFO: OPT time: 0.950\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:08:04,949 INFO: Final:  check the software version by typing this command\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:08:04,950 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  71%|███████   | 1033/1450 [22:05<07:34,  1.09s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:08:05,058 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:08:05,104 INFO: Partial:  live in a really small apartment\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:08:05,140 INFO: Augmented nbest from 100 to 117 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:08:06,264 INFO: OPT time: 1.123\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:08:06,264 INFO: Final:  live in a really small apartment\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:08:06,264 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  71%|███████▏  | 1034/1450 [22:06<07:55,  1.14s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:08:06,460 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:08:06,540 INFO: Partial:  maybe yu live to for away frum your family\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:08:06,585 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:08:07,787 INFO: OPT time: 1.201\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:08:07,787 INFO: Final:  maybe you live to for away from your family\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:08:07,787 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  71%|███████▏  | 1035/1450 [22:07<08:15,  1.19s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:08:07,962 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:08:08,046 INFO: Partial:  think it happened about ten or fifteen years ago\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:08:08,102 INFO: Augmented nbest from 100 to 104 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:08:09,276 INFO: OPT time: 1.174\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:08:09,276 INFO: Final:  think it happened about ten or fifteen years ago\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:08:09,277 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  71%|███████▏  | 1036/1450 [22:09<08:55,  1.29s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:08:09,466 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:08:09,531 INFO: Partial:  hope yu enjoyed redding this blog pursed\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:08:09,581 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:08:10,715 INFO: OPT time: 1.134\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:08:10,715 INFO: Final:  hope you enjoyed redding this blog post\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:08:10,715 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  72%|███████▏  | 1037/1450 [22:10<09:18,  1.35s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:08:10,869 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:08:10,942 INFO: Partial:  oui goh on vacation at different places every year\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:08:10,975 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:08:12,109 INFO: OPT time: 1.134\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:08:12,109 INFO: Final:  we go on vacation at different places every year\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:08:12,110 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  72%|███████▏  | 1038/1450 [22:12<09:27,  1.38s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:08:12,273 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:08:12,352 INFO: Partial:  akhtar that they will be destroyed\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:08:12,411 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:08:13,267 INFO: OPT time: 0.856\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:08:13,267 INFO: Final:  after that they will be destroyed\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:08:13,267 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  72%|███████▏  | 1039/1450 [22:13<09:28,  1.38s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:08:13,379 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:08:13,409 INFO: Partial:  lyke classical muzik\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:08:13,432 INFO: Augmented nbest from 100 to 117 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:08:14,250 INFO: OPT time: 0.817\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:08:14,250 INFO: Final:  i like classical music\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:08:14,250 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  72%|███████▏  | 1040/1450 [22:14<08:59,  1.32s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:08:14,377 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:08:14,429 INFO: Partial:  he is a therapists my trade\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:08:14,465 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:08:15,316 INFO: OPT time: 0.851\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:08:15,316 INFO: Final:  he is a therapist by trade\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:08:15,317 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  72%|███████▏  | 1041/1450 [22:15<08:17,  1.22s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:08:15,478 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:08:15,531 INFO: Partial:  lyke when ai lived in washington\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:08:15,571 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:08:16,558 INFO: OPT time: 0.987\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:08:16,558 INFO: Final:  like when i lived in washington\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:08:16,558 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  72%|███████▏  | 1042/1450 [22:16<07:57,  1.17s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:08:16,683 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:08:16,757 INFO: Partial:  the players are pretty unfocused at this point\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:08:16,811 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:08:17,801 INFO: OPT time: 0.989\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:08:17,801 INFO: Final:  the players are pretty unfocused at this point\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:08:17,802 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  72%|███████▏  | 1043/1450 [22:18<08:05,  1.19s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:08:17,985 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:08:18,047 INFO: Partial:  always get those spam phone calls\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:08:18,089 INFO: Augmented nbest from 100 to 114 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:08:19,097 INFO: OPT time: 1.008\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:08:19,097 INFO: Final:  always get those spam phone calls\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:08:19,097 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  72%|███████▏  | 1044/1450 [22:19<08:10,  1.21s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:08:19,288 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:08:19,341 INFO: Partial:  that was before ai moved out here\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:08:19,386 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:08:20,348 INFO: OPT time: 0.961\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:08:20,348 INFO: Final:  that was before i moved out here\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:08:20,349 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  72%|███████▏  | 1045/1450 [22:20<08:19,  1.23s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:08:20,491 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:08:20,555 INFO: Partial:  forget where sze gott it\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:08:20,589 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:08:21,561 INFO: OPT time: 0.972\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:08:21,562 INFO: Final:  forget where she got it\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:08:21,562 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  72%|███████▏  | 1046/1450 [22:21<08:20,  1.24s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:08:21,695 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:08:21,747 INFO: Partial:  they were elected to the committee\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:08:21,775 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:08:22,626 INFO: OPT time: 0.852\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:08:22,627 INFO: Final:  they were elected to the committee\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:08:22,627 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  72%|███████▏  | 1047/1450 [22:23<08:16,  1.23s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:08:22,796 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:08:22,893 INFO: Partial:  also remember and illustrated version of this story\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:08:22,949 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:08:23,937 INFO: OPT time: 0.989\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:08:23,938 INFO: Final:  also remember and illustrated version of this story\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:08:23,938 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  72%|███████▏  | 1048/1450 [22:24<07:54,  1.18s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:08:24,100 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:08:24,154 INFO: Partial:  my husband didn't lyke that\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:08:24,187 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:08:24,997 INFO: OPT time: 0.810\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:08:24,997 INFO: Final:  my husband didn't like that\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:08:24,998 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  72%|███████▏  | 1049/1450 [22:25<08:09,  1.22s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:08:25,104 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:08:25,182 INFO: Partial:  both teems walked away with just won point each\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:08:25,236 INFO: Augmented nbest from 100 to 104 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:08:26,397 INFO: OPT time: 1.161\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:08:26,397 INFO: Final:  both teams walked away with just one point each\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:08:26,397 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  72%|███████▏  | 1050/1450 [22:26<07:48,  1.17s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:08:26,506 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:08:26,583 INFO: Partial:  the to meyn stars of the show gott married\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:08:26,648 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:08:27,849 INFO: OPT time: 1.201\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:08:27,849 INFO: Final:  the to main stars of the show got married\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:08:27,850 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  72%|███████▏  | 1051/1450 [22:27<08:14,  1.24s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:08:28,011 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:08:28,065 INFO: Partial:  it was on the news this mourning\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:08:28,099 INFO: Augmented nbest from 100 to 112 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:08:29,061 INFO: OPT time: 0.962\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:08:29,061 INFO: Final:  it was on the news this morning\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:08:29,061 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  73%|███████▎  | 1052/1450 [22:29<08:38,  1.30s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:08:29,214 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:08:29,281 INFO: Partial:  has he ever been your favorite player\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:08:29,328 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:08:30,281 INFO: OPT time: 0.952\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:08:30,281 INFO: Final:  has he ever been your favorite player\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:08:30,281 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  73%|███████▎  | 1053/1450 [22:30<08:26,  1.28s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:08:30,417 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:08:30,564 INFO: Partial:  public implantation around here is bitty good\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:08:30,631 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:08:31,620 INFO: OPT time: 0.988\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:08:31,620 INFO: Final:  public implantation around here is petty good\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:08:31,621 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  73%|███████▎  | 1054/1450 [22:31<08:18,  1.26s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:08:31,824 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:08:31,939 INFO: Partial:  peasant siem lyke they are terry must with it\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:08:32,031 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:08:33,194 INFO: OPT time: 1.163\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:08:33,194 INFO: Final:  peasant seem like they are terry must with it\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:08:33,195 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  73%|███████▎  | 1055/1450 [22:33<08:26,  1.28s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:08:33,329 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:08:33,403 INFO: Partial:  that nye was remarkably incompetent\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:08:33,430 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:08:34,241 INFO: OPT time: 0.811\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:08:34,242 INFO: Final:  that guy was remarkably incompetent\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:08:34,242 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  73%|███████▎  | 1056/1450 [22:34<09:00,  1.37s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:08:34,427 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:08:34,476 INFO: Partial:  lyke to have somebody kumm with the\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:08:34,512 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:08:35,481 INFO: OPT time: 0.969\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:08:35,481 INFO: Final:  like to have somebody come with the\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:08:35,482 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  73%|███████▎  | 1057/1450 [22:35<08:20,  1.27s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:08:35,631 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:08:35,670 INFO: Partial:  lyke to to that\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:08:35,704 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:08:36,507 INFO: OPT time: 0.803\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:08:36,507 INFO: Final:  ide like to to that\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:08:36,507 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  73%|███████▎  | 1058/1450 [22:36<08:15,  1.26s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:08:36,636 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:08:36,720 INFO: Partial:  grew upp in oliver\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:08:36,753 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:08:37,561 INFO: OPT time: 0.808\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:08:37,561 INFO: Final:  grew up in oklahoma\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:08:37,562 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  73%|███████▎  | 1059/1450 [22:37<07:46,  1.19s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:08:37,736 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:08:37,804 INFO: Partial:  se it was about twenty for intra dollars\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:08:37,856 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:08:38,986 INFO: OPT time: 1.130\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:08:38,986 INFO: Final:  ide say it was about twenty for intra dollars\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:08:38,987 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  73%|███████▎  | 1060/1450 [22:39<07:28,  1.15s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:08:39,141 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:08:39,275 INFO: Partial:  having perimeter in jury duty myself\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:08:39,337 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:08:40,308 INFO: OPT time: 0.970\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:08:40,308 INFO: Final:  having participated in jury duty myself\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:08:40,309 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  73%|███████▎  | 1061/1450 [22:40<07:59,  1.23s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:08:40,445 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:08:40,492 INFO: Partial:  pasing that otte to each other\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:08:40,587 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:08:41,440 INFO: OPT time: 0.854\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:08:41,441 INFO: Final:  passing that on to each other\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:08:41,441 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  73%|███████▎  | 1062/1450 [22:41<08:08,  1.26s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:08:41,646 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:08:41,691 INFO: Partial:  siems lyke ai just mott it\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:08:41,737 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:08:42,691 INFO: OPT time: 0.953\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:08:42,691 INFO: Final:  seems like i just bought it\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:08:42,691 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  73%|███████▎  | 1063/1450 [22:42<07:52,  1.22s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:08:42,848 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:08:42,956 INFO: Partial:  no ai have to due my aerobics\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:08:43,022 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:08:44,180 INFO: OPT time: 1.158\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:08:44,181 INFO: Final:  know ai have to due my aerobics\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:08:44,181 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  73%|███████▎  | 1064/1450 [22:44<07:54,  1.23s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:08:44,353 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:08:44,461 INFO: Partial:  jansson is vowing to appeal the decision\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:08:44,511 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:08:45,495 INFO: OPT time: 0.983\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:08:45,495 INFO: Final:  jansen is vowing to appeal the decision\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:08:45,495 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  73%|███████▎  | 1065/1450 [22:45<08:23,  1.31s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:08:45,655 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:08:45,714 INFO: Partial:  was this decision mad it why now\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:08:45,770 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:08:46,749 INFO: OPT time: 0.979\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:08:46,749 INFO: Final:  was this decision made it why now\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:08:46,750 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  74%|███████▎  | 1066/1450 [22:46<08:22,  1.31s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:08:46,857 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:08:46,954 INFO: Partial:  any city kroeze it gets for timorous\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:08:47,059 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:08:48,209 INFO: OPT time: 1.150\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:08:48,209 INFO: Final:  any city crows it gets for teachers\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:08:48,210 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  74%|███████▎  | 1067/1450 [22:48<08:15,  1.29s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:08:48,364 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:08:48,395 INFO: Partial:  was really pretty\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:08:48,417 INFO: Augmented nbest from 100 to 109 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:08:49,124 INFO: OPT time: 0.707\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:08:49,124 INFO: Final:  it was really pretty\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:08:49,124 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  74%|███████▎  | 1068/1450 [22:49<08:33,  1.34s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:08:49,261 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:08:49,329 INFO: Partial:  yu are good oui can goh get house live\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:08:49,426 INFO: Augmented nbest from 100 to 167 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:08:51,185 ERROR: Error during OPT rescore: CUDA out of memory. Tried to allocate 242.00 MiB (GPU 0; 14.74 GiB total capacity; 13.64 GiB already allocated; 188.19 MiB free; 14.27 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:08:53,312 INFO: OPT time: 3.886\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:08:53,312 INFO: Final:  you are good oui can go get hause live\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:08:53,313 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  74%|███████▎  | 1069/1450 [22:50<07:42,  1.21s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:08:53,475 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:08:53,564 INFO: Partial:  a town caisson to always\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:08:53,613 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:08:54,462 INFO: OPT time: 0.849\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:08:54,463 INFO: Final:  it a town adjacent to always\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:08:54,463 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  74%|███████▍  | 1070/1450 [22:54<13:20,  2.11s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:08:54,576 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:08:54,607 INFO: Partial:  everybody siems to lyke that\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:08:54,632 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:08:55,488 INFO: OPT time: 0.856\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:08:55,488 INFO: Final:  everybody seems to like that\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:08:55,489 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  74%|███████▍  | 1071/1450 [22:55<11:29,  1.82s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:08:55,675 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:08:55,705 INFO: Partial:  because yu hurd it\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:08:55,735 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:08:56,425 INFO: OPT time: 0.690\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:08:56,426 INFO: Final:  because you heard it\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:08:56,426 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  74%|███████▍  | 1072/1450 [22:56<09:57,  1.58s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:08:56,578 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:08:56,654 INFO: Partial:  where nott meiring anything and this payne in time\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:08:56,726 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:08:57,893 INFO: OPT time: 1.167\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:08:57,893 INFO: Final:  where not meiring anything and this pain in time\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:08:57,894 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  74%|███████▍  | 1073/1450 [22:57<08:43,  1.39s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:08:58,084 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:08:58,168 INFO: Partial:  they good be just about eakle\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:08:58,219 INFO: Augmented nbest from 100 to 106 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:08:59,196 INFO: OPT time: 0.977\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:08:59,196 INFO: Final:  they could be just about equal\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:08:59,196 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  74%|███████▍  | 1074/1450 [22:59<08:50,  1.41s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:08:59,389 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:08:59,464 INFO: Partial:  deduct have any problem doing it the wurst time\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:08:59,533 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:00,902 INFO: OPT time: 1.369\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:00,902 INFO: Final:  they deduct have any problem doing it the worst time\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:00,903 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  74%|███████▍  | 1075/1450 [23:00<08:37,  1.38s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:01,092 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:01,157 INFO: Partial:  rittle hupp in sum where\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:01,294 INFO: Augmented nbest from 100 to 118 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:02,405 INFO: OPT time: 1.111\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:02,405 INFO: Final:  indal hull in some where\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:02,406 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  74%|███████▍  | 1076/1450 [23:02<09:12,  1.48s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:02,603 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:02,691 INFO: Partial:  this vevey is really on television\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:02,740 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:03,684 INFO: OPT time: 0.943\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:03,684 INFO: Final:  this fairy is really on television\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:03,685 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  74%|███████▍  | 1077/1450 [23:03<09:13,  1.49s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:03,799 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:03,846 INFO: Partial:  everybody has that sejm mindset\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:03,881 INFO: Augmented nbest from 100 to 114 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:05,000 INFO: OPT time: 1.119\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:05,000 INFO: Final:  everybody has that same mindset\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:05,001 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  74%|███████▍  | 1078/1450 [23:05<08:49,  1.42s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:05,197 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:05,293 INFO: Partial:  girls renny cities laux\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:05,487 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:06,292 INFO: OPT time: 0.805\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:06,292 INFO: Final:  girls rennie cities long\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:06,293 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  74%|███████▍  | 1079/1450 [23:06<08:36,  1.39s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:06,410 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:06,438 INFO: Partial:  yu probably wooden\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:06,457 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:07,111 INFO: OPT time: 0.653\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:07,111 INFO: Final:  you probably wouldn't\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:07,111 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  74%|███████▍  | 1080/1450 [23:07<08:23,  1.36s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:07,301 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:07,339 INFO: Partial:  it was on the news every nate\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:07,390 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:08,329 INFO: OPT time: 0.939\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:08,330 INFO: Final:  it was on the news every night\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:08,330 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  75%|███████▍  | 1081/1450 [23:08<07:22,  1.20s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:08,505 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:08,544 INFO: Partial:  his story is nott usual\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:08,581 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:09,285 INFO: OPT time: 0.704\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:09,285 INFO: Final:  his story is not unusual\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:09,286 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  75%|███████▍  | 1082/1450 [23:09<07:23,  1.20s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:09,406 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:09,477 INFO: Partial:  and dote with sum olives\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:09,570 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:10,271 INFO: OPT time: 0.701\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:10,271 INFO: Final:  and cooked with some olives\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:10,272 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  75%|███████▍  | 1083/1450 [23:10<06:54,  1.13s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:10,416 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:10,474 INFO: Partial:  had fouled an intrie point\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:10,509 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:11,454 INFO: OPT time: 0.944\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:11,454 INFO: Final:  had found an intrie point\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:11,454 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  75%|███████▍  | 1084/1450 [23:11<06:37,  1.09s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:11,610 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:11,649 INFO: Partial:  they dote kell them\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:11,686 INFO: Augmented nbest from 100 to 104 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:12,392 INFO: OPT time: 0.706\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:12,392 INFO: Final:  they dote kill them\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:12,393 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  75%|███████▍  | 1085/1450 [23:12<06:47,  1.12s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:12,514 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:12,543 INFO: Partial:  selling the water\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:12,564 INFO: Augmented nbest from 100 to 117 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:13,378 INFO: OPT time: 0.814\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:13,378 INFO: Final:  selling the water\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:13,379 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  75%|███████▍  | 1086/1450 [23:13<06:26,  1.06s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:13,515 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:13,632 INFO: Partial:  business is usual for traders\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:13,677 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:14,384 INFO: OPT time: 0.707\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:14,384 INFO: Final:  business as usual for traders\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:14,385 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  75%|███████▍  | 1087/1450 [23:14<06:17,  1.04s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:14,518 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:14,600 INFO: Partial:  they gave us a messel diel\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:14,700 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:15,555 INFO: OPT time: 0.855\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:15,555 INFO: Final:  they gave us a messel deal\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:15,556 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  75%|███████▌  | 1088/1450 [23:15<06:12,  1.03s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:15,725 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:15,831 INFO: Partial:  the reality is its usually nott the cayce\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:15,894 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:16,877 INFO: OPT time: 0.982\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:16,877 INFO: Final:  the reality is its usually not the case\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:16,878 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  75%|███████▌  | 1089/1450 [23:16<06:26,  1.07s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:17,024 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:17,073 INFO: Partial:  wunder where they due that\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:17,106 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:17,959 INFO: OPT time: 0.853\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:17,959 INFO: Final:  wonder where they do that\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:17,960 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  75%|███████▌  | 1090/1450 [23:18<06:52,  1.15s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:18,128 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:18,222 INFO: Partial:  he kept is doanh liked and casual butt frame\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:18,298 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:19,467 INFO: OPT time: 1.169\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:19,467 INFO: Final:  he kept is doan like and casual but frame\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:19,467 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  75%|███████▌  | 1091/1450 [23:19<06:44,  1.13s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:19,633 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:19,673 INFO: Partial:  paranoid in the past\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:19,703 INFO: Augmented nbest from 100 to 106 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:20,537 INFO: OPT time: 0.835\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:20,538 INFO: Final:  paranoid in the past\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:20,538 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  75%|███████▌  | 1092/1450 [23:20<07:24,  1.24s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:20,733 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:20,811 INFO: Partial:  there movie to rarity\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:20,843 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:21,537 INFO: OPT time: 0.694\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:21,538 INFO: Final:  their movie to rarity\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:21,538 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  75%|███████▌  | 1093/1450 [23:21<07:04,  1.19s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:21,735 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:21,823 INFO: Partial:  and ai always that in was kind of out of mennen\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:21,909 INFO: Augmented nbest from 100 to 101 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:23,126 INFO: OPT time: 1.217\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:23,126 INFO: Final:  and i always that it was kind of out of mennan\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:23,127 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  75%|███████▌  | 1094/1450 [23:22<06:43,  1.13s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:23,241 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:23,328 INFO: Partial:  oui did fined simple good texas\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:23,379 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:24,361 INFO: OPT time: 0.981\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:24,361 INFO: Final:  we did find simple good texas\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:24,362 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  76%|███████▌  | 1095/1450 [23:24<07:30,  1.27s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:24,543 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:24,588 INFO: Partial:  what grupe yu happen to be in\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:24,629 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:25,583 INFO: OPT time: 0.954\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:25,583 INFO: Final:  what group you happen to be in\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:25,583 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  76%|███████▌  | 1096/1450 [23:25<07:25,  1.26s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:25,746 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:25,817 INFO: Partial:  there is a competition ola top\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:25,943 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:26,888 INFO: OPT time: 0.945\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:26,889 INFO: Final:  there is a competition the top\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:26,889 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  76%|███████▌  | 1097/1450 [23:27<07:20,  1.25s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:27,055 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:27,138 INFO: Partial:  atz what ai did when ai was trying upp\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:27,220 INFO: Augmented nbest from 100 to 102 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:28,435 INFO: OPT time: 1.215\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:28,435 INFO: Final:  atz what i did when i was trying up\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:28,436 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  76%|███████▌  | 1098/1450 [23:28<07:25,  1.27s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:28,553 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:28,634 INFO: Partial:  really wanted to goh on the rafting trim\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:28,711 INFO: Augmented nbest from 100 to 105 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:29,883 INFO: OPT time: 1.172\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:29,883 INFO: Final:  really wanted to go on the rafting trip\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:29,883 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  76%|███████▌  | 1099/1450 [23:29<07:53,  1.35s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:30,057 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:30,113 INFO: Partial:  oui went with sum friends of ours\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:30,156 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:31,280 INFO: OPT time: 1.123\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:31,280 INFO: Final:  we went with some friends of ours\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:31,281 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  76%|███████▌  | 1100/1450 [23:31<08:02,  1.38s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:31,457 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:31,528 INFO: Partial:  can make my pies frum krass\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:31,601 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:32,588 INFO: OPT time: 0.987\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:32,588 INFO: Final:  can make my pies from scratch\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:32,589 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  76%|███████▌  | 1101/1450 [23:32<08:03,  1.38s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:32,765 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:32,824 INFO: Partial:  nott total butt suss frum cars\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:32,880 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:33,858 INFO: OPT time: 0.979\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:33,859 INFO: Final:  not total but just from cars\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:33,859 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  76%|███████▌  | 1102/1450 [23:34<07:53,  1.36s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:33,966 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:34,027 INFO: Partial:  the older old meaty\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:34,075 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:34,767 INFO: OPT time: 0.692\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:34,767 INFO: Final:  the older old meta\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:34,768 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  76%|███████▌  | 1103/1450 [23:35<07:42,  1.33s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:34,968 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:35,025 INFO: Partial:  think souter are later\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:35,063 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:35,760 INFO: OPT time: 0.696\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:35,760 INFO: Final:  think suter or later\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:35,760 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  76%|███████▌  | 1104/1450 [23:36<06:57,  1.21s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:35,870 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:35,903 INFO: Partial:  send mi sum money\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:35,927 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:36,627 INFO: OPT time: 0.700\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:36,627 INFO: Final:  send me some money\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:36,628 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  76%|███████▌  | 1105/1450 [23:37<06:34,  1.14s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:36,770 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:36,850 INFO: Partial:  yu get a lot of graphics in there\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:36,913 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:37,868 INFO: OPT time: 0.955\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:37,868 INFO: Final:  you get a lot of graphics in there\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:37,869 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  76%|███████▋  | 1106/1450 [23:38<06:04,  1.06s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:38,076 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:38,146 INFO: Partial:  ai was sitting upp a daycare\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:38,200 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:39,152 INFO: OPT time: 0.952\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:39,152 INFO: Final:  if ai was setting up a daycare\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:39,153 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  76%|███████▋  | 1107/1450 [23:39<06:22,  1.11s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:39,279 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:39,356 INFO: Partial:  he was found dade after an explosion was hurd\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:39,436 INFO: Augmented nbest from 100 to 106 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:40,622 INFO: OPT time: 1.186\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:40,623 INFO: Final:  he was found dead after an explosion was heard\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:40,623 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  76%|███████▋  | 1108/1450 [23:40<06:38,  1.17s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:40,783 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:40,830 INFO: Partial:  due a year long project\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:40,856 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:41,672 INFO: OPT time: 0.815\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:41,672 INFO: Final:  do a year long project\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:41,672 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  76%|███████▋  | 1109/1450 [23:42<07:08,  1.26s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:41,784 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:41,825 INFO: Partial:  when would people to it\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:41,854 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:42,554 INFO: OPT time: 0.701\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:42,555 INFO: Final:  when would people to it\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:42,555 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  77%|███████▋  | 1110/1450 [23:43<06:46,  1.19s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:42,686 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:42,760 INFO: Partial:  nott quite as big of that\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:42,816 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:43,672 INFO: OPT time: 0.856\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:43,673 INFO: Final:  not quite as big of that\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:43,673 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  77%|███████▋  | 1111/1450 [23:43<06:13,  1.10s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:43,793 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:43,897 INFO: Partial:  have nott doughten any request get\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:43,966 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:44,948 INFO: OPT time: 0.981\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:44,948 INFO: Final:  have not gotten any request get\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:44,949 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  77%|███████▋  | 1112/1450 [23:45<06:13,  1.11s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:45,097 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:45,157 INFO: Partial:  bases that they yoos\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:45,190 INFO: Augmented nbest from 100 to 110 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:46,041 INFO: OPT time: 0.850\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:46,041 INFO: Final:  bases that they ewes\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:46,041 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  77%|███████▋  | 1113/1450 [23:46<06:29,  1.16s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:46,197 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:46,228 INFO: Partial:  actually they have\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:46,251 INFO: Augmented nbest from 100 to 132 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:46,945 INFO: OPT time: 0.694\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:46,945 INFO: Final:  actually they have\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:46,946 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  77%|███████▋  | 1114/1450 [23:47<06:22,  1.14s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:47,096 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:47,138 INFO: Partial:  anything wry that\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:47,164 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:47,685 INFO: OPT time: 0.520\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:47,685 INFO: Final:  anything like that\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:47,686 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  77%|███████▋  | 1115/1450 [23:48<05:57,  1.07s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:47,800 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:47,840 INFO: Partial:  was the write decision\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:47,863 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:48,659 INFO: OPT time: 0.797\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:48,660 INFO: Final:  it was the right decision\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:48,660 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  77%|███████▋  | 1116/1450 [23:49<05:23,  1.03trial/s]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:48,801 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:48,908 INFO: Partial:  motorists are advised to avoid the erria\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:48,967 INFO: Augmented nbest from 100 to 134 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:50,431 INFO: OPT time: 1.464\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:50,431 INFO: Final:  motorists are advised to avoid the area\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:50,432 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  77%|███████▋  | 1117/1450 [23:50<05:23,  1.03trial/s]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:50,605 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:50,677 INFO: Partial:  checking the blogs and stuff\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:50,730 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:51,530 INFO: OPT time: 0.800\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:51,531 INFO: Final:  checking the blogs and stuff\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:51,531 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  77%|███████▋  | 1118/1450 [23:51<06:42,  1.21s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:51,709 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:51,782 INFO: Partial:  have the chains to really freehand\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:51,839 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:52,814 INFO: OPT time: 0.975\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:52,814 INFO: Final:  have the chance to really freehand\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:52,815 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  77%|███████▋  | 1119/1450 [23:52<06:29,  1.18s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:53,014 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:53,063 INFO: Partial:  being in interfere now\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:53,092 INFO: Augmented nbest from 100 to 102 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:53,760 INFO: OPT time: 0.668\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:53,761 INFO: Final:  being in interfere now\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:53,761 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  77%|███████▋  | 1120/1450 [23:54<06:39,  1.21s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:53,913 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:53,977 INFO: Partial:  lykes to sci lows in church\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:54,051 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:54,997 INFO: OPT time: 0.945\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:54,997 INFO: Final:  he likes to sci lows in church\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:54,997 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  77%|███████▋  | 1121/1450 [23:55<06:11,  1.13s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:55,119 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:55,196 INFO: Partial:  advice on sun or daughter going to college\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:55,256 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:56,378 INFO: OPT time: 1.122\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:56,378 INFO: Final:  advice on son or daughter going to college\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:56,379 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  77%|███████▋  | 1122/1450 [23:56<06:21,  1.16s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:56,520 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:56,553 INFO: Partial:  yu dint would to\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:56,582 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:57,284 INFO: OPT time: 0.702\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:57,285 INFO: Final:  you dint would to\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:57,285 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  77%|███████▋  | 1123/1450 [23:57<06:41,  1.23s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:57,421 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:57,481 INFO: Partial:  in the navy\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:57,519 INFO: Augmented nbest from 100 to 102 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:58,181 INFO: OPT time: 0.661\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:58,181 INFO: Final:  in the navy\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:58,181 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  78%|███████▊  | 1124/1450 [23:58<06:08,  1.13s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:58,326 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:58,358 INFO: Partial:  have yu hurd that\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:58,384 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:59,183 INFO: OPT time: 0.799\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:59,183 INFO: Final:  have you heard that\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:59,183 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  78%|███████▊  | 1125/1450 [23:59<05:44,  1.06s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:59,326 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:59,433 INFO: Partial:  cannot be measure and yet it exist\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:09:59,509 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:10:00,491 INFO: OPT time: 0.982\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:10:00,491 INFO: Final:  it cannot be measure and yet it exist\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:10:00,491 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  78%|███████▊  | 1126/1450 [24:00<05:38,  1.04s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:10:00,635 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:10:00,770 INFO: Partial:  think piano his always good pickron\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:10:00,865 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:10:01,803 INFO: OPT time: 0.937\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:10:01,803 INFO: Final:  think piano is always good background\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:10:01,803 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  78%|███████▊  | 1127/1450 [24:01<06:02,  1.12s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:10:01,941 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:10:01,992 INFO: Partial:  trying to stick in with that\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:10:02,028 INFO: Augmented nbest from 100 to 106 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:10:02,993 INFO: OPT time: 0.965\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:10:02,993 INFO: Final:  trying to stick in with that\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:10:02,993 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  78%|███████▊  | 1128/1450 [24:03<06:19,  1.18s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:10:03,137 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:10:03,234 INFO: Partial:  unfortunately they are nott good filters\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:10:03,278 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:10:04,246 INFO: OPT time: 0.968\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:10:04,246 INFO: Final:  unfortunately they are not good fighters\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:10:04,247 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  78%|███████▊  | 1129/1450 [24:04<06:19,  1.18s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:10:04,440 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:10:04,510 INFO: Partial:  think nott a lot of people phair that why\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:10:04,595 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:10:05,584 INFO: OPT time: 0.989\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:10:05,585 INFO: Final:  think not a lot of people fair that my\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:10:05,585 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  78%|███████▊  | 1130/1450 [24:05<06:25,  1.20s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:10:05,745 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:10:05,813 INFO: Partial:  oui jun have aborted it\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:10:05,882 INFO: Augmented nbest from 100 to 108 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:10:06,855 INFO: OPT time: 0.973\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:10:06,855 INFO: Final:  we should have aborted it\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:10:06,856 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  78%|███████▊  | 1131/1450 [24:07<06:36,  1.24s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:10:07,047 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:10:07,134 INFO: Partial:  hoff the television and stay of the computer\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:10:07,188 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:10:08,170 INFO: OPT time: 0.982\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:10:08,170 INFO: Final:  june off the television and stay of the computer\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:10:08,171 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  78%|███████▊  | 1132/1450 [24:08<06:38,  1.25s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:10:08,351 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:10:08,431 INFO: Partial:  finn towards won another\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:10:08,469 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:10:09,124 INFO: OPT time: 0.655\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:10:09,124 INFO: Final:  fin towards one another\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:10:09,125 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  78%|███████▊  | 1133/1450 [24:09<06:42,  1.27s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:10:09,251 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:10:09,306 INFO: Partial:  cars yu can bye stokke in the company\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:10:09,383 INFO: Augmented nbest from 100 to 127 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:10:10,985 INFO: OPT time: 1.602\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:10:10,985 INFO: Final:  cars u can by stock in the compagnie\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:10:10,986 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  78%|███████▊  | 1134/1450 [24:10<06:11,  1.18s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:10:11,157 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:10:11,241 INFO: Partial:  was the maned nott washable\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:10:11,273 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:10:12,126 INFO: OPT time: 0.853\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:10:12,126 INFO: Final:  was the maid not washable\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:10:12,127 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  78%|███████▊  | 1135/1450 [24:12<07:15,  1.38s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:10:12,257 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:10:12,312 INFO: Partial:  nied to make a phone kaul or to\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:10:12,371 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:10:13,516 INFO: OPT time: 1.145\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:10:13,516 INFO: Final:  need to make a phone call or to\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:10:13,516 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  78%|███████▊  | 1136/1450 [24:13<06:51,  1.31s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:10:13,663 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:10:13,703 INFO: Partial:  really enjoyed it whyte a pate\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:10:13,760 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:10:14,696 INFO: OPT time: 0.936\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:10:14,696 INFO: Final:  really enjoyed it quite a pit\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:10:14,697 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  78%|███████▊  | 1137/1450 [24:14<06:57,  1.33s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:10:14,866 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:10:14,953 INFO: Partial:  will be our furse change to sci each other in quite awhile\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:10:15,046 INFO: Augmented nbest from 100 to 160 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:10:17,008 ERROR: Error during OPT rescore: CUDA out of memory. Tried to allocate 262.00 MiB (GPU 0; 14.74 GiB total capacity; 13.75 GiB already allocated; 262.19 MiB free; 14.20 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:10:19,207 INFO: OPT time: 4.160\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:10:19,207 INFO: Final:  will be our first change to c each other in quite awhile\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:10:19,207 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  78%|███████▊  | 1138/1450 [24:16<06:41,  1.29s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:10:19,376 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:10:19,416 INFO: Partial:  explore before yu exploit\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:10:19,442 INFO: Augmented nbest from 100 to 108 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:10:20,157 INFO: OPT time: 0.715\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:10:20,157 INFO: Final:  explore before you exploit\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:10:20,158 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  79%|███████▊  | 1139/1450 [24:20<11:41,  2.25s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:10:20,275 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:10:20,441 INFO: Partial:  your wellcome to kumm over anytime without duties\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:10:20,625 INFO: Augmented nbest from 100 to 103 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:10:21,631 INFO: OPT time: 1.006\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:10:21,631 INFO: Final:  your welcome to come over anytime without duties\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:10:21,631 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  79%|███████▊  | 1140/1450 [24:21<09:37,  1.86s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:10:21,793 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:10:21,840 INFO: Partial:  what woodby entrusting\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:10:21,863 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:10:22,697 INFO: OPT time: 0.834\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:10:22,697 INFO: Final:  what would be interesting\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:10:22,698 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  79%|███████▊  | 1141/1450 [24:23<08:59,  1.75s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:10:22,882 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:10:22,918 INFO: Partial:  think that the meyn problem\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:10:22,949 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:10:23,756 INFO: OPT time: 0.807\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:10:23,756 INFO: Final:  think that the main problem\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:10:23,757 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  79%|███████▉  | 1142/1450 [24:24<07:55,  1.54s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:10:23,886 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:10:23,928 INFO: Partial:  would a won to bye morr\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:10:23,981 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:10:24,915 INFO: OPT time: 0.934\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:10:24,915 INFO: Final:  wood a one to buy more\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:10:24,915 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  79%|███████▉  | 1143/1450 [24:25<07:08,  1.40s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:10:25,090 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:10:25,131 INFO: Partial:  how mutsch precision to yu nied\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:10:25,183 INFO: Augmented nbest from 100 to 200 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:10:27,057 INFO: OPT time: 1.874\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:10:27,057 INFO: Final:  how much precision to you need\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:10:27,058 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  79%|███████▉  | 1144/1450 [24:26<06:45,  1.33s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:10:27,196 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:10:27,267 INFO: Partial:  have nott titan them in a long time\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:10:27,333 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:10:28,456 INFO: OPT time: 1.122\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:10:28,456 INFO: Final:  have not tighten them in a long time\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:10:28,456 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  79%|███████▉  | 1145/1450 [24:28<07:59,  1.57s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:10:28,603 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:10:28,778 INFO: Partial:  he old is conversation jewry\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:10:28,871 INFO: Augmented nbest from 100 to 104 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:10:29,698 INFO: OPT time: 0.826\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:10:29,698 INFO: Final:  he old is conversation juicy\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:10:29,698 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  79%|███████▉  | 1146/1450 [24:29<07:41,  1.52s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:10:29,906 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:10:30,079 INFO: Partial:  pei for the hukstra dental insurance place vision\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:10:30,304 INFO: Augmented nbest from 100 to 109 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:10:31,507 INFO: OPT time: 1.202\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:10:31,507 INFO: Final:  pay for the extra dental insurance place vision\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:10:31,507 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  79%|███████▉  | 1147/1450 [24:31<07:15,  1.44s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:10:31,713 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:10:31,733 INFO: Partial:  no that\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:10:31,748 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:10:32,168 INFO: OPT time: 0.420\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:10:32,168 INFO: Final:  know that\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:10:32,169 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  79%|███████▉  | 1148/1450 [24:32<07:47,  1.55s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:10:32,305 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:10:32,397 INFO: Partial:  read the while trade data and the new yule times\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:10:32,569 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:10:33,947 INFO: OPT time: 1.377\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:10:33,947 INFO: Final:  read the while trade data and the new yule times\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:10:33,948 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  79%|███████▉  | 1149/1450 [24:33<06:25,  1.28s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:10:34,117 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:10:34,190 INFO: Partial:  then ai when accrue with it\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:10:34,328 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:10:35,277 INFO: OPT time: 0.949\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:10:35,277 INFO: Final:  then i want ecru with it\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:10:35,277 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  79%|███████▉  | 1150/1450 [24:35<07:09,  1.43s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:10:35,415 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:10:35,467 INFO: Partial:  oui get decimated are the time\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:10:35,505 INFO: Augmented nbest from 100 to 101 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:10:36,486 INFO: OPT time: 0.981\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:10:36,486 INFO: Final:  we get decimated are the time\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:10:36,487 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  79%|███████▉  | 1151/1450 [24:36<06:58,  1.40s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:10:36,615 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:10:36,772 INFO: Partial:  yu relies why the uniting stains was in biddle its\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:10:36,887 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:10:38,273 INFO: OPT time: 1.386\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:10:38,273 INFO: Final:  you relies why the uniting stains was in the biddle its\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:10:38,274 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  79%|███████▉  | 1152/1450 [24:37<06:40,  1.34s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:10:38,424 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:10:38,532 INFO: Partial:  childrey is imperious uneconomic lodi\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:10:38,570 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:10:39,522 INFO: OPT time: 0.951\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:10:39,522 INFO: Final:  childrey is experience an economic lowdown\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:10:39,523 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  80%|███████▉  | 1153/1450 [24:39<07:18,  1.48s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:10:39,723 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:10:39,887 INFO: Partial:  he rotated is verities to them every time\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:10:40,000 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:10:40,985 INFO: OPT time: 0.985\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:10:40,985 INFO: Final:  he donated is rarity to them every time\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:10:40,986 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  80%|███████▉  | 1154/1450 [24:40<06:56,  1.41s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:10:41,129 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:10:41,249 INFO: Partial:  interstate closures are creating a lot of driving\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:10:41,302 INFO: Augmented nbest from 100 to 104 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:10:42,444 INFO: OPT time: 1.141\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:10:42,444 INFO: Final:  interstate closures are creating a lot of driving\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:10:42,445 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  80%|███████▉  | 1155/1450 [24:42<07:00,  1.42s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:10:42,630 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:10:42,690 INFO: Partial:  the police gott them read hinted\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:10:42,731 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:10:43,584 INFO: OPT time: 0.853\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:10:43,584 INFO: Final:  the police got them red hinted\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:10:43,585 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  80%|███████▉  | 1156/1450 [24:43<07:01,  1.43s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:10:43,734 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:10:43,774 INFO: Partial:  have been involved in an collision\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:10:43,801 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:10:44,749 INFO: OPT time: 0.949\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:10:44,749 INFO: Final:  you have been involved in an collision\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:10:44,750 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  80%|███████▉  | 1157/1450 [24:45<06:34,  1.35s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:10:44,937 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:10:44,972 INFO: Partial:  klose to sci level\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:10:45,004 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:10:45,694 INFO: OPT time: 0.690\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:10:45,694 INFO: Final:  klose to sea level\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:10:45,695 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  80%|███████▉  | 1158/1450 [24:46<06:17,  1.29s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:10:45,839 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:10:45,924 INFO: Partial:  doanh yu wake yu and been apple to goh\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:10:46,169 INFO: Augmented nbest from 100 to 197 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:10:48,277 ERROR: Error during OPT rescore: CUDA out of memory. Tried to allocate 100.00 MiB (GPU 0; 14.74 GiB total capacity; 14.09 GiB already allocated; 50.19 MiB free; 14.40 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:10:48,662 ERROR: Error during OPT rescore: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.74 GiB total capacity; 14.36 GiB already allocated; 10.19 MiB free; 14.44 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:10:48,663 INFO: OPT time: 2.494\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:10:48,663 INFO: Final:  doan ewe wake ewe and been appel to gogh\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:10:48,664 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  80%|███████▉  | 1159/1450 [24:47<05:45,  1.19s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:10:48,851 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:10:48,904 INFO: Partial:  it tapes yu in gone company\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:10:48,967 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:10:49,955 INFO: OPT time: 0.987\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:10:49,955 INFO: Final:  it tapes you in gone company\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:10:49,955 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  80%|████████  | 1160/1450 [24:50<08:19,  1.72s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:10:50,150 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:10:50,242 INFO: Partial:  a divide worman\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:10:50,444 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:10:51,096 INFO: OPT time: 0.652\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:10:51,096 INFO: Final:  i divide women\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:10:51,097 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  80%|████████  | 1161/1450 [24:51<07:40,  1.59s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:10:51,262 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:10:51,314 INFO: Partial:  mutsch morr loud get the get\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:10:51,356 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:10:52,329 INFO: OPT time: 0.973\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:10:52,329 INFO: Final:  much more loud get the get\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:10:52,330 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  80%|████████  | 1162/1450 [24:52<06:59,  1.46s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:10:52,455 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:10:52,528 INFO: Partial:  oui are rival for the pleasure of serving yoor\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:10:52,599 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:10:53,771 INFO: OPT time: 1.172\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:10:53,771 INFO: Final:  we are rival for the pleasure of serving u\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:10:53,771 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  80%|████████  | 1163/1450 [24:53<06:38,  1.39s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:10:53,958 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:10:54,076 INFO: Partial:  they tend to make decision makes on there mood an a tartan time\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:10:54,310 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:10:55,762 INFO: OPT time: 1.451\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:10:55,762 INFO: Final:  they tend to make decision based on their mood an a certain time\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:10:55,762 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  80%|████████  | 1164/1450 [24:55<06:42,  1.41s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:10:55,970 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:10:56,037 INFO: Partial:  aull gott a pei weighs this year\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:10:56,106 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:10:57,091 INFO: OPT time: 0.985\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:10:57,091 INFO: Final:  all got a pay ways this year\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:10:57,091 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  80%|████████  | 1165/1450 [24:57<07:30,  1.58s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:10:57,271 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:10:57,288 INFO: Partial:  think about this\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:10:57,300 INFO: Augmented nbest from 80 to 80 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:10:57,724 INFO: OPT time: 0.423\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:10:57,724 INFO: Final:  think about this\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:10:57,724 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  80%|████████  | 1166/1450 [24:58<07:07,  1.51s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:10:57,866 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:10:58,015 INFO: Partial:  he published a paper un the sabra last year\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:10:58,141 INFO: Augmented nbest from 100 to 108 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:10:59,315 INFO: OPT time: 1.174\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:10:59,316 INFO: Final:  he published a paper on the sabra last year\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:10:59,316 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  80%|████████  | 1167/1450 [24:59<05:51,  1.24s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:10:59,474 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:10:59,552 INFO: Partial:  the supreme kort where bui decision duguay\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:10:59,618 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:11:00,761 INFO: OPT time: 1.143\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:11:00,761 INFO: Final:  the supreme court where bui a decision today\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:11:00,761 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  81%|████████  | 1168/1450 [25:00<06:20,  1.35s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:11:00,878 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:11:00,948 INFO: Partial:  and aull of sighted they were card\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:11:01,040 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:11:02,027 INFO: OPT time: 0.987\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:11:02,027 INFO: Final:  and all of a cited they were card\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:11:02,027 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  81%|████████  | 1169/1450 [25:02<06:27,  1.38s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:11:02,182 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:11:02,259 INFO: Partial:  this is there yearly compensation\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:11:02,304 INFO: Augmented nbest from 100 to 130 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:11:03,232 INFO: OPT time: 0.928\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:11:03,232 INFO: Final:  this is their yearly compensation\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:11:03,233 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  81%|████████  | 1170/1450 [25:03<06:16,  1.34s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:11:03,381 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:11:03,465 INFO: Partial:  southern california and stil pretty large\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:11:03,507 INFO: Augmented nbest from 100 to 104 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:11:04,688 INFO: OPT time: 1.181\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:11:04,689 INFO: Final:  southern california and still pretty large\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:11:04,689 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  81%|████████  | 1171/1450 [25:04<06:03,  1.30s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:11:04,884 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:11:04,987 INFO: Partial:  was in semele situation\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:11:05,072 INFO: Augmented nbest from 100 to 110 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:11:05,924 INFO: OPT time: 0.851\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:11:05,924 INFO: Final:  was in a civil situation\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:11:05,925 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  81%|████████  | 1172/1450 [25:06<06:14,  1.35s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:11:06,088 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:11:06,152 INFO: Partial:  this is the point where yu want to tasting\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:11:06,209 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:11:07,367 INFO: OPT time: 1.158\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:11:07,368 INFO: Final:  this is the point where yu want to taste it\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:11:07,368 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  81%|████████  | 1173/1450 [25:07<06:04,  1.31s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:11:07,492 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:11:07,617 INFO: Partial:  lasting saturday oui aull whate out to ditter\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:11:07,721 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:11:08,924 INFO: OPT time: 1.202\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:11:08,924 INFO: Final:  last saturday oui all wait out to deter\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:11:08,924 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  81%|████████  | 1174/1450 [25:08<06:13,  1.35s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:11:09,100 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:11:09,156 INFO: Partial:  was very hopeful anyway\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:11:09,181 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:11:09,991 INFO: OPT time: 0.810\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:11:09,991 INFO: Final:  was very hopeful anyway\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:11:09,992 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  81%|████████  | 1175/1450 [25:10<06:28,  1.41s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:11:10,095 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:11:10,217 INFO: Partial:  guess my concerned is about the ordering that oui are ridding\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:11:10,349 INFO: Augmented nbest from 100 to 112 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:11:11,939 INFO: OPT time: 1.590\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:11:11,939 INFO: Final:  guess my concern is about the ordering that we are ridding\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:11:11,940 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  81%|████████  | 1176/1450 [25:11<05:58,  1.31s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:11:12,106 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:11:12,176 INFO: Partial:  computer has good storing complicity and it\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:11:12,223 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:11:13,341 INFO: OPT time: 1.118\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:11:13,341 INFO: Final:  my computer has good storing capacity and it\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:11:13,342 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  81%|████████  | 1177/1450 [25:13<06:49,  1.50s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:11:13,506 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:11:13,570 INFO: Partial:  haven't been bakke home in five years\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:11:13,613 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:11:14,740 INFO: OPT time: 1.127\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:11:14,740 INFO: Final:  haven't been back home in five years\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:11:14,741 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  81%|████████  | 1178/1450 [25:14<06:40,  1.47s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:11:14,911 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:11:14,992 INFO: Partial:  weave gott to living rooms in our new house\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:11:15,074 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:11:16,237 INFO: OPT time: 1.162\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:11:16,237 INFO: Final:  weave got to living rooms in our new house\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:11:16,238 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  81%|████████▏ | 1179/1450 [25:16<06:32,  1.45s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:11:16,415 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:11:16,455 INFO: Partial:  yu would think so\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:11:16,488 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:11:17,146 INFO: OPT time: 0.658\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:11:17,146 INFO: Final:  you would think so\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:11:17,147 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  81%|████████▏ | 1180/1450 [25:17<06:35,  1.46s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:11:17,316 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:11:17,387 INFO: Partial:  dote want to mass anything upp\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:11:17,452 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:11:18,398 INFO: OPT time: 0.946\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:11:18,398 INFO: Final:  dote want to mess anything up\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:11:18,399 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  81%|████████▏ | 1181/1450 [25:18<05:49,  1.30s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:11:18,521 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:11:18,564 INFO: Partial:  butt atz the point\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:11:18,598 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:11:19,286 INFO: OPT time: 0.688\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:11:19,286 INFO: Final:  but that's the point\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:11:19,287 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  82%|████████▏ | 1182/1450 [25:19<05:44,  1.28s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:11:19,421 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:11:19,505 INFO: Partial:  that is a good idea\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:11:19,552 INFO: Augmented nbest from 100 to 122 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:11:20,538 INFO: OPT time: 0.986\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:11:20,538 INFO: Final:  that is a good idea\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:11:20,539 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  82%|████████▏ | 1183/1450 [25:20<05:11,  1.17s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:11:20,725 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:11:20,776 INFO: Partial:  dote foell very good\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:11:20,811 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:11:21,619 INFO: OPT time: 0.808\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:11:21,619 INFO: Final:  dote feel very good\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:11:21,620 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  82%|████████▏ | 1184/1450 [25:21<05:16,  1.19s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:11:21,726 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:11:21,803 INFO: Partial:  have already practised sum of them\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:11:21,836 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:11:22,686 INFO: OPT time: 0.850\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:11:22,686 INFO: Final:  have already practiced some of them\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:11:22,687 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  82%|████████▏ | 1185/1450 [25:23<05:06,  1.16s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:11:22,829 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:11:22,886 INFO: Partial:  valli hur opinion\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:11:22,937 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:11:23,594 INFO: OPT time: 0.657\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:11:23,594 INFO: Final:  value her opinion\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:11:23,594 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  82%|████████▏ | 1186/1450 [25:24<04:58,  1.13s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:11:23,736 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:11:23,811 INFO: Partial:  tietz hur to write hur name\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:11:23,878 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:11:24,727 INFO: OPT time: 0.849\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:11:24,727 INFO: Final:  tex her to write her name\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:11:24,728 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  82%|████████▏ | 1187/1450 [25:25<04:39,  1.06s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:11:24,839 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:11:24,915 INFO: Partial:  if there is someone at the dorr\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:11:24,978 INFO: Augmented nbest from 100 to 108 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:11:25,918 INFO: OPT time: 0.941\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:11:25,918 INFO: Final:  if there is someone at the door\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:11:25,919 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  82%|████████▏ | 1188/1450 [25:26<04:44,  1.08s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:11:26,038 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:11:26,095 INFO: Partial:  its good preparation for college\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:11:26,130 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:11:26,976 INFO: OPT time: 0.846\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:11:26,976 INFO: Final:  its good preparation for college\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:11:26,977 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  82%|████████▏ | 1189/1450 [25:27<04:51,  1.12s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:11:27,138 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:11:27,207 INFO: Partial:  love this teem and the new kutsch\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:11:27,270 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:11:28,213 INFO: OPT time: 0.943\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:11:28,214 INFO: Final:  love this team and the new coach\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:11:28,214 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  82%|████████▏ | 1190/1450 [25:28<04:45,  1.10s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:11:28,343 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:11:28,464 INFO: Partial:  the orcutt will it sentell and south amerika\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:11:28,544 INFO: Augmented nbest from 100 to 104 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:11:29,938 INFO: OPT time: 1.394\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:11:29,938 INFO: Final:  the organ will eat sentell and south america\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:11:29,939 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  82%|████████▏ | 1191/1450 [25:29<04:55,  1.14s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:11:30,049 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:11:30,070 INFO: Partial:  that is write\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:11:30,092 INFO: Augmented nbest from 100 to 117 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:11:30,883 INFO: OPT time: 0.791\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:11:30,883 INFO: Final:  that is right\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:11:30,883 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  82%|████████▏ | 1192/1450 [25:31<05:39,  1.32s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:11:31,047 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:11:31,168 INFO: Partial:  there is quite a bit of crime in that neighbourhood\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:11:31,236 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:11:32,363 INFO: OPT time: 1.126\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:11:32,363 INFO: Final:  there is quite a bit of crime in that neighborhood\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:11:32,364 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  82%|████████▏ | 1193/1450 [25:32<05:09,  1.20s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:11:32,552 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:11:32,606 INFO: Partial:  ditton mined doing that at aull\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:11:32,664 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:11:33,610 INFO: OPT time: 0.946\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:11:33,610 INFO: Final:  dun mind doing that at all\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:11:33,610 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  82%|████████▏ | 1194/1450 [25:33<05:29,  1.29s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:11:33,757 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:11:33,836 INFO: Partial:  did yu get to talk to him before he left\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:11:33,899 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:11:35,062 INFO: OPT time: 1.163\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:11:35,062 INFO: Final:  did you get to talk to him before he left\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:11:35,063 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  82%|████████▏ | 1195/1450 [25:35<05:25,  1.28s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:11:35,259 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:11:35,316 INFO: Partial:  because there dahn was at work\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:11:35,369 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:11:36,310 INFO: OPT time: 0.941\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:11:36,310 INFO: Final:  because their den was at work\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:11:36,311 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  82%|████████▏ | 1196/1450 [25:36<05:37,  1.33s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:11:36,463 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:11:36,606 INFO: Partial:  the utilities are already paid for this both\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:11:36,665 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:11:37,612 INFO: OPT time: 0.947\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:11:37,612 INFO: Final:  the utilities are already paid for this both\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:11:37,613 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  83%|████████▎ | 1197/1450 [25:37<05:29,  1.30s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:11:37,765 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:11:37,831 INFO: Partial:  oui usually discuss business over launch\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:11:37,872 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:11:38,835 INFO: OPT time: 0.963\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:11:38,835 INFO: Final:  we usually discuss business over lunch\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:11:38,835 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  83%|████████▎ | 1198/1450 [25:39<05:28,  1.30s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:11:38,966 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:11:39,066 INFO: Partial:  he distant really pei attention in klass\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:11:39,136 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:11:40,257 INFO: OPT time: 1.121\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:11:40,257 INFO: Final:  he docent really pay attention in class\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:11:40,257 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  83%|████████▎ | 1199/1450 [25:40<05:21,  1.28s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:11:40,373 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:11:40,413 INFO: Partial:  its well wurth it\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:11:40,443 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:11:41,282 INFO: OPT time: 0.840\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:11:41,283 INFO: Final:  its well worth it\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:11:41,283 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  83%|████████▎ | 1200/1450 [25:41<05:30,  1.32s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:11:41,471 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:11:41,520 INFO: Partial:  what kind of work due yu due\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:11:41,572 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:11:42,549 INFO: OPT time: 0.977\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:11:42,549 INFO: Final:  what kind of work due you due\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:11:42,550 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  83%|████████▎ | 1201/1450 [25:42<05:07,  1.23s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:11:42,675 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:11:42,737 INFO: Partial:  oui wirt sure how to due that\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:11:42,791 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:11:43,944 INFO: OPT time: 1.153\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:11:43,944 INFO: Final:  oui wert sure how to du that\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:11:43,945 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  83%|████████▎ | 1202/1450 [25:43<05:08,  1.24s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:11:44,079 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:11:44,166 INFO: Partial:  have these fun lyttle parties at nite\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:11:44,247 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:11:45,360 INFO: OPT time: 1.113\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:11:45,360 INFO: Final:  have these fun little parties at night\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:11:45,361 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  83%|████████▎ | 1203/1450 [25:45<05:18,  1.29s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:11:45,483 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:11:45,540 INFO: Partial:  they have nott been mayde aware of this\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:11:45,581 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:11:46,695 INFO: OPT time: 1.114\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:11:46,695 INFO: Final:  they have not been made aware of this\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:11:46,695 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  83%|████████▎ | 1204/1450 [25:46<05:26,  1.33s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:11:46,885 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:11:46,949 INFO: Partial:  at that point sze was already gone\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:11:46,989 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:11:48,130 INFO: OPT time: 1.141\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:11:48,130 INFO: Final:  at that point she was already gone\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:11:48,131 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  83%|████████▎ | 1205/1450 [25:48<05:25,  1.33s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:11:48,289 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:11:48,389 INFO: Partial:  dote want to pei hur to be a baby sitter\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:11:48,466 INFO: Augmented nbest from 100 to 113 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:11:49,953 INFO: OPT time: 1.486\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:11:49,953 INFO: Final:  dint want to pay her to be a baby sitter\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:11:49,954 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  83%|████████▎ | 1206/1450 [25:49<05:32,  1.36s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:11:50,096 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:11:50,189 INFO: Partial:  when did they make that book into a movie\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:11:50,249 INFO: Augmented nbest from 100 to 130 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:11:51,686 INFO: OPT time: 1.437\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:11:51,686 INFO: Final:  when did they make that book into a movie\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:11:51,687 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  83%|████████▎ | 1207/1450 [25:51<06:04,  1.50s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:11:51,796 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:11:51,839 INFO: Partial:  dive seen aull of this before\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:11:51,867 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:11:52,802 INFO: OPT time: 0.935\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:11:52,802 INFO: Final:  i seen all of this before\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:11:52,803 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  83%|████████▎ | 1208/1450 [25:53<06:19,  1.57s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:11:52,998 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:11:53,091 INFO: Partial:  oui had and opry of the flu last both\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:11:53,163 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:11:54,363 INFO: OPT time: 1.200\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:11:54,363 INFO: Final:  we had and opry of the flu last both\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:11:54,364 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  83%|████████▎ | 1209/1450 [25:54<05:45,  1.43s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:11:54,502 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:11:54,586 INFO: Partial:  always a pleasure to sci and talk to them\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:11:54,641 INFO: Augmented nbest from 100 to 149 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:11:56,199 INFO: OPT time: 1.558\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:11:56,199 INFO: Final:  always a pleasure to see and talk to them\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:11:56,200 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  83%|████████▎ | 1210/1450 [25:55<05:53,  1.47s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:11:56,305 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:11:56,382 INFO: Partial:  theirs a parte of mi that mixes them\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:11:56,432 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:11:57,567 INFO: OPT time: 1.135\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:11:57,567 INFO: Final:  theirs a part of me that mixes them\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:11:57,568 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  84%|████████▎ | 1211/1450 [25:57<06:17,  1.58s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:11:57,709 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:11:57,801 INFO: Partial:  due oui have to whate until everyone is whitey\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:11:57,858 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:11:59,242 INFO: OPT time: 1.385\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:11:59,242 INFO: Final:  do oui have to wait until everyone is whitey\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:11:59,243 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  84%|████████▎ | 1212/1450 [25:59<06:01,  1.52s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:11:59,413 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:11:59,540 INFO: Partial:  they visited there grandmother at the nursing home\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:11:59,592 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:12:00,573 INFO: OPT time: 0.981\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:12:00,573 INFO: Final:  they visited their grandmother at the nursing home\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:12:00,573 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  84%|████████▎ | 1213/1450 [26:00<06:10,  1.56s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:12:00,714 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:12:00,786 INFO: Partial:  its gott people something for joy\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:12:00,836 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:12:01,775 INFO: OPT time: 0.939\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:12:01,775 INFO: Final:  its got people something for joy\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:12:01,775 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  84%|████████▎ | 1214/1450 [26:02<05:52,  1.49s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:12:01,917 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:12:02,018 INFO: Partial:  nott everybody has a pitcher perfect bhatti\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:12:02,159 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:12:03,146 INFO: OPT time: 0.987\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:12:03,146 INFO: Final:  not everybody has a pitcher perfect party\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:12:03,147 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  84%|████████▍ | 1215/1450 [26:03<05:30,  1.41s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:12:03,326 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:12:03,395 INFO: Partial:  yu will be learning lats of new stuff\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:12:03,456 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:12:04,581 INFO: OPT time: 1.124\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:12:04,581 INFO: Final:  you will be learning lats of new stuff\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:12:04,581 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  84%|████████▍ | 1216/1450 [26:04<05:26,  1.40s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:12:04,721 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:12:04,762 INFO: Partial:  the people are really nice\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:12:04,794 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:12:05,727 INFO: OPT time: 0.933\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:12:05,727 INFO: Final:  the people are really nice\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:12:05,728 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  84%|████████▍ | 1217/1450 [26:06<05:28,  1.41s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:12:05,921 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:12:05,960 INFO: Partial:  everybody just luvs it\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:12:05,988 INFO: Augmented nbest from 100 to 144 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:12:07,157 INFO: OPT time: 1.169\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:12:07,157 INFO: Final:  everybody just loves it\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:12:07,158 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  84%|████████▍ | 1218/1450 [26:07<05:08,  1.33s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:12:07,324 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:12:07,365 INFO: Partial:  mite be lyke mi\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:12:07,402 INFO: Augmented nbest from 100 to 104 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:12:08,324 INFO: OPT time: 0.922\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:12:08,324 INFO: Final:  you mite be like me\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:12:08,325 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  84%|████████▍ | 1219/1450 [26:08<05:14,  1.36s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:12:08,530 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:12:08,580 INFO: Partial:  guess it was last year\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:12:08,616 INFO: Augmented nbest from 100 to 153 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:12:09,782 INFO: OPT time: 1.166\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:12:09,783 INFO: Final:  guess it was last year\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:12:09,783 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  84%|████████▍ | 1220/1450 [26:09<04:59,  1.30s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:12:09,932 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:12:10,022 INFO: Partial:  it just happened within the last three weeks\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:12:10,063 INFO: Augmented nbest from 100 to 109 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:12:11,252 INFO: OPT time: 1.189\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:12:11,252 INFO: Final:  it just happened within the last three weeks\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:12:11,253 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  84%|████████▍ | 1221/1450 [26:11<05:08,  1.35s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:12:11,436 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:12:11,499 INFO: Partial:  it wasn't really that important to mi\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:12:11,546 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:12:12,666 INFO: OPT time: 1.120\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:12:12,666 INFO: Final:  it wasn't really that important to me\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:12:12,667 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  84%|████████▍ | 1222/1450 [26:12<05:15,  1.39s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:12:12,838 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:12:12,918 INFO: Partial:  dote no of any other state with this policy\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:12:12,955 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:12:14,085 INFO: OPT time: 1.129\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:12:14,085 INFO: Final:  dint know of any other state with this policy\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:12:14,085 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  84%|████████▍ | 1223/1450 [26:14<05:16,  1.39s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:12:14,242 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:12:14,322 INFO: Partial:  could here the terror in is voice\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:12:14,369 INFO: Augmented nbest from 100 to 122 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:12:15,369 INFO: OPT time: 1.000\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:12:15,369 INFO: Final:  could hear the terror in his voice\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:12:15,370 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  84%|████████▍ | 1224/1450 [26:15<05:16,  1.40s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:12:15,545 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:12:15,661 INFO: Partial:  and ai always thought it was kind of out of fashion\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:12:15,745 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:12:16,945 INFO: OPT time: 1.199\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:12:16,945 INFO: Final:  and i always thought it was kind of out of fashion\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:12:16,946 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  84%|████████▍ | 1225/1450 [26:16<05:07,  1.37s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:12:17,152 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:12:17,229 INFO: Partial:  oui did fined several good doctors\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:12:17,271 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:12:18,219 INFO: OPT time: 0.948\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:12:18,219 INFO: Final:  we did find several good doctors\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:12:18,219 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  85%|████████▍ | 1226/1450 [26:18<05:20,  1.43s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:12:18,352 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:12:18,417 INFO: Partial:  it depends what grupe yu happen to be in\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:12:18,470 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:12:19,594 INFO: OPT time: 1.124\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:12:19,594 INFO: Final:  it depends what group you happen to be in\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:12:19,594 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  85%|████████▍ | 1227/1450 [26:19<05:08,  1.38s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:12:19,757 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:12:19,838 INFO: Partial:  atz what ai did for money when ai was growing upp\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:12:19,929 INFO: Augmented nbest from 100 to 106 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:12:21,410 INFO: OPT time: 1.481\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:12:21,410 INFO: Final:  that what i did for money when i was growing up\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:12:21,411 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  85%|████████▍ | 1228/1450 [26:21<05:06,  1.38s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:12:21,561 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:12:21,667 INFO: Partial:  really wanted to goh on the riffing trimpe\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:12:21,751 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:12:22,883 INFO: OPT time: 1.131\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:12:22,883 INFO: Final:  really wanted to go on the riffing trip\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:12:22,883 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  85%|████████▍ | 1229/1450 [26:22<05:33,  1.51s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:12:23,066 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:12:23,123 INFO: Partial:  oui went with sum friends of ours\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:12:23,161 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:12:24,137 INFO: OPT time: 0.976\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:12:24,137 INFO: Final:  we went with some friends of ours\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:12:24,138 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  85%|████████▍ | 1230/1450 [26:24<05:29,  1.50s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:12:24,264 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:12:24,343 INFO: Partial:  can make my pyles frum scratch\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:12:24,415 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:12:25,361 INFO: OPT time: 0.945\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:12:25,361 INFO: Final:  can make my pies from scratch\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:12:25,362 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  85%|████████▍ | 1231/1450 [26:25<05:12,  1.43s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:12:25,472 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:12:25,533 INFO: Partial:  the older old people are so old\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:12:25,591 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:12:26,536 INFO: OPT time: 0.945\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:12:26,536 INFO: Final:  the older old people are so old\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:12:26,537 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  85%|████████▍ | 1232/1450 [26:26<04:57,  1.37s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:12:26,671 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:12:26,782 INFO: Partial:  only nied to due it whats for a total been\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:12:26,853 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:12:27,979 INFO: OPT time: 1.126\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:12:27,979 INFO: Final:  only need to do it once for a total been\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:12:27,980 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  85%|████████▌ | 1233/1450 [26:27<04:43,  1.31s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:12:28,175 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:12:28,254 INFO: Partial:  butt at wirt point did the phair really sette in\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:12:28,339 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:12:29,535 INFO: OPT time: 1.196\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:12:29,535 INFO: Final:  but at what point did the phair really set in\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:12:29,536 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  85%|████████▌ | 1234/1450 [26:29<04:51,  1.35s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:12:29,679 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:12:29,747 INFO: Partial:  have been in persson aull my life\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:12:29,852 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:12:30,960 INFO: OPT time: 1.108\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:12:30,960 INFO: Final:  have been in person all my life\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:12:30,961 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  85%|████████▌ | 1235/1450 [26:30<05:03,  1.41s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:12:31,081 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:12:31,135 INFO: Partial:  save gott a good thing going\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:12:31,169 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:12:32,108 INFO: OPT time: 0.939\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:12:32,109 INFO: Final:  lave got a good thing going\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:12:32,109 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  85%|████████▌ | 1236/1450 [26:32<05:02,  1.42s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:12:32,283 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:12:32,348 INFO: Partial:  the whey yu handle yourself is expensive\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:12:32,384 INFO: Augmented nbest from 100 to 108 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:12:33,368 INFO: OPT time: 0.984\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:12:33,368 INFO: Final:  the way you handle yourself is expensive\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:12:33,368 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  85%|████████▌ | 1237/1450 [26:33<04:44,  1.34s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:12:33,485 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:12:33,531 INFO: Partial:  my wife would just love that\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:12:33,562 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:12:34,405 INFO: OPT time: 0.843\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:12:34,405 INFO: Final:  my wife would just love that\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:12:34,406 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  85%|████████▌ | 1238/1450 [26:34<04:38,  1.31s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:12:34,587 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:12:34,664 INFO: Partial:  our values of diversity and inclusion are drug\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:12:34,716 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:12:35,664 INFO: OPT time: 0.947\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:12:35,664 INFO: Final:  our values of diversity and inclusion are drug\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:12:35,665 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  85%|████████▌ | 1239/1450 [26:35<04:19,  1.23s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:12:35,791 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:12:35,892 INFO: Partial:  yu play regular difficulty it is nott so bad\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:12:35,976 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:12:37,098 INFO: OPT time: 1.122\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:12:37,098 INFO: Final:  if you play regular difficulty it is not so bad\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:12:37,098 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  86%|████████▌ | 1240/1450 [26:37<04:20,  1.24s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:12:37,297 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:12:37,403 INFO: Partial:  where living in a relatively new erria\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:12:37,463 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:12:38,407 INFO: OPT time: 0.943\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:12:38,407 INFO: Final:  where living in a relatively new area\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:12:38,407 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  86%|████████▌ | 1241/1450 [26:38<04:31,  1.30s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:12:38,597 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:12:38,687 INFO: Partial:  downe there on the fixing wife bye the pilz\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:12:38,760 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:12:39,880 INFO: OPT time: 1.119\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:12:39,880 INFO: Final:  down there on the fixing wife by the pills\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:12:39,881 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  86%|████████▌ | 1242/1450 [26:39<04:30,  1.30s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:12:40,003 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:12:40,067 INFO: Partial:  well aisle be with other people\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:12:40,118 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:12:40,968 INFO: OPT time: 0.850\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:12:40,968 INFO: Final:  well heil be with other people\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:12:40,969 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  86%|████████▌ | 1243/1450 [26:41<04:39,  1.35s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:12:41,105 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:12:41,170 INFO: Partial:  guess oui due get it frum people to\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:12:41,216 INFO: Augmented nbest from 100 to 112 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:12:42,573 INFO: OPT time: 1.357\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:12:42,573 INFO: Final:  guess we do get it from people to\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:12:42,574 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  86%|████████▌ | 1244/1450 [26:42<04:22,  1.27s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:12:42,707 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:12:42,773 INFO: Partial:  maybe oui should move to the south\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:12:42,805 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:12:43,931 INFO: OPT time: 1.125\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:12:43,931 INFO: Final:  maybe we should move to the south\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:12:43,931 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  86%|████████▌ | 1245/1450 [26:44<04:41,  1.37s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:12:44,109 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:12:44,177 INFO: Partial:  how many of these coins will oui nied\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:12:44,240 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:12:45,369 INFO: OPT time: 1.129\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:12:45,369 INFO: Final:  how many of these coins will we nead\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:12:45,370 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  86%|████████▌ | 1246/1450 [26:45<04:39,  1.37s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:12:45,515 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:12:45,602 INFO: Partial:  yu drink a lot of caffeine yule stay away\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:12:45,671 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:12:46,839 INFO: OPT time: 1.168\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:12:46,839 INFO: Final:  you drink a lot of caffeine yule stay awake\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:12:46,840 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  86%|████████▌ | 1247/1450 [26:46<04:41,  1.39s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:12:47,019 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:12:47,139 INFO: Partial:  showing data is an excellent whey to prove a point\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:12:47,242 INFO: Augmented nbest from 100 to 138 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:12:49,122 INFO: OPT time: 1.880\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:12:49,122 INFO: Final:  showing data is an excellent way to prove a point\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:12:49,122 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  86%|████████▌ | 1248/1450 [26:48<04:45,  1.41s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:12:49,326 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:12:49,382 INFO: Partial:  it was a cordless phone\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:12:49,413 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:12:50,262 INFO: OPT time: 0.849\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:12:50,262 INFO: Final:  it was a cordless phone\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:12:50,263 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  86%|████████▌ | 1249/1450 [26:50<05:36,  1.67s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:12:50,427 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:12:50,505 INFO: Partial:  due nott charge except for emergencies\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:12:50,538 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:12:51,477 INFO: OPT time: 0.939\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:12:51,477 INFO: Final:  do not charge except for emergencies\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:12:51,478 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  86%|████████▌ | 1250/1450 [26:51<05:02,  1.51s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:12:51,629 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:12:51,705 INFO: Partial:  be there in the afternoon\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:12:51,746 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:12:52,540 INFO: OPT time: 0.794\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:12:52,540 INFO: Final:  isle be there in the afternoon\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:12:52,541 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  86%|████████▋ | 1251/1450 [26:52<04:43,  1.42s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:12:52,734 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:12:52,843 INFO: Partial:  latz goh visit for lyke a shortt weekend or something\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:12:52,922 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:12:54,296 INFO: OPT time: 1.374\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:12:54,297 INFO: Final:  lets go visit for like a short weekend or something\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:12:54,297 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  86%|████████▋ | 1252/1450 [26:53<04:20,  1.32s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:12:54,439 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:12:54,502 INFO: Partial:  think atz the whey this is dunne\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:12:54,556 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:12:55,512 INFO: OPT time: 0.956\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:12:55,512 INFO: Final:  think gnats the way this is done\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:12:55,512 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  86%|████████▋ | 1253/1450 [26:55<04:45,  1.45s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:12:55,638 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:12:55,682 INFO: Partial:  put of the system\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:12:55,712 INFO: Augmented nbest from 100 to 117 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:12:56,524 INFO: OPT time: 0.811\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:12:56,524 INFO: Final:  part of the system\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:12:56,524 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  86%|████████▋ | 1254/1450 [26:56<04:30,  1.38s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:12:56,639 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:12:56,751 INFO: Partial:  everyone nose how to make a tuna phish sumlin\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:12:56,825 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:12:58,027 INFO: OPT time: 1.201\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:12:58,027 INFO: Final:  everyone knows how to make a tuna fish sumlin\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:12:58,028 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  87%|████████▋ | 1255/1450 [26:57<04:07,  1.27s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:12:58,147 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:12:58,205 INFO: Partial:  get remember the guiles name\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:12:58,245 INFO: Augmented nbest from 100 to 107 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:12:59,076 INFO: OPT time: 0.831\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:12:59,076 INFO: Final:  get remember the guys name\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:12:59,076 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  87%|████████▋ | 1256/1450 [26:59<04:19,  1.34s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:12:59,248 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:12:59,307 INFO: Partial:  what due yu think about this research\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:12:59,339 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:13:00,197 INFO: OPT time: 0.858\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:13:00,197 INFO: Final:  what do you think about this research\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:13:00,197 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  87%|████████▋ | 1257/1450 [27:00<04:01,  1.25s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:13:00,348 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:13:00,474 INFO: Partial:  oui love wheatie fresh vegetables in the summer\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:13:00,547 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:13:01,669 INFO: OPT time: 1.122\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:13:01,669 INFO: Final:  we love meaty fresh vegetables in the summer\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:13:01,669 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  87%|████████▋ | 1258/1450 [27:01<03:52,  1.21s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:13:01,854 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:13:01,897 INFO: Partial:  yu can sci what ai mien\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:13:01,938 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:13:02,923 INFO: OPT time: 0.984\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:13:02,923 INFO: Final:  u can cie what ai mean\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:13:02,923 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  87%|████████▋ | 1259/1450 [27:03<04:06,  1.29s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:13:03,055 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:13:03,166 INFO: Partial:  am and asian women with a whyte boyfriend\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:13:03,234 INFO: Augmented nbest from 100 to 118 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:13:04,622 INFO: OPT time: 1.387\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:13:04,622 INFO: Final:  am an asian women with a white boyfriend\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:13:04,622 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  87%|████████▋ | 1260/1450 [27:04<04:03,  1.28s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:13:04,758 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:13:04,830 INFO: Partial:  oui felt goatee\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:13:04,888 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:13:05,734 INFO: OPT time: 0.846\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:13:05,734 INFO: Final:  we felt guilty\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:13:05,735 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  87%|████████▋ | 1261/1450 [27:06<04:25,  1.41s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:13:05,863 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:13:05,896 INFO: Partial:  really lyke it\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:13:05,920 INFO: Augmented nbest from 100 to 126 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:13:06,759 INFO: OPT time: 0.839\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:13:06,760 INFO: Final:  really like it\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:13:06,760 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  87%|████████▋ | 1262/1450 [27:07<04:07,  1.32s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:13:06,963 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:13:07,063 INFO: Partial:  can sit in the sun aull dey around the poul\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:13:07,189 INFO: Augmented nbest from 100 to 131 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:13:08,760 INFO: OPT time: 1.571\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:13:08,760 INFO: Final:  can sit in the sun all day around the pool\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:13:08,761 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  87%|████████▋ | 1263/1450 [27:08<03:49,  1.23s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:13:08,873 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:13:08,937 INFO: Partial:  really dote want to sci them goh\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:13:09,001 INFO: Augmented nbest from 100 to 116 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:13:10,209 INFO: OPT time: 1.208\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:13:10,209 INFO: Final:  really dote want to see them go\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:13:10,210 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  87%|████████▋ | 1264/1450 [27:10<04:31,  1.46s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:13:10,374 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:13:10,466 INFO: Partial:  aull what a reward or whatever\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:13:10,518 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:13:11,371 INFO: OPT time: 0.853\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:13:11,372 INFO: Final:  the all what a reward or whatever\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:13:11,372 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  87%|████████▋ | 1265/1450 [27:11<04:29,  1.46s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:13:11,575 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:13:11,638 INFO: Partial:  quit doing that myself\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:13:11,665 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:13:12,478 INFO: OPT time: 0.813\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:13:12,478 INFO: Final:  i quit doing that myself\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:13:12,478 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  87%|████████▋ | 1266/1450 [27:12<04:11,  1.37s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:13:12,675 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:13:12,745 INFO: Partial:  the restaurant must bags the expansion\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:13:12,792 INFO: Augmented nbest from 100 to 104 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:13:13,755 INFO: OPT time: 0.963\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:13:13,755 INFO: Final:  the restaurant must back the expansion\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:13:13,755 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  87%|████████▋ | 1267/1450 [27:13<03:56,  1.29s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:13:13,877 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:13:13,949 INFO: Partial:  where due yu goh camping at around here\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:13:14,002 INFO: Augmented nbest from 100 to 128 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:13:15,185 INFO: OPT time: 1.183\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:13:15,185 INFO: Final:  where du you go camping at around here\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:13:15,186 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  87%|████████▋ | 1268/1450 [27:15<03:54,  1.29s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:13:15,380 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:13:15,450 INFO: Partial:  try to save that for the weekend\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:13:15,490 INFO: Augmented nbest from 100 to 127 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:13:16,685 INFO: OPT time: 1.195\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:13:16,685 INFO: Final:  try to save that for the weekend\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:13:16,686 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  88%|████████▊ | 1269/1450 [27:16<04:00,  1.33s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:13:16,885 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:13:16,919 INFO: Partial:  when does school start\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:13:16,950 INFO: Augmented nbest from 100 to 116 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:13:17,867 INFO: OPT time: 0.917\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:13:17,868 INFO: Final:  when does school start\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:13:17,868 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  88%|████████▊ | 1270/1450 [27:18<04:08,  1.38s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:13:17,986 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:13:18,036 INFO: Partial:  atz just the whey it was\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:13:18,078 INFO: Augmented nbest from 100 to 106 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:13:19,055 INFO: OPT time: 0.976\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:13:19,055 INFO: Final:  that just the way it was\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:13:19,055 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  88%|████████▊ | 1271/1450 [27:19<03:56,  1.32s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:13:19,189 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:13:19,274 INFO: Partial:  vegetables grow in the fiends\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:13:19,311 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:13:20,262 INFO: OPT time: 0.951\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:13:20,262 INFO: Final:  vegetables grow in the fields\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:13:20,262 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  88%|████████▊ | 1272/1450 [27:20<03:48,  1.28s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:13:20,393 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:13:20,514 INFO: Partial:  had ended upp it a very simply leite erria\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:13:20,608 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:13:21,813 INFO: OPT time: 1.205\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:13:21,813 INFO: Final:  had ended up it a very simply leet area\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:13:21,814 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  88%|████████▊ | 1273/1450 [27:21<03:42,  1.26s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:13:21,998 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:13:22,107 INFO: Partial:  note get my rata a those baber\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:13:22,264 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:13:23,401 INFO: OPT time: 1.137\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:13:23,401 INFO: Final:  not get my rata of those baber\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:13:23,402 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  88%|████████▊ | 1274/1450 [27:23<03:56,  1.35s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:13:23,608 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:13:23,674 INFO: Partial:  wooden them to corps to get won for hur\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:13:23,757 INFO: Augmented nbest from 100 to 108 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:13:24,930 INFO: OPT time: 1.173\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:13:24,930 INFO: Final:  wooden them to core to get one for her\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:13:24,930 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  88%|████████▊ | 1275/1450 [27:24<04:08,  1.42s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:13:25,105 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:13:25,186 INFO: Partial:  then ai think yu have a morr appealable oppress\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:13:25,252 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:13:26,634 INFO: OPT time: 1.381\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:13:26,634 INFO: Final:  then ai think you have a more appealable oppress\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:13:26,635 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  88%|████████▊ | 1276/1450 [27:26<04:12,  1.45s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:13:26,808 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:13:26,835 INFO: Partial:  just doanh lyke that\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:13:26,863 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:13:27,663 INFO: OPT time: 0.800\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:13:27,663 INFO: Final:  just doan like that\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:13:27,664 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  88%|████████▊ | 1277/1450 [27:28<04:24,  1.53s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:13:27,807 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:13:27,904 INFO: Partial:  yu sci it trying theirs problem\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:13:27,963 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:13:28,823 INFO: OPT time: 0.859\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:13:28,823 INFO: Final:  you see it trying theirs problem\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:13:28,823 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  88%|████████▊ | 1278/1450 [27:29<03:57,  1.38s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:13:29,013 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:13:29,080 INFO: Partial:  whats the want of the\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:13:29,151 INFO: Augmented nbest from 100 to 131 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:13:30,137 INFO: OPT time: 0.985\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:13:30,137 INFO: Final:  whats the one of the\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:13:30,138 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  88%|████████▊ | 1279/1450 [27:30<03:44,  1.31s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:13:30,319 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:13:30,420 INFO: Partial:  wayson even coverage for in\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:13:30,494 INFO: Augmented nbest from 100 to 102 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:13:31,316 INFO: OPT time: 0.822\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:13:31,316 INFO: Final:  watches even coverage for in\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:13:31,317 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  88%|████████▊ | 1280/1450 [27:31<03:43,  1.31s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:13:31,520 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:13:31,693 INFO: Partial:  engines of arter whore dollars passing thru the kanai\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:13:31,869 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:13:33,322 INFO: OPT time: 1.453\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:13:33,322 INFO: Final:  engines of arter or dollars passing through the kanai\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:13:33,323 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  88%|████████▊ | 1281/1450 [27:32<03:35,  1.27s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:13:33,531 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:13:33,623 INFO: Partial:  no when a was working things wa deferral\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:13:33,733 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:13:34,887 INFO: OPT time: 1.154\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:13:34,887 INFO: Final:  no when a was working things the deferral\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:13:34,888 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  88%|████████▊ | 1282/1450 [27:34<04:10,  1.49s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:13:35,031 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:13:35,086 INFO: Partial:  joist things upp lyttle butt\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:13:35,149 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:13:36,084 INFO: OPT time: 0.935\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:13:36,084 INFO: Final:  just things up little bit\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:13:36,085 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  88%|████████▊ | 1283/1450 [27:36<04:12,  1.51s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:13:36,234 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:13:36,435 INFO: Partial:  mover is popular it deis in elaters rigor\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:13:37,318 INFO: Augmented nbest from 100 to 108 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:13:38,515 INFO: OPT time: 1.196\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:13:38,515 INFO: Final:  mover is popular it does in arens rigor\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:13:38,515 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  89%|████████▊ | 1284/1450 [27:37<03:55,  1.42s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:13:38,661 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:13:38,740 INFO: Partial:  doanh no if yell ever siem again\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:13:38,846 INFO: Augmented nbest from 100 to 108 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:13:40,001 INFO: OPT time: 1.156\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:13:40,001 INFO: Final:  doan know if yelle ever seem again\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:13:40,002 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  89%|████████▊ | 1285/1450 [27:39<04:44,  1.72s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:13:40,147 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:13:40,274 INFO: Partial:  ai loved in new yu city or washington\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:13:40,389 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:13:41,545 INFO: OPT time: 1.156\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:13:41,546 INFO: Final:  if ai loved in new yew city or washington\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:13:41,546 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  89%|████████▊ | 1286/1450 [27:41<04:30,  1.65s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:13:41,748 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:13:41,795 INFO: Partial:  yu want to home over after skew\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:13:41,852 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:13:42,799 INFO: OPT time: 0.947\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:13:42,799 INFO: Final:  you want to home over after your\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:13:42,800 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  89%|████████▉ | 1287/1450 [27:42<04:23,  1.62s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:13:42,950 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:13:43,088 INFO: Partial:  theirs frerking tilles and both says of the river\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:13:43,399 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:13:44,582 INFO: OPT time: 1.183\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:13:44,582 INFO: Final:  theirs rowing tiles and both said of the river\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:13:44,583 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  89%|████████▉ | 1288/1450 [27:44<04:04,  1.51s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:13:44,767 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:13:44,893 INFO: Partial:  it sames the people just goh in suckers\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:13:45,054 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:13:46,202 INFO: OPT time: 1.148\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:13:46,202 INFO: Final:  it seems the people just go in suckers\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:13:46,203 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  89%|████████▉ | 1289/1450 [27:46<04:16,  1.59s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:13:46,363 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:13:46,422 INFO: Partial:  what oui canam mutt with\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:13:46,549 INFO: Augmented nbest from 100 to 154 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:13:47,971 INFO: OPT time: 1.422\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:13:47,971 INFO: Final:  what we canam a with\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:13:47,972 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  89%|████████▉ | 1290/1450 [27:47<04:16,  1.60s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:13:48,166 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:13:48,324 INFO: Partial:  computers pisses are very complicated\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:13:48,437 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:13:49,373 INFO: OPT time: 0.936\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:13:49,373 INFO: Final:  computers buses are very complicated\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:13:49,373 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  89%|████████▉ | 1291/1450 [27:49<04:22,  1.65s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:13:49,568 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:13:49,620 INFO: Partial:  where always be taxes for something\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:13:49,655 INFO: Augmented nbest from 100 to 127 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:13:50,806 INFO: OPT time: 1.150\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:13:50,806 INFO: Final:  where always be taxes for something\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:13:50,807 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  89%|████████▉ | 1292/1450 [27:50<04:08,  1.58s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:13:50,967 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:13:51,115 INFO: Partial:  thinkin sub causes nat is correct\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:13:51,351 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:13:52,324 INFO: OPT time: 0.972\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:13:52,324 INFO: Final:  thinkin some causes that is correct\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:13:52,324 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  89%|████████▉ | 1293/1450 [27:52<04:00,  1.53s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:13:52,482 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:13:52,608 INFO: Partial:  will home the country rymer eventually\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:13:52,849 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:13:53,787 INFO: OPT time: 0.938\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:13:53,787 INFO: Final:  they will home the country rammer eventually\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:13:53,788 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  89%|████████▉ | 1294/1450 [27:53<03:58,  1.53s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:13:53,981 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:13:54,069 INFO: Partial:  sudden be that whey ai owned think\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:13:54,146 INFO: Augmented nbest from 100 to 165 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:13:56,038 INFO: OPT time: 1.892\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:13:56,038 INFO: Final:  sudden be that way ai old think\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:13:56,039 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  89%|████████▉ | 1295/1450 [27:55<03:53,  1.51s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:13:56,183 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:13:56,285 INFO: Partial:  caught of has fall cibro un the place\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:13:56,835 INFO: Augmented nbest from 100 to 121 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:13:58,242 INFO: OPT time: 1.407\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:13:58,242 INFO: Final:  cott of has fall deploy on the place\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:13:58,242 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  89%|████████▉ | 1296/1450 [27:57<04:26,  1.73s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:13:58,401 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:13:58,480 INFO: Partial:  is aull about every contentions and many\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:13:58,573 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:13:59,693 INFO: OPT time: 1.120\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:13:59,693 INFO: Final:  it is all about every contentions and many\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:13:59,693 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  89%|████████▉ | 1297/1450 [27:59<04:46,  1.87s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:13:59,895 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:13:59,946 INFO: Partial:  its pott of the equation\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:13:59,969 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:14:00,776 INFO: OPT time: 0.807\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:14:00,776 INFO: Final:  its part of the equation\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:14:00,777 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  90%|████████▉ | 1298/1450 [28:01<04:25,  1.75s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:14:00,892 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:14:00,955 INFO: Partial:  theirs another aspect of this\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:14:00,988 INFO: Augmented nbest from 100 to 110 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:14:01,836 INFO: OPT time: 0.849\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:14:01,837 INFO: Final:  theirs another aspect of this\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:14:01,837 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  90%|████████▉ | 1299/1450 [28:02<03:53,  1.55s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:14:01,995 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:14:02,070 INFO: Partial:  hurd a full volatile\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:14:02,122 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:14:02,818 INFO: OPT time: 0.696\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:14:02,819 INFO: Final:  he heard a full volatile\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:14:02,819 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  90%|████████▉ | 1300/1450 [28:03<03:30,  1.40s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:14:02,999 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:14:03,044 INFO: Partial:  oui does goulden stand it\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:14:03,078 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:14:04,016 INFO: OPT time: 0.938\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:14:04,016 INFO: Final:  we does gooden stand it\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:14:04,016 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  90%|████████▉ | 1301/1450 [28:04<03:10,  1.28s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:14:04,200 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:14:04,297 INFO: Partial:  the story was a very deporting story\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:14:04,348 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:14:05,478 INFO: OPT time: 1.129\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:14:05,478 INFO: Final:  the story was a very deporting story\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:14:05,478 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  90%|████████▉ | 1302/1450 [28:05<03:05,  1.25s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:14:05,600 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:14:05,679 INFO: Partial:  popular kind of shu for hacking\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:14:05,723 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:14:06,660 INFO: OPT time: 0.937\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:14:06,660 INFO: Final:  popular kind of shoe for hacking\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:14:06,660 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  90%|████████▉ | 1303/1450 [28:06<03:13,  1.31s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:14:06,803 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:14:06,863 INFO: Partial:  yu want to my something\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:14:06,898 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:14:07,707 INFO: OPT time: 0.808\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:14:07,707 INFO: Final:  due you want to my something\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:14:07,707 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  90%|████████▉ | 1304/1450 [28:08<03:06,  1.28s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:14:07,905 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:14:07,964 INFO: Partial:  what would yu due about it\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:14:08,003 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:14:08,818 INFO: OPT time: 0.815\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:14:08,818 INFO: Final:  what would you do about it\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:14:08,819 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  90%|█████████ | 1305/1450 [28:09<02:54,  1.21s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:14:09,007 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:14:09,078 INFO: Partial:  this is justa storti point\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:14:09,124 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:14:09,976 INFO: OPT time: 0.852\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:14:09,976 INFO: Final:  this is just a storti point\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:14:09,977 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  90%|█████████ | 1306/1450 [28:10<02:49,  1.18s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:14:10,112 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:14:10,242 INFO: Partial:  when due yu want the babysitter to can\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:14:10,305 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:14:11,295 INFO: OPT time: 0.989\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:14:11,295 INFO: Final:  when to you want the babysitter to came\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:14:11,295 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  90%|█████████ | 1307/1450 [28:11<02:47,  1.17s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:14:11,413 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:14:11,568 INFO: Partial:  dote no what your mighty pacific is on your phone\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:14:11,707 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:14:13,095 INFO: OPT time: 1.387\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:14:13,095 INFO: Final:  dent know what your mighty pacific is on your phone\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:14:13,095 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  90%|█████████ | 1308/1450 [28:12<02:52,  1.22s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:14:13,222 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:14:13,331 INFO: Partial:  dote ditties any time difference\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:14:13,420 INFO: Augmented nbest from 100 to 106 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:14:14,389 INFO: OPT time: 0.969\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:14:14,390 INFO: Final:  they dot notice any time difference\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:14:14,390 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  90%|█████████ | 1309/1450 [28:14<03:16,  1.39s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:14:14,523 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:14:14,601 INFO: Partial:  it was a bittersweet joy\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:14:14,648 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:14:15,590 INFO: OPT time: 0.941\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:14:15,590 INFO: Final:  it was a bittersweet joy\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:14:15,591 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  90%|█████████ | 1310/1450 [28:15<03:10,  1.36s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:14:15,723 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:14:15,811 INFO: Partial:  think its definitely gotten bettor\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:14:15,858 INFO: Augmented nbest from 100 to 113 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:14:16,731 INFO: OPT time: 0.873\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:14:16,731 INFO: Final:  think its definitely gotten better\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:14:16,732 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  90%|█████████ | 1311/1450 [28:17<03:02,  1.31s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:14:16,923 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:14:17,028 INFO: Partial:  they due nott pennies anything pursifull these daze\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:14:17,106 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:14:18,266 INFO: OPT time: 1.159\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:14:18,266 INFO: Final:  they due not pennies anything pursifull these days\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:14:18,266 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  90%|█████████ | 1312/1450 [28:18<02:54,  1.26s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:14:18,429 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:14:18,502 INFO: Partial:  dote have a problem at aull with employees\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:14:18,553 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:14:19,682 INFO: OPT time: 1.129\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:14:19,682 INFO: Final:  dent have a problem at all with employees\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:14:19,683 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  91%|█████████ | 1313/1450 [28:19<03:04,  1.34s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:14:19,828 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:14:19,915 INFO: Partial:  take a sheryl and get dressed\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:14:19,991 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:14:20,852 INFO: OPT time: 0.861\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:14:20,852 INFO: Final:  take a shower and get dressed\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:14:20,853 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  91%|█████████ | 1314/1450 [28:21<03:05,  1.37s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:14:21,034 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:14:21,099 INFO: Partial:  both of my katz or dillard\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:14:21,144 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:14:22,098 INFO: OPT time: 0.954\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:14:22,098 INFO: Final:  both of my cats or deployed\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:14:22,098 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  91%|█████████ | 1315/1450 [28:22<02:56,  1.31s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:14:22,234 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:14:22,346 INFO: Partial:  just lett out deduct spied any money\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:14:22,461 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:14:23,415 INFO: OPT time: 0.953\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:14:23,415 INFO: Final:  just let out deduct spend any money\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:14:23,415 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  91%|█████████ | 1316/1450 [28:23<02:52,  1.29s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:14:23,544 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:14:23,622 INFO: Partial:  there could be a lot of options\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:14:23,670 INFO: Augmented nbest from 100 to 104 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:14:24,599 INFO: OPT time: 0.928\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:14:24,599 INFO: Final:  there could be a lot of options\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:14:24,600 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  91%|█████████ | 1317/1450 [28:24<02:52,  1.30s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:14:24,741 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:14:24,826 INFO: Partial:  other that that they have the usual stuff\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:14:24,880 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:14:26,004 INFO: OPT time: 1.124\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:14:26,004 INFO: Final:  other than that they have the usual stuff\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:14:26,004 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  91%|█████████ | 1318/1450 [28:26<02:46,  1.26s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:14:26,144 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:14:26,178 INFO: Partial:  is really sterry\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:14:26,203 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:14:26,891 INFO: OPT time: 0.688\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:14:26,891 INFO: Final:  it is really scary\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:14:26,892 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  91%|█████████ | 1319/1450 [28:27<02:51,  1.31s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:14:27,045 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:14:27,116 INFO: Partial:  theirs at least won katt in the house\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:14:27,184 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:14:28,178 INFO: OPT time: 0.994\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:14:28,179 INFO: Final:  theirs at least one cat in the house\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:14:28,179 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  91%|█████████ | 1320/1450 [28:28<02:33,  1.18s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:14:28,348 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:14:28,422 INFO: Partial:  nott sure how there going to foell about it\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:14:28,489 INFO: Augmented nbest from 100 to 158 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:14:30,447 INFO: OPT time: 1.957\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:14:30,447 INFO: Final:  not sure how their going to feel about it\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:14:30,447 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  91%|█████████ | 1321/1450 [28:29<02:36,  1.21s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:14:30,553 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:14:30,596 INFO: Partial:  sze did very wheel there\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:14:30,632 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:14:31,484 INFO: OPT time: 0.852\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:14:31,484 INFO: Final:  she did very wheel there\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:14:31,485 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  91%|█████████ | 1322/1450 [28:31<03:15,  1.53s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:14:31,656 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:14:31,702 INFO: Partial:  sze dunne live with us\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:14:31,743 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:14:32,595 INFO: OPT time: 0.852\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:14:32,595 INFO: Final:  she done live with us\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:14:32,595 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  91%|█████████ | 1323/1450 [28:32<02:55,  1.38s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:14:32,760 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:14:32,801 INFO: Partial:  that really wind\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:14:32,839 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:14:33,522 INFO: OPT time: 0.682\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:14:33,522 INFO: Final:  that really weird\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:14:33,522 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  91%|█████████▏| 1324/1450 [28:34<02:43,  1.30s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:14:33,662 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:14:33,755 INFO: Partial:  its a pleasure to make your appointees\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:14:33,799 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:14:34,786 INFO: OPT time: 0.986\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:14:34,786 INFO: Final:  its a pleasure to make your appointees\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:14:34,787 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  91%|█████████▏| 1325/1450 [28:34<02:28,  1.19s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:14:34,965 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:14:35,072 INFO: Partial:  hope yu have enjoyed this tutorial\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:14:35,110 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:14:36,060 INFO: OPT time: 0.950\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:14:36,060 INFO: Final:  hope you have enjoyed this tutorial\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:14:36,061 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  91%|█████████▏| 1326/1450 [28:36<02:30,  1.21s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:14:36,168 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:14:36,248 INFO: Partial:  the jury system insel is nott picked\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:14:36,332 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:14:37,320 INFO: OPT time: 0.988\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:14:37,320 INFO: Final:  the jury system insult is not picked\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:14:37,321 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  92%|█████████▏| 1327/1450 [28:37<02:31,  1.23s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:14:37,475 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:14:37,605 INFO: Partial:  my parents always said if oui wanted a carre oui hatt to dey for it\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:14:37,797 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:14:39,733 INFO: OPT time: 1.937\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:14:39,734 INFO: Final:  my parents always said if oui wanted a carre oui had to day for it\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:14:39,734 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  92%|█████████▏| 1328/1450 [28:38<02:31,  1.24s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:14:39,880 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:14:40,006 INFO: Partial:  penton those at bye the septic take\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:14:40,095 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:14:41,080 INFO: OPT time: 0.985\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:14:41,080 INFO: Final:  penton those out by the septic take\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:14:41,081 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  92%|█████████▏| 1329/1450 [28:41<03:12,  1.59s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:14:41,288 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:14:41,382 INFO: Partial:  it happens every single month without foell\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:14:41,432 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:14:42,411 INFO: OPT time: 0.979\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:14:42,411 INFO: Final:  it happens every single month without feel\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:14:42,412 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  92%|█████████▏| 1330/1450 [28:42<03:02,  1.52s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:14:42,587 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:14:42,717 INFO: Partial:  animates had somehow gotten into the dr\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:14:42,821 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:14:43,963 INFO: OPT time: 1.142\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:14:43,963 INFO: Final:  animates had somehow gotten into the trash\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:14:43,964 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  92%|█████████▏| 1331/1450 [28:43<02:53,  1.46s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:14:44,094 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:14:44,146 INFO: Partial:  dunne sum other things to\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:14:44,191 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:14:44,993 INFO: OPT time: 0.802\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:14:44,993 INFO: Final:  done some other things to\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:14:44,994 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  92%|█████████▏| 1332/1450 [28:45<02:55,  1.49s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:14:45,194 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:14:45,310 INFO: Partial:  kind of a pectic in the worse ty thing\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:14:45,413 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:14:46,773 INFO: OPT time: 1.360\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:14:46,774 INFO: Final:  kind of a picnic in the worse thai thing\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:14:46,774 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  92%|█████████▏| 1333/1450 [28:46<02:38,  1.35s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:14:46,900 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:14:46,993 INFO: Partial:  actually this fall ai am going bakke to school\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:14:47,051 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:14:48,242 INFO: OPT time: 1.190\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:14:48,242 INFO: Final:  actually this fall i am going back to school\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:14:48,242 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  92%|█████████▏| 1334/1450 [28:48<02:51,  1.48s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:14:48,399 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:14:48,480 INFO: Partial:  our immigration history\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:14:48,517 INFO: Augmented nbest from 100 to 105 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:14:49,189 INFO: OPT time: 0.672\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:14:49,189 INFO: Final:  our immigration history\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:14:49,189 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  92%|█████████▏| 1335/1450 [28:49<02:49,  1.48s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:14:49,300 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:14:49,365 INFO: Partial:  oui used to always enjoy wanting\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:14:49,391 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:14:50,364 INFO: OPT time: 0.973\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:14:50,364 INFO: Final:  we used to always enjoy watching\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:14:50,365 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  92%|█████████▏| 1336/1450 [28:50<02:30,  1.32s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:14:50,501 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:14:50,551 INFO: Partial:  yu goh outside and play\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:14:50,581 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:14:51,276 INFO: OPT time: 0.695\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:14:51,276 INFO: Final:  you go outside and play\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:14:51,277 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  92%|█████████▏| 1337/1450 [28:51<02:24,  1.28s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:14:51,404 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:14:51,491 INFO: Partial:  gude thing that it was a provant school\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:14:51,576 INFO: Augmented nbest from 100 to 103 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:14:52,718 INFO: OPT time: 1.141\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:14:52,718 INFO: Final:  good thing that it was a private school\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:14:52,718 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  92%|█████████▏| 1338/1450 [28:52<02:10,  1.17s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:14:52,912 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:14:52,980 INFO: Partial:  no to women who went there\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:14:53,036 INFO: Augmented nbest from 100 to 149 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:14:54,432 INFO: OPT time: 1.395\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:14:54,432 INFO: Final:  no to women who went there\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:14:54,432 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  92%|█████████▏| 1339/1450 [28:54<02:18,  1.25s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:14:54,613 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:14:54,717 INFO: Partial:  them darted a jig dissing policy\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:14:54,832 INFO: Augmented nbest from 100 to 127 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:14:56,029 INFO: OPT time: 1.197\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:14:56,029 INFO: Final:  them darted a jig dissing policy\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:14:56,030 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  92%|█████████▏| 1340/1450 [28:55<02:32,  1.39s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:14:56,222 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:14:56,301 INFO: Partial:  think nyers about seventy of them\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:14:56,334 INFO: Augmented nbest from 100 to 132 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:14:57,468 INFO: OPT time: 1.134\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:14:57,469 INFO: Final:  think theirs about seventy of them\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:14:57,469 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  92%|█████████▏| 1341/1450 [28:57<02:38,  1.45s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:14:57,618 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:14:57,690 INFO: Partial:  if your serving another teac with it\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:14:57,746 INFO: Augmented nbest from 100 to 115 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:14:58,756 INFO: OPT time: 1.010\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:14:58,756 INFO: Final:  if your serving another take with it\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:14:58,757 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  93%|█████████▎| 1342/1450 [28:58<02:36,  1.45s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:14:58,925 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:14:58,980 INFO: Partial:  hurd different\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:14:59,004 INFO: Augmented nbest from 100 to 108 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:14:59,654 INFO: OPT time: 0.650\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:14:59,654 INFO: Final:  i heard different\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:14:59,655 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  93%|█████████▎| 1343/1450 [29:00<02:29,  1.40s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:14:59,826 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:14:59,914 INFO: Partial:  dote himself there school basically\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:14:59,963 INFO: Augmented nbest from 100 to 106 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:15:00,795 INFO: OPT time: 0.832\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:15:00,795 INFO: Final:  he dote himself their school basically\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:15:00,796 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  93%|█████████▎| 1344/1450 [29:01<02:12,  1.25s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:15:00,931 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:15:00,981 INFO: Partial:  then ai hur a very nott explosion\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:15:01,036 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:15:02,021 INFO: OPT time: 0.985\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:15:02,021 INFO: Final:  then ai heard a very not explosion\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:15:02,022 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  93%|█████████▎| 1345/1450 [29:02<02:07,  1.22s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:15:02,131 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:15:02,266 INFO: Partial:  das is a potato favre\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:15:02,674 INFO: Augmented nbest from 100 to 101 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:15:03,646 INFO: OPT time: 0.972\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:15:03,646 INFO: Final:  das is a potato favor\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:15:03,647 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  93%|█████████▎| 1346/1450 [29:03<02:06,  1.22s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:15:03,843 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:15:03,927 INFO: Partial:  this good ashen to kundrat\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:15:04,001 INFO: Augmented nbest from 100 to 118 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:15:05,131 INFO: OPT time: 1.130\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:15:05,131 INFO: Final:  this a good ashen to condit\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:15:05,132 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  93%|█████████▎| 1347/1450 [29:05<02:18,  1.34s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:15:05,240 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:15:05,318 INFO: Partial:  yu juan tit inside or alcide\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:15:05,367 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:15:06,343 INFO: OPT time: 0.976\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:15:06,343 INFO: Final:  u watt tit inside or aside\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:15:06,344 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  93%|█████████▎| 1348/1450 [29:06<02:21,  1.38s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:15:06,541 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:15:06,642 INFO: Partial:  so oui giggly state insert\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:15:06,754 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:15:07,696 INFO: OPT time: 0.942\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:15:07,697 INFO: Final:  so we casually state insert\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:15:07,697 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  93%|█████████▎| 1349/1450 [29:07<02:14,  1.33s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:15:07,846 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:15:08,102 INFO: Partial:  displaces frum other university will bissette there races\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:15:08,196 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:15:09,350 INFO: OPT time: 1.154\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:15:09,350 INFO: Final:  displaces from other universities will beset their races\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:15:09,350 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  93%|█████████▎| 1350/1450 [29:09<02:13,  1.34s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:15:09,550 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:15:09,609 INFO: Partial:  nie sported to month them\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:15:09,734 INFO: Augmented nbest from 100 to 103 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:15:10,652 INFO: OPT time: 0.918\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:15:10,652 INFO: Final:  they ne sported to mun them\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:15:10,653 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  93%|█████████▎| 1351/1450 [29:10<02:21,  1.43s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:15:10,858 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:15:10,932 INFO: Partial:  gose herre a phew this abound stell\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:15:11,009 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:15:12,133 INFO: OPT time: 1.124\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:15:12,133 INFO: Final:  goes where a few this abound stell\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:15:12,133 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  93%|█████████▎| 1352/1450 [29:12<02:16,  1.39s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:15:12,254 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:15:12,278 INFO: Partial:  so fall\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:15:12,302 INFO: Augmented nbest from 100 to 104 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:15:12,962 INFO: OPT time: 0.660\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:15:12,962 INFO: Final:  the so fall\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:15:12,962 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  93%|█████████▎| 1353/1450 [29:13<02:17,  1.42s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:15:13,153 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:15:13,272 INFO: Partial:  it is really plies lumper atz college of will\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:15:13,660 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:15:15,036 INFO: OPT time: 1.376\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:15:15,036 INFO: Final:  it is really plays stempel atz college of will\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:15:15,037 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  93%|█████████▎| 1354/1450 [29:14<01:59,  1.24s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:15:15,167 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:15:15,316 INFO: Partial:  avi germ will teach yu on evader\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:15:15,899 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:15:16,881 INFO: OPT time: 0.983\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:15:16,882 INFO: Final:  heavy germ will teach you on evader\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:15:16,882 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  93%|█████████▎| 1355/1450 [29:16<02:21,  1.49s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:15:17,079 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:15:17,183 INFO: Partial:  was a elation the be have\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:15:17,271 INFO: Augmented nbest from 100 to 101 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:15:18,223 INFO: OPT time: 0.952\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:15:18,223 INFO: Final:  was a deflation the bee have\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:15:18,224 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  94%|█████████▎| 1356/1450 [29:18<02:30,  1.60s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:15:18,365 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:15:18,418 INFO: Partial:  is han to remember\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:15:18,522 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:15:19,207 INFO: OPT time: 0.684\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:15:19,207 INFO: Final:  it is for to remember\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:15:19,207 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  94%|█████████▎| 1357/1450 [29:19<02:21,  1.52s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:15:19,372 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:15:19,438 INFO: Partial:  then ai hurd a very can explosion\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:15:19,511 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:15:20,508 INFO: OPT time: 0.998\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:15:20,509 INFO: Final:  then ai heard a very can explosion\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:15:20,509 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  94%|█████████▎| 1358/1450 [29:20<02:05,  1.36s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:15:20,669 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:15:20,794 INFO: Partial:  get is a rillette farmer\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:15:21,061 INFO: Augmented nbest from 100 to 120 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:15:22,191 INFO: OPT time: 1.130\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:15:22,191 INFO: Final:  get is a potato farmer\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:15:22,191 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  94%|█████████▎| 1359/1450 [29:21<02:02,  1.34s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:15:22,379 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:15:22,448 INFO: Partial:  matzoh good option to consider\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:15:22,481 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:15:23,419 INFO: OPT time: 0.938\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:15:23,420 INFO: Final:  that a good option to consider\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:15:23,420 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  94%|█████████▍| 1360/1450 [29:23<02:10,  1.44s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:15:23,575 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:15:23,656 INFO: Partial:  yu when it inside or upside\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:15:23,701 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:15:24,511 INFO: OPT time: 0.810\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:15:24,512 INFO: Final:  you won it inside or upside\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:15:24,512 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  94%|█████████▍| 1361/1450 [29:24<02:02,  1.38s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:15:24,680 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:15:24,820 INFO: Partial:  so whey valli sette estate\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:15:25,052 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:15:26,001 INFO: OPT time: 0.948\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:15:26,001 INFO: Final:  so whey valley set outside\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:15:26,002 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  94%|█████████▍| 1362/1450 [29:25<01:53,  1.29s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:15:26,192 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:15:26,536 INFO: Partial:  bases rha either commission will percent there laces\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:15:26,735 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:15:27,724 INFO: OPT time: 0.989\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:15:27,724 INFO: Final:  bases raw other commission will percent their races\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:15:27,725 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  94%|█████████▍| 1363/1450 [29:27<01:57,  1.35s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:15:27,896 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:15:27,982 INFO: Partial:  are diel spreading to bake them\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:15:28,111 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:15:28,927 INFO: OPT time: 0.816\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:15:28,927 INFO: Final:  are deal spending to bake them\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:15:28,928 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  94%|█████████▍| 1364/1450 [29:29<02:05,  1.46s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:15:29,095 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:15:29,187 INFO: Partial:  gose there arda phew this offend stil\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:15:29,278 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:15:30,453 INFO: OPT time: 1.174\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:15:30,453 INFO: Final:  goes there are a few this offend stil\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:15:30,453 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  94%|█████████▍| 1365/1450 [29:30<01:57,  1.39s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:15:30,595 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:15:30,638 INFO: Partial:  are so blog\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:15:30,680 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:15:31,332 INFO: OPT time: 0.652\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:15:31,332 INFO: Final:  they are so blog\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:15:31,333 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  94%|█████████▍| 1366/1450 [29:31<01:59,  1.43s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:15:31,494 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:15:31,650 INFO: Partial:  is a fraley blogs lapre on relig a fall\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:15:32,018 INFO: Augmented nbest from 100 to 115 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:15:33,401 INFO: OPT time: 1.383\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:15:33,401 INFO: Final:  it is a fraley blogs lapre on rollers a fall\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:15:33,402 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  94%|█████████▍| 1367/1450 [29:32<01:44,  1.26s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:15:33,614 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:15:33,764 INFO: Partial:  alvey job thy teach yaw on afraid\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:15:34,247 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:15:35,224 INFO: OPT time: 0.977\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:15:35,224 INFO: Final:  avi job thy teach your on afraid\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:15:35,224 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  94%|█████████▍| 1368/1450 [29:34<02:03,  1.50s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:15:35,418 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:15:35,540 INFO: Partial:  it was a dulcine the whey pei hoff\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:15:36,005 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:15:37,208 INFO: OPT time: 1.203\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:15:37,208 INFO: Final:  it was a dunson that whey pay hoff\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:15:37,209 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  94%|█████████▍| 1369/1450 [29:36<02:09,  1.60s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:15:37,418 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:15:37,512 INFO: Partial:  itty ault to remember\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:15:37,736 INFO: Augmented nbest from 100 to 106 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:15:38,442 INFO: OPT time: 0.706\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:15:38,442 INFO: Final:  it a want to remember\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:15:38,443 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  94%|█████████▍| 1370/1450 [29:38<02:17,  1.72s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:15:38,618 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:15:38,740 INFO: Partial:  oui happened handa lot of problems with the new computer at aull\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:15:38,821 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:15:40,278 INFO: OPT time: 1.456\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:15:40,278 INFO: Final:  oui happened had a lot of problems with the new computer at all\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:15:40,278 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  95%|█████████▍| 1371/1450 [29:39<02:04,  1.57s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:15:40,417 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:15:40,507 INFO: Partial:  a sit and enjoy the wind\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:15:40,571 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:15:41,509 INFO: OPT time: 0.938\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:15:41,509 INFO: Final:  take a sit and enjoy the wind\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:15:41,510 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  95%|█████████▍| 1372/1450 [29:41<02:08,  1.65s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:15:41,619 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:15:41,780 INFO: Partial:  think oui fulfilled our obligation\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:15:41,881 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:15:42,687 INFO: OPT time: 0.806\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:15:42,687 INFO: Final:  think we fulfilled our obligation\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:15:42,688 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  95%|█████████▍| 1373/1450 [29:42<01:57,  1.52s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:15:42,820 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:15:42,881 INFO: Partial:  should study this no species\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:15:42,921 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:15:43,728 INFO: OPT time: 0.807\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:15:43,728 INFO: Final:  they should study this new species\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:15:43,729 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  95%|█████████▍| 1374/1450 [29:44<01:47,  1.42s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:15:43,921 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:15:44,026 INFO: Partial:  bubbly oui tkach komp and summon\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:15:44,101 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:15:45,255 INFO: OPT time: 1.154\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:15:45,256 INFO: Final:  bubbly wee catch comp and summon\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:15:45,256 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  95%|█████████▍| 1375/1450 [29:45<01:38,  1.31s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:15:45,428 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:15:45,580 INFO: Partial:  picking at dote in a ridell\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:15:45,731 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:15:46,681 INFO: OPT time: 0.949\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:15:46,681 INFO: Final:  picking up dent in a midair\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:15:46,681 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  95%|█████████▍| 1376/1450 [29:46<01:41,  1.37s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:15:46,835 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:15:47,064 INFO: Partial:  stud bye concentrating and expensing sure visualization power\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:15:47,167 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:15:48,331 INFO: OPT time: 1.163\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:15:48,331 INFO: Final:  star by concentrating and expensing sure visualization power\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:15:48,332 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  95%|█████████▍| 1377/1450 [29:48<01:41,  1.39s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:15:48,538 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:15:48,646 INFO: Partial:  guess where both pretty dreadful people\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:15:48,716 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:15:49,833 INFO: OPT time: 1.117\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:15:49,833 INFO: Final:  guess where both pretty radical people\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:15:49,833 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  95%|█████████▌| 1378/1450 [29:49<01:45,  1.47s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:15:50,038 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:15:50,094 INFO: Partial:  it was on is whey there\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:15:50,149 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:15:50,968 INFO: OPT time: 0.818\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:15:50,968 INFO: Final:  it was on is way there\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:15:50,968 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  95%|█████████▌| 1379/1450 [29:51<01:44,  1.48s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:15:51,138 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:15:51,186 INFO: Partial:  are probably whyte\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:15:51,220 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:15:51,912 INFO: OPT time: 0.692\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:15:51,912 INFO: Final:  you are probably white\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:15:51,913 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  95%|█████████▌| 1380/1450 [29:52<01:36,  1.37s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:15:52,040 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:15:52,178 INFO: Partial:  am shoring to convex in to what aull this downe\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:15:52,376 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:15:53,759 INFO: OPT time: 1.383\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:15:53,759 INFO: Final:  am chiding to convex in to what all this down\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:15:53,760 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  95%|█████████▌| 1381/1450 [29:53<01:25,  1.25s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:15:53,951 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:15:54,024 INFO: Partial:  they work at it a lyttle bit\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:15:54,087 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:15:55,211 INFO: OPT time: 1.123\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:15:55,211 INFO: Final:  if they work at it a little bit\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:15:55,211 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  95%|█████████▌| 1382/1450 [29:55<01:36,  1.43s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:15:55,349 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:15:55,430 INFO: Partial:  think the did a will good job of that\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:15:55,484 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:15:56,613 INFO: OPT time: 1.129\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:15:56,613 INFO: Final:  think they did a well good job of that\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:15:56,614 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  95%|█████████▌| 1383/1450 [29:56<01:36,  1.43s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:15:56,749 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:15:56,808 INFO: Partial:  that what there doing\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:15:56,858 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:15:57,556 INFO: OPT time: 0.698\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:15:57,557 INFO: Final:  that what there doing\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:15:57,557 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  95%|█████████▌| 1384/1450 [29:58<01:34,  1.42s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:15:57,755 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:15:57,863 INFO: Partial:  its a really good movie\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:15:57,978 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:15:58,825 INFO: OPT time: 0.847\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:15:58,826 INFO: Final:  its a really good movie\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:15:58,826 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  96%|█████████▌| 1385/1450 [29:58<01:23,  1.28s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:15:58,962 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:15:59,065 INFO: Partial:  must your sinton favorite food\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:15:59,159 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:15:59,968 INFO: OPT time: 0.809\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:15:59,968 INFO: Final:  what your section favorite food\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:15:59,969 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  96%|█████████▌| 1386/1450 [30:00<01:21,  1.28s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:16:00,164 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:16:00,234 INFO: Partial:  people are pressing\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:16:00,297 INFO: Augmented nbest from 100 to 113 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:16:01,094 INFO: OPT time: 0.797\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:16:01,094 INFO: Final:  people are pressing\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:16:01,095 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  96%|█████████▌| 1387/1450 [30:01<01:17,  1.24s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:16:01,263 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:16:01,324 INFO: Partial:  there never will be\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:16:01,371 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:16:02,066 INFO: OPT time: 0.695\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:16:02,066 INFO: Final:  there never will be\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:16:02,066 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  96%|█████████▌| 1388/1450 [30:02<01:14,  1.20s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:16:02,262 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:16:02,362 INFO: Partial:  what of the leys that is a product\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:16:02,453 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:16:03,416 INFO: OPT time: 0.963\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:16:03,416 INFO: Final:  what of the things that is a product\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:16:03,417 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  96%|█████████▌| 1389/1450 [30:03<01:09,  1.13s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:16:03,569 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:16:03,753 INFO: Partial:  this kind to koby pitiful territory\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:16:03,892 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:16:04,753 INFO: OPT time: 0.861\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:16:04,753 INFO: Final:  this kind to be pitiful territory\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:16:04,753 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  96%|█████████▌| 1390/1450 [30:04<01:11,  1.20s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:16:04,875 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:16:04,943 INFO: Partial:  can due whatever the want\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:16:04,982 INFO: Augmented nbest from 100 to 105 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:16:05,909 INFO: OPT time: 0.927\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:16:05,909 INFO: Final:  can do whatever they want\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:16:05,910 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  96%|█████████▌| 1391/1450 [30:06<01:13,  1.24s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:16:06,069 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:16:06,153 INFO: Partial:  the only costs of things that yu can yoos\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:16:06,235 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:16:07,407 INFO: OPT time: 1.172\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:16:07,407 INFO: Final:  the only costs of things that you can ewes\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:16:07,408 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  96%|█████████▌| 1392/1450 [30:07<01:10,  1.22s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:16:07,571 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:16:07,622 INFO: Partial:  that kind of understandable\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:16:07,653 INFO: Augmented nbest from 100 to 164 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:16:08,790 INFO: OPT time: 1.137\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:16:08,790 INFO: Final:  that's kind of understandable\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:16:08,791 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  96%|█████████▌| 1393/1450 [30:08<01:14,  1.30s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:16:08,973 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:16:09,073 INFO: Partial:  the bedell of a residential erria\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:16:09,112 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:16:10,067 INFO: OPT time: 0.954\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:16:10,067 INFO: Final:  the middle of a residential area\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:16:10,068 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  96%|█████████▌| 1394/1450 [30:10<01:14,  1.32s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:16:10,176 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:16:10,237 INFO: Partial:  yu serving another des with it\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:16:10,278 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:16:11,127 INFO: OPT time: 0.850\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:16:11,128 INFO: Final:  you serving another desk with it\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:16:11,128 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  96%|█████████▌| 1395/1450 [30:11<01:12,  1.31s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:16:11,283 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:16:11,396 INFO: Partial:  he basically put unsell thru school\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:16:11,463 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:16:12,321 INFO: OPT time: 0.857\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:16:12,321 INFO: Final:  he basically put itself through school\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:16:12,322 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  96%|█████████▋| 1396/1450 [30:12<01:06,  1.24s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:16:12,486 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:16:12,658 INFO: Partial:  carre is a nineteen eighty sense tighter\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:16:12,815 INFO: Augmented nbest from 100 to 110 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:16:13,989 INFO: OPT time: 1.174\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:16:13,989 INFO: Final:  my car is a nineteen eighty sense tighter\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:16:13,990 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  96%|█████████▋| 1397/1450 [30:13<01:04,  1.22s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:16:14,198 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:16:14,266 INFO: Partial:  get read of the to that oui have what now\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:16:14,348 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:16:15,548 INFO: OPT time: 1.200\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:16:15,548 INFO: Final:  get read of the to that we have what now\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:16:15,548 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  96%|█████████▋| 1398/1450 [30:15<01:10,  1.36s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:16:15,693 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:16:15,738 INFO: Partial:  am an american citizen\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:16:15,766 INFO: Augmented nbest from 100 to 109 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:16:16,707 INFO: OPT time: 0.941\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:16:16,707 INFO: Final:  am an american citizen\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:16:16,707 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  96%|█████████▋| 1399/1450 [30:16<01:12,  1.42s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:16:16,894 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:16:16,978 INFO: Partial:  that why oui decided to build an edition\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:16:17,056 INFO: Augmented nbest from 100 to 145 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:16:18,580 INFO: OPT time: 1.524\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:16:18,580 INFO: Final:  that why we decided to build an edition\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:16:18,581 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  97%|█████████▋| 1400/1450 [30:18<01:06,  1.34s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:16:18,701 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:16:18,767 INFO: Partial:  whats that merry about\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:16:18,817 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:16:19,515 INFO: OPT time: 0.698\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:16:19,515 INFO: Final:  whats that merry about\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:16:19,516 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  97%|█████████▋| 1401/1450 [30:20<01:13,  1.50s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:16:19,704 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:16:19,913 INFO: Partial:  the benefit having visit insurances for the remaley\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:16:20,138 INFO: Augmented nbest from 100 to 113 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:16:21,575 INFO: OPT time: 1.437\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:16:21,575 INFO: Final:  the benefit of having visit insurances for the remaley\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:16:21,576 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  97%|█████████▋| 1402/1450 [30:20<01:03,  1.33s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:16:21,715 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:16:21,753 INFO: Partial:  yu get fined them\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:16:21,792 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:16:22,483 INFO: OPT time: 0.691\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:16:22,483 INFO: Final:  you get find them\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:16:22,484 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  97%|█████████▋| 1403/1450 [30:23<01:12,  1.55s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:16:22,610 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:16:22,692 INFO: Partial:  what kyne of consenting to yu to\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:16:22,767 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:16:23,755 INFO: OPT time: 0.988\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:16:23,755 INFO: Final:  what kind of consenting to you to\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:16:23,755 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  97%|█████████▋| 1404/1450 [30:23<01:02,  1.36s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:16:23,912 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:16:24,083 INFO: Partial:  been at comfinance where dipple oley whoa to are three arouses a dey\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:16:24,321 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:16:26,252 INFO: OPT time: 1.931\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:16:26,252 INFO: Final:  been at companions where dipple oley whoa to are three arouses a day\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:16:26,253 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  97%|█████████▋| 1405/1450 [30:25<00:59,  1.33s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:16:26,426 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:16:26,533 INFO: Partial:  was livvie bettor turn years abor that am now\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:16:26,697 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:16:28,150 INFO: OPT time: 1.453\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:16:28,150 INFO: Final:  was livvie bettor turn years ago that am now\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:16:28,151 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  97%|█████████▋| 1406/1450 [30:27<01:13,  1.68s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:16:28,326 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:16:28,385 INFO: Partial:  kumm a gott to yu\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:16:28,487 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:16:29,302 INFO: OPT time: 0.815\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:16:29,302 INFO: Final:  cum a got to you\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:16:29,303 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  97%|█████████▋| 1407/1450 [30:29<01:15,  1.75s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:16:29,431 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:16:29,518 INFO: Partial:  ise ahl deigning collor\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:16:29,661 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:16:30,512 INFO: OPT time: 0.852\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:16:30,513 INFO: Final:  eyes are changing collor\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:16:30,513 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  97%|█████████▋| 1408/1450 [30:30<01:05,  1.57s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:16:30,632 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:16:30,729 INFO: Partial:  our annoying project development\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:16:30,760 INFO: Augmented nbest from 100 to 119 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:16:31,579 INFO: OPT time: 0.819\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:16:31,579 INFO: Final:  our annoying project development\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:16:31,579 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  97%|█████████▋| 1409/1450 [30:31<00:59,  1.46s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:16:31,728 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:16:31,864 INFO: Partial:  thing oui have about thirteen betz left or our cloned\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:16:32,140 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:16:33,525 INFO: OPT time: 1.385\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:16:33,525 INFO: Final:  thing we have about thirteen bets left or our cloned\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:16:33,526 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  97%|█████████▋| 1410/1450 [30:33<00:53,  1.34s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:16:33,644 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:16:33,795 INFO: Partial:  lyke worse choosing jurgens except for country muzik\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:16:33,992 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:16:35,177 INFO: OPT time: 1.185\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:16:35,177 INFO: Final:  like worse choosing versions except for country music\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:16:35,178 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  97%|█████████▋| 1411/1450 [30:34<00:59,  1.52s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:16:35,343 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:16:35,588 INFO: Partial:  was meaning on the as of my it\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:16:36,274 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:16:37,245 INFO: OPT time: 0.971\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:16:37,245 INFO: Final:  was meaning on the as of why it\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:16:37,246 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  97%|█████████▋| 1412/1450 [30:36<00:59,  1.56s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:16:37,490 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:16:37,581 INFO: Partial:  ruddy luvs them there mutsch\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:16:37,816 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:16:38,657 INFO: OPT time: 0.841\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:16:38,657 INFO: Final:  ruddy loves them there much\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:16:38,657 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  97%|█████████▋| 1413/1450 [30:38<01:03,  1.71s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:16:38,862 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:16:38,922 INFO: Partial:  this the whate have\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:16:38,987 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:16:39,643 INFO: OPT time: 0.656\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:16:39,644 INFO: Final:  this the white have\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:16:39,644 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  98%|█████████▊| 1414/1450 [30:40<00:58,  1.62s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:16:39,851 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:16:40,063 INFO: Partial:  just wad the wetter pour on the puppet\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:16:40,166 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:16:41,307 INFO: OPT time: 1.141\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:16:41,307 INFO: Final:  they just wad the water pour on the puppet\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:16:41,308 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  98%|█████████▊| 1415/1450 [30:41<00:50,  1.43s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:16:41,456 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:16:41,539 INFO: Partial:  what in the middle of my deck\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:16:41,677 INFO: Augmented nbest from 100 to 128 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:16:42,865 INFO: OPT time: 1.188\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:16:42,865 INFO: Final:  what in the middle of my deck\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:16:42,866 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  98%|█████████▊| 1416/1450 [30:42<00:51,  1.50s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:16:43,062 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:16:43,247 INFO: Partial:  has dahn to what masses read accost others\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:16:43,472 INFO: Augmented nbest from 100 to 140 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:16:45,000 INFO: OPT time: 1.528\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:16:45,000 INFO: Final:  has chan to what masses read against others\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:16:45,001 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  98%|█████████▊| 1417/1450 [30:44<00:50,  1.52s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:16:45,169 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:16:45,351 INFO: Partial:  enjoyed betty has a gagen\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:16:46,098 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:16:47,070 INFO: OPT time: 0.971\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:16:47,070 INFO: Final:  enjoy betty has a gagen\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:16:47,070 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  98%|█████████▊| 1418/1450 [30:46<00:54,  1.70s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:16:47,286 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:16:47,348 INFO: Partial:  would to yu think\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:16:47,421 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:16:48,080 INFO: OPT time: 0.659\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:16:48,080 INFO: Final:  would to you think\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:16:48,081 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  98%|█████████▊| 1419/1450 [30:48<00:56,  1.81s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:16:48,272 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:16:48,335 INFO: Partial:  many yu yu have\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:16:48,393 INFO: Augmented nbest from 100 to 137 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:16:49,338 INFO: OPT time: 0.944\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:16:49,338 INFO: Final:  many you you have\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:16:49,338 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  98%|█████████▊| 1420/1450 [30:49<00:47,  1.57s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:16:49,473 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:16:49,687 INFO: Partial:  wife bother is the only repairable bit\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:16:51,457 INFO: Augmented nbest from 100 to 105 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:16:52,374 INFO: OPT time: 0.917\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:16:52,374 INFO: Final:  wife bother is the only capitalized bit\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:16:52,375 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  98%|█████████▊| 1421/1450 [30:50<00:42,  1.48s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:16:52,678 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:16:52,814 INFO: Partial:  was in ellette fora ministry\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:16:52,908 INFO: Augmented nbest from 100 to 101 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:16:53,773 INFO: OPT time: 0.865\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:16:53,773 INFO: Final:  was in ellette for a ministry\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:16:53,773 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  98%|█████████▊| 1422/1450 [30:53<00:54,  1.95s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:16:53,886 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:16:53,999 INFO: Partial:  the card galusha read be off\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:16:54,132 INFO: Augmented nbest from 100 to 107 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:16:55,144 INFO: OPT time: 1.012\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:16:55,144 INFO: Final:  the card galusha raid be off\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:16:55,145 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  98%|█████████▊| 1423/1450 [30:55<00:48,  1.78s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:16:55,288 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:16:55,382 INFO: Partial:  when ai was undine years old\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:16:55,464 INFO: Augmented nbest from 100 to 108 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:16:56,478 INFO: OPT time: 1.014\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:16:56,478 INFO: Final:  when i was undine years old\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:16:56,478 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  98%|█████████▊| 1424/1450 [30:56<00:43,  1.66s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:16:56,590 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:16:56,652 INFO: Partial:  he wooden ever really talk about it\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:16:56,701 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:16:57,599 INFO: OPT time: 0.898\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:16:57,599 INFO: Final:  he wouldn't ever really talk about it\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:16:57,600 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  98%|█████████▊| 1425/1450 [30:57<00:39,  1.56s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:16:57,790 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:16:57,846 INFO: Partial:  had for brothers\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:16:57,870 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:16:58,489 INFO: OPT time: 0.619\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:16:58,490 INFO: Final:  had four brothers\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:16:58,490 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  98%|█████████▊| 1426/1450 [30:59<00:34,  1.43s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:16:58,692 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:16:58,730 INFO: Partial:  good sci that\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:16:58,758 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:16:59,378 INFO: OPT time: 0.620\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:16:59,379 INFO: Final:  good see that\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:16:59,379 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  98%|█████████▊| 1427/1450 [30:59<00:29,  1.27s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:16:59,495 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:16:59,559 INFO: Partial:  if subway keim and hurd it\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:16:59,634 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:17:00,414 INFO: OPT time: 0.780\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:17:00,414 INFO: Final:  if subway came and heard it\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:17:00,415 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  98%|█████████▊| 1428/1450 [31:00<00:25,  1.15s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:17:00,601 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:17:00,648 INFO: Partial:  haven't really prest it out\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:17:00,690 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:17:01,712 INFO: OPT time: 1.022\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:17:01,712 INFO: Final:  haven't really priced it out\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:17:01,713 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  99%|█████████▊| 1429/1450 [31:01<00:23,  1.12s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:17:01,901 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:17:01,947 INFO: Partial:  that was very discordant\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:17:01,978 INFO: Augmented nbest from 100 to 106 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:17:02,745 INFO: OPT time: 0.768\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:17:02,745 INFO: Final:  that was very discordant\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:17:02,746 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  99%|█████████▊| 1430/1450 [31:03<00:23,  1.17s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:17:02,901 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:17:03,004 INFO: Partial:  there actually due thinnes lyke this\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:17:03,069 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:17:03,857 INFO: OPT time: 0.788\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:17:03,857 INFO: Final:  there actually do things like this\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:17:03,858 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  99%|█████████▊| 1431/1450 [31:04<00:21,  1.13s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:17:04,005 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:17:04,093 INFO: Partial:  abet gets been once a months\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:17:04,161 INFO: Augmented nbest from 100 to 119 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:17:05,212 INFO: OPT time: 1.051\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:17:05,212 INFO: Final:  my abet gets been once a month\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:17:05,212 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  99%|█████████▉| 1432/1450 [31:05<00:20,  1.12s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:17:05,410 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:17:05,542 INFO: Partial:  no oui live in recanting for seven years\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:17:05,606 INFO: Augmented nbest from 100 to 112 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:17:06,978 INFO: OPT time: 1.371\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:17:06,978 INFO: Final:  no we live in rekindle for seven years\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:17:06,978 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  99%|█████████▉| 1433/1450 [31:06<00:20,  1.19s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:17:07,116 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:17:07,161 INFO: Partial:  dote no what thanks about\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:17:07,197 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:17:07,949 INFO: OPT time: 0.752\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:17:07,949 INFO: Final:  dote know what thinks about\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:17:07,949 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  99%|█████████▉| 1434/1450 [31:08<00:21,  1.37s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:17:08,117 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:17:08,354 INFO: Partial:  there are always new counterfeits or problems are christmases\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:17:08,442 INFO: Augmented nbest from 100 to 125 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:17:09,979 INFO: OPT time: 1.537\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:17:09,979 INFO: Final:  there are always new counterfeits or problems or christmases\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:17:09,980 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  99%|█████████▉| 1435/1450 [31:09<00:18,  1.25s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:17:10,126 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:17:10,232 INFO: Partial:  talking about incredibly lise forks\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:17:10,317 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:17:11,065 INFO: OPT time: 0.747\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:17:11,065 INFO: Final:  talking about incredibly lies force\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:17:11,065 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  99%|█████████▉| 1436/1450 [31:11<00:20,  1.48s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:17:11,228 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:17:11,321 INFO: Partial:  theirs a couple new tensions this year\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:17:11,370 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:17:12,280 INFO: OPT time: 0.910\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:17:12,280 INFO: Final:  theirs a couple new teachers this year\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:17:12,280 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  99%|█████████▉| 1437/1450 [31:12<00:17,  1.36s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:17:12,428 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:17:12,575 INFO: Partial:  the lastest for carrots are barre expensive\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:17:12,665 INFO: Augmented nbest from 100 to 151 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:17:14,108 INFO: OPT time: 1.443\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:17:14,108 INFO: Final:  the license for carrots are berry expensive\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:17:14,109 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  99%|█████████▉| 1438/1450 [31:13<00:15,  1.32s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:17:14,235 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:17:14,276 INFO: Partial:  oui enjoyed having who here\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:17:14,308 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:17:15,090 INFO: OPT time: 0.782\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:17:15,091 INFO: Final:  we enjoyed having who here\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:17:15,091 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  99%|█████████▉| 1439/1450 [31:15<00:16,  1.47s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:17:15,233 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:17:15,300 INFO: Partial:  was wanting on a farm lox summy\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:17:15,382 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:17:16,421 INFO: OPT time: 1.039\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:17:16,421 INFO: Final:  was wanting on a farm loss summy\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:17:16,422 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  99%|█████████▉| 1440/1450 [31:16<00:13,  1.32s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:17:16,538 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:17:16,616 INFO: Partial:  these boye katz are upp to aull sorts of things\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:17:16,689 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:17:17,901 INFO: OPT time: 1.212\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:17:17,901 INFO: Final:  these boy cats are up to all sorts of things\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:17:17,902 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  99%|█████████▉| 1441/1450 [31:17<00:11,  1.33s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:17:18,043 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:17:18,216 INFO: Partial:  the optioned is pension bye its lumen whyte\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:17:18,334 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:17:19,503 INFO: OPT time: 1.169\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:17:19,503 INFO: Final:  the oxidant is pension by its lumen white\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:17:19,503 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model:  99%|█████████▉| 1442/1450 [31:19<00:10,  1.37s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:17:19,651 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:17:19,805 INFO: Partial:  ena riesen persian of wickets should be fite\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:17:19,962 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:17:21,340 INFO: OPT time: 1.379\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:17:21,340 INFO: Final:  ena riesen version of wickets should be fight\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:17:21,341 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model: 100%|█████████▉| 1443/1450 [31:20<00:10,  1.44s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:17:21,457 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:17:21,529 INFO: Partial:  the internet\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:17:21,557 INFO: Augmented nbest from 100 to 117 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:17:22,162 INFO: OPT time: 0.605\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:17:22,162 INFO: Final:  the internet\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:17:22,162 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model: 100%|█████████▉| 1444/1450 [31:22<00:09,  1.56s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:17:22,351 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:17:22,422 INFO: Partial:  since they doanh have the really fee\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:17:22,484 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:17:23,520 INFO: OPT time: 1.036\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:17:23,520 INFO: Final:  since they dint have the really fee\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:17:23,521 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model: 100%|█████████▉| 1445/1450 [31:23<00:06,  1.34s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:17:23,656 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:17:23,764 INFO: Partial:  theirs a lot of new section in the document\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:17:23,829 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:17:24,866 INFO: OPT time: 1.036\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:17:24,866 INFO: Final:  theirs a lot of new section in the document\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:17:24,866 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model: 100%|█████████▉| 1446/1450 [31:24<00:05,  1.34s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:17:25,057 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:17:25,114 INFO: Partial:  and our handa have away\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:17:25,164 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:17:25,950 INFO: OPT time: 0.785\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:17:25,950 INFO: Final:  and our and a half away\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:17:25,950 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model: 100%|█████████▉| 1447/1450 [31:26<00:04,  1.34s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:17:26,060 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:17:26,113 INFO: Partial:  sze boss at the other won\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:17:26,151 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:17:26,932 INFO: OPT time: 0.780\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:17:26,932 INFO: Final:  she boss at the other one\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:17:26,933 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model: 100%|█████████▉| 1448/1450 [31:27<00:02,  1.27s/trial]\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:17:27,062 INFO: Reset the language model.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:17:27,156 INFO: Partial:  well baby that is nasser factor\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:17:27,239 INFO: Augmented nbest from 100 to 100 candidates.\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:17:28,250 INFO: OPT time: 1.010\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:17:28,250 INFO: Final:  well baby that is enticing factor\n",
      "\u001b[95mcmd1:\u001b[0m 2025-12-24 08:17:28,250 INFO: Finalized the language model.\n",
      "\u001b[95mcmd1:\u001b[0m \n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model: 100%|█████████▉| 1449/1450 [31:28<00:01,  1.18s/trial]\n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model: 100%|██████████| 1450/1450 [31:29<00:00,  1.22s/trial]\n",
      "\u001b[35mcmd2:\u001b[0m Running remote language model: 100%|██████████| 1450/1450 [31:29<00:00,  1.30s/trial]\n",
      "\u001b[35mcmd2:\u001b[0m Saved submission file to ~/baseline_rnn_test_predicted_sentences_20251224_081728.csv\n",
      "\u001b[35mcmd2:\u001b[0m Saved detailed results to ~/detailed_results_test_20251224_081728.csv\n",
      "\u001b[95mcmd1:\u001b[0m Traceback (most recent call last):\n",
      "\u001b[95mcmd1:\u001b[0m   File \"/kaggle/working/Brain-To-Text-MOA/language_model/language-model-standalone.py\", line 824, in <module>\n",
      "\u001b[95mcmd1:\u001b[0m     main(args)\n",
      "\u001b[95mcmd1:\u001b[0m   File \"/kaggle/working/Brain-To-Text-MOA/language_model/language-model-standalone.py\", line 747, in main\n",
      "\u001b[95mcmd1:\u001b[0m     read_result = r.xread(\n",
      "\u001b[95mcmd1:\u001b[0m   File \"/root/miniconda3/envs/b2txt25_lm/lib/python3.9/site-packages/redis/commands/core.py\", line 3961, in xread\n",
      "\u001b[95mcmd1:\u001b[0m     return self.execute_command(\"XREAD\", *pieces)\n",
      "\u001b[95mcmd1:\u001b[0m   File \"/root/miniconda3/envs/b2txt25_lm/lib/python3.9/site-packages/redis/client.py\", line 545, in execute_command\n",
      "\u001b[95mcmd1:\u001b[0m     return conn.retry.call_with_retry(\n",
      "\u001b[95mcmd1:\u001b[0m   File \"/root/miniconda3/envs/b2txt25_lm/lib/python3.9/site-packages/redis/retry.py\", line 46, in call_with_retry\n",
      "\u001b[95mcmd1:\u001b[0m     return do()\n",
      "\u001b[95mcmd1:\u001b[0m   File \"/root/miniconda3/envs/b2txt25_lm/lib/python3.9/site-packages/redis/client.py\", line 546, in <lambda>\n",
      "\u001b[95mcmd1:\u001b[0m     lambda: self._send_command_parse_response(\n",
      "\u001b[95mcmd1:\u001b[0m   File \"/root/miniconda3/envs/b2txt25_lm/lib/python3.9/site-packages/redis/client.py\", line 522, in _send_command_parse_response\n",
      "\u001b[95mcmd1:\u001b[0m     return self.parse_response(conn, command_name, **options)\n",
      "\u001b[95mcmd1:\u001b[0m   File \"/root/miniconda3/envs/b2txt25_lm/lib/python3.9/site-packages/redis/client.py\", line 562, in parse_response\n",
      "\u001b[95mcmd1:\u001b[0m     response = connection.read_response()\n",
      "\u001b[95mcmd1:\u001b[0m   File \"/root/miniconda3/envs/b2txt25_lm/lib/python3.9/site-packages/redis/connection.py\", line 512, in read_response\n",
      "\u001b[95mcmd1:\u001b[0m     response = self._parser.read_response(disable_decoding=disable_decoding)\n",
      "\u001b[95mcmd1:\u001b[0m   File \"/root/miniconda3/envs/b2txt25_lm/lib/python3.9/site-packages/redis/_parsers/resp2.py\", line 15, in read_response\n",
      "\u001b[95mcmd1:\u001b[0m     result = self._read_response(disable_decoding=disable_decoding)\n",
      "\u001b[95mcmd1:\u001b[0m   File \"/root/miniconda3/envs/b2txt25_lm/lib/python3.9/site-packages/redis/_parsers/resp2.py\", line 25, in _read_response\n",
      "\u001b[95mcmd1:\u001b[0m     raw = self._buffer.readline()\n",
      "\u001b[95mcmd1:\u001b[0m   File \"/root/miniconda3/envs/b2txt25_lm/lib/python3.9/site-packages/redis/_parsers/socket.py\", line 115, in readline\n",
      "\u001b[95mcmd1:\u001b[0m     self._read_from_socket()\n",
      "\u001b[95mcmd1:\u001b[0m   File \"/root/miniconda3/envs/b2txt25_lm/lib/python3.9/site-packages/redis/_parsers/socket.py\", line 65, in _read_from_socket\n",
      "\u001b[95mcmd1:\u001b[0m     data = self._sock.recv(socket_read_size)\n",
      "\u001b[95mcmd1:\u001b[0m KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_86/1090513943.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;31m# Wait for both to complete\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m \u001b[0mthread1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m \u001b[0mthread2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.11/threading.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1118\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1119\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wait_for_tstate_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1120\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1121\u001b[0m             \u001b[0;31m# the behavior of a negative timeout isn't documented, but\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.11/threading.py\u001b[0m in \u001b[0;36m_wait_for_tstate_lock\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m   1137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1138\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1139\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1140\u001b[0m                 \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1141\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Install Redis server using apt (system package manager)\n",
    "!apt-get update\n",
    "!apt-get install -y redis-server\n",
    "\n",
    "# Start Redis server in the background\n",
    "!redis-server --daemonize yes\n",
    "\n",
    "!mkdir -p ~/miniconda3\n",
    "!wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh -O ~/miniconda3/miniconda.sh\n",
    "!bash ~/miniconda3/miniconda.sh -b -u -p ~/miniconda3\n",
    "!rm ~/miniconda3/miniconda.sh\n",
    "!source ~/miniconda3/bin/activate\n",
    "\n",
    "!~/miniconda3/bin/conda tos accept --override-channels --channel https://repo.anaconda.com/pkgs/main\n",
    "!~/miniconda3/bin/conda tos accept --override-channels --channel https://repo.anaconda.com/pkgs/r\n",
    "\n",
    "!rm -r ./Brain-To-Text-MOA || true\n",
    "!git clone \"https://github.com/vuvanqh/Brain-To-Text-MOA\"\n",
    "\n",
    "!cd ./Brain-To-Text-MOA\n",
    "\n",
    "%cd /kaggle/working/Brain-To-Text-MOA/\n",
    "\n",
    "!rm -rf language_model/runtime/server/x86/build || true\n",
    "!rm -rf language_model/runtime/server/x86/fc_base || true\n",
    "\n",
    "import subprocess\n",
    "import threading\n",
    "\n",
    "class Colors:\n",
    "    CMD1 = '\\033[95m'  # Pink\n",
    "    CMD2 = '\\033[35m'  # Purple\n",
    "    RESET = '\\033[0m'\n",
    "\n",
    "def run_command(command, prefix, color=\"\"):\n",
    "    \"\"\"Run a shell command and print output in real-time with colored prefix\"\"\"\n",
    "    process = subprocess.Popen(\n",
    "        command,\n",
    "        shell=True,\n",
    "        stdout=subprocess.PIPE,\n",
    "        stderr=subprocess.STDOUT,\n",
    "        text=True,\n",
    "        bufsize=1,\n",
    "        executable='/bin/bash'\n",
    "    )\n",
    "    \n",
    "    # Print output in real-time with colored prefix\n",
    "    for line in process.stdout:\n",
    "        print(f\"{color}{prefix}:{Colors.RESET} {line}\", end='')\n",
    "    \n",
    "    process.wait()\n",
    "    return process.returncode\n",
    "\n",
    "# Define your commands\n",
    "cmd1 = \"alias conda='~/miniconda3/bin/conda' && source ~/miniconda3/bin/activate && bash setup_lm.sh && conda activate b2txt25_lm && python language_model/language-model-standalone.py --lm_path language_model/pretrained_language_models/openwebtext_1gram_lm_sil --do_opt --nbest 100 --acoustic_scale 0.325 --blank_penalty 90 --alpha 0.55 --redis_ip localhost --gpu_number 0\"\n",
    "cmd2 = \"echo 'Sleeping for 15 minutes...' && sleep 900 && alias conda='~/miniconda3/bin/conda' && source ~/miniconda3/bin/activate && bash setup.sh && conda activate b2txt25 && python model_training/evaluate_model.py --gpu_number 1 --model_path /kaggle/input/brain-to-text-25/t15_pretrained_rnn_baseline/t15_pretrained_rnn_baseline/ --data_dir /kaggle/input/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final --csv_path ./data/t15_copyTaskData_description.csv --eval_type test\"\n",
    "\n",
    "# Create threads with colored prefixes\n",
    "thread1 = threading.Thread(target=run_command, args=(cmd1, \"cmd1\", Colors.CMD1))\n",
    "thread2 = threading.Thread(target=run_command, args=(cmd2, \"cmd2\", Colors.CMD2))\n",
    "\n",
    "# Start both threads\n",
    "thread1.start()\n",
    "thread2.start()\n",
    "\n",
    "# Wait for both to complete\n",
    "thread1.join()\n",
    "thread2.join()\n",
    "\n",
    "print(\"Both commands completed!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a01f10e8",
   "metadata": {},
   "source": [
    "2. Run this to evaluate the model on the validation set (ground truth available so it creates a detailed results file):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "543236c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hit:1 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
      "Get:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n",
      "Get:3 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,632 B]\n",
      "Get:4 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]        \n",
      "Get:5 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]           \n",
      "Get:6 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [2,225 kB]\n",
      "Get:7 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]      \n",
      "Get:8 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ Packages [83.6 kB]\n",
      "Get:9 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB] \n",
      "Get:10 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [9,572 kB] \n",
      "Get:11 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,860 kB]\n",
      "Hit:12 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
      "Get:13 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [3,966 kB]\n",
      "Hit:14 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease   \n",
      "Get:15 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,598 kB]\n",
      "Get:16 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [6,411 kB]\n",
      "Get:17 http://archive.ubuntu.com/ubuntu jammy-updates/multiverse amd64 Packages [69.2 kB]\n",
      "Get:18 http://archive.ubuntu.com/ubuntu jammy-backports/universe amd64 Packages [37.2 kB]\n",
      "Get:19 http://archive.ubuntu.com/ubuntu jammy-backports/main amd64 Packages [83.9 kB]\n",
      "Get:20 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease [18.1 kB]\n",
      "Get:21 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 Packages [38.5 kB]\n",
      "Get:22 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,287 kB]\n",
      "Get:23 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [6,205 kB]\n",
      "Get:24 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [3,633 kB]\n",
      "Fetched 20.8 MB in 3s (7,998 kB/s)                           \n",
      "Reading package lists... Done\n",
      "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
      "E: dpkg was interrupted, you must manually run 'dpkg --configure -a' to correct the problem. \n",
      "Collecting redis\n",
      "  Downloading redis-7.1.0-py3-none-any.whl.metadata (12 kB)\n",
      "Downloading redis-7.1.0-py3-none-any.whl (354 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m354.2/354.2 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: redis\n",
      "Successfully installed redis-7.1.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "--2025-12-23 22:13:50--  https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh\n",
      "Resolving repo.anaconda.com (repo.anaconda.com)... 104.16.191.158, 104.16.32.241, 2606:4700::6810:20f1, ...\n",
      "Connecting to repo.anaconda.com (repo.anaconda.com)|104.16.191.158|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 156772981 (150M) [application/octet-stream]\n",
      "Saving to: ‘/root/miniconda3/miniconda.sh’\n",
      "\n",
      "/root/miniconda3/mi 100%[===================>] 149.51M   135MB/s    in 1.1s    \n",
      "\n",
      "2025-12-23 22:13:51 (135 MB/s) - ‘/root/miniconda3/miniconda.sh’ saved [156772981/156772981]\n",
      "\n",
      "PREFIX=/root/miniconda3\n",
      "Unpacking bootstrapper...\n",
      "Unpacking payload...\n",
      "\n",
      "Installing base environment...\n",
      "\n",
      "Preparing transaction: ...working... done\n",
      "Executing transaction: ...working... done\n",
      "installation finished.\n",
      "WARNING:\n",
      "    You currently have a PYTHONPATH environment variable set. This may cause\n",
      "    unexpected behavior when running the Python interpreter in Miniconda3.\n",
      "    For best results, please verify that your PYTHONPATH only points to\n",
      "    directories of packages that are compatible with the Python interpreter\n",
      "    in Miniconda3: /root/miniconda3\n",
      "accepted Terms of Service for \u001b[4;94mhttps://repo.anaconda.com/pkgs/main\u001b[0m\n",
      "accepted Terms of Service for \u001b[4;94mhttps://repo.anaconda.com/pkgs/r\u001b[0m\n",
      "rm: cannot remove './Brain-To-Text-MOA': No such file or directory\n",
      "Cloning into 'Brain-To-Text-MOA'...\n",
      "remote: Enumerating objects: 2966, done.\u001b[K\n",
      "remote: Counting objects: 100% (27/27), done.\u001b[K\n",
      "remote: Compressing objects: 100% (19/19), done.\u001b[K\n",
      "remote: Total 2966 (delta 9), reused 20 (delta 7), pack-reused 2939 (from 3)\u001b[K\n",
      "Receiving objects: 100% (2966/2966), 82.00 MiB | 44.03 MiB/s, done.\n",
      "Resolving deltas: 100% (385/385), done.\n",
      "/kaggle/working/Brain-To-Text-MOA\n",
      "\u001b[92mcmd2:\u001b[0m Jupyter detected...\n",
      "\u001b[92mcmd2:\u001b[0m 2 channel Terms of Service accepted\n",
      "\u001b[94mcmd1:\u001b[0m Jupyter detected...\n",
      "\u001b[94mcmd1:\u001b[0m 2 channel Terms of Service accepted\n",
      "\u001b[92mcmd2:\u001b[0m Retrieving notices: done\n",
      "\u001b[92mcmd2:\u001b[0m Channels:\n",
      "\u001b[92mcmd2:\u001b[0m  - defaults\n",
      "\u001b[92mcmd2:\u001b[0m Platform: linux-64\n",
      "\u001b[94mcmd1:\u001b[0m Retrieving notices: done\n",
      "\u001b[94mcmd1:\u001b[0m Channels:\n",
      "\u001b[94mcmd1:\u001b[0m  - defaults\n",
      "\u001b[94mcmd1:\u001b[0m Platform: linux-64\n",
      "\u001b[92mcmd2:\u001b[0m Collecting package metadata (repodata.json): done\n",
      "\u001b[92mcmd2:\u001b[0m Solving environment: done\n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m ## Package Plan ##\n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m   environment location: /root/miniconda3/envs/b2txt25\n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m   added / updated specs:\n",
      "\u001b[92mcmd2:\u001b[0m     - python=3.10\n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m The following packages will be downloaded:\n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m     package                    |            build\n",
      "\u001b[92mcmd2:\u001b[0m     ---------------------------|-----------------\n",
      "\u001b[92mcmd2:\u001b[0m     libnsl-2.0.0               |       h5eee18b_0          31 KB\n",
      "\u001b[92mcmd2:\u001b[0m     python-3.10.19             |       h6fa692b_0        24.5 MB\n",
      "\u001b[92mcmd2:\u001b[0m     setuptools-80.9.0          |  py310h06a4308_0         1.4 MB\n",
      "\u001b[92mcmd2:\u001b[0m     wheel-0.45.1               |  py310h06a4308_0         115 KB\n",
      "\u001b[92mcmd2:\u001b[0m     ------------------------------------------------------------\n",
      "\u001b[92mcmd2:\u001b[0m                                            Total:        26.0 MB\n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m The following NEW packages will be INSTALLED:\n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m   _libgcc_mutex      pkgs/main/linux-64::_libgcc_mutex-0.1-main \n",
      "\u001b[92mcmd2:\u001b[0m   _openmp_mutex      pkgs/main/linux-64::_openmp_mutex-5.1-1_gnu \n",
      "\u001b[92mcmd2:\u001b[0m   bzip2              pkgs/main/linux-64::bzip2-1.0.8-h5eee18b_6 \n",
      "\u001b[92mcmd2:\u001b[0m   ca-certificates    pkgs/main/linux-64::ca-certificates-2025.12.2-h06a4308_0 \n",
      "\u001b[92mcmd2:\u001b[0m   expat              pkgs/main/linux-64::expat-2.7.3-h7354ed3_4 \n",
      "\u001b[92mcmd2:\u001b[0m   ld_impl_linux-64   pkgs/main/linux-64::ld_impl_linux-64-2.44-h153f514_2 \n",
      "\u001b[92mcmd2:\u001b[0m   libexpat           pkgs/main/linux-64::libexpat-2.7.3-h7354ed3_4 \n",
      "\u001b[92mcmd2:\u001b[0m   libffi             pkgs/main/linux-64::libffi-3.4.4-h6a678d5_1 \n",
      "\u001b[92mcmd2:\u001b[0m   libgcc             pkgs/main/linux-64::libgcc-15.2.0-h69a1729_7 \n",
      "\u001b[92mcmd2:\u001b[0m   libgcc-ng          pkgs/main/linux-64::libgcc-ng-15.2.0-h166f726_7 \n",
      "\u001b[92mcmd2:\u001b[0m   libgomp            pkgs/main/linux-64::libgomp-15.2.0-h4751f2c_7 \n",
      "\u001b[92mcmd2:\u001b[0m   libnsl             pkgs/main/linux-64::libnsl-2.0.0-h5eee18b_0 \n",
      "\u001b[92mcmd2:\u001b[0m   libstdcxx          pkgs/main/linux-64::libstdcxx-15.2.0-h39759b7_7 \n",
      "\u001b[92mcmd2:\u001b[0m   libstdcxx-ng       pkgs/main/linux-64::libstdcxx-ng-15.2.0-hc03a8fd_7 \n",
      "\u001b[92mcmd2:\u001b[0m   libuuid            pkgs/main/linux-64::libuuid-1.41.5-h5eee18b_0 \n",
      "\u001b[92mcmd2:\u001b[0m   libxcb             pkgs/main/linux-64::libxcb-1.17.0-h9b100fa_0 \n",
      "\u001b[92mcmd2:\u001b[0m   libzlib            pkgs/main/linux-64::libzlib-1.3.1-hb25bd0a_0 \n",
      "\u001b[92mcmd2:\u001b[0m   ncurses            pkgs/main/linux-64::ncurses-6.5-h7934f7d_0 \n",
      "\u001b[92mcmd2:\u001b[0m   openssl            pkgs/main/linux-64::openssl-3.0.18-hd6dcaed_0 \n",
      "\u001b[92mcmd2:\u001b[0m   pip                pkgs/main/noarch::pip-25.3-pyhc872135_0 \n",
      "\u001b[92mcmd2:\u001b[0m   pthread-stubs      pkgs/main/linux-64::pthread-stubs-0.3-h0ce48e5_1 \n",
      "\u001b[92mcmd2:\u001b[0m   python             pkgs/main/linux-64::python-3.10.19-h6fa692b_0 \n",
      "\u001b[92mcmd2:\u001b[0m   readline           pkgs/main/linux-64::readline-8.3-hc2a1206_0 \n",
      "\u001b[92mcmd2:\u001b[0m   setuptools         pkgs/main/linux-64::setuptools-80.9.0-py310h06a4308_0 \n",
      "\u001b[92mcmd2:\u001b[0m   sqlite             pkgs/main/linux-64::sqlite-3.51.0-h2a70700_0 \n",
      "\u001b[92mcmd2:\u001b[0m   tk                 pkgs/main/linux-64::tk-8.6.15-h54e0aa7_0 \n",
      "\u001b[92mcmd2:\u001b[0m   tzdata             pkgs/main/noarch::tzdata-2025b-h04d1e81_0 \n",
      "\u001b[92mcmd2:\u001b[0m   wheel              pkgs/main/linux-64::wheel-0.45.1-py310h06a4308_0 \n",
      "\u001b[92mcmd2:\u001b[0m   xorg-libx11        pkgs/main/linux-64::xorg-libx11-1.8.12-h9b100fa_1 \n",
      "\u001b[92mcmd2:\u001b[0m   xorg-libxau        pkgs/main/linux-64::xorg-libxau-1.0.12-h9b100fa_0 \n",
      "\u001b[92mcmd2:\u001b[0m   xorg-libxdmcp      pkgs/main/linux-64::xorg-libxdmcp-1.1.5-h9b100fa_0 \n",
      "\u001b[92mcmd2:\u001b[0m   xorg-xorgproto     pkgs/main/linux-64::xorg-xorgproto-2024.1-h5eee18b_1 \n",
      "\u001b[92mcmd2:\u001b[0m   xz                 pkgs/main/linux-64::xz-5.6.4-h5eee18b_1 \n",
      "\u001b[92mcmd2:\u001b[0m   zlib               pkgs/main/linux-64::zlib-1.3.1-hb25bd0a_0 \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Downloading and Extracting Packages: ...working...\n",
      "\u001b[92mcmd2:\u001b[0m python-3.10.19       | 24.5 MB   |            |   0% \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m setuptools-80.9.0    | 1.4 MB    |            |   0% \u001b[A\n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m wheel-0.45.1         | 115 KB    |            |   0% \u001b[A\u001b[A\n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m libnsl-2.0.0         | 31 KB     |            |   0% \u001b[A\u001b[A\u001b[A\n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m setuptools-80.9.0    | 1.4 MB    | 1          |   1% \u001b[A\n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m libnsl-2.0.0         | 31 KB     | #####1     |  52% \u001b[A\u001b[A\u001b[A\n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m libnsl-2.0.0         | 31 KB     | ########## | 100% \u001b[A\u001b[A\u001b[A\n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m libnsl-2.0.0         | 31 KB     | ########## | 100% \u001b[A\u001b[A\u001b[A\n",
      "\u001b[92mcmd2:\u001b[0m python-3.10.19       | 24.5 MB   |            |   0% \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m setuptools-80.9.0    | 1.4 MB    | ########## | 100% \u001b[A\n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m wheel-0.45.1         | 115 KB    | #3         |  14% \u001b[A\u001b[A\n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m wheel-0.45.1         | 115 KB    | ########## | 100% \u001b[A\u001b[A\n",
      "\u001b[92mcmd2:\u001b[0m python-3.10.19       | 24.5 MB   | #5         |  16% \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m wheel-0.45.1         | 115 KB    | ########## | 100% \u001b[A\u001b[A\n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m wheel-0.45.1         | 115 KB    | ########## | 100% \u001b[A\u001b[A\n",
      "\u001b[92mcmd2:\u001b[0m python-3.10.19       | 24.5 MB   | ####7      |  48% \n",
      "\u001b[92mcmd2:\u001b[0m python-3.10.19       | 24.5 MB   | #########1 |  91% \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m setuptools-80.9.0    | 1.4 MB    | ########## | 100% \u001b[A\n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m setuptools-80.9.0    | 1.4 MB    | ########## | 100% \u001b[A\n",
      "\u001b[94mcmd1:\u001b[0m Collecting package metadata (repodata.json): done\n",
      "\u001b[94mcmd1:\u001b[0m Solving environment: done\n",
      "\u001b[94mcmd1:\u001b[0m \n",
      "\u001b[94mcmd1:\u001b[0m ## Package Plan ##\n",
      "\u001b[94mcmd1:\u001b[0m \n",
      "\u001b[94mcmd1:\u001b[0m   environment location: /root/miniconda3/envs/b2txt25_lm\n",
      "\u001b[94mcmd1:\u001b[0m \n",
      "\u001b[94mcmd1:\u001b[0m   added / updated specs:\n",
      "\u001b[94mcmd1:\u001b[0m     - python=3.9\n",
      "\u001b[94mcmd1:\u001b[0m \n",
      "\u001b[94mcmd1:\u001b[0m \n",
      "\u001b[94mcmd1:\u001b[0m The following packages will be downloaded:\n",
      "\u001b[94mcmd1:\u001b[0m \n",
      "\u001b[94mcmd1:\u001b[0m     package                    |            build\n",
      "\u001b[94mcmd1:\u001b[0m     ---------------------------|-----------------\n",
      "\u001b[94mcmd1:\u001b[0m     python-3.9.25              |       h0dcde21_1        23.0 MB\n",
      "\u001b[94mcmd1:\u001b[0m     setuptools-80.9.0          |   py39h06a4308_0         1.4 MB\n",
      "\u001b[94mcmd1:\u001b[0m     wheel-0.45.1               |   py39h06a4308_0         114 KB\n",
      "\u001b[94mcmd1:\u001b[0m     ------------------------------------------------------------\n",
      "\u001b[94mcmd1:\u001b[0m                                            Total:        24.6 MB\n",
      "\u001b[94mcmd1:\u001b[0m \n",
      "\u001b[94mcmd1:\u001b[0m The following NEW packages will be INSTALLED:\n",
      "\u001b[94mcmd1:\u001b[0m \n",
      "\u001b[94mcmd1:\u001b[0m   _libgcc_mutex      pkgs/main/linux-64::_libgcc_mutex-0.1-main \n",
      "\u001b[94mcmd1:\u001b[0m   _openmp_mutex      pkgs/main/linux-64::_openmp_mutex-5.1-1_gnu \n",
      "\u001b[94mcmd1:\u001b[0m   bzip2              pkgs/main/linux-64::bzip2-1.0.8-h5eee18b_6 \n",
      "\u001b[94mcmd1:\u001b[0m   ca-certificates    pkgs/main/linux-64::ca-certificates-2025.12.2-h06a4308_0 \n",
      "\u001b[94mcmd1:\u001b[0m   expat              pkgs/main/linux-64::expat-2.7.3-h7354ed3_4 \n",
      "\u001b[94mcmd1:\u001b[0m   ld_impl_linux-64   pkgs/main/linux-64::ld_impl_linux-64-2.44-h153f514_2 \n",
      "\u001b[94mcmd1:\u001b[0m   libexpat           pkgs/main/linux-64::libexpat-2.7.3-h7354ed3_4 \n",
      "\u001b[94mcmd1:\u001b[0m   libffi             pkgs/main/linux-64::libffi-3.4.4-h6a678d5_1 \n",
      "\u001b[94mcmd1:\u001b[0m   libgcc             pkgs/main/linux-64::libgcc-15.2.0-h69a1729_7 \n",
      "\u001b[94mcmd1:\u001b[0m   libgcc-ng          pkgs/main/linux-64::libgcc-ng-15.2.0-h166f726_7 \n",
      "\u001b[94mcmd1:\u001b[0m   libgomp            pkgs/main/linux-64::libgomp-15.2.0-h4751f2c_7 \n",
      "\u001b[94mcmd1:\u001b[0m   libnsl             pkgs/main/linux-64::libnsl-2.0.0-h5eee18b_0 \n",
      "\u001b[94mcmd1:\u001b[0m   libstdcxx          pkgs/main/linux-64::libstdcxx-15.2.0-h39759b7_7 \n",
      "\u001b[94mcmd1:\u001b[0m   libstdcxx-ng       pkgs/main/linux-64::libstdcxx-ng-15.2.0-hc03a8fd_7 \n",
      "\u001b[94mcmd1:\u001b[0m   libuuid            pkgs/main/linux-64::libuuid-1.41.5-h5eee18b_0 \n",
      "\u001b[94mcmd1:\u001b[0m   libxcb             pkgs/main/linux-64::libxcb-1.17.0-h9b100fa_0 \n",
      "\u001b[94mcmd1:\u001b[0m   libzlib            pkgs/main/linux-64::libzlib-1.3.1-hb25bd0a_0 \n",
      "\u001b[94mcmd1:\u001b[0m   ncurses            pkgs/main/linux-64::ncurses-6.5-h7934f7d_0 \n",
      "\u001b[94mcmd1:\u001b[0m   openssl            pkgs/main/linux-64::openssl-3.0.18-hd6dcaed_0 \n",
      "\u001b[94mcmd1:\u001b[0m   pip                pkgs/main/noarch::pip-25.3-pyhc872135_0 \n",
      "\u001b[94mcmd1:\u001b[0m   pthread-stubs      pkgs/main/linux-64::pthread-stubs-0.3-h0ce48e5_1 \n",
      "\u001b[94mcmd1:\u001b[0m   python             pkgs/main/linux-64::python-3.9.25-h0dcde21_1 \n",
      "\u001b[94mcmd1:\u001b[0m   readline           pkgs/main/linux-64::readline-8.3-hc2a1206_0 \n",
      "\u001b[94mcmd1:\u001b[0m   setuptools         pkgs/main/linux-64::setuptools-80.9.0-py39h06a4308_0 \n",
      "\u001b[94mcmd1:\u001b[0m   sqlite             pkgs/main/linux-64::sqlite-3.51.0-h2a70700_0 \n",
      "\u001b[94mcmd1:\u001b[0m   tk                 pkgs/main/linux-64::tk-8.6.15-h54e0aa7_0 \n",
      "\u001b[94mcmd1:\u001b[0m   tzdata             pkgs/main/noarch::tzdata-2025b-h04d1e81_0 \n",
      "\u001b[94mcmd1:\u001b[0m   wheel              pkgs/main/linux-64::wheel-0.45.1-py39h06a4308_0 \n",
      "\u001b[94mcmd1:\u001b[0m   xorg-libx11        pkgs/main/linux-64::xorg-libx11-1.8.12-h9b100fa_1 \n",
      "\u001b[94mcmd1:\u001b[0m   xorg-libxau        pkgs/main/linux-64::xorg-libxau-1.0.12-h9b100fa_0 \n",
      "\u001b[94mcmd1:\u001b[0m   xorg-libxdmcp      pkgs/main/linux-64::xorg-libxdmcp-1.1.5-h9b100fa_0 \n",
      "\u001b[94mcmd1:\u001b[0m   xorg-xorgproto     pkgs/main/linux-64::xorg-xorgproto-2024.1-h5eee18b_1 \n",
      "\u001b[94mcmd1:\u001b[0m   xz                 pkgs/main/linux-64::xz-5.6.4-h5eee18b_1 \n",
      "\u001b[94mcmd1:\u001b[0m   zlib               pkgs/main/linux-64::zlib-1.3.1-hb25bd0a_0 \n",
      "\u001b[94mcmd1:\u001b[0m \n",
      "\u001b[94mcmd1:\u001b[0m \n",
      "\u001b[94mcmd1:\u001b[0m \n",
      "\u001b[94mcmd1:\u001b[0m Downloading and Extracting Packages: ...working...\n",
      "\u001b[94mcmd1:\u001b[0m python-3.9.25        | 23.0 MB   |            |   0% \n",
      "\u001b[94mcmd1:\u001b[0m \n",
      "\u001b[94mcmd1:\u001b[0m setuptools-80.9.0    | 1.4 MB    |            |   0% \u001b[A\n",
      "\u001b[94mcmd1:\u001b[0m \n",
      "\u001b[94mcmd1:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m python-3.10.19       | 24.5 MB   | ########## | 100% \n",
      "\u001b[92mcmd2:\u001b[0m python-3.10.19       | 24.5 MB   | ########## | 100% \n",
      "\u001b[92mcmd2:\u001b[0m                                                      \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m                                                      \u001b[A\n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m                                                      \u001b[A\u001b[A\n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m                                                      \u001b[A\u001b[A\u001b[A done\n",
      "\u001b[94mcmd1:\u001b[0m wheel-0.45.1         | 114 KB    |            |   0% \u001b[A\u001b[A\n",
      "\u001b[94mcmd1:\u001b[0m python-3.9.25        | 23.0 MB   |            |   0% \n",
      "\u001b[94mcmd1:\u001b[0m \n",
      "\u001b[94mcmd1:\u001b[0m \n",
      "\u001b[94mcmd1:\u001b[0m wheel-0.45.1         | 114 KB    | #4         |  14% \u001b[A\u001b[A\n",
      "\u001b[94mcmd1:\u001b[0m \n",
      "\u001b[94mcmd1:\u001b[0m setuptools-80.9.0    | 1.4 MB    | 1          |   1% \u001b[A\n",
      "\u001b[94mcmd1:\u001b[0m \n",
      "\u001b[94mcmd1:\u001b[0m \n",
      "\u001b[94mcmd1:\u001b[0m wheel-0.45.1         | 114 KB    | ########## | 100% \u001b[A\u001b[A\n",
      "\u001b[94mcmd1:\u001b[0m \n",
      "\u001b[94mcmd1:\u001b[0m \n",
      "\u001b[94mcmd1:\u001b[0m wheel-0.45.1         | 114 KB    | ########## | 100% \u001b[A\u001b[A\n",
      "\u001b[94mcmd1:\u001b[0m \n",
      "\u001b[94mcmd1:\u001b[0m setuptools-80.9.0    | 1.4 MB    | ########## | 100% \u001b[A\n",
      "\u001b[94mcmd1:\u001b[0m python-3.9.25        | 23.0 MB   | #5         |  15% \n",
      "\u001b[94mcmd1:\u001b[0m python-3.9.25        | 23.0 MB   | ###        |  30% \n",
      "\u001b[92mcmd2:\u001b[0m Preparing transaction: done\n",
      "\u001b[94mcmd1:\u001b[0m python-3.9.25        | 23.0 MB   | #####3     |  53% \n",
      "\u001b[94mcmd1:\u001b[0m \n",
      "\u001b[94mcmd1:\u001b[0m setuptools-80.9.0    | 1.4 MB    | ########## | 100% \u001b[A\n",
      "\u001b[94mcmd1:\u001b[0m \n",
      "\u001b[94mcmd1:\u001b[0m setuptools-80.9.0    | 1.4 MB    | ########## | 100% \u001b[A\n",
      "\u001b[94mcmd1:\u001b[0m python-3.9.25        | 23.0 MB   | ######9    |  70% \n",
      "\u001b[94mcmd1:\u001b[0m python-3.9.25        | 23.0 MB   | ########3  |  84% \n",
      "\u001b[94mcmd1:\u001b[0m python-3.9.25        | 23.0 MB   | #########7 |  98% \n",
      "\u001b[94mcmd1:\u001b[0m python-3.9.25        | 23.0 MB   | ########## | 100% \n",
      "\u001b[94mcmd1:\u001b[0m python-3.9.25        | 23.0 MB   | ########## | 100% \n",
      "\u001b[94mcmd1:\u001b[0m                                                      \n",
      "\u001b[94mcmd1:\u001b[0m \n",
      "\u001b[94mcmd1:\u001b[0m                                                      \u001b[A\n",
      "\u001b[94mcmd1:\u001b[0m \n",
      "\u001b[94mcmd1:\u001b[0m \n",
      "\u001b[94mcmd1:\u001b[0m                                                      \u001b[A\u001b[A done\n",
      "\u001b[92mcmd2:\u001b[0m Verifying transaction: done\n",
      "\u001b[94mcmd1:\u001b[0m Preparing transaction: done\n",
      "\u001b[94mcmd1:\u001b[0m Verifying transaction: done\n",
      "\u001b[92mcmd2:\u001b[0m Executing transaction: done\n",
      "\u001b[92mcmd2:\u001b[0m #\n",
      "\u001b[92mcmd2:\u001b[0m # To activate this environment, use\n",
      "\u001b[92mcmd2:\u001b[0m #\n",
      "\u001b[92mcmd2:\u001b[0m #     $ conda activate b2txt25\n",
      "\u001b[92mcmd2:\u001b[0m #\n",
      "\u001b[92mcmd2:\u001b[0m # To deactivate an active environment, use\n",
      "\u001b[92mcmd2:\u001b[0m #\n",
      "\u001b[92mcmd2:\u001b[0m #     $ conda deactivate\n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Requirement already satisfied: pip in /root/miniconda3/envs/b2txt25/lib/python3.10/site-packages (25.3)\n",
      "\u001b[94mcmd1:\u001b[0m Executing transaction: done\n",
      "\u001b[94mcmd1:\u001b[0m #\n",
      "\u001b[94mcmd1:\u001b[0m # To activate this environment, use\n",
      "\u001b[94mcmd1:\u001b[0m #\n",
      "\u001b[94mcmd1:\u001b[0m #     $ conda activate b2txt25_lm\n",
      "\u001b[94mcmd1:\u001b[0m #\n",
      "\u001b[94mcmd1:\u001b[0m # To deactivate an active environment, use\n",
      "\u001b[94mcmd1:\u001b[0m #\n",
      "\u001b[94mcmd1:\u001b[0m #     $ conda deactivate\n",
      "\u001b[94mcmd1:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Looking in indexes: https://download.pytorch.org/whl/cu126\n",
      "\u001b[92mcmd2:\u001b[0m Collecting torch\n",
      "\u001b[92mcmd2:\u001b[0m   Downloading https://download.pytorch.org/whl/cu126/torch-2.9.1%2Bcu126-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (30 kB)\n",
      "\u001b[94mcmd1:\u001b[0m Requirement already satisfied: pip in /root/miniconda3/envs/b2txt25_lm/lib/python3.9/site-packages (25.3)\n",
      "\u001b[92mcmd2:\u001b[0m Collecting torchvision\n",
      "\u001b[92mcmd2:\u001b[0m   Downloading https://download.pytorch.org/whl/cu126/torchvision-0.24.1%2Bcu126-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (5.9 kB)\n",
      "\u001b[92mcmd2:\u001b[0m Collecting torchaudio\n",
      "\u001b[92mcmd2:\u001b[0m   Downloading https://download.pytorch.org/whl/cu126/torchaudio-2.9.1%2Bcu126-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (6.9 kB)\n",
      "\u001b[94mcmd1:\u001b[0m Collecting torch==1.13.1\n",
      "\u001b[94mcmd1:\u001b[0m   Downloading torch-1.13.1-cp39-cp39-manylinux1_x86_64.whl.metadata (24 kB)\n",
      "\u001b[94mcmd1:\u001b[0m Collecting redis==5.0.6\n",
      "\u001b[94mcmd1:\u001b[0m   Downloading redis-5.0.6-py3-none-any.whl.metadata (9.3 kB)\n",
      "\u001b[92mcmd2:\u001b[0m Collecting filelock (from torch)\n",
      "\u001b[94mcmd1:\u001b[0m Collecting jupyter==1.1.1\n",
      "\u001b[94mcmd1:\u001b[0m   Downloading jupyter-1.1.1-py2.py3-none-any.whl.metadata (2.0 kB)\n",
      "\u001b[92mcmd2:\u001b[0m   Downloading filelock-3.20.0-py3-none-any.whl.metadata (2.1 kB)\n",
      "\u001b[92mcmd2:\u001b[0m Collecting typing-extensions>=4.10.0 (from torch)\n",
      "\u001b[92mcmd2:\u001b[0m   Downloading https://download.pytorch.org/whl/typing_extensions-4.15.0-py3-none-any.whl.metadata (3.3 kB)\n",
      "\u001b[94mcmd1:\u001b[0m Collecting numpy==1.24.4\n",
      "\u001b[94mcmd1:\u001b[0m   Downloading numpy-1.24.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.6 kB)\n",
      "\u001b[92mcmd2:\u001b[0m Collecting sympy>=1.13.3 (from torch)\n",
      "\u001b[92mcmd2:\u001b[0m   Downloading sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
      "\u001b[94mcmd1:\u001b[0m Collecting matplotlib==3.9.0\n",
      "\u001b[94mcmd1:\u001b[0m   Downloading matplotlib-3.9.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
      "\u001b[92mcmd2:\u001b[0m Collecting networkx>=2.5.1 (from torch)\n",
      "\u001b[92mcmd2:\u001b[0m   Downloading networkx-3.4.2-py3-none-any.whl.metadata (6.3 kB)\n",
      "\u001b[94mcmd1:\u001b[0m Collecting scipy==1.11.1\n",
      "\u001b[94mcmd1:\u001b[0m   Downloading scipy-1.11.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (59 kB)\n",
      "\u001b[92mcmd2:\u001b[0m Collecting jinja2 (from torch)\n",
      "\u001b[92mcmd2:\u001b[0m   Downloading https://download.pytorch.org/whl/jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
      "\u001b[94mcmd1:\u001b[0m Collecting scikit-learn==1.6.1\n",
      "\u001b[94mcmd1:\u001b[0m   Downloading scikit_learn-1.6.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
      "\u001b[94mcmd1:\u001b[0m Collecting tqdm==4.66.4\n",
      "\u001b[94mcmd1:\u001b[0m   Downloading tqdm-4.66.4-py3-none-any.whl.metadata (57 kB)\n",
      "\u001b[94mcmd1:\u001b[0m Collecting g2p_en==2.1.0\n",
      "\u001b[94mcmd1:\u001b[0m   Downloading g2p_en-2.1.0-py3-none-any.whl.metadata (4.5 kB)\n",
      "\u001b[94mcmd1:\u001b[0m Collecting omegaconf==2.3.0\n",
      "\u001b[92mcmd2:\u001b[0m Collecting fsspec>=0.8.5 (from torch)\n",
      "\u001b[94mcmd1:\u001b[0m   Downloading omegaconf-2.3.0-py3-none-any.whl.metadata (3.9 kB)\n",
      "\u001b[92mcmd2:\u001b[0m   Downloading fsspec-2025.12.0-py3-none-any.whl.metadata (10 kB)\n",
      "\u001b[92mcmd2:\u001b[0m Collecting nvidia-cuda-nvrtc-cu12==12.6.77 (from torch)\n",
      "\u001b[94mcmd1:\u001b[0m Collecting huggingface-hub==0.23.4\n",
      "\u001b[94mcmd1:\u001b[0m   Downloading huggingface_hub-0.23.4-py3-none-any.whl.metadata (12 kB)\n",
      "\u001b[92mcmd2:\u001b[0m   Downloading https://pypi.nvidia.com/nvidia-cuda-nvrtc-cu12/nvidia_cuda_nvrtc_cu12-12.6.77-py3-none-manylinux2014_x86_64.whl (23.7 MB)\n",
      "\u001b[94mcmd1:\u001b[0m Collecting transformers==4.40.0\n",
      "\u001b[94mcmd1:\u001b[0m   Downloading transformers-4.40.0-py3-none-any.whl.metadata (137 kB)\n",
      "\u001b[92mcmd2:\u001b[0m      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 23.7/23.7 MB 147.2 MB/s  0:00:00\n",
      "\u001b[92mcmd2:\u001b[0m Collecting nvidia-cuda-runtime-cu12==12.6.77 (from torch)\n",
      "\u001b[92mcmd2:\u001b[0m   Downloading https://pypi.nvidia.com/nvidia-cuda-runtime-cu12/nvidia_cuda_runtime_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (897 kB)\n",
      "\u001b[92mcmd2:\u001b[0m      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 897.7/897.7 kB 145.1 MB/s  0:00:00\n",
      "\u001b[92mcmd2:\u001b[0m Collecting nvidia-cuda-cupti-cu12==12.6.80 (from torch)\n",
      "\u001b[92mcmd2:\u001b[0m   Downloading https://pypi.nvidia.com/nvidia-cuda-cupti-cu12/nvidia_cuda_cupti_cu12-12.6.80-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (8.9 MB)\n",
      "\u001b[92mcmd2:\u001b[0m      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 8.9/8.9 MB 179.6 MB/s  0:00:00\n",
      "\u001b[92mcmd2:\u001b[0m Collecting nvidia-cudnn-cu12==9.10.2.21 (from torch)\n",
      "\u001b[92mcmd2:\u001b[0m   Downloading https://pypi.nvidia.com/nvidia-cudnn-cu12/nvidia_cudnn_cu12-9.10.2.21-py3-none-manylinux_2_27_x86_64.whl (706.8 MB)\n",
      "\u001b[94mcmd1:\u001b[0m Collecting tokenizers==0.19.1\n",
      "\u001b[94mcmd1:\u001b[0m   Downloading tokenizers-0.19.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "\u001b[94mcmd1:\u001b[0m Collecting accelerate==0.33.0\n",
      "\u001b[94mcmd1:\u001b[0m   Downloading accelerate-0.33.0-py3-none-any.whl.metadata (18 kB)\n",
      "\u001b[94mcmd1:\u001b[0m Collecting bitsandbytes==0.41.1\n",
      "\u001b[94mcmd1:\u001b[0m   Downloading bitsandbytes-0.41.1-py3-none-any.whl.metadata (9.8 kB)\n",
      "\u001b[94mcmd1:\u001b[0m Collecting typing-extensions (from torch==1.13.1)\n",
      "\u001b[94mcmd1:\u001b[0m   Downloading typing_extensions-4.15.0-py3-none-any.whl.metadata (3.3 kB)\n",
      "\u001b[94mcmd1:\u001b[0m Collecting nvidia-cuda-runtime-cu11==11.7.99 (from torch==1.13.1)\n",
      "\u001b[94mcmd1:\u001b[0m   Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "\u001b[94mcmd1:\u001b[0m Collecting nvidia-cudnn-cu11==8.5.0.96 (from torch==1.13.1)\n",
      "\u001b[94mcmd1:\u001b[0m   Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "\u001b[94mcmd1:\u001b[0m Collecting nvidia-cublas-cu11==11.10.3.66 (from torch==1.13.1)\n",
      "\u001b[94mcmd1:\u001b[0m   Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "\u001b[94mcmd1:\u001b[0m Collecting nvidia-cuda-nvrtc-cu11==11.7.99 (from torch==1.13.1)\n",
      "\u001b[94mcmd1:\u001b[0m   Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "\u001b[94mcmd1:\u001b[0m Collecting async-timeout>=4.0.3 (from redis==5.0.6)\n",
      "\u001b[94mcmd1:\u001b[0m   Downloading async_timeout-5.0.1-py3-none-any.whl.metadata (5.1 kB)\n",
      "\u001b[94mcmd1:\u001b[0m Collecting notebook (from jupyter==1.1.1)\n",
      "\u001b[94mcmd1:\u001b[0m   Downloading notebook-7.5.1-py3-none-any.whl.metadata (10 kB)\n",
      "\u001b[94mcmd1:\u001b[0m Collecting jupyter-console (from jupyter==1.1.1)\n",
      "\u001b[94mcmd1:\u001b[0m   Downloading jupyter_console-6.6.3-py3-none-any.whl.metadata (5.8 kB)\n",
      "\u001b[94mcmd1:\u001b[0m Collecting nbconvert (from jupyter==1.1.1)\n",
      "\u001b[94mcmd1:\u001b[0m   Downloading nbconvert-7.16.6-py3-none-any.whl.metadata (8.5 kB)\n",
      "\u001b[94mcmd1:\u001b[0m Collecting ipykernel (from jupyter==1.1.1)\n",
      "\u001b[94mcmd1:\u001b[0m   Downloading ipykernel-6.31.0-py3-none-any.whl.metadata (4.5 kB)\n",
      "\u001b[94mcmd1:\u001b[0m Collecting ipywidgets (from jupyter==1.1.1)\n",
      "\u001b[94mcmd1:\u001b[0m   Downloading ipywidgets-8.1.8-py3-none-any.whl.metadata (2.4 kB)\n",
      "\u001b[94mcmd1:\u001b[0m Collecting jupyterlab (from jupyter==1.1.1)\n",
      "\u001b[94mcmd1:\u001b[0m   Downloading jupyterlab-4.5.1-py3-none-any.whl.metadata (16 kB)\n",
      "\u001b[94mcmd1:\u001b[0m Collecting contourpy>=1.0.1 (from matplotlib==3.9.0)\n",
      "\u001b[94mcmd1:\u001b[0m   Downloading contourpy-1.3.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.4 kB)\n",
      "\u001b[94mcmd1:\u001b[0m Collecting cycler>=0.10 (from matplotlib==3.9.0)\n",
      "\u001b[94mcmd1:\u001b[0m   Downloading cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "\u001b[94mcmd1:\u001b[0m Collecting fonttools>=4.22.0 (from matplotlib==3.9.0)\n",
      "\u001b[94mcmd1:\u001b[0m   Downloading fonttools-4.60.2-cp39-cp39-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (113 kB)\n",
      "\u001b[94mcmd1:\u001b[0m Collecting kiwisolver>=1.3.1 (from matplotlib==3.9.0)\n",
      "\u001b[94mcmd1:\u001b[0m   Downloading kiwisolver-1.4.7-cp39-cp39-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (6.3 kB)\n",
      "\u001b[94mcmd1:\u001b[0m Collecting packaging>=20.0 (from matplotlib==3.9.0)\n",
      "\u001b[94mcmd1:\u001b[0m   Downloading packaging-25.0-py3-none-any.whl.metadata (3.3 kB)\n",
      "\u001b[94mcmd1:\u001b[0m Collecting pillow>=8 (from matplotlib==3.9.0)\n",
      "\u001b[94mcmd1:\u001b[0m   Downloading pillow-11.3.0-cp39-cp39-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (9.0 kB)\n",
      "\u001b[94mcmd1:\u001b[0m Collecting pyparsing>=2.3.1 (from matplotlib==3.9.0)\n",
      "\u001b[94mcmd1:\u001b[0m   Downloading pyparsing-3.3.1-py3-none-any.whl.metadata (5.6 kB)\n",
      "\u001b[94mcmd1:\u001b[0m Collecting python-dateutil>=2.7 (from matplotlib==3.9.0)\n",
      "\u001b[94mcmd1:\u001b[0m   Downloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl.metadata (8.4 kB)\n",
      "\u001b[94mcmd1:\u001b[0m Collecting importlib-resources>=3.2.0 (from matplotlib==3.9.0)\n",
      "\u001b[92mcmd2:\u001b[0m      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 706.8/706.8 MB 149.9 MB/s  0:00:04\n",
      "\u001b[94mcmd1:\u001b[0m   Downloading importlib_resources-6.5.2-py3-none-any.whl.metadata (3.9 kB)\n",
      "\u001b[94mcmd1:\u001b[0m Collecting joblib>=1.2.0 (from scikit-learn==1.6.1)\n",
      "\u001b[94mcmd1:\u001b[0m   Downloading joblib-1.5.3-py3-none-any.whl.metadata (5.5 kB)\n",
      "\u001b[94mcmd1:\u001b[0m Collecting threadpoolctl>=3.1.0 (from scikit-learn==1.6.1)\n",
      "\u001b[94mcmd1:\u001b[0m   Downloading threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "\u001b[94mcmd1:\u001b[0m Collecting nltk>=3.2.4 (from g2p_en==2.1.0)\n",
      "\u001b[94mcmd1:\u001b[0m   Downloading nltk-3.9.2-py3-none-any.whl.metadata (3.2 kB)\n",
      "\u001b[94mcmd1:\u001b[0m Collecting inflect>=0.3.1 (from g2p_en==2.1.0)\n",
      "\u001b[94mcmd1:\u001b[0m   Downloading inflect-7.5.0-py3-none-any.whl.metadata (24 kB)\n",
      "\u001b[94mcmd1:\u001b[0m Collecting distance>=0.1.3 (from g2p_en==2.1.0)\n",
      "\u001b[94mcmd1:\u001b[0m   Downloading Distance-0.1.3.tar.gz (180 kB)\n",
      "\u001b[94mcmd1:\u001b[0m   Installing build dependencies: started\n",
      "\u001b[92mcmd2:\u001b[0m Collecting nvidia-cublas-cu12==12.6.4.1 (from torch)\n",
      "\u001b[92mcmd2:\u001b[0m   Downloading https://pypi.nvidia.com/nvidia-cublas-cu12/nvidia_cublas_cu12-12.6.4.1-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (393.1 MB)\n",
      "\u001b[94mcmd1:\u001b[0m   Installing build dependencies: finished with status 'done'\n",
      "\u001b[94mcmd1:\u001b[0m   Getting requirements to build wheel: started\n",
      "\u001b[94mcmd1:\u001b[0m   Getting requirements to build wheel: finished with status 'done'\n",
      "\u001b[94mcmd1:\u001b[0m   Preparing metadata (pyproject.toml): started\n",
      "\u001b[94mcmd1:\u001b[0m   Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "\u001b[94mcmd1:\u001b[0m Collecting antlr4-python3-runtime==4.9.* (from omegaconf==2.3.0)\n",
      "\u001b[94mcmd1:\u001b[0m   Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n",
      "\u001b[94mcmd1:\u001b[0m   Installing build dependencies: started\n",
      "\u001b[92mcmd2:\u001b[0m      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 393.1/393.1 MB 158.3 MB/s  0:00:02\n",
      "\u001b[94mcmd1:\u001b[0m   Installing build dependencies: finished with status 'done'\n",
      "\u001b[94mcmd1:\u001b[0m   Getting requirements to build wheel: started\n",
      "\u001b[94mcmd1:\u001b[0m   Getting requirements to build wheel: finished with status 'done'\n",
      "\u001b[94mcmd1:\u001b[0m   Preparing metadata (pyproject.toml): started\n",
      "\u001b[94mcmd1:\u001b[0m   Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "\u001b[94mcmd1:\u001b[0m Collecting PyYAML>=5.1.0 (from omegaconf==2.3.0)\n",
      "\u001b[94mcmd1:\u001b[0m   Downloading pyyaml-6.0.3-cp39-cp39-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (2.4 kB)\n",
      "\u001b[94mcmd1:\u001b[0m Collecting filelock (from huggingface-hub==0.23.4)\n",
      "\u001b[94mcmd1:\u001b[0m   Downloading filelock-3.19.1-py3-none-any.whl.metadata (2.1 kB)\n",
      "\u001b[94mcmd1:\u001b[0m Collecting fsspec>=2023.5.0 (from huggingface-hub==0.23.4)\n",
      "\u001b[94mcmd1:\u001b[0m   Downloading fsspec-2025.10.0-py3-none-any.whl.metadata (10 kB)\n",
      "\u001b[94mcmd1:\u001b[0m Collecting requests (from huggingface-hub==0.23.4)\n",
      "\u001b[94mcmd1:\u001b[0m   Downloading requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
      "\u001b[92mcmd2:\u001b[0m Collecting nvidia-cufft-cu12==11.3.0.4 (from torch)\n",
      "\u001b[92mcmd2:\u001b[0m   Downloading https://pypi.nvidia.com/nvidia-cufft-cu12/nvidia_cufft_cu12-11.3.0.4-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (200.2 MB)\n",
      "\u001b[94mcmd1:\u001b[0m Collecting regex!=2019.12.17 (from transformers==4.40.0)\n",
      "\u001b[92mcmd2:\u001b[0m      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 200.2/200.2 MB 147.3 MB/s  0:00:01\n",
      "\u001b[94mcmd1:\u001b[0m   Downloading regex-2025.11.3-cp39-cp39-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (40 kB)\n",
      "\u001b[94mcmd1:\u001b[0m Collecting safetensors>=0.4.1 (from transformers==4.40.0)\n",
      "\u001b[94mcmd1:\u001b[0m   Downloading safetensors-0.7.0-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
      "\u001b[92mcmd2:\u001b[0m Collecting nvidia-curand-cu12==10.3.7.77 (from torch)\n",
      "\u001b[92mcmd2:\u001b[0m   Downloading https://pypi.nvidia.com/nvidia-curand-cu12/nvidia_curand_cu12-10.3.7.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (56.3 MB)\n",
      "\u001b[94mcmd1:\u001b[0m Collecting psutil (from accelerate==0.33.0)\n",
      "\u001b[94mcmd1:\u001b[0m   Downloading psutil-7.2.0-cp36-abi3-manylinux2010_x86_64.manylinux_2_12_x86_64.manylinux_2_28_x86_64.whl.metadata (22 kB)\n",
      "\u001b[94mcmd1:\u001b[0m Requirement already satisfied: setuptools in /root/miniconda3/envs/b2txt25_lm/lib/python3.9/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch==1.13.1) (80.9.0)\n",
      "\u001b[94mcmd1:\u001b[0m Requirement already satisfied: wheel in /root/miniconda3/envs/b2txt25_lm/lib/python3.9/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch==1.13.1) (0.45.1)\n",
      "\u001b[94mcmd1:\u001b[0m Collecting zipp>=3.1.0 (from importlib-resources>=3.2.0->matplotlib==3.9.0)\n",
      "\u001b[94mcmd1:\u001b[0m   Downloading zipp-3.23.0-py3-none-any.whl.metadata (3.6 kB)\n",
      "\u001b[94mcmd1:\u001b[0m Collecting more_itertools>=8.5.0 (from inflect>=0.3.1->g2p_en==2.1.0)\n",
      "\u001b[94mcmd1:\u001b[0m   Downloading more_itertools-10.8.0-py3-none-any.whl.metadata (39 kB)\n",
      "\u001b[92mcmd2:\u001b[0m      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 56.3/56.3 MB 157.1 MB/s  0:00:00\n",
      "\u001b[94mcmd1:\u001b[0m Collecting typeguard>=4.0.1 (from inflect>=0.3.1->g2p_en==2.1.0)\n",
      "\u001b[94mcmd1:\u001b[0m   Downloading typeguard-4.4.4-py3-none-any.whl.metadata (3.3 kB)\n",
      "\u001b[94mcmd1:\u001b[0m Collecting click (from nltk>=3.2.4->g2p_en==2.1.0)\n",
      "\u001b[94mcmd1:\u001b[0m   Downloading click-8.1.8-py3-none-any.whl.metadata (2.3 kB)\n",
      "\u001b[92mcmd2:\u001b[0m Collecting nvidia-cusolver-cu12==11.7.1.2 (from torch)\n",
      "\u001b[94mcmd1:\u001b[0m Collecting six>=1.5 (from python-dateutil>=2.7->matplotlib==3.9.0)\n",
      "\u001b[94mcmd1:\u001b[0m   Downloading six-1.17.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
      "\u001b[92mcmd2:\u001b[0m   Downloading https://pypi.nvidia.com/nvidia-cusolver-cu12/nvidia_cusolver_cu12-11.7.1.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (158.2 MB)\n",
      "\u001b[94mcmd1:\u001b[0m Collecting importlib_metadata>=3.6 (from typeguard>=4.0.1->inflect>=0.3.1->g2p_en==2.1.0)\n",
      "\u001b[94mcmd1:\u001b[0m   Downloading importlib_metadata-8.7.1-py3-none-any.whl.metadata (4.7 kB)\n",
      "\u001b[94mcmd1:\u001b[0m Collecting comm>=0.1.1 (from ipykernel->jupyter==1.1.1)\n",
      "\u001b[94mcmd1:\u001b[0m   Downloading comm-0.2.3-py3-none-any.whl.metadata (3.7 kB)\n",
      "\u001b[94mcmd1:\u001b[0m Collecting debugpy>=1.6.5 (from ipykernel->jupyter==1.1.1)\n",
      "\u001b[94mcmd1:\u001b[0m   Downloading debugpy-1.8.19-cp39-cp39-manylinux_2_34_x86_64.whl.metadata (1.4 kB)\n",
      "\u001b[94mcmd1:\u001b[0m Collecting ipython>=7.23.1 (from ipykernel->jupyter==1.1.1)\n",
      "\u001b[94mcmd1:\u001b[0m   Downloading ipython-8.18.1-py3-none-any.whl.metadata (6.0 kB)\n",
      "\u001b[94mcmd1:\u001b[0m Collecting jupyter-client>=8.0.0 (from ipykernel->jupyter==1.1.1)\n",
      "\u001b[94mcmd1:\u001b[0m   Downloading jupyter_client-8.6.3-py3-none-any.whl.metadata (8.3 kB)\n",
      "\u001b[94mcmd1:\u001b[0m Collecting jupyter-core!=5.0.*,>=4.12 (from ipykernel->jupyter==1.1.1)\n",
      "\u001b[94mcmd1:\u001b[0m   Downloading jupyter_core-5.8.1-py3-none-any.whl.metadata (1.6 kB)\n",
      "\u001b[92mcmd2:\u001b[0m      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 158.2/158.2 MB 156.0 MB/s  0:00:01\n",
      "\u001b[94mcmd1:\u001b[0m Collecting matplotlib-inline>=0.1 (from ipykernel->jupyter==1.1.1)\n",
      "\u001b[94mcmd1:\u001b[0m   Downloading matplotlib_inline-0.2.1-py3-none-any.whl.metadata (2.3 kB)\n",
      "\u001b[94mcmd1:\u001b[0m Collecting nest-asyncio>=1.4 (from ipykernel->jupyter==1.1.1)\n",
      "\u001b[94mcmd1:\u001b[0m   Downloading nest_asyncio-1.6.0-py3-none-any.whl.metadata (2.8 kB)\n",
      "\u001b[92mcmd2:\u001b[0m Collecting nvidia-cusparse-cu12==12.5.4.2 (from torch)\n",
      "\u001b[92mcmd2:\u001b[0m   Downloading https://pypi.nvidia.com/nvidia-cusparse-cu12/nvidia_cusparse_cu12-12.5.4.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (216.6 MB)\n",
      "\u001b[94mcmd1:\u001b[0m Collecting pyzmq>=25 (from ipykernel->jupyter==1.1.1)\n",
      "\u001b[94mcmd1:\u001b[0m   Downloading pyzmq-27.1.0-cp39-cp39-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (6.0 kB)\n",
      "\u001b[94mcmd1:\u001b[0m Collecting tornado>=6.2 (from ipykernel->jupyter==1.1.1)\n",
      "\u001b[94mcmd1:\u001b[0m   Downloading tornado-6.5.4-cp39-abi3-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.8 kB)\n",
      "\u001b[94mcmd1:\u001b[0m Collecting traitlets>=5.4.0 (from ipykernel->jupyter==1.1.1)\n",
      "\u001b[94mcmd1:\u001b[0m   Downloading traitlets-5.14.3-py3-none-any.whl.metadata (10 kB)\n",
      "\u001b[94mcmd1:\u001b[0m Collecting decorator (from ipython>=7.23.1->ipykernel->jupyter==1.1.1)\n",
      "\u001b[94mcmd1:\u001b[0m   Downloading decorator-5.2.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "\u001b[94mcmd1:\u001b[0m Collecting jedi>=0.16 (from ipython>=7.23.1->ipykernel->jupyter==1.1.1)\n",
      "\u001b[94mcmd1:\u001b[0m   Downloading jedi-0.19.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "\u001b[94mcmd1:\u001b[0m Collecting prompt-toolkit<3.1.0,>=3.0.41 (from ipython>=7.23.1->ipykernel->jupyter==1.1.1)\n",
      "\u001b[94mcmd1:\u001b[0m   Downloading prompt_toolkit-3.0.52-py3-none-any.whl.metadata (6.4 kB)\n",
      "\u001b[94mcmd1:\u001b[0m Collecting pygments>=2.4.0 (from ipython>=7.23.1->ipykernel->jupyter==1.1.1)\n",
      "\u001b[94mcmd1:\u001b[0m   Downloading pygments-2.19.2-py3-none-any.whl.metadata (2.5 kB)\n",
      "\u001b[94mcmd1:\u001b[0m Collecting stack-data (from ipython>=7.23.1->ipykernel->jupyter==1.1.1)\n",
      "\u001b[94mcmd1:\u001b[0m   Downloading stack_data-0.6.3-py3-none-any.whl.metadata (18 kB)\n",
      "\u001b[92mcmd2:\u001b[0m      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 216.6/216.6 MB 169.1 MB/s  0:00:01\n",
      "\u001b[94mcmd1:\u001b[0m Collecting exceptiongroup (from ipython>=7.23.1->ipykernel->jupyter==1.1.1)\n",
      "\u001b[94mcmd1:\u001b[0m   Downloading exceptiongroup-1.3.1-py3-none-any.whl.metadata (6.7 kB)\n",
      "\u001b[94mcmd1:\u001b[0m Collecting pexpect>4.3 (from ipython>=7.23.1->ipykernel->jupyter==1.1.1)\n",
      "\u001b[94mcmd1:\u001b[0m   Downloading pexpect-4.9.0-py2.py3-none-any.whl.metadata (2.5 kB)\n",
      "\u001b[94mcmd1:\u001b[0m Collecting wcwidth (from prompt-toolkit<3.1.0,>=3.0.41->ipython>=7.23.1->ipykernel->jupyter==1.1.1)\n",
      "\u001b[94mcmd1:\u001b[0m   Downloading wcwidth-0.2.14-py2.py3-none-any.whl.metadata (15 kB)\n",
      "\u001b[94mcmd1:\u001b[0m Collecting parso<0.9.0,>=0.8.4 (from jedi>=0.16->ipython>=7.23.1->ipykernel->jupyter==1.1.1)\n",
      "\u001b[94mcmd1:\u001b[0m   Downloading parso-0.8.5-py2.py3-none-any.whl.metadata (8.3 kB)\n",
      "\u001b[94mcmd1:\u001b[0m Collecting platformdirs>=2.5 (from jupyter-core!=5.0.*,>=4.12->ipykernel->jupyter==1.1.1)\n",
      "\u001b[94mcmd1:\u001b[0m   Downloading platformdirs-4.4.0-py3-none-any.whl.metadata (12 kB)\n",
      "\u001b[94mcmd1:\u001b[0m Collecting ptyprocess>=0.5 (from pexpect>4.3->ipython>=7.23.1->ipykernel->jupyter==1.1.1)\n",
      "\u001b[94mcmd1:\u001b[0m   Downloading ptyprocess-0.7.0-py2.py3-none-any.whl.metadata (1.3 kB)\n",
      "\u001b[94mcmd1:\u001b[0m Collecting widgetsnbextension~=4.0.14 (from ipywidgets->jupyter==1.1.1)\n",
      "\u001b[94mcmd1:\u001b[0m   Downloading widgetsnbextension-4.0.15-py3-none-any.whl.metadata (1.6 kB)\n",
      "\u001b[92mcmd2:\u001b[0m Collecting nvidia-cusparselt-cu12==0.7.1 (from torch)\n",
      "\u001b[92mcmd2:\u001b[0m   Downloading https://pypi.nvidia.com/nvidia-cusparselt-cu12/nvidia_cusparselt_cu12-0.7.1-py3-none-manylinux2014_x86_64.whl (287.2 MB)\n",
      "\u001b[94mcmd1:\u001b[0m Collecting jupyterlab_widgets~=3.0.15 (from ipywidgets->jupyter==1.1.1)\n",
      "\u001b[94mcmd1:\u001b[0m   Downloading jupyterlab_widgets-3.0.16-py3-none-any.whl.metadata (20 kB)\n",
      "\u001b[94mcmd1:\u001b[0m Collecting async-lru>=1.0.0 (from jupyterlab->jupyter==1.1.1)\n",
      "\u001b[94mcmd1:\u001b[0m   Downloading async_lru-2.0.5-py3-none-any.whl.metadata (4.5 kB)\n",
      "\u001b[94mcmd1:\u001b[0m Collecting httpx<1,>=0.25.0 (from jupyterlab->jupyter==1.1.1)\n",
      "\u001b[94mcmd1:\u001b[0m   Downloading httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "\u001b[94mcmd1:\u001b[0m Collecting jinja2>=3.0.3 (from jupyterlab->jupyter==1.1.1)\n",
      "\u001b[94mcmd1:\u001b[0m   Downloading jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
      "\u001b[94mcmd1:\u001b[0m Collecting jupyter-lsp>=2.0.0 (from jupyterlab->jupyter==1.1.1)\n",
      "\u001b[94mcmd1:\u001b[0m   Downloading jupyter_lsp-2.3.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "\u001b[94mcmd1:\u001b[0m Collecting jupyter-server<3,>=2.4.0 (from jupyterlab->jupyter==1.1.1)\n",
      "\u001b[94mcmd1:\u001b[0m   Downloading jupyter_server-2.17.0-py3-none-any.whl.metadata (8.5 kB)\n",
      "\u001b[92mcmd2:\u001b[0m      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 287.2/287.2 MB 155.9 MB/s  0:00:01\n",
      "\u001b[94mcmd1:\u001b[0m Collecting jupyterlab-server<3,>=2.28.0 (from jupyterlab->jupyter==1.1.1)\n",
      "\u001b[94mcmd1:\u001b[0m   Downloading jupyterlab_server-2.28.0-py3-none-any.whl.metadata (5.9 kB)\n",
      "\u001b[92mcmd2:\u001b[0m Collecting nvidia-nccl-cu12==2.27.5 (from torch)\n",
      "\u001b[92mcmd2:\u001b[0m   Downloading https://pypi.nvidia.com/nvidia-nccl-cu12/nvidia_nccl_cu12-2.27.5-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (322.3 MB)\n",
      "\u001b[94mcmd1:\u001b[0m Collecting notebook-shim>=0.2 (from jupyterlab->jupyter==1.1.1)\n",
      "\u001b[94mcmd1:\u001b[0m   Downloading notebook_shim-0.2.4-py3-none-any.whl.metadata (4.0 kB)\n",
      "\u001b[94mcmd1:\u001b[0m Collecting tomli>=1.2.2 (from jupyterlab->jupyter==1.1.1)\n",
      "\u001b[94mcmd1:\u001b[0m   WARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ProtocolError('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer'))': /packages/77/b8/0135fadc89e73be292b473cb820b4f5a08197779206b33191e801feeae40/tomli-2.3.0-py3-none-any.whl.metadata\n",
      "\u001b[94mcmd1:\u001b[0m   Downloading tomli-2.3.0-py3-none-any.whl.metadata (10 kB)\n",
      "\u001b[94mcmd1:\u001b[0m Collecting anyio (from httpx<1,>=0.25.0->jupyterlab->jupyter==1.1.1)\n",
      "\u001b[94mcmd1:\u001b[0m   Downloading anyio-4.12.0-py3-none-any.whl.metadata (4.3 kB)\n",
      "\u001b[94mcmd1:\u001b[0m Collecting certifi (from httpx<1,>=0.25.0->jupyterlab->jupyter==1.1.1)\n",
      "\u001b[94mcmd1:\u001b[0m   Downloading certifi-2025.11.12-py3-none-any.whl.metadata (2.5 kB)\n",
      "\u001b[92mcmd2:\u001b[0m      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 322.3/322.3 MB 159.1 MB/s  0:00:01\n",
      "\u001b[94mcmd1:\u001b[0m Collecting httpcore==1.* (from httpx<1,>=0.25.0->jupyterlab->jupyter==1.1.1)\n",
      "\u001b[94mcmd1:\u001b[0m   Downloading httpcore-1.0.9-py3-none-any.whl.metadata (21 kB)\n",
      "\u001b[94mcmd1:\u001b[0m Collecting idna (from httpx<1,>=0.25.0->jupyterlab->jupyter==1.1.1)\n",
      "\u001b[94mcmd1:\u001b[0m   Downloading idna-3.11-py3-none-any.whl.metadata (8.4 kB)\n",
      "\u001b[94mcmd1:\u001b[0m Collecting h11>=0.16 (from httpcore==1.*->httpx<1,>=0.25.0->jupyterlab->jupyter==1.1.1)\n",
      "\u001b[94mcmd1:\u001b[0m   Downloading h11-0.16.0-py3-none-any.whl.metadata (8.3 kB)\n",
      "\u001b[94mcmd1:\u001b[0m Collecting argon2-cffi>=21.1 (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter==1.1.1)\n",
      "\u001b[94mcmd1:\u001b[0m   Downloading argon2_cffi-25.1.0-py3-none-any.whl.metadata (4.1 kB)\n",
      "\u001b[94mcmd1:\u001b[0m Collecting jupyter-events>=0.11.0 (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter==1.1.1)\n",
      "\u001b[94mcmd1:\u001b[0m   Downloading jupyter_events-0.12.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "\u001b[94mcmd1:\u001b[0m Collecting jupyter-server-terminals>=0.4.4 (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter==1.1.1)\n",
      "\u001b[94mcmd1:\u001b[0m   Downloading jupyter_server_terminals-0.5.3-py3-none-any.whl.metadata (5.6 kB)\n",
      "\u001b[94mcmd1:\u001b[0m Collecting nbformat>=5.3.0 (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter==1.1.1)\n",
      "\u001b[94mcmd1:\u001b[0m   Downloading nbformat-5.10.4-py3-none-any.whl.metadata (3.6 kB)\n",
      "\u001b[94mcmd1:\u001b[0m Collecting overrides>=5.0 (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter==1.1.1)\n",
      "\u001b[94mcmd1:\u001b[0m   Downloading overrides-7.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "\u001b[94mcmd1:\u001b[0m Collecting prometheus-client>=0.9 (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter==1.1.1)\n",
      "\u001b[94mcmd1:\u001b[0m   Downloading prometheus_client-0.23.1-py3-none-any.whl.metadata (1.9 kB)\n",
      "\u001b[94mcmd1:\u001b[0m Collecting send2trash>=1.8.2 (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter==1.1.1)\n",
      "\u001b[94mcmd1:\u001b[0m   Downloading Send2Trash-1.8.3-py3-none-any.whl.metadata (4.0 kB)\n",
      "\u001b[94mcmd1:\u001b[0m Collecting terminado>=0.8.3 (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter==1.1.1)\n",
      "\u001b[94mcmd1:\u001b[0m   Downloading terminado-0.18.1-py3-none-any.whl.metadata (5.8 kB)\n",
      "\u001b[92mcmd2:\u001b[0m Collecting nvidia-nvshmem-cu12==3.3.20 (from torch)\n",
      "\u001b[94mcmd1:\u001b[0m Collecting websocket-client>=1.7 (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter==1.1.1)\n",
      "\u001b[92mcmd2:\u001b[0m   Downloading https://pypi.nvidia.com/nvidia-nvshmem-cu12/nvidia_nvshmem_cu12-3.3.20-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (124.7 MB)\n",
      "\u001b[94mcmd1:\u001b[0m   Downloading websocket_client-1.9.0-py3-none-any.whl.metadata (8.3 kB)\n",
      "\u001b[94mcmd1:\u001b[0m Collecting babel>=2.10 (from jupyterlab-server<3,>=2.28.0->jupyterlab->jupyter==1.1.1)\n",
      "\u001b[94mcmd1:\u001b[0m   Downloading babel-2.17.0-py3-none-any.whl.metadata (2.0 kB)\n",
      "\u001b[94mcmd1:\u001b[0m Collecting json5>=0.9.0 (from jupyterlab-server<3,>=2.28.0->jupyterlab->jupyter==1.1.1)\n",
      "\u001b[94mcmd1:\u001b[0m   Downloading json5-0.12.1-py3-none-any.whl.metadata (36 kB)\n",
      "\u001b[94mcmd1:\u001b[0m Collecting jsonschema>=4.18.0 (from jupyterlab-server<3,>=2.28.0->jupyterlab->jupyter==1.1.1)\n",
      "\u001b[94mcmd1:\u001b[0m   Downloading jsonschema-4.25.1-py3-none-any.whl.metadata (7.6 kB)\n",
      "\u001b[94mcmd1:\u001b[0m Collecting argon2-cffi-bindings (from argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab->jupyter==1.1.1)\n",
      "\u001b[94mcmd1:\u001b[0m   Downloading argon2_cffi_bindings-25.1.0-cp39-abi3-manylinux_2_26_x86_64.manylinux_2_28_x86_64.whl.metadata (7.4 kB)\n",
      "\u001b[94mcmd1:\u001b[0m Collecting MarkupSafe>=2.0 (from jinja2>=3.0.3->jupyterlab->jupyter==1.1.1)\n",
      "\u001b[92mcmd2:\u001b[0m      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 124.7/124.7 MB 177.9 MB/s  0:00:00\n",
      "\u001b[94mcmd1:\u001b[0m   Downloading markupsafe-3.0.3-cp39-cp39-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (2.7 kB)\n",
      "\u001b[94mcmd1:\u001b[0m Collecting attrs>=22.2.0 (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.28.0->jupyterlab->jupyter==1.1.1)\n",
      "\u001b[94mcmd1:\u001b[0m   Downloading attrs-25.4.0-py3-none-any.whl.metadata (10 kB)\n",
      "\u001b[94mcmd1:\u001b[0m Collecting jsonschema-specifications>=2023.03.6 (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.28.0->jupyterlab->jupyter==1.1.1)\n",
      "\u001b[94mcmd1:\u001b[0m   Downloading jsonschema_specifications-2025.9.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "\u001b[94mcmd1:\u001b[0m Collecting referencing>=0.28.4 (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.28.0->jupyterlab->jupyter==1.1.1)\n",
      "\u001b[94mcmd1:\u001b[0m   Downloading referencing-0.36.2-py3-none-any.whl.metadata (2.8 kB)\n",
      "\u001b[92mcmd2:\u001b[0m Collecting nvidia-nvtx-cu12==12.6.77 (from torch)\n",
      "\u001b[92mcmd2:\u001b[0m   Downloading https://pypi.nvidia.com/nvidia-nvtx-cu12/nvidia_nvtx_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89 kB)\n",
      "\u001b[92mcmd2:\u001b[0m Collecting nvidia-nvjitlink-cu12==12.6.85 (from torch)\n",
      "\u001b[92mcmd2:\u001b[0m   Downloading https://pypi.nvidia.com/nvidia-nvjitlink-cu12/nvidia_nvjitlink_cu12-12.6.85-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (19.7 MB)\n",
      "\u001b[92mcmd2:\u001b[0m      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 19.7/19.7 MB 128.0 MB/s  0:00:00\n",
      "\u001b[92mcmd2:\u001b[0m Collecting nvidia-cufile-cu12==1.11.1.6 (from torch)\n",
      "\u001b[92mcmd2:\u001b[0m   Downloading https://pypi.nvidia.com/nvidia-cufile-cu12/nvidia_cufile_cu12-1.11.1.6-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.1 MB)\n",
      "\u001b[92mcmd2:\u001b[0m      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.1/1.1 MB 202.4 MB/s  0:00:00\n",
      "\u001b[94mcmd1:\u001b[0m Collecting rpds-py>=0.7.1 (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.28.0->jupyterlab->jupyter==1.1.1)\n",
      "\u001b[94mcmd1:\u001b[0m   Downloading rpds_py-0.27.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\n",
      "\u001b[92mcmd2:\u001b[0m Collecting triton==3.5.1 (from torch)\n",
      "\u001b[94mcmd1:\u001b[0m Collecting python-json-logger>=2.0.4 (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter==1.1.1)\n",
      "\u001b[92mcmd2:\u001b[0m   Downloading https://download.pytorch.org/whl/triton-3.5.1-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.7 kB)\n",
      "\u001b[94mcmd1:\u001b[0m   Downloading python_json_logger-4.0.0-py3-none-any.whl.metadata (4.0 kB)\n",
      "\u001b[94mcmd1:\u001b[0m Collecting rfc3339-validator (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter==1.1.1)\n",
      "\u001b[94mcmd1:\u001b[0m   Downloading rfc3339_validator-0.1.4-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "\u001b[94mcmd1:\u001b[0m Collecting rfc3986-validator>=0.1.1 (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter==1.1.1)\n",
      "\u001b[94mcmd1:\u001b[0m   Downloading rfc3986_validator-0.1.1-py2.py3-none-any.whl.metadata (1.7 kB)\n",
      "\u001b[94mcmd1:\u001b[0m Collecting fqdn (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter==1.1.1)\n",
      "\u001b[94mcmd1:\u001b[0m   Downloading fqdn-1.5.1-py3-none-any.whl.metadata (1.4 kB)\n",
      "\u001b[94mcmd1:\u001b[0m Collecting isoduration (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter==1.1.1)\n",
      "\u001b[94mcmd1:\u001b[0m   Downloading isoduration-20.11.0-py3-none-any.whl.metadata (5.7 kB)\n",
      "\u001b[94mcmd1:\u001b[0m Collecting jsonpointer>1.13 (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter==1.1.1)\n",
      "\u001b[94mcmd1:\u001b[0m   Downloading jsonpointer-3.0.0-py2.py3-none-any.whl.metadata (2.3 kB)\n",
      "\u001b[94mcmd1:\u001b[0m Collecting rfc3987-syntax>=1.1.0 (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter==1.1.1)\n",
      "\u001b[94mcmd1:\u001b[0m   Downloading rfc3987_syntax-1.1.0-py3-none-any.whl.metadata (7.7 kB)\n",
      "\u001b[94mcmd1:\u001b[0m Collecting uri-template (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter==1.1.1)\n",
      "\u001b[94mcmd1:\u001b[0m   Downloading uri_template-1.3.0-py3-none-any.whl.metadata (8.8 kB)\n",
      "\u001b[94mcmd1:\u001b[0m Collecting webcolors>=24.6.0 (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter==1.1.1)\n",
      "\u001b[94mcmd1:\u001b[0m   Downloading webcolors-24.11.1-py3-none-any.whl.metadata (2.2 kB)\n",
      "\u001b[94mcmd1:\u001b[0m Collecting beautifulsoup4 (from nbconvert->jupyter==1.1.1)\n",
      "\u001b[94mcmd1:\u001b[0m   Downloading beautifulsoup4-4.14.3-py3-none-any.whl.metadata (3.8 kB)\n",
      "\u001b[94mcmd1:\u001b[0m Collecting bleach!=5.0.0 (from bleach[css]!=5.0.0->nbconvert->jupyter==1.1.1)\n",
      "\u001b[94mcmd1:\u001b[0m   Downloading bleach-6.2.0-py3-none-any.whl.metadata (30 kB)\n",
      "\u001b[94mcmd1:\u001b[0m Collecting defusedxml (from nbconvert->jupyter==1.1.1)\n",
      "\u001b[94mcmd1:\u001b[0m   Downloading defusedxml-0.7.1-py2.py3-none-any.whl.metadata (32 kB)\n",
      "\u001b[94mcmd1:\u001b[0m Collecting jupyterlab-pygments (from nbconvert->jupyter==1.1.1)\n",
      "\u001b[94mcmd1:\u001b[0m   Downloading jupyterlab_pygments-0.3.0-py3-none-any.whl.metadata (4.4 kB)\n",
      "\u001b[94mcmd1:\u001b[0m Collecting mistune<4,>=2.0.3 (from nbconvert->jupyter==1.1.1)\n",
      "\u001b[94mcmd1:\u001b[0m   Downloading mistune-3.2.0-py3-none-any.whl.metadata (1.9 kB)\n",
      "\u001b[94mcmd1:\u001b[0m Collecting nbclient>=0.5.0 (from nbconvert->jupyter==1.1.1)\n",
      "\u001b[94mcmd1:\u001b[0m   Downloading nbclient-0.10.2-py3-none-any.whl.metadata (8.3 kB)\n",
      "\u001b[94mcmd1:\u001b[0m Collecting pandocfilters>=1.4.1 (from nbconvert->jupyter==1.1.1)\n",
      "\u001b[94mcmd1:\u001b[0m   Downloading pandocfilters-1.5.1-py2.py3-none-any.whl.metadata (9.0 kB)\n",
      "\u001b[94mcmd1:\u001b[0m Collecting webencodings (from bleach!=5.0.0->bleach[css]!=5.0.0->nbconvert->jupyter==1.1.1)\n",
      "\u001b[94mcmd1:\u001b[0m   Downloading webencodings-0.5.1-py2.py3-none-any.whl.metadata (2.1 kB)\n",
      "\u001b[92mcmd2:\u001b[0m Collecting numpy (from torchvision)\n",
      "\u001b[92mcmd2:\u001b[0m   WARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ProtocolError('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))': /packages/b4/63/3de6a34ad7ad6646ac7d2f55ebc6ad439dbbf9c4370017c50cf403fb19b5/numpy-2.2.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "\u001b[94mcmd1:\u001b[0m Collecting tinycss2<1.5,>=1.1.0 (from bleach[css]!=5.0.0->nbconvert->jupyter==1.1.1)\n",
      "\u001b[94mcmd1:\u001b[0m   Downloading tinycss2-1.4.0-py3-none-any.whl.metadata (3.0 kB)\n",
      "\u001b[92mcmd2:\u001b[0m   Downloading numpy-2.2.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n",
      "\u001b[94mcmd1:\u001b[0m Collecting fastjsonschema>=2.15 (from nbformat>=5.3.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter==1.1.1)\n",
      "\u001b[94mcmd1:\u001b[0m   Downloading fastjsonschema-2.21.2-py3-none-any.whl.metadata (2.3 kB)\n",
      "\u001b[94mcmd1:\u001b[0m Collecting charset_normalizer<4,>=2 (from requests->huggingface-hub==0.23.4)\n",
      "\u001b[94mcmd1:\u001b[0m   Downloading charset_normalizer-3.4.4-cp39-cp39-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (37 kB)\n",
      "\u001b[94mcmd1:\u001b[0m Collecting urllib3<3,>=1.21.1 (from requests->huggingface-hub==0.23.4)\n",
      "\u001b[94mcmd1:\u001b[0m   Downloading urllib3-2.6.2-py3-none-any.whl.metadata (6.6 kB)\n",
      "\u001b[94mcmd1:\u001b[0m Collecting lark>=1.2.2 (from rfc3987-syntax>=1.1.0->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter==1.1.1)\n",
      "\u001b[94mcmd1:\u001b[0m   Downloading lark-1.3.1-py3-none-any.whl.metadata (1.8 kB)\n",
      "\u001b[94mcmd1:\u001b[0m Collecting cffi>=1.0.1 (from argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab->jupyter==1.1.1)\n",
      "\u001b[94mcmd1:\u001b[0m   Downloading cffi-2.0.0-cp39-cp39-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.6 kB)\n",
      "\u001b[94mcmd1:\u001b[0m Collecting pycparser (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab->jupyter==1.1.1)\n",
      "\u001b[94mcmd1:\u001b[0m   Downloading pycparser-2.23-py3-none-any.whl.metadata (993 bytes)\n",
      "\u001b[94mcmd1:\u001b[0m Collecting soupsieve>=1.6.1 (from beautifulsoup4->nbconvert->jupyter==1.1.1)\n",
      "\u001b[94mcmd1:\u001b[0m   Downloading soupsieve-2.8.1-py3-none-any.whl.metadata (4.6 kB)\n",
      "\u001b[94mcmd1:\u001b[0m Collecting arrow>=0.15.0 (from isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter==1.1.1)\n",
      "\u001b[94mcmd1:\u001b[0m   Downloading arrow-1.4.0-py3-none-any.whl.metadata (7.7 kB)\n",
      "\u001b[94mcmd1:\u001b[0m Collecting tzdata (from arrow>=0.15.0->isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter==1.1.1)\n",
      "\u001b[92mcmd2:\u001b[0m Collecting pillow!=8.3.*,>=5.3.0 (from torchvision)\n",
      "\u001b[94mcmd1:\u001b[0m   Downloading tzdata-2025.3-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "\u001b[92mcmd2:\u001b[0m   Downloading pillow-12.0.0-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (8.8 kB)\n",
      "\u001b[94mcmd1:\u001b[0m Collecting executing>=1.2.0 (from stack-data->ipython>=7.23.1->ipykernel->jupyter==1.1.1)\n",
      "\u001b[94mcmd1:\u001b[0m   Downloading executing-2.2.1-py2.py3-none-any.whl.metadata (8.9 kB)\n",
      "\u001b[94mcmd1:\u001b[0m Collecting asttokens>=2.1.0 (from stack-data->ipython>=7.23.1->ipykernel->jupyter==1.1.1)\n",
      "\u001b[94mcmd1:\u001b[0m   Downloading asttokens-3.0.1-py3-none-any.whl.metadata (4.9 kB)\n",
      "\u001b[94mcmd1:\u001b[0m Collecting pure-eval (from stack-data->ipython>=7.23.1->ipykernel->jupyter==1.1.1)\n",
      "\u001b[94mcmd1:\u001b[0m   Downloading pure_eval-0.2.3-py3-none-any.whl.metadata (6.3 kB)\n",
      "\u001b[92mcmd2:\u001b[0m Collecting mpmath<1.4,>=1.1.0 (from sympy>=1.13.3->torch)\n",
      "\u001b[92mcmd2:\u001b[0m   Downloading mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "\u001b[94mcmd1:\u001b[0m Downloading torch-1.13.1-cp39-cp39-manylinux1_x86_64.whl (887.4 MB)\n",
      "\u001b[92mcmd2:\u001b[0m Collecting MarkupSafe>=2.0 (from jinja2->torch)\n",
      "\u001b[92mcmd2:\u001b[0m   Downloading https://download.pytorch.org/whl/MarkupSafe-2.1.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)\n",
      "\u001b[92mcmd2:\u001b[0m Downloading https://download.pytorch.org/whl/cu126/torch-2.9.1%2Bcu126-cp310-cp310-manylinux_2_28_x86_64.whl (832.9 MB)\n",
      "\u001b[92mcmd2:\u001b[0m    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 832.9/832.9 MB 24.7 MB/s  0:00:13\n",
      "\u001b[92mcmd2:\u001b[0m Downloading https://download.pytorch.org/whl/triton-3.5.1-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (170.3 MB)\n",
      "\u001b[92mcmd2:\u001b[0m    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 170.3/170.3 MB 77.9 MB/s  0:00:02\n",
      "\u001b[92mcmd2:\u001b[0m Downloading https://download.pytorch.org/whl/cu126/torchvision-0.24.1%2Bcu126-cp310-cp310-manylinux_2_28_x86_64.whl (7.3 MB)\n",
      "\u001b[92mcmd2:\u001b[0m    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 7.3/7.3 MB 102.5 MB/s  0:00:00\n",
      "\u001b[92mcmd2:\u001b[0m Downloading https://download.pytorch.org/whl/cu126/torchaudio-2.9.1%2Bcu126-cp310-cp310-manylinux_2_28_x86_64.whl (1.9 MB)\n",
      "\u001b[92mcmd2:\u001b[0m    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.9/1.9 MB 62.4 MB/s  0:00:00\n",
      "\u001b[92mcmd2:\u001b[0m Downloading fsspec-2025.12.0-py3-none-any.whl (201 kB)\n",
      "\u001b[92mcmd2:\u001b[0m Downloading networkx-3.4.2-py3-none-any.whl (1.7 MB)\n",
      "\u001b[92mcmd2:\u001b[0m    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.7/1.7 MB 36.2 MB/s  0:00:00\n",
      "\u001b[92mcmd2:\u001b[0m Downloading pillow-12.0.0-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (7.0 MB)\n",
      "\u001b[92mcmd2:\u001b[0m    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 7.0/7.0 MB 116.8 MB/s  0:00:00\n",
      "\u001b[92mcmd2:\u001b[0m Downloading sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
      "\u001b[92mcmd2:\u001b[0m    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 6.3/6.3 MB 129.4 MB/s  0:00:00\n",
      "\u001b[92mcmd2:\u001b[0m Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "\u001b[92mcmd2:\u001b[0m    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 536.2/536.2 kB 16.3 MB/s  0:00:00\n",
      "\u001b[92mcmd2:\u001b[0m Downloading https://download.pytorch.org/whl/typing_extensions-4.15.0-py3-none-any.whl (44 kB)\n",
      "\u001b[92mcmd2:\u001b[0m Downloading filelock-3.20.0-py3-none-any.whl (16 kB)\n",
      "\u001b[92mcmd2:\u001b[0m Downloading https://download.pytorch.org/whl/jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
      "\u001b[92mcmd2:\u001b[0m Downloading numpy-2.2.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.8 MB)\n",
      "\u001b[92mcmd2:\u001b[0m    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 16.8/16.8 MB 174.7 MB/s  0:00:00\n",
      "\u001b[92mcmd2:\u001b[0m Installing collected packages: nvidia-cusparselt-cu12, mpmath, typing-extensions, triton, sympy, pillow, nvidia-nvtx-cu12, nvidia-nvshmem-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufile-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, networkx, MarkupSafe, fsspec, filelock, nvidia-cusparse-cu12, nvidia-cufft-cu12, nvidia-cudnn-cu12, jinja2, nvidia-cusolver-cu12, torch, torchvision, torchaudio\n",
      "\u001b[94mcmd1:\u001b[0m    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 887.4/887.4 MB 12.3 MB/s  0:00:51\n",
      "\u001b[94mcmd1:\u001b[0m Downloading redis-5.0.6-py3-none-any.whl (252 kB)\n",
      "\u001b[94mcmd1:\u001b[0m Downloading jupyter-1.1.1-py2.py3-none-any.whl (2.7 kB)\n",
      "\u001b[94mcmd1:\u001b[0m Downloading numpy-1.24.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\n",
      "\u001b[94mcmd1:\u001b[0m    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 17.3/17.3 MB 81.5 MB/s  0:00:00\n",
      "\u001b[94mcmd1:\u001b[0m Downloading matplotlib-3.9.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.3 MB)\n",
      "\u001b[94mcmd1:\u001b[0m    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 8.3/8.3 MB 16.3 MB/s  0:00:00\n",
      "\u001b[94mcmd1:\u001b[0m Downloading scipy-1.11.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (36.5 MB)\n",
      "\u001b[94mcmd1:\u001b[0m    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 36.5/36.5 MB 7.5 MB/s  0:00:04\n",
      "\u001b[94mcmd1:\u001b[0m Downloading scikit_learn-1.6.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.5 MB)\n",
      "\u001b[94mcmd1:\u001b[0m    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 13.5/13.5 MB 81.6 MB/s  0:00:00\n",
      "\u001b[94mcmd1:\u001b[0m Downloading tqdm-4.66.4-py3-none-any.whl (78 kB)\n",
      "\u001b[94mcmd1:\u001b[0m Downloading g2p_en-2.1.0-py3-none-any.whl (3.1 MB)\n",
      "\u001b[94mcmd1:\u001b[0m    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.1/3.1 MB 67.7 MB/s  0:00:00\n",
      "\u001b[94mcmd1:\u001b[0m Downloading omegaconf-2.3.0-py3-none-any.whl (79 kB)\n",
      "\u001b[94mcmd1:\u001b[0m Downloading huggingface_hub-0.23.4-py3-none-any.whl (402 kB)\n",
      "\u001b[94mcmd1:\u001b[0m Downloading transformers-4.40.0-py3-none-any.whl (9.0 MB)\n",
      "\u001b[94mcmd1:\u001b[0m    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 9.0/9.0 MB 86.2 MB/s  0:00:00\n",
      "\u001b[94mcmd1:\u001b[0m Downloading tokenizers-0.19.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
      "\u001b[94mcmd1:\u001b[0m    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.6/3.6 MB 26.6 MB/s  0:00:00\n",
      "\u001b[94mcmd1:\u001b[0m Downloading accelerate-0.33.0-py3-none-any.whl (315 kB)\n",
      "\u001b[94mcmd1:\u001b[0m Downloading bitsandbytes-0.41.1-py3-none-any.whl (92.6 MB)\n",
      "\u001b[94mcmd1:\u001b[0m    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 92.6/92.6 MB 18.5 MB/s  0:00:04\n",
      "\u001b[94mcmd1:\u001b[0m Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n",
      "\u001b[94mcmd1:\u001b[0m    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 317.1/317.1 MB 65.2 MB/s  0:00:04\n",
      "\u001b[94mcmd1:\u001b[0m Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n",
      "\u001b[94mcmd1:\u001b[0m    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 21.0/21.0 MB 79.9 MB/s  0:00:00\n",
      "\u001b[94mcmd1:\u001b[0m Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n",
      "\u001b[94mcmd1:\u001b[0m    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 849.3/849.3 kB 25.2 MB/s  0:00:00\n",
      "\u001b[94mcmd1:\u001b[0m Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n",
      "\u001b[94mcmd1:\u001b[0m    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 557.1/557.1 MB 13.2 MB/s  0:00:22\n",
      "\u001b[94mcmd1:\u001b[0m Downloading async_timeout-5.0.1-py3-none-any.whl (6.2 kB)\n",
      "\u001b[94mcmd1:\u001b[0m Downloading contourpy-1.3.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (321 kB)\n",
      "\u001b[94mcmd1:\u001b[0m Downloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "\u001b[94mcmd1:\u001b[0m Downloading fonttools-4.60.2-cp39-cp39-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (4.8 MB)\n",
      "\u001b[94mcmd1:\u001b[0m    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 4.8/4.8 MB 62.7 MB/s  0:00:00\n",
      "\u001b[94mcmd1:\u001b[0m Downloading fsspec-2025.10.0-py3-none-any.whl (200 kB)\n",
      "\u001b[94mcmd1:\u001b[0m Downloading importlib_resources-6.5.2-py3-none-any.whl (37 kB)\n",
      "\u001b[94mcmd1:\u001b[0m Downloading inflect-7.5.0-py3-none-any.whl (35 kB)\n",
      "\u001b[94mcmd1:\u001b[0m Downloading joblib-1.5.3-py3-none-any.whl (309 kB)\n",
      "\u001b[94mcmd1:\u001b[0m Downloading kiwisolver-1.4.7-cp39-cp39-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.6 MB)\n",
      "\u001b[94mcmd1:\u001b[0m    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.6/1.6 MB 37.0 MB/s  0:00:00\n",
      "\u001b[94mcmd1:\u001b[0m Downloading more_itertools-10.8.0-py3-none-any.whl (69 kB)\n",
      "\u001b[94mcmd1:\u001b[0m Downloading nltk-3.9.2-py3-none-any.whl (1.5 MB)\n",
      "\u001b[94mcmd1:\u001b[0m    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.5/1.5 MB 45.5 MB/s  0:00:00\n",
      "\u001b[94mcmd1:\u001b[0m Downloading packaging-25.0-py3-none-any.whl (66 kB)\n",
      "\u001b[94mcmd1:\u001b[0m Downloading pillow-11.3.0-cp39-cp39-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (6.6 MB)\n",
      "\u001b[94mcmd1:\u001b[0m    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 6.6/6.6 MB 76.7 MB/s  0:00:00\n",
      "\u001b[94mcmd1:\u001b[0m Downloading pyparsing-3.3.1-py3-none-any.whl (121 kB)\n",
      "\u001b[94mcmd1:\u001b[0m Downloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)\n",
      "\u001b[94mcmd1:\u001b[0m Downloading pyyaml-6.0.3-cp39-cp39-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (750 kB)\n",
      "\u001b[94mcmd1:\u001b[0m    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 750.8/750.8 kB 21.7 MB/s  0:00:00\n",
      "\u001b[94mcmd1:\u001b[0m Downloading regex-2025.11.3-cp39-cp39-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (791 kB)\n",
      "\u001b[94mcmd1:\u001b[0m    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 791.2/791.2 kB 22.8 MB/s  0:00:00\n",
      "\u001b[94mcmd1:\u001b[0m Downloading safetensors-0.7.0-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (507 kB)\n",
      "\u001b[94mcmd1:\u001b[0m Downloading six-1.17.0-py2.py3-none-any.whl (11 kB)\n",
      "\u001b[94mcmd1:\u001b[0m Downloading threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "\u001b[94mcmd1:\u001b[0m Downloading typeguard-4.4.4-py3-none-any.whl (34 kB)\n",
      "\u001b[94mcmd1:\u001b[0m Downloading importlib_metadata-8.7.1-py3-none-any.whl (27 kB)\n",
      "\u001b[94mcmd1:\u001b[0m Downloading typing_extensions-4.15.0-py3-none-any.whl (44 kB)\n",
      "\u001b[94mcmd1:\u001b[0m Downloading zipp-3.23.0-py3-none-any.whl (10 kB)\n",
      "\u001b[94mcmd1:\u001b[0m Downloading click-8.1.8-py3-none-any.whl (98 kB)\n",
      "\u001b[94mcmd1:\u001b[0m Downloading filelock-3.19.1-py3-none-any.whl (15 kB)\n",
      "\u001b[94mcmd1:\u001b[0m Downloading ipykernel-6.31.0-py3-none-any.whl (117 kB)\n",
      "\u001b[94mcmd1:\u001b[0m Downloading comm-0.2.3-py3-none-any.whl (7.3 kB)\n",
      "\u001b[94mcmd1:\u001b[0m Downloading debugpy-1.8.19-cp39-cp39-manylinux_2_34_x86_64.whl (3.1 MB)\n",
      "\u001b[94mcmd1:\u001b[0m    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.1/3.1 MB 61.4 MB/s  0:00:00\n",
      "\u001b[94mcmd1:\u001b[0m Downloading ipython-8.18.1-py3-none-any.whl (808 kB)\n",
      "\u001b[94mcmd1:\u001b[0m    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 808.2/808.2 kB 25.3 MB/s  0:00:00\n",
      "\u001b[94mcmd1:\u001b[0m Downloading prompt_toolkit-3.0.52-py3-none-any.whl (391 kB)\n",
      "\u001b[94mcmd1:\u001b[0m Downloading jedi-0.19.2-py2.py3-none-any.whl (1.6 MB)\n",
      "\u001b[94mcmd1:\u001b[0m    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.6/1.6 MB 47.3 MB/s  0:00:00\n",
      "\u001b[94mcmd1:\u001b[0m Downloading parso-0.8.5-py2.py3-none-any.whl (106 kB)\n",
      "\u001b[94mcmd1:\u001b[0m Downloading jupyter_client-8.6.3-py3-none-any.whl (106 kB)\n",
      "\u001b[94mcmd1:\u001b[0m Downloading jupyter_core-5.8.1-py3-none-any.whl (28 kB)\n",
      "\u001b[94mcmd1:\u001b[0m Downloading matplotlib_inline-0.2.1-py3-none-any.whl (9.5 kB)\n",
      "\u001b[94mcmd1:\u001b[0m Downloading nest_asyncio-1.6.0-py3-none-any.whl (5.2 kB)\n",
      "\u001b[94mcmd1:\u001b[0m Downloading pexpect-4.9.0-py2.py3-none-any.whl (63 kB)\n",
      "\u001b[94mcmd1:\u001b[0m Downloading platformdirs-4.4.0-py3-none-any.whl (18 kB)\n",
      "\u001b[94mcmd1:\u001b[0m Downloading psutil-7.2.0-cp36-abi3-manylinux2010_x86_64.manylinux_2_12_x86_64.manylinux_2_28_x86_64.whl (154 kB)\n",
      "\u001b[94mcmd1:\u001b[0m Downloading ptyprocess-0.7.0-py2.py3-none-any.whl (13 kB)\n",
      "\u001b[94mcmd1:\u001b[0m Downloading pygments-2.19.2-py3-none-any.whl (1.2 MB)\n",
      "\u001b[94mcmd1:\u001b[0m    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.2/1.2 MB 36.9 MB/s  0:00:00\n",
      "\u001b[94mcmd1:\u001b[0m Downloading pyzmq-27.1.0-cp39-cp39-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (863 kB)\n",
      "\u001b[94mcmd1:\u001b[0m    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 863.8/863.8 kB 13.4 MB/s  0:00:00\n",
      "\u001b[94mcmd1:\u001b[0m Downloading tornado-6.5.4-cp39-abi3-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (445 kB)\n",
      "\u001b[94mcmd1:\u001b[0m Downloading traitlets-5.14.3-py3-none-any.whl (85 kB)\n",
      "\u001b[94mcmd1:\u001b[0m Downloading decorator-5.2.1-py3-none-any.whl (9.2 kB)\n",
      "\u001b[94mcmd1:\u001b[0m Downloading exceptiongroup-1.3.1-py3-none-any.whl (16 kB)\n",
      "\u001b[94mcmd1:\u001b[0m Downloading ipywidgets-8.1.8-py3-none-any.whl (139 kB)\n",
      "\u001b[94mcmd1:\u001b[0m Downloading jupyterlab_widgets-3.0.16-py3-none-any.whl (914 kB)\n",
      "\u001b[94mcmd1:\u001b[0m    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 914.9/914.9 kB 22.8 MB/s  0:00:00\n",
      "\u001b[94mcmd1:\u001b[0m Downloading widgetsnbextension-4.0.15-py3-none-any.whl (2.2 MB)\n",
      "\u001b[94mcmd1:\u001b[0m    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.2/2.2 MB 37.0 MB/s  0:00:00\n",
      "\u001b[94mcmd1:\u001b[0m Downloading jupyter_console-6.6.3-py3-none-any.whl (24 kB)\n",
      "\u001b[94mcmd1:\u001b[0m Downloading jupyterlab-4.5.1-py3-none-any.whl (12.4 MB)\n",
      "\u001b[94mcmd1:\u001b[0m    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 12.4/12.4 MB 91.8 MB/s  0:00:00\n",
      "\u001b[94mcmd1:\u001b[0m Downloading httpx-0.28.1-py3-none-any.whl (73 kB)\n",
      "\u001b[94mcmd1:\u001b[0m Downloading httpcore-1.0.9-py3-none-any.whl (78 kB)\n",
      "\u001b[94mcmd1:\u001b[0m Downloading jupyter_server-2.17.0-py3-none-any.whl (388 kB)\n",
      "\u001b[94mcmd1:\u001b[0m Downloading jupyterlab_server-2.28.0-py3-none-any.whl (59 kB)\n",
      "\u001b[94mcmd1:\u001b[0m Downloading anyio-4.12.0-py3-none-any.whl (113 kB)\n",
      "\u001b[94mcmd1:\u001b[0m Downloading argon2_cffi-25.1.0-py3-none-any.whl (14 kB)\n",
      "\u001b[94mcmd1:\u001b[0m Downloading async_lru-2.0.5-py3-none-any.whl (6.1 kB)\n",
      "\u001b[94mcmd1:\u001b[0m Downloading babel-2.17.0-py3-none-any.whl (10.2 MB)\n",
      "\u001b[94mcmd1:\u001b[0m    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 10.2/10.2 MB 87.9 MB/s  0:00:00\n",
      "\u001b[94mcmd1:\u001b[0m Downloading h11-0.16.0-py3-none-any.whl (37 kB)\n",
      "\u001b[94mcmd1:\u001b[0m Downloading idna-3.11-py3-none-any.whl (71 kB)\n",
      "\u001b[94mcmd1:\u001b[0m Downloading jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
      "\u001b[94mcmd1:\u001b[0m Downloading json5-0.12.1-py3-none-any.whl (36 kB)\n",
      "\u001b[94mcmd1:\u001b[0m Downloading jsonschema-4.25.1-py3-none-any.whl (90 kB)\n",
      "\u001b[94mcmd1:\u001b[0m Downloading attrs-25.4.0-py3-none-any.whl (67 kB)\n",
      "\u001b[94mcmd1:\u001b[0m Downloading jsonschema_specifications-2025.9.1-py3-none-any.whl (18 kB)\n",
      "\u001b[94mcmd1:\u001b[0m Downloading jupyter_events-0.12.0-py3-none-any.whl (19 kB)\n",
      "\u001b[94mcmd1:\u001b[0m Downloading jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
      "\u001b[94mcmd1:\u001b[0m Downloading jupyter_lsp-2.3.0-py3-none-any.whl (76 kB)\n",
      "\u001b[94mcmd1:\u001b[0m Downloading jupyter_server_terminals-0.5.3-py3-none-any.whl (13 kB)\n",
      "\u001b[94mcmd1:\u001b[0m Downloading markupsafe-3.0.3-cp39-cp39-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (20 kB)\n",
      "\u001b[94mcmd1:\u001b[0m Downloading nbconvert-7.16.6-py3-none-any.whl (258 kB)\n",
      "\u001b[94mcmd1:\u001b[0m Downloading mistune-3.2.0-py3-none-any.whl (53 kB)\n",
      "\u001b[94mcmd1:\u001b[0m Downloading bleach-6.2.0-py3-none-any.whl (163 kB)\n",
      "\u001b[94mcmd1:\u001b[0m Downloading tinycss2-1.4.0-py3-none-any.whl (26 kB)\n",
      "\u001b[94mcmd1:\u001b[0m Downloading nbclient-0.10.2-py3-none-any.whl (25 kB)\n",
      "\u001b[94mcmd1:\u001b[0m Downloading nbformat-5.10.4-py3-none-any.whl (78 kB)\n",
      "\u001b[94mcmd1:\u001b[0m Downloading fastjsonschema-2.21.2-py3-none-any.whl (24 kB)\n",
      "\u001b[94mcmd1:\u001b[0m Downloading notebook_shim-0.2.4-py3-none-any.whl (13 kB)\n",
      "\u001b[94mcmd1:\u001b[0m Downloading overrides-7.7.0-py3-none-any.whl (17 kB)\n",
      "\u001b[94mcmd1:\u001b[0m Downloading pandocfilters-1.5.1-py2.py3-none-any.whl (8.7 kB)\n",
      "\u001b[94mcmd1:\u001b[0m Downloading prometheus_client-0.23.1-py3-none-any.whl (61 kB)\n",
      "\u001b[94mcmd1:\u001b[0m Downloading python_json_logger-4.0.0-py3-none-any.whl (15 kB)\n",
      "\u001b[94mcmd1:\u001b[0m Downloading referencing-0.36.2-py3-none-any.whl (26 kB)\n",
      "\u001b[94mcmd1:\u001b[0m Downloading requests-2.32.5-py3-none-any.whl (64 kB)\n",
      "\u001b[94mcmd1:\u001b[0m Downloading charset_normalizer-3.4.4-cp39-cp39-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (153 kB)\n",
      "\u001b[94mcmd1:\u001b[0m Downloading urllib3-2.6.2-py3-none-any.whl (131 kB)\n",
      "\u001b[94mcmd1:\u001b[0m Downloading certifi-2025.11.12-py3-none-any.whl (159 kB)\n",
      "\u001b[94mcmd1:\u001b[0m Downloading rfc3986_validator-0.1.1-py2.py3-none-any.whl (4.2 kB)\n",
      "\u001b[94mcmd1:\u001b[0m Downloading rfc3987_syntax-1.1.0-py3-none-any.whl (8.0 kB)\n",
      "\u001b[94mcmd1:\u001b[0m Downloading lark-1.3.1-py3-none-any.whl (113 kB)\n",
      "\u001b[94mcmd1:\u001b[0m Downloading rpds_py-0.27.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (384 kB)\n",
      "\u001b[94mcmd1:\u001b[0m Downloading Send2Trash-1.8.3-py3-none-any.whl (18 kB)\n",
      "\u001b[94mcmd1:\u001b[0m Downloading terminado-0.18.1-py3-none-any.whl (14 kB)\n",
      "\u001b[94mcmd1:\u001b[0m Downloading tomli-2.3.0-py3-none-any.whl (14 kB)\n",
      "\u001b[94mcmd1:\u001b[0m Downloading webcolors-24.11.1-py3-none-any.whl (14 kB)\n",
      "\u001b[94mcmd1:\u001b[0m Downloading webencodings-0.5.1-py2.py3-none-any.whl (11 kB)\n",
      "\u001b[94mcmd1:\u001b[0m Downloading websocket_client-1.9.0-py3-none-any.whl (82 kB)\n",
      "\u001b[94mcmd1:\u001b[0m Downloading argon2_cffi_bindings-25.1.0-cp39-abi3-manylinux_2_26_x86_64.manylinux_2_28_x86_64.whl (87 kB)\n",
      "\u001b[94mcmd1:\u001b[0m Downloading cffi-2.0.0-cp39-cp39-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (216 kB)\n",
      "\u001b[94mcmd1:\u001b[0m Downloading beautifulsoup4-4.14.3-py3-none-any.whl (107 kB)\n",
      "\u001b[94mcmd1:\u001b[0m Downloading soupsieve-2.8.1-py3-none-any.whl (36 kB)\n",
      "\u001b[94mcmd1:\u001b[0m Downloading defusedxml-0.7.1-py2.py3-none-any.whl (25 kB)\n",
      "\u001b[94mcmd1:\u001b[0m Downloading fqdn-1.5.1-py3-none-any.whl (9.1 kB)\n",
      "\u001b[94mcmd1:\u001b[0m Downloading isoduration-20.11.0-py3-none-any.whl (11 kB)\n",
      "\u001b[94mcmd1:\u001b[0m Downloading arrow-1.4.0-py3-none-any.whl (68 kB)\n",
      "\u001b[94mcmd1:\u001b[0m Downloading jupyterlab_pygments-0.3.0-py3-none-any.whl (15 kB)\n",
      "\u001b[94mcmd1:\u001b[0m Downloading notebook-7.5.1-py3-none-any.whl (14.5 MB)\n",
      "\u001b[94mcmd1:\u001b[0m    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 14.5/14.5 MB 104.1 MB/s  0:00:00\n",
      "\u001b[94mcmd1:\u001b[0m Downloading pycparser-2.23-py3-none-any.whl (118 kB)\n",
      "\u001b[94mcmd1:\u001b[0m Downloading rfc3339_validator-0.1.4-py2.py3-none-any.whl (3.5 kB)\n",
      "\u001b[94mcmd1:\u001b[0m Downloading stack_data-0.6.3-py3-none-any.whl (24 kB)\n",
      "\u001b[94mcmd1:\u001b[0m Downloading asttokens-3.0.1-py3-none-any.whl (27 kB)\n",
      "\u001b[94mcmd1:\u001b[0m Downloading executing-2.2.1-py2.py3-none-any.whl (28 kB)\n",
      "\u001b[94mcmd1:\u001b[0m Downloading pure_eval-0.2.3-py3-none-any.whl (11 kB)\n",
      "\u001b[94mcmd1:\u001b[0m Downloading tzdata-2025.3-py2.py3-none-any.whl (348 kB)\n",
      "\u001b[94mcmd1:\u001b[0m Downloading uri_template-1.3.0-py3-none-any.whl (11 kB)\n",
      "\u001b[94mcmd1:\u001b[0m Downloading wcwidth-0.2.14-py2.py3-none-any.whl (37 kB)\n",
      "\u001b[94mcmd1:\u001b[0m Building wheels for collected packages: antlr4-python3-runtime, distance\n",
      "\u001b[94mcmd1:\u001b[0m   Building wheel for antlr4-python3-runtime (pyproject.toml): started\n",
      "\u001b[94mcmd1:\u001b[0m   Building wheel for antlr4-python3-runtime (pyproject.toml): finished with status 'done'\n",
      "\u001b[94mcmd1:\u001b[0m   Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144591 sha256=86540df9cf73f016170236245604b89098ebe16be9e6e5dd6d84f619acd88dd7\n",
      "\u001b[94mcmd1:\u001b[0m   Stored in directory: /root/.cache/pip/wheels/23/cf/80/f3efa822e6ab23277902ee9165fe772eeb1dfb8014f359020a\n",
      "\u001b[94mcmd1:\u001b[0m   Building wheel for distance (pyproject.toml): started\n",
      "\u001b[94mcmd1:\u001b[0m   Building wheel for distance (pyproject.toml): finished with status 'done'\n",
      "\u001b[94mcmd1:\u001b[0m   Created wheel for distance: filename=distance-0.1.3-py3-none-any.whl size=16321 sha256=acc0a16ccf8e340367e2d3ad4211c7ea196bda8b8ec508c19c2ef5dbfc2b56e8\n",
      "\u001b[94mcmd1:\u001b[0m   Stored in directory: /root/.cache/pip/wheels/fb/b3/aa/04241cced6d1722b132273b1d6aafba317887ec004f48b853a\n",
      "\u001b[94mcmd1:\u001b[0m Successfully built antlr4-python3-runtime distance\n",
      "\u001b[94mcmd1:\u001b[0m Installing collected packages: webencodings, pure-eval, ptyprocess, fastjsonschema, distance, bitsandbytes, antlr4-python3-runtime, zipp, widgetsnbextension, websocket-client, webcolors, wcwidth, urllib3, uri-template, tzdata, typing-extensions, traitlets, tqdm, tornado, tomli, tinycss2, threadpoolctl, soupsieve, six, send2trash, safetensors, rpds-py, rfc3986-validator, regex, pyzmq, PyYAML, pyparsing, pygments, pycparser, psutil, prometheus-client, platformdirs, pillow, pexpect, parso, pandocfilters, packaging, overrides, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cublas-cu11, numpy, nest-asyncio, more_itertools, MarkupSafe, lark, kiwisolver, jupyterlab_widgets, jupyterlab-pygments, jsonpointer, json5, joblib, idna, h11, fsspec, fqdn, fonttools, filelock, executing, defusedxml, decorator, debugpy, cycler, comm, click, charset_normalizer, certifi, bleach, babel, attrs, async-timeout, asttokens, terminado, stack-data, scipy, rfc3987-syntax, rfc3339-validator, requests, referencing, redis, python-json-logger, python-dateutil, prompt-toolkit, omegaconf, nvidia-cudnn-cu11, nltk, mistune, matplotlib-inline, jupyter-core, jinja2, jedi, importlib-resources, importlib_metadata, httpcore, exceptiongroup, contourpy, cffi, beautifulsoup4, async-lru, typeguard, torch, scikit-learn, matplotlib, jupyter-server-terminals, jupyter-client, jsonschema-specifications, ipython, huggingface-hub, arrow, argon2-cffi-bindings, anyio, tokenizers, jsonschema, isoduration, ipywidgets, ipykernel, inflect, httpx, argon2-cffi, accelerate, transformers, nbformat, jupyter-console, g2p_en, nbclient, jupyter-events, nbconvert, jupyter-server, notebook-shim, jupyterlab-server, jupyter-lsp, jupyterlab, notebook, jupyter\n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Successfully installed MarkupSafe-2.1.5 filelock-3.20.0 fsspec-2025.12.0 jinja2-3.1.6 mpmath-1.3.0 networkx-3.4.2 numpy-2.2.6 nvidia-cublas-cu12-12.6.4.1 nvidia-cuda-cupti-cu12-12.6.80 nvidia-cuda-nvrtc-cu12-12.6.77 nvidia-cuda-runtime-cu12-12.6.77 nvidia-cudnn-cu12-9.10.2.21 nvidia-cufft-cu12-11.3.0.4 nvidia-cufile-cu12-1.11.1.6 nvidia-curand-cu12-10.3.7.77 nvidia-cusolver-cu12-11.7.1.2 nvidia-cusparse-cu12-12.5.4.2 nvidia-cusparselt-cu12-0.7.1 nvidia-nccl-cu12-2.27.5 nvidia-nvjitlink-cu12-12.6.85 nvidia-nvshmem-cu12-3.3.20 nvidia-nvtx-cu12-12.6.77 pillow-12.0.0 sympy-1.14.0 torch-2.9.1+cu126 torchaudio-2.9.1+cu126 torchvision-0.24.1+cu126 triton-3.5.1 typing-extensions-4.15.0\n",
      "\u001b[92mcmd2:\u001b[0m Obtaining file:///kaggle/working/Brain-To-Text-MOA\n",
      "\u001b[92mcmd2:\u001b[0m   Installing build dependencies: started\n",
      "\u001b[92mcmd2:\u001b[0m   Installing build dependencies: finished with status 'done'\n",
      "\u001b[92mcmd2:\u001b[0m   Checking if build backend supports build_editable: started\n",
      "\u001b[92mcmd2:\u001b[0m   Checking if build backend supports build_editable: finished with status 'done'\n",
      "\u001b[92mcmd2:\u001b[0m   Getting requirements to build editable: started\n",
      "\u001b[92mcmd2:\u001b[0m   Getting requirements to build editable: finished with status 'done'\n",
      "\u001b[92mcmd2:\u001b[0m   Preparing editable metadata (pyproject.toml): started\n",
      "\u001b[92mcmd2:\u001b[0m   Preparing editable metadata (pyproject.toml): finished with status 'done'\n",
      "\u001b[92mcmd2:\u001b[0m Collecting redis==5.2.1\n",
      "\u001b[92mcmd2:\u001b[0m   Downloading redis-5.2.1-py3-none-any.whl.metadata (9.1 kB)\n",
      "\u001b[92mcmd2:\u001b[0m Collecting jupyter==1.1.1\n",
      "\u001b[92mcmd2:\u001b[0m   Using cached jupyter-1.1.1-py2.py3-none-any.whl.metadata (2.0 kB)\n",
      "\u001b[92mcmd2:\u001b[0m Collecting numpy==2.1.2\n",
      "\u001b[92mcmd2:\u001b[0m   Downloading numpy-2.1.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
      "\u001b[92mcmd2:\u001b[0m Collecting pandas==2.3.0\n",
      "\u001b[92mcmd2:\u001b[0m   Downloading pandas-2.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (91 kB)\n",
      "\u001b[92mcmd2:\u001b[0m Collecting matplotlib==3.10.1\n",
      "\u001b[92mcmd2:\u001b[0m   Downloading matplotlib-3.10.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
      "\u001b[92mcmd2:\u001b[0m Collecting scipy==1.15.2\n",
      "\u001b[92mcmd2:\u001b[0m   Downloading scipy-1.15.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
      "\u001b[92mcmd2:\u001b[0m Collecting scikit-learn==1.6.1\n",
      "\u001b[92mcmd2:\u001b[0m   Downloading scikit_learn-1.6.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
      "\u001b[92mcmd2:\u001b[0m Collecting tqdm==4.67.1\n",
      "\u001b[92mcmd2:\u001b[0m   Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "\u001b[92mcmd2:\u001b[0m Collecting g2p_en==2.1.0\n",
      "\u001b[92mcmd2:\u001b[0m   Using cached g2p_en-2.1.0-py3-none-any.whl.metadata (4.5 kB)\n",
      "\u001b[92mcmd2:\u001b[0m Collecting h5py==3.13.0\n",
      "\u001b[92mcmd2:\u001b[0m   Downloading h5py-3.13.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.5 kB)\n",
      "\u001b[92mcmd2:\u001b[0m Collecting omegaconf==2.3.0\n",
      "\u001b[92mcmd2:\u001b[0m   Using cached omegaconf-2.3.0-py3-none-any.whl.metadata (3.9 kB)\n",
      "\u001b[92mcmd2:\u001b[0m Collecting editdistance==0.8.1\n",
      "\u001b[92mcmd2:\u001b[0m   Downloading editdistance-0.8.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.9 kB)\n",
      "\u001b[92mcmd2:\u001b[0m Collecting huggingface-hub==0.33.1\n",
      "\u001b[92mcmd2:\u001b[0m   Downloading huggingface_hub-0.33.1-py3-none-any.whl.metadata (14 kB)\n",
      "\u001b[92mcmd2:\u001b[0m Collecting transformers==4.53.0\n",
      "\u001b[92mcmd2:\u001b[0m   Downloading transformers-4.53.0-py3-none-any.whl.metadata (39 kB)\n",
      "\u001b[92mcmd2:\u001b[0m Collecting tokenizers==0.21.2\n",
      "\u001b[92mcmd2:\u001b[0m   Downloading tokenizers-0.21.2-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "\u001b[92mcmd2:\u001b[0m Collecting accelerate==1.8.1\n",
      "\u001b[92mcmd2:\u001b[0m   Downloading accelerate-1.8.1-py3-none-any.whl.metadata (19 kB)\n",
      "\u001b[92mcmd2:\u001b[0m Collecting bitsandbytes==0.46.0\n",
      "\u001b[92mcmd2:\u001b[0m   Downloading bitsandbytes-0.46.0-py3-none-manylinux_2_24_x86_64.whl.metadata (10 kB)\n",
      "\u001b[92mcmd2:\u001b[0m Collecting async-timeout>=4.0.3 (from redis==5.2.1)\n",
      "\u001b[92mcmd2:\u001b[0m   Using cached async_timeout-5.0.1-py3-none-any.whl.metadata (5.1 kB)\n",
      "\u001b[92mcmd2:\u001b[0m Collecting notebook (from jupyter==1.1.1)\n",
      "\u001b[92mcmd2:\u001b[0m   Using cached notebook-7.5.1-py3-none-any.whl.metadata (10 kB)\n",
      "\u001b[92mcmd2:\u001b[0m Collecting jupyter-console (from jupyter==1.1.1)\n",
      "\u001b[92mcmd2:\u001b[0m   Using cached jupyter_console-6.6.3-py3-none-any.whl.metadata (5.8 kB)\n",
      "\u001b[92mcmd2:\u001b[0m Collecting nbconvert (from jupyter==1.1.1)\n",
      "\u001b[92mcmd2:\u001b[0m   Using cached nbconvert-7.16.6-py3-none-any.whl.metadata (8.5 kB)\n",
      "\u001b[92mcmd2:\u001b[0m Collecting ipykernel (from jupyter==1.1.1)\n",
      "\u001b[92mcmd2:\u001b[0m   Downloading ipykernel-7.1.0-py3-none-any.whl.metadata (4.5 kB)\n",
      "\u001b[92mcmd2:\u001b[0m Collecting ipywidgets (from jupyter==1.1.1)\n",
      "\u001b[92mcmd2:\u001b[0m   Using cached ipywidgets-8.1.8-py3-none-any.whl.metadata (2.4 kB)\n",
      "\u001b[92mcmd2:\u001b[0m Collecting jupyterlab (from jupyter==1.1.1)\n",
      "\u001b[92mcmd2:\u001b[0m   Using cached jupyterlab-4.5.1-py3-none-any.whl.metadata (16 kB)\n",
      "\u001b[92mcmd2:\u001b[0m Collecting python-dateutil>=2.8.2 (from pandas==2.3.0)\n",
      "\u001b[92mcmd2:\u001b[0m   Using cached python_dateutil-2.9.0.post0-py2.py3-none-any.whl.metadata (8.4 kB)\n",
      "\u001b[92mcmd2:\u001b[0m Collecting pytz>=2020.1 (from pandas==2.3.0)\n",
      "\u001b[92mcmd2:\u001b[0m   Downloading pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "\u001b[92mcmd2:\u001b[0m Collecting tzdata>=2022.7 (from pandas==2.3.0)\n",
      "\u001b[92mcmd2:\u001b[0m   Using cached tzdata-2025.3-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "\u001b[92mcmd2:\u001b[0m Collecting contourpy>=1.0.1 (from matplotlib==3.10.1)\n",
      "\u001b[92mcmd2:\u001b[0m   Downloading contourpy-1.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.5 kB)\n",
      "\u001b[92mcmd2:\u001b[0m Collecting cycler>=0.10 (from matplotlib==3.10.1)\n",
      "\u001b[92mcmd2:\u001b[0m   Using cached cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "\u001b[92mcmd2:\u001b[0m Collecting fonttools>=4.22.0 (from matplotlib==3.10.1)\n",
      "\u001b[92mcmd2:\u001b[0m   Downloading fonttools-4.61.1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (114 kB)\n",
      "\u001b[92mcmd2:\u001b[0m Collecting kiwisolver>=1.3.1 (from matplotlib==3.10.1)\n",
      "\u001b[92mcmd2:\u001b[0m   Downloading kiwisolver-1.4.9-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (6.3 kB)\n",
      "\u001b[92mcmd2:\u001b[0m Collecting packaging>=20.0 (from matplotlib==3.10.1)\n",
      "\u001b[92mcmd2:\u001b[0m   Using cached packaging-25.0-py3-none-any.whl.metadata (3.3 kB)\n",
      "\u001b[92mcmd2:\u001b[0m Requirement already satisfied: pillow>=8 in /root/miniconda3/envs/b2txt25/lib/python3.10/site-packages (from matplotlib==3.10.1) (12.0.0)\n",
      "\u001b[92mcmd2:\u001b[0m Collecting pyparsing>=2.3.1 (from matplotlib==3.10.1)\n",
      "\u001b[92mcmd2:\u001b[0m   Using cached pyparsing-3.3.1-py3-none-any.whl.metadata (5.6 kB)\n",
      "\u001b[92mcmd2:\u001b[0m Collecting joblib>=1.2.0 (from scikit-learn==1.6.1)\n",
      "\u001b[92mcmd2:\u001b[0m   Using cached joblib-1.5.3-py3-none-any.whl.metadata (5.5 kB)\n",
      "\u001b[92mcmd2:\u001b[0m Collecting threadpoolctl>=3.1.0 (from scikit-learn==1.6.1)\n",
      "\u001b[92mcmd2:\u001b[0m   Using cached threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "\u001b[92mcmd2:\u001b[0m Collecting nltk>=3.2.4 (from g2p_en==2.1.0)\n",
      "\u001b[92mcmd2:\u001b[0m   Using cached nltk-3.9.2-py3-none-any.whl.metadata (3.2 kB)\n",
      "\u001b[92mcmd2:\u001b[0m Collecting inflect>=0.3.1 (from g2p_en==2.1.0)\n",
      "\u001b[92mcmd2:\u001b[0m   Using cached inflect-7.5.0-py3-none-any.whl.metadata (24 kB)\n",
      "\u001b[92mcmd2:\u001b[0m Collecting distance>=0.1.3 (from g2p_en==2.1.0)\n",
      "\u001b[92mcmd2:\u001b[0m   Using cached Distance-0.1.3.tar.gz (180 kB)\n",
      "\u001b[92mcmd2:\u001b[0m   Installing build dependencies: started\n",
      "\u001b[92mcmd2:\u001b[0m   Installing build dependencies: finished with status 'done'\n",
      "\u001b[92mcmd2:\u001b[0m   Getting requirements to build wheel: started\n",
      "\u001b[92mcmd2:\u001b[0m   Getting requirements to build wheel: finished with status 'done'\n",
      "\u001b[92mcmd2:\u001b[0m   Preparing metadata (pyproject.toml): started\n",
      "\u001b[92mcmd2:\u001b[0m   Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "\u001b[92mcmd2:\u001b[0m Collecting antlr4-python3-runtime==4.9.* (from omegaconf==2.3.0)\n",
      "\u001b[92mcmd2:\u001b[0m   Using cached antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n",
      "\u001b[92mcmd2:\u001b[0m   Installing build dependencies: started\n",
      "\u001b[92mcmd2:\u001b[0m   Installing build dependencies: finished with status 'done'\n",
      "\u001b[92mcmd2:\u001b[0m   Getting requirements to build wheel: started\n",
      "\u001b[92mcmd2:\u001b[0m   Getting requirements to build wheel: finished with status 'done'\n",
      "\u001b[92mcmd2:\u001b[0m   Preparing metadata (pyproject.toml): started\n",
      "\u001b[92mcmd2:\u001b[0m   Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "\u001b[92mcmd2:\u001b[0m Collecting PyYAML>=5.1.0 (from omegaconf==2.3.0)\n",
      "\u001b[92mcmd2:\u001b[0m   Downloading pyyaml-6.0.3-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (2.4 kB)\n",
      "\u001b[92mcmd2:\u001b[0m Requirement already satisfied: filelock in /root/miniconda3/envs/b2txt25/lib/python3.10/site-packages (from huggingface-hub==0.33.1) (3.20.0)\n",
      "\u001b[92mcmd2:\u001b[0m Requirement already satisfied: fsspec>=2023.5.0 in /root/miniconda3/envs/b2txt25/lib/python3.10/site-packages (from huggingface-hub==0.33.1) (2025.12.0)\n",
      "\u001b[92mcmd2:\u001b[0m Collecting requests (from huggingface-hub==0.33.1)\n",
      "\u001b[92mcmd2:\u001b[0m   Using cached requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
      "\u001b[92mcmd2:\u001b[0m Requirement already satisfied: typing-extensions>=3.7.4.3 in /root/miniconda3/envs/b2txt25/lib/python3.10/site-packages (from huggingface-hub==0.33.1) (4.15.0)\n",
      "\u001b[92mcmd2:\u001b[0m Collecting hf-xet<2.0.0,>=1.1.2 (from huggingface-hub==0.33.1)\n",
      "\u001b[92mcmd2:\u001b[0m   Downloading hf_xet-1.2.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
      "\u001b[92mcmd2:\u001b[0m Collecting regex!=2019.12.17 (from transformers==4.53.0)\n",
      "\u001b[92mcmd2:\u001b[0m   Downloading regex-2025.11.3-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (40 kB)\n",
      "\u001b[92mcmd2:\u001b[0m Collecting safetensors>=0.4.3 (from transformers==4.53.0)\n",
      "\u001b[92mcmd2:\u001b[0m   Using cached safetensors-0.7.0-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
      "\u001b[92mcmd2:\u001b[0m Collecting psutil (from accelerate==1.8.1)\n",
      "\u001b[92mcmd2:\u001b[0m   Using cached psutil-7.2.0-cp36-abi3-manylinux2010_x86_64.manylinux_2_12_x86_64.manylinux_2_28_x86_64.whl.metadata (22 kB)\n",
      "\u001b[92mcmd2:\u001b[0m Requirement already satisfied: torch>=2.0.0 in /root/miniconda3/envs/b2txt25/lib/python3.10/site-packages (from accelerate==1.8.1) (2.9.1+cu126)\n",
      "\u001b[92mcmd2:\u001b[0m Requirement already satisfied: sympy>=1.13.3 in /root/miniconda3/envs/b2txt25/lib/python3.10/site-packages (from torch>=2.0.0->accelerate==1.8.1) (1.14.0)\n",
      "\u001b[92mcmd2:\u001b[0m Requirement already satisfied: networkx>=2.5.1 in /root/miniconda3/envs/b2txt25/lib/python3.10/site-packages (from torch>=2.0.0->accelerate==1.8.1) (3.4.2)\n",
      "\u001b[92mcmd2:\u001b[0m Requirement already satisfied: jinja2 in /root/miniconda3/envs/b2txt25/lib/python3.10/site-packages (from torch>=2.0.0->accelerate==1.8.1) (3.1.6)\n",
      "\u001b[92mcmd2:\u001b[0m Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /root/miniconda3/envs/b2txt25/lib/python3.10/site-packages (from torch>=2.0.0->accelerate==1.8.1) (12.6.77)\n",
      "\u001b[92mcmd2:\u001b[0m Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /root/miniconda3/envs/b2txt25/lib/python3.10/site-packages (from torch>=2.0.0->accelerate==1.8.1) (12.6.77)\n",
      "\u001b[92mcmd2:\u001b[0m Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /root/miniconda3/envs/b2txt25/lib/python3.10/site-packages (from torch>=2.0.0->accelerate==1.8.1) (12.6.80)\n",
      "\u001b[92mcmd2:\u001b[0m Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /root/miniconda3/envs/b2txt25/lib/python3.10/site-packages (from torch>=2.0.0->accelerate==1.8.1) (9.10.2.21)\n",
      "\u001b[92mcmd2:\u001b[0m Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /root/miniconda3/envs/b2txt25/lib/python3.10/site-packages (from torch>=2.0.0->accelerate==1.8.1) (12.6.4.1)\n",
      "\u001b[92mcmd2:\u001b[0m Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /root/miniconda3/envs/b2txt25/lib/python3.10/site-packages (from torch>=2.0.0->accelerate==1.8.1) (11.3.0.4)\n",
      "\u001b[92mcmd2:\u001b[0m Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /root/miniconda3/envs/b2txt25/lib/python3.10/site-packages (from torch>=2.0.0->accelerate==1.8.1) (10.3.7.77)\n",
      "\u001b[92mcmd2:\u001b[0m Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /root/miniconda3/envs/b2txt25/lib/python3.10/site-packages (from torch>=2.0.0->accelerate==1.8.1) (11.7.1.2)\n",
      "\u001b[92mcmd2:\u001b[0m Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /root/miniconda3/envs/b2txt25/lib/python3.10/site-packages (from torch>=2.0.0->accelerate==1.8.1) (12.5.4.2)\n",
      "\u001b[92mcmd2:\u001b[0m Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /root/miniconda3/envs/b2txt25/lib/python3.10/site-packages (from torch>=2.0.0->accelerate==1.8.1) (0.7.1)\n",
      "\u001b[92mcmd2:\u001b[0m Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /root/miniconda3/envs/b2txt25/lib/python3.10/site-packages (from torch>=2.0.0->accelerate==1.8.1) (2.27.5)\n",
      "\u001b[92mcmd2:\u001b[0m Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /root/miniconda3/envs/b2txt25/lib/python3.10/site-packages (from torch>=2.0.0->accelerate==1.8.1) (3.3.20)\n",
      "\u001b[92mcmd2:\u001b[0m Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /root/miniconda3/envs/b2txt25/lib/python3.10/site-packages (from torch>=2.0.0->accelerate==1.8.1) (12.6.77)\n",
      "\u001b[92mcmd2:\u001b[0m Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /root/miniconda3/envs/b2txt25/lib/python3.10/site-packages (from torch>=2.0.0->accelerate==1.8.1) (12.6.85)\n",
      "\u001b[92mcmd2:\u001b[0m Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /root/miniconda3/envs/b2txt25/lib/python3.10/site-packages (from torch>=2.0.0->accelerate==1.8.1) (1.11.1.6)\n",
      "\u001b[92mcmd2:\u001b[0m Requirement already satisfied: triton==3.5.1 in /root/miniconda3/envs/b2txt25/lib/python3.10/site-packages (from torch>=2.0.0->accelerate==1.8.1) (3.5.1)\n",
      "\u001b[92mcmd2:\u001b[0m Collecting more_itertools>=8.5.0 (from inflect>=0.3.1->g2p_en==2.1.0)\n",
      "\u001b[92mcmd2:\u001b[0m   Using cached more_itertools-10.8.0-py3-none-any.whl.metadata (39 kB)\n",
      "\u001b[92mcmd2:\u001b[0m Collecting typeguard>=4.0.1 (from inflect>=0.3.1->g2p_en==2.1.0)\n",
      "\u001b[92mcmd2:\u001b[0m   Using cached typeguard-4.4.4-py3-none-any.whl.metadata (3.3 kB)\n",
      "\u001b[92mcmd2:\u001b[0m Collecting click (from nltk>=3.2.4->g2p_en==2.1.0)\n",
      "\u001b[92mcmd2:\u001b[0m   Downloading click-8.3.1-py3-none-any.whl.metadata (2.6 kB)\n",
      "\u001b[92mcmd2:\u001b[0m Collecting six>=1.5 (from python-dateutil>=2.8.2->pandas==2.3.0)\n",
      "\u001b[92mcmd2:\u001b[0m   Using cached six-1.17.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
      "\u001b[92mcmd2:\u001b[0m Requirement already satisfied: mpmath<1.4,>=1.1.0 in /root/miniconda3/envs/b2txt25/lib/python3.10/site-packages (from sympy>=1.13.3->torch>=2.0.0->accelerate==1.8.1) (1.3.0)\n",
      "\u001b[92mcmd2:\u001b[0m Collecting comm>=0.1.1 (from ipykernel->jupyter==1.1.1)\n",
      "\u001b[92mcmd2:\u001b[0m   Using cached comm-0.2.3-py3-none-any.whl.metadata (3.7 kB)\n",
      "\u001b[92mcmd2:\u001b[0m Collecting debugpy>=1.6.5 (from ipykernel->jupyter==1.1.1)\n",
      "\u001b[92mcmd2:\u001b[0m   Downloading debugpy-1.8.19-cp310-cp310-manylinux_2_34_x86_64.whl.metadata (1.4 kB)\n",
      "\u001b[92mcmd2:\u001b[0m Collecting ipython>=7.23.1 (from ipykernel->jupyter==1.1.1)\n",
      "\u001b[92mcmd2:\u001b[0m   Downloading ipython-8.37.0-py3-none-any.whl.metadata (5.1 kB)\n",
      "\u001b[92mcmd2:\u001b[0m Collecting jupyter-client>=8.0.0 (from ipykernel->jupyter==1.1.1)\n",
      "\u001b[92mcmd2:\u001b[0m   Downloading jupyter_client-8.7.0-py3-none-any.whl.metadata (8.3 kB)\n",
      "\u001b[92mcmd2:\u001b[0m Collecting jupyter-core!=5.0.*,>=4.12 (from ipykernel->jupyter==1.1.1)\n",
      "\u001b[92mcmd2:\u001b[0m   Downloading jupyter_core-5.9.1-py3-none-any.whl.metadata (1.5 kB)\n",
      "\u001b[92mcmd2:\u001b[0m Collecting matplotlib-inline>=0.1 (from ipykernel->jupyter==1.1.1)\n",
      "\u001b[92mcmd2:\u001b[0m   Using cached matplotlib_inline-0.2.1-py3-none-any.whl.metadata (2.3 kB)\n",
      "\u001b[92mcmd2:\u001b[0m Collecting nest-asyncio>=1.4 (from ipykernel->jupyter==1.1.1)\n",
      "\u001b[92mcmd2:\u001b[0m   Using cached nest_asyncio-1.6.0-py3-none-any.whl.metadata (2.8 kB)\n",
      "\u001b[92mcmd2:\u001b[0m Collecting pyzmq>=25 (from ipykernel->jupyter==1.1.1)\n",
      "\u001b[92mcmd2:\u001b[0m   Downloading pyzmq-27.1.0-cp310-cp310-manylinux_2_26_x86_64.manylinux_2_28_x86_64.whl.metadata (6.0 kB)\n",
      "\u001b[92mcmd2:\u001b[0m Collecting tornado>=6.2 (from ipykernel->jupyter==1.1.1)\n",
      "\u001b[92mcmd2:\u001b[0m   Using cached tornado-6.5.4-cp39-abi3-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.8 kB)\n",
      "\u001b[92mcmd2:\u001b[0m Collecting traitlets>=5.4.0 (from ipykernel->jupyter==1.1.1)\n",
      "\u001b[92mcmd2:\u001b[0m   Using cached traitlets-5.14.3-py3-none-any.whl.metadata (10 kB)\n",
      "\u001b[92mcmd2:\u001b[0m Collecting decorator (from ipython>=7.23.1->ipykernel->jupyter==1.1.1)\n",
      "\u001b[92mcmd2:\u001b[0m   Using cached decorator-5.2.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "\u001b[92mcmd2:\u001b[0m Collecting exceptiongroup (from ipython>=7.23.1->ipykernel->jupyter==1.1.1)\n",
      "\u001b[92mcmd2:\u001b[0m   Using cached exceptiongroup-1.3.1-py3-none-any.whl.metadata (6.7 kB)\n",
      "\u001b[92mcmd2:\u001b[0m Collecting jedi>=0.16 (from ipython>=7.23.1->ipykernel->jupyter==1.1.1)\n",
      "\u001b[92mcmd2:\u001b[0m   Using cached jedi-0.19.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "\u001b[92mcmd2:\u001b[0m Collecting pexpect>4.3 (from ipython>=7.23.1->ipykernel->jupyter==1.1.1)\n",
      "\u001b[92mcmd2:\u001b[0m   Using cached pexpect-4.9.0-py2.py3-none-any.whl.metadata (2.5 kB)\n",
      "\u001b[92mcmd2:\u001b[0m Collecting prompt_toolkit<3.1.0,>=3.0.41 (from ipython>=7.23.1->ipykernel->jupyter==1.1.1)\n",
      "\u001b[92mcmd2:\u001b[0m   Using cached prompt_toolkit-3.0.52-py3-none-any.whl.metadata (6.4 kB)\n",
      "\u001b[92mcmd2:\u001b[0m Collecting pygments>=2.4.0 (from ipython>=7.23.1->ipykernel->jupyter==1.1.1)\n",
      "\u001b[92mcmd2:\u001b[0m   Using cached pygments-2.19.2-py3-none-any.whl.metadata (2.5 kB)\n",
      "\u001b[92mcmd2:\u001b[0m Collecting stack_data (from ipython>=7.23.1->ipykernel->jupyter==1.1.1)\n",
      "\u001b[92mcmd2:\u001b[0m   Using cached stack_data-0.6.3-py3-none-any.whl.metadata (18 kB)\n",
      "\u001b[92mcmd2:\u001b[0m Collecting wcwidth (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=7.23.1->ipykernel->jupyter==1.1.1)\n",
      "\u001b[92mcmd2:\u001b[0m   Using cached wcwidth-0.2.14-py2.py3-none-any.whl.metadata (15 kB)\n",
      "\u001b[92mcmd2:\u001b[0m Collecting parso<0.9.0,>=0.8.4 (from jedi>=0.16->ipython>=7.23.1->ipykernel->jupyter==1.1.1)\n",
      "\u001b[92mcmd2:\u001b[0m   Using cached parso-0.8.5-py2.py3-none-any.whl.metadata (8.3 kB)\n",
      "\u001b[92mcmd2:\u001b[0m Collecting platformdirs>=2.5 (from jupyter-core!=5.0.*,>=4.12->ipykernel->jupyter==1.1.1)\n",
      "\u001b[92mcmd2:\u001b[0m   Downloading platformdirs-4.5.1-py3-none-any.whl.metadata (12 kB)\n",
      "\u001b[92mcmd2:\u001b[0m Collecting ptyprocess>=0.5 (from pexpect>4.3->ipython>=7.23.1->ipykernel->jupyter==1.1.1)\n",
      "\u001b[92mcmd2:\u001b[0m   Using cached ptyprocess-0.7.0-py2.py3-none-any.whl.metadata (1.3 kB)\n",
      "\u001b[92mcmd2:\u001b[0m Collecting widgetsnbextension~=4.0.14 (from ipywidgets->jupyter==1.1.1)\n",
      "\u001b[92mcmd2:\u001b[0m   Using cached widgetsnbextension-4.0.15-py3-none-any.whl.metadata (1.6 kB)\n",
      "\u001b[92mcmd2:\u001b[0m Collecting jupyterlab_widgets~=3.0.15 (from ipywidgets->jupyter==1.1.1)\n",
      "\u001b[92mcmd2:\u001b[0m   Using cached jupyterlab_widgets-3.0.16-py3-none-any.whl.metadata (20 kB)\n",
      "\u001b[92mcmd2:\u001b[0m Requirement already satisfied: MarkupSafe>=2.0 in /root/miniconda3/envs/b2txt25/lib/python3.10/site-packages (from jinja2->torch>=2.0.0->accelerate==1.8.1) (2.1.5)\n",
      "\u001b[92mcmd2:\u001b[0m Collecting async-lru>=1.0.0 (from jupyterlab->jupyter==1.1.1)\n",
      "\u001b[92mcmd2:\u001b[0m   Using cached async_lru-2.0.5-py3-none-any.whl.metadata (4.5 kB)\n",
      "\u001b[92mcmd2:\u001b[0m Collecting httpx<1,>=0.25.0 (from jupyterlab->jupyter==1.1.1)\n",
      "\u001b[92mcmd2:\u001b[0m   Using cached httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "\u001b[92mcmd2:\u001b[0m Collecting jupyter-lsp>=2.0.0 (from jupyterlab->jupyter==1.1.1)\n",
      "\u001b[92mcmd2:\u001b[0m   Using cached jupyter_lsp-2.3.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "\u001b[92mcmd2:\u001b[0m Collecting jupyter-server<3,>=2.4.0 (from jupyterlab->jupyter==1.1.1)\n",
      "\u001b[92mcmd2:\u001b[0m   Using cached jupyter_server-2.17.0-py3-none-any.whl.metadata (8.5 kB)\n",
      "\u001b[92mcmd2:\u001b[0m Collecting jupyterlab-server<3,>=2.28.0 (from jupyterlab->jupyter==1.1.1)\n",
      "\u001b[92mcmd2:\u001b[0m   Using cached jupyterlab_server-2.28.0-py3-none-any.whl.metadata (5.9 kB)\n",
      "\u001b[92mcmd2:\u001b[0m Collecting notebook-shim>=0.2 (from jupyterlab->jupyter==1.1.1)\n",
      "\u001b[92mcmd2:\u001b[0m   Using cached notebook_shim-0.2.4-py3-none-any.whl.metadata (4.0 kB)\n",
      "\u001b[92mcmd2:\u001b[0m Requirement already satisfied: setuptools>=41.1.0 in /root/miniconda3/envs/b2txt25/lib/python3.10/site-packages (from jupyterlab->jupyter==1.1.1) (80.9.0)\n",
      "\u001b[92mcmd2:\u001b[0m Collecting tomli>=1.2.2 (from jupyterlab->jupyter==1.1.1)\n",
      "\u001b[92mcmd2:\u001b[0m   Using cached tomli-2.3.0-py3-none-any.whl.metadata (10 kB)\n",
      "\u001b[92mcmd2:\u001b[0m Collecting anyio (from httpx<1,>=0.25.0->jupyterlab->jupyter==1.1.1)\n",
      "\u001b[92mcmd2:\u001b[0m   Using cached anyio-4.12.0-py3-none-any.whl.metadata (4.3 kB)\n",
      "\u001b[92mcmd2:\u001b[0m Collecting certifi (from httpx<1,>=0.25.0->jupyterlab->jupyter==1.1.1)\n",
      "\u001b[92mcmd2:\u001b[0m   Using cached certifi-2025.11.12-py3-none-any.whl.metadata (2.5 kB)\n",
      "\u001b[92mcmd2:\u001b[0m Collecting httpcore==1.* (from httpx<1,>=0.25.0->jupyterlab->jupyter==1.1.1)\n",
      "\u001b[92mcmd2:\u001b[0m   Using cached httpcore-1.0.9-py3-none-any.whl.metadata (21 kB)\n",
      "\u001b[92mcmd2:\u001b[0m Collecting idna (from httpx<1,>=0.25.0->jupyterlab->jupyter==1.1.1)\n",
      "\u001b[92mcmd2:\u001b[0m   Using cached idna-3.11-py3-none-any.whl.metadata (8.4 kB)\n",
      "\u001b[92mcmd2:\u001b[0m Collecting h11>=0.16 (from httpcore==1.*->httpx<1,>=0.25.0->jupyterlab->jupyter==1.1.1)\n",
      "\u001b[92mcmd2:\u001b[0m   Using cached h11-0.16.0-py3-none-any.whl.metadata (8.3 kB)\n",
      "\u001b[92mcmd2:\u001b[0m Collecting argon2-cffi>=21.1 (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter==1.1.1)\n",
      "\u001b[92mcmd2:\u001b[0m   Using cached argon2_cffi-25.1.0-py3-none-any.whl.metadata (4.1 kB)\n",
      "\u001b[92mcmd2:\u001b[0m Collecting jupyter-events>=0.11.0 (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter==1.1.1)\n",
      "\u001b[92mcmd2:\u001b[0m   Using cached jupyter_events-0.12.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "\u001b[92mcmd2:\u001b[0m Collecting jupyter-server-terminals>=0.4.4 (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter==1.1.1)\n",
      "\u001b[92mcmd2:\u001b[0m   Using cached jupyter_server_terminals-0.5.3-py3-none-any.whl.metadata (5.6 kB)\n",
      "\u001b[92mcmd2:\u001b[0m Collecting nbformat>=5.3.0 (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter==1.1.1)\n",
      "\u001b[92mcmd2:\u001b[0m   Using cached nbformat-5.10.4-py3-none-any.whl.metadata (3.6 kB)\n",
      "\u001b[92mcmd2:\u001b[0m Collecting overrides>=5.0 (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter==1.1.1)\n",
      "\u001b[92mcmd2:\u001b[0m   Using cached overrides-7.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "\u001b[92mcmd2:\u001b[0m Collecting prometheus-client>=0.9 (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter==1.1.1)\n",
      "\u001b[92mcmd2:\u001b[0m   Using cached prometheus_client-0.23.1-py3-none-any.whl.metadata (1.9 kB)\n",
      "\u001b[92mcmd2:\u001b[0m Collecting send2trash>=1.8.2 (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter==1.1.1)\n",
      "\u001b[92mcmd2:\u001b[0m   Using cached Send2Trash-1.8.3-py3-none-any.whl.metadata (4.0 kB)\n",
      "\u001b[92mcmd2:\u001b[0m Collecting terminado>=0.8.3 (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter==1.1.1)\n",
      "\u001b[92mcmd2:\u001b[0m   Using cached terminado-0.18.1-py3-none-any.whl.metadata (5.8 kB)\n",
      "\u001b[92mcmd2:\u001b[0m Collecting websocket-client>=1.7 (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter==1.1.1)\n",
      "\u001b[92mcmd2:\u001b[0m   Using cached websocket_client-1.9.0-py3-none-any.whl.metadata (8.3 kB)\n",
      "\u001b[92mcmd2:\u001b[0m Collecting babel>=2.10 (from jupyterlab-server<3,>=2.28.0->jupyterlab->jupyter==1.1.1)\n",
      "\u001b[92mcmd2:\u001b[0m   Using cached babel-2.17.0-py3-none-any.whl.metadata (2.0 kB)\n",
      "\u001b[92mcmd2:\u001b[0m Collecting json5>=0.9.0 (from jupyterlab-server<3,>=2.28.0->jupyterlab->jupyter==1.1.1)\n",
      "\u001b[92mcmd2:\u001b[0m   Using cached json5-0.12.1-py3-none-any.whl.metadata (36 kB)\n",
      "\u001b[92mcmd2:\u001b[0m Collecting jsonschema>=4.18.0 (from jupyterlab-server<3,>=2.28.0->jupyterlab->jupyter==1.1.1)\n",
      "\u001b[92mcmd2:\u001b[0m   Using cached jsonschema-4.25.1-py3-none-any.whl.metadata (7.6 kB)\n",
      "\u001b[92mcmd2:\u001b[0m Collecting argon2-cffi-bindings (from argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab->jupyter==1.1.1)\n",
      "\u001b[92mcmd2:\u001b[0m   Using cached argon2_cffi_bindings-25.1.0-cp39-abi3-manylinux_2_26_x86_64.manylinux_2_28_x86_64.whl.metadata (7.4 kB)\n",
      "\u001b[92mcmd2:\u001b[0m Collecting attrs>=22.2.0 (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.28.0->jupyterlab->jupyter==1.1.1)\n",
      "\u001b[92mcmd2:\u001b[0m   Using cached attrs-25.4.0-py3-none-any.whl.metadata (10 kB)\n",
      "\u001b[92mcmd2:\u001b[0m Collecting jsonschema-specifications>=2023.03.6 (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.28.0->jupyterlab->jupyter==1.1.1)\n",
      "\u001b[92mcmd2:\u001b[0m   Using cached jsonschema_specifications-2025.9.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "\u001b[92mcmd2:\u001b[0m Collecting referencing>=0.28.4 (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.28.0->jupyterlab->jupyter==1.1.1)\n",
      "\u001b[92mcmd2:\u001b[0m   Downloading referencing-0.37.0-py3-none-any.whl.metadata (2.8 kB)\n",
      "\u001b[92mcmd2:\u001b[0m Collecting rpds-py>=0.7.1 (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.28.0->jupyterlab->jupyter==1.1.1)\n",
      "\u001b[92mcmd2:\u001b[0m   Downloading rpds_py-0.30.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
      "\u001b[92mcmd2:\u001b[0m Collecting python-json-logger>=2.0.4 (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter==1.1.1)\n",
      "\u001b[92mcmd2:\u001b[0m   Using cached python_json_logger-4.0.0-py3-none-any.whl.metadata (4.0 kB)\n",
      "\u001b[92mcmd2:\u001b[0m Collecting rfc3339-validator (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter==1.1.1)\n",
      "\u001b[92mcmd2:\u001b[0m   Using cached rfc3339_validator-0.1.4-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "\u001b[92mcmd2:\u001b[0m Collecting rfc3986-validator>=0.1.1 (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter==1.1.1)\n",
      "\u001b[92mcmd2:\u001b[0m   Using cached rfc3986_validator-0.1.1-py2.py3-none-any.whl.metadata (1.7 kB)\n",
      "\u001b[92mcmd2:\u001b[0m Collecting fqdn (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter==1.1.1)\n",
      "\u001b[92mcmd2:\u001b[0m   Using cached fqdn-1.5.1-py3-none-any.whl.metadata (1.4 kB)\n",
      "\u001b[92mcmd2:\u001b[0m Collecting isoduration (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter==1.1.1)\n",
      "\u001b[92mcmd2:\u001b[0m   Using cached isoduration-20.11.0-py3-none-any.whl.metadata (5.7 kB)\n",
      "\u001b[92mcmd2:\u001b[0m Collecting jsonpointer>1.13 (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter==1.1.1)\n",
      "\u001b[92mcmd2:\u001b[0m   Using cached jsonpointer-3.0.0-py2.py3-none-any.whl.metadata (2.3 kB)\n",
      "\u001b[92mcmd2:\u001b[0m Collecting rfc3987-syntax>=1.1.0 (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter==1.1.1)\n",
      "\u001b[92mcmd2:\u001b[0m   Using cached rfc3987_syntax-1.1.0-py3-none-any.whl.metadata (7.7 kB)\n",
      "\u001b[92mcmd2:\u001b[0m Collecting uri-template (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter==1.1.1)\n",
      "\u001b[92mcmd2:\u001b[0m   Using cached uri_template-1.3.0-py3-none-any.whl.metadata (8.8 kB)\n",
      "\u001b[92mcmd2:\u001b[0m Collecting webcolors>=24.6.0 (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter==1.1.1)\n",
      "\u001b[92mcmd2:\u001b[0m   Downloading webcolors-25.10.0-py3-none-any.whl.metadata (2.2 kB)\n",
      "\u001b[92mcmd2:\u001b[0m Collecting beautifulsoup4 (from nbconvert->jupyter==1.1.1)\n",
      "\u001b[92mcmd2:\u001b[0m   Using cached beautifulsoup4-4.14.3-py3-none-any.whl.metadata (3.8 kB)\n",
      "\u001b[92mcmd2:\u001b[0m Collecting bleach!=5.0.0 (from bleach[css]!=5.0.0->nbconvert->jupyter==1.1.1)\n",
      "\u001b[92mcmd2:\u001b[0m   Downloading bleach-6.3.0-py3-none-any.whl.metadata (31 kB)\n",
      "\u001b[92mcmd2:\u001b[0m Collecting defusedxml (from nbconvert->jupyter==1.1.1)\n",
      "\u001b[92mcmd2:\u001b[0m   Using cached defusedxml-0.7.1-py2.py3-none-any.whl.metadata (32 kB)\n",
      "\u001b[92mcmd2:\u001b[0m Collecting jupyterlab-pygments (from nbconvert->jupyter==1.1.1)\n",
      "\u001b[92mcmd2:\u001b[0m   Using cached jupyterlab_pygments-0.3.0-py3-none-any.whl.metadata (4.4 kB)\n",
      "\u001b[92mcmd2:\u001b[0m Collecting mistune<4,>=2.0.3 (from nbconvert->jupyter==1.1.1)\n",
      "\u001b[92mcmd2:\u001b[0m   Using cached mistune-3.2.0-py3-none-any.whl.metadata (1.9 kB)\n",
      "\u001b[92mcmd2:\u001b[0m Collecting nbclient>=0.5.0 (from nbconvert->jupyter==1.1.1)\n",
      "\u001b[92mcmd2:\u001b[0m   Downloading nbclient-0.10.4-py3-none-any.whl.metadata (8.3 kB)\n",
      "\u001b[92mcmd2:\u001b[0m Collecting pandocfilters>=1.4.1 (from nbconvert->jupyter==1.1.1)\n",
      "\u001b[92mcmd2:\u001b[0m   Using cached pandocfilters-1.5.1-py2.py3-none-any.whl.metadata (9.0 kB)\n",
      "\u001b[92mcmd2:\u001b[0m Collecting webencodings (from bleach!=5.0.0->bleach[css]!=5.0.0->nbconvert->jupyter==1.1.1)\n",
      "\u001b[92mcmd2:\u001b[0m   Using cached webencodings-0.5.1-py2.py3-none-any.whl.metadata (2.1 kB)\n",
      "\u001b[92mcmd2:\u001b[0m Collecting tinycss2<1.5,>=1.1.0 (from bleach[css]!=5.0.0->nbconvert->jupyter==1.1.1)\n",
      "\u001b[92mcmd2:\u001b[0m   Using cached tinycss2-1.4.0-py3-none-any.whl.metadata (3.0 kB)\n",
      "\u001b[92mcmd2:\u001b[0m Collecting fastjsonschema>=2.15 (from nbformat>=5.3.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter==1.1.1)\n",
      "\u001b[92mcmd2:\u001b[0m   Using cached fastjsonschema-2.21.2-py3-none-any.whl.metadata (2.3 kB)\n",
      "\u001b[92mcmd2:\u001b[0m Collecting charset_normalizer<4,>=2 (from requests->huggingface-hub==0.33.1)\n",
      "\u001b[92mcmd2:\u001b[0m   Downloading charset_normalizer-3.4.4-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (37 kB)\n",
      "\u001b[92mcmd2:\u001b[0m Collecting urllib3<3,>=1.21.1 (from requests->huggingface-hub==0.33.1)\n",
      "\u001b[92mcmd2:\u001b[0m   Using cached urllib3-2.6.2-py3-none-any.whl.metadata (6.6 kB)\n",
      "\u001b[92mcmd2:\u001b[0m Collecting lark>=1.2.2 (from rfc3987-syntax>=1.1.0->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter==1.1.1)\n",
      "\u001b[92mcmd2:\u001b[0m   Using cached lark-1.3.1-py3-none-any.whl.metadata (1.8 kB)\n",
      "\u001b[92mcmd2:\u001b[0m Collecting cffi>=1.0.1 (from argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab->jupyter==1.1.1)\n",
      "\u001b[92mcmd2:\u001b[0m   Downloading cffi-2.0.0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.6 kB)\n",
      "\u001b[92mcmd2:\u001b[0m Collecting pycparser (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab->jupyter==1.1.1)\n",
      "\u001b[92mcmd2:\u001b[0m   Using cached pycparser-2.23-py3-none-any.whl.metadata (993 bytes)\n",
      "\u001b[92mcmd2:\u001b[0m Collecting soupsieve>=1.6.1 (from beautifulsoup4->nbconvert->jupyter==1.1.1)\n",
      "\u001b[92mcmd2:\u001b[0m   Using cached soupsieve-2.8.1-py3-none-any.whl.metadata (4.6 kB)\n",
      "\u001b[92mcmd2:\u001b[0m Collecting arrow>=0.15.0 (from isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter==1.1.1)\n",
      "\u001b[92mcmd2:\u001b[0m   Using cached arrow-1.4.0-py3-none-any.whl.metadata (7.7 kB)\n",
      "\u001b[92mcmd2:\u001b[0m Collecting executing>=1.2.0 (from stack_data->ipython>=7.23.1->ipykernel->jupyter==1.1.1)\n",
      "\u001b[92mcmd2:\u001b[0m   Using cached executing-2.2.1-py2.py3-none-any.whl.metadata (8.9 kB)\n",
      "\u001b[92mcmd2:\u001b[0m Collecting asttokens>=2.1.0 (from stack_data->ipython>=7.23.1->ipykernel->jupyter==1.1.1)\n",
      "\u001b[92mcmd2:\u001b[0m   Using cached asttokens-3.0.1-py3-none-any.whl.metadata (4.9 kB)\n",
      "\u001b[92mcmd2:\u001b[0m Collecting pure-eval (from stack_data->ipython>=7.23.1->ipykernel->jupyter==1.1.1)\n",
      "\u001b[92mcmd2:\u001b[0m   Using cached pure_eval-0.2.3-py3-none-any.whl.metadata (6.3 kB)\n",
      "\u001b[92mcmd2:\u001b[0m Downloading redis-5.2.1-py3-none-any.whl (261 kB)\n",
      "\u001b[92mcmd2:\u001b[0m Using cached jupyter-1.1.1-py2.py3-none-any.whl (2.7 kB)\n",
      "\u001b[92mcmd2:\u001b[0m Downloading numpy-2.1.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.3 MB)\n",
      "\u001b[92mcmd2:\u001b[0m    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 16.3/16.3 MB 10.9 MB/s  0:00:01\n",
      "\u001b[92mcmd2:\u001b[0m Downloading pandas-2.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.3 MB)\n",
      "\u001b[92mcmd2:\u001b[0m    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 12.3/12.3 MB 11.0 MB/s  0:00:01\n",
      "\u001b[92mcmd2:\u001b[0m Downloading matplotlib-3.10.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.6 MB)\n",
      "\u001b[92mcmd2:\u001b[0m    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 8.6/8.6 MB 24.0 MB/s  0:00:00\n",
      "\u001b[92mcmd2:\u001b[0m Downloading scipy-1.15.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (37.6 MB)\n",
      "\u001b[92mcmd2:\u001b[0m    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 37.6/37.6 MB 24.1 MB/s  0:00:01\n",
      "\u001b[92mcmd2:\u001b[0m Downloading scikit_learn-1.6.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.5 MB)\n",
      "\u001b[92mcmd2:\u001b[0m    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 13.5/13.5 MB 31.8 MB/s  0:00:00\n",
      "\u001b[92mcmd2:\u001b[0m Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "\u001b[92mcmd2:\u001b[0m Using cached g2p_en-2.1.0-py3-none-any.whl (3.1 MB)\n",
      "\u001b[92mcmd2:\u001b[0m Downloading h5py-3.13.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.5 MB)\n",
      "\u001b[92mcmd2:\u001b[0m    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 4.5/4.5 MB 28.8 MB/s  0:00:00\n",
      "\u001b[92mcmd2:\u001b[0m Using cached omegaconf-2.3.0-py3-none-any.whl (79 kB)\n",
      "\u001b[92mcmd2:\u001b[0m Downloading editdistance-0.8.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (401 kB)\n",
      "\u001b[92mcmd2:\u001b[0m Downloading huggingface_hub-0.33.1-py3-none-any.whl (515 kB)\n",
      "\u001b[92mcmd2:\u001b[0m Downloading transformers-4.53.0-py3-none-any.whl (10.8 MB)\n",
      "\u001b[92mcmd2:\u001b[0m    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 10.8/10.8 MB 33.2 MB/s  0:00:00\n",
      "\u001b[92mcmd2:\u001b[0m Downloading tokenizers-0.21.2-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
      "\u001b[92mcmd2:\u001b[0m    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.1/3.1 MB 26.4 MB/s  0:00:00\n",
      "\u001b[92mcmd2:\u001b[0m Downloading accelerate-1.8.1-py3-none-any.whl (365 kB)\n",
      "\u001b[92mcmd2:\u001b[0m Downloading bitsandbytes-0.46.0-py3-none-manylinux_2_24_x86_64.whl (67.0 MB)\n",
      "\u001b[92mcmd2:\u001b[0m    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 67.0/67.0 MB 6.5 MB/s  0:00:10\n",
      "\u001b[92mcmd2:\u001b[0m Downloading hf_xet-1.2.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
      "\u001b[92mcmd2:\u001b[0m    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.3/3.3 MB 5.5 MB/s  0:00:00\n",
      "\u001b[92mcmd2:\u001b[0m Using cached async_timeout-5.0.1-py3-none-any.whl (6.2 kB)\n",
      "\u001b[92mcmd2:\u001b[0m Downloading contourpy-1.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (325 kB)\n",
      "\u001b[92mcmd2:\u001b[0m Using cached cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "\u001b[92mcmd2:\u001b[0m Downloading fonttools-4.61.1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (4.9 MB)\n",
      "\u001b[92mcmd2:\u001b[0m    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 4.9/4.9 MB 34.5 MB/s  0:00:00\n",
      "\u001b[92mcmd2:\u001b[0m Using cached inflect-7.5.0-py3-none-any.whl (35 kB)\n",
      "\u001b[92mcmd2:\u001b[0m Using cached joblib-1.5.3-py3-none-any.whl (309 kB)\n",
      "\u001b[92mcmd2:\u001b[0m Downloading kiwisolver-1.4.9-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.6 MB)\n",
      "\u001b[92mcmd2:\u001b[0m    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.6/1.6 MB 26.4 MB/s  0:00:00\n",
      "\u001b[92mcmd2:\u001b[0m Using cached more_itertools-10.8.0-py3-none-any.whl (69 kB)\n",
      "\u001b[92mcmd2:\u001b[0m Using cached nltk-3.9.2-py3-none-any.whl (1.5 MB)\n",
      "\u001b[92mcmd2:\u001b[0m Using cached packaging-25.0-py3-none-any.whl (66 kB)\n",
      "\u001b[92mcmd2:\u001b[0m Using cached pyparsing-3.3.1-py3-none-any.whl (121 kB)\n",
      "\u001b[92mcmd2:\u001b[0m Using cached python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)\n",
      "\u001b[92mcmd2:\u001b[0m Downloading pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "\u001b[92mcmd2:\u001b[0m Downloading pyyaml-6.0.3-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (770 kB)\n",
      "\u001b[92mcmd2:\u001b[0m    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 770.3/770.3 kB 15.2 MB/s  0:00:00\n",
      "\u001b[92mcmd2:\u001b[0m Downloading regex-2025.11.3-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (791 kB)\n",
      "\u001b[92mcmd2:\u001b[0m    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 791.7/791.7 kB 18.0 MB/s  0:00:00\n",
      "\u001b[92mcmd2:\u001b[0m Using cached safetensors-0.7.0-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (507 kB)\n",
      "\u001b[92mcmd2:\u001b[0m Using cached six-1.17.0-py2.py3-none-any.whl (11 kB)\n",
      "\u001b[92mcmd2:\u001b[0m Using cached threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "\u001b[92mcmd2:\u001b[0m Using cached typeguard-4.4.4-py3-none-any.whl (34 kB)\n",
      "\u001b[92mcmd2:\u001b[0m Using cached tzdata-2025.3-py2.py3-none-any.whl (348 kB)\n",
      "\u001b[92mcmd2:\u001b[0m Downloading click-8.3.1-py3-none-any.whl (108 kB)\n",
      "\u001b[92mcmd2:\u001b[0m Downloading ipykernel-7.1.0-py3-none-any.whl (117 kB)\n",
      "\u001b[92mcmd2:\u001b[0m Using cached comm-0.2.3-py3-none-any.whl (7.3 kB)\n",
      "\u001b[92mcmd2:\u001b[0m Downloading debugpy-1.8.19-cp310-cp310-manylinux_2_34_x86_64.whl (3.1 MB)\n",
      "\u001b[92mcmd2:\u001b[0m    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.1/3.1 MB 32.9 MB/s  0:00:00\n",
      "\u001b[92mcmd2:\u001b[0m Downloading ipython-8.37.0-py3-none-any.whl (831 kB)\n",
      "\u001b[92mcmd2:\u001b[0m    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 831.9/831.9 kB 17.2 MB/s  0:00:00\n",
      "\u001b[92mcmd2:\u001b[0m Using cached prompt_toolkit-3.0.52-py3-none-any.whl (391 kB)\n",
      "\u001b[92mcmd2:\u001b[0m Using cached jedi-0.19.2-py2.py3-none-any.whl (1.6 MB)\n",
      "\u001b[92mcmd2:\u001b[0m Using cached parso-0.8.5-py2.py3-none-any.whl (106 kB)\n",
      "\u001b[92mcmd2:\u001b[0m Downloading jupyter_client-8.7.0-py3-none-any.whl (106 kB)\n",
      "\u001b[92mcmd2:\u001b[0m Downloading jupyter_core-5.9.1-py3-none-any.whl (29 kB)\n",
      "\u001b[92mcmd2:\u001b[0m Using cached matplotlib_inline-0.2.1-py3-none-any.whl (9.5 kB)\n",
      "\u001b[92mcmd2:\u001b[0m Using cached nest_asyncio-1.6.0-py3-none-any.whl (5.2 kB)\n",
      "\u001b[92mcmd2:\u001b[0m Using cached pexpect-4.9.0-py2.py3-none-any.whl (63 kB)\n",
      "\u001b[92mcmd2:\u001b[0m Downloading platformdirs-4.5.1-py3-none-any.whl (18 kB)\n",
      "\u001b[92mcmd2:\u001b[0m Using cached psutil-7.2.0-cp36-abi3-manylinux2010_x86_64.manylinux_2_12_x86_64.manylinux_2_28_x86_64.whl (154 kB)\n",
      "\u001b[92mcmd2:\u001b[0m Using cached ptyprocess-0.7.0-py2.py3-none-any.whl (13 kB)\n",
      "\u001b[92mcmd2:\u001b[0m Using cached pygments-2.19.2-py3-none-any.whl (1.2 MB)\n",
      "\u001b[92mcmd2:\u001b[0m Downloading pyzmq-27.1.0-cp310-cp310-manylinux_2_26_x86_64.manylinux_2_28_x86_64.whl (854 kB)\n",
      "\u001b[92mcmd2:\u001b[0m    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 854.1/854.1 kB 18.9 MB/s  0:00:00\n",
      "\u001b[92mcmd2:\u001b[0m Using cached tornado-6.5.4-cp39-abi3-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (445 kB)\n",
      "\u001b[92mcmd2:\u001b[0m Using cached traitlets-5.14.3-py3-none-any.whl (85 kB)\n",
      "\u001b[92mcmd2:\u001b[0m Using cached decorator-5.2.1-py3-none-any.whl (9.2 kB)\n",
      "\u001b[92mcmd2:\u001b[0m Using cached exceptiongroup-1.3.1-py3-none-any.whl (16 kB)\n",
      "\u001b[92mcmd2:\u001b[0m Using cached ipywidgets-8.1.8-py3-none-any.whl (139 kB)\n",
      "\u001b[92mcmd2:\u001b[0m Using cached jupyterlab_widgets-3.0.16-py3-none-any.whl (914 kB)\n",
      "\u001b[92mcmd2:\u001b[0m Using cached widgetsnbextension-4.0.15-py3-none-any.whl (2.2 MB)\n",
      "\u001b[92mcmd2:\u001b[0m Using cached jupyter_console-6.6.3-py3-none-any.whl (24 kB)\n",
      "\u001b[92mcmd2:\u001b[0m Using cached jupyterlab-4.5.1-py3-none-any.whl (12.4 MB)\n",
      "\u001b[92mcmd2:\u001b[0m Using cached httpx-0.28.1-py3-none-any.whl (73 kB)\n",
      "\u001b[92mcmd2:\u001b[0m Using cached httpcore-1.0.9-py3-none-any.whl (78 kB)\n",
      "\u001b[92mcmd2:\u001b[0m Using cached jupyter_server-2.17.0-py3-none-any.whl (388 kB)\n",
      "\u001b[92mcmd2:\u001b[0m Using cached jupyterlab_server-2.28.0-py3-none-any.whl (59 kB)\n",
      "\u001b[92mcmd2:\u001b[0m Using cached anyio-4.12.0-py3-none-any.whl (113 kB)\n",
      "\u001b[92mcmd2:\u001b[0m Using cached argon2_cffi-25.1.0-py3-none-any.whl (14 kB)\n",
      "\u001b[92mcmd2:\u001b[0m Using cached async_lru-2.0.5-py3-none-any.whl (6.1 kB)\n",
      "\u001b[92mcmd2:\u001b[0m Using cached babel-2.17.0-py3-none-any.whl (10.2 MB)\n",
      "\u001b[92mcmd2:\u001b[0m Using cached h11-0.16.0-py3-none-any.whl (37 kB)\n",
      "\u001b[92mcmd2:\u001b[0m Using cached idna-3.11-py3-none-any.whl (71 kB)\n",
      "\u001b[92mcmd2:\u001b[0m Using cached json5-0.12.1-py3-none-any.whl (36 kB)\n",
      "\u001b[92mcmd2:\u001b[0m Using cached jsonschema-4.25.1-py3-none-any.whl (90 kB)\n",
      "\u001b[92mcmd2:\u001b[0m Using cached attrs-25.4.0-py3-none-any.whl (67 kB)\n",
      "\u001b[92mcmd2:\u001b[0m Using cached jsonschema_specifications-2025.9.1-py3-none-any.whl (18 kB)\n",
      "\u001b[92mcmd2:\u001b[0m Using cached jupyter_events-0.12.0-py3-none-any.whl (19 kB)\n",
      "\u001b[92mcmd2:\u001b[0m Using cached jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
      "\u001b[92mcmd2:\u001b[0m Using cached jupyter_lsp-2.3.0-py3-none-any.whl (76 kB)\n",
      "\u001b[92mcmd2:\u001b[0m Using cached jupyter_server_terminals-0.5.3-py3-none-any.whl (13 kB)\n",
      "\u001b[92mcmd2:\u001b[0m Using cached nbconvert-7.16.6-py3-none-any.whl (258 kB)\n",
      "\u001b[92mcmd2:\u001b[0m Using cached mistune-3.2.0-py3-none-any.whl (53 kB)\n",
      "\u001b[92mcmd2:\u001b[0m Downloading bleach-6.3.0-py3-none-any.whl (164 kB)\n",
      "\u001b[92mcmd2:\u001b[0m Using cached tinycss2-1.4.0-py3-none-any.whl (26 kB)\n",
      "\u001b[92mcmd2:\u001b[0m Downloading nbclient-0.10.4-py3-none-any.whl (25 kB)\n",
      "\u001b[92mcmd2:\u001b[0m Using cached nbformat-5.10.4-py3-none-any.whl (78 kB)\n",
      "\u001b[92mcmd2:\u001b[0m Using cached fastjsonschema-2.21.2-py3-none-any.whl (24 kB)\n",
      "\u001b[92mcmd2:\u001b[0m Using cached notebook_shim-0.2.4-py3-none-any.whl (13 kB)\n",
      "\u001b[92mcmd2:\u001b[0m Using cached overrides-7.7.0-py3-none-any.whl (17 kB)\n",
      "\u001b[92mcmd2:\u001b[0m Using cached pandocfilters-1.5.1-py2.py3-none-any.whl (8.7 kB)\n",
      "\u001b[92mcmd2:\u001b[0m Using cached prometheus_client-0.23.1-py3-none-any.whl (61 kB)\n",
      "\u001b[92mcmd2:\u001b[0m Using cached python_json_logger-4.0.0-py3-none-any.whl (15 kB)\n",
      "\u001b[92mcmd2:\u001b[0m Downloading referencing-0.37.0-py3-none-any.whl (26 kB)\n",
      "\u001b[92mcmd2:\u001b[0m Using cached requests-2.32.5-py3-none-any.whl (64 kB)\n",
      "\u001b[92mcmd2:\u001b[0m Downloading charset_normalizer-3.4.4-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (153 kB)\n",
      "\u001b[92mcmd2:\u001b[0m Using cached urllib3-2.6.2-py3-none-any.whl (131 kB)\n",
      "\u001b[92mcmd2:\u001b[0m Using cached certifi-2025.11.12-py3-none-any.whl (159 kB)\n",
      "\u001b[92mcmd2:\u001b[0m Using cached rfc3986_validator-0.1.1-py2.py3-none-any.whl (4.2 kB)\n",
      "\u001b[92mcmd2:\u001b[0m Using cached rfc3987_syntax-1.1.0-py3-none-any.whl (8.0 kB)\n",
      "\u001b[92mcmd2:\u001b[0m Using cached lark-1.3.1-py3-none-any.whl (113 kB)\n",
      "\u001b[92mcmd2:\u001b[0m Downloading rpds_py-0.30.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (390 kB)\n",
      "\u001b[92mcmd2:\u001b[0m Using cached Send2Trash-1.8.3-py3-none-any.whl (18 kB)\n",
      "\u001b[92mcmd2:\u001b[0m Using cached terminado-0.18.1-py3-none-any.whl (14 kB)\n",
      "\u001b[92mcmd2:\u001b[0m Using cached tomli-2.3.0-py3-none-any.whl (14 kB)\n",
      "\u001b[92mcmd2:\u001b[0m Downloading webcolors-25.10.0-py3-none-any.whl (14 kB)\n",
      "\u001b[92mcmd2:\u001b[0m Using cached webencodings-0.5.1-py2.py3-none-any.whl (11 kB)\n",
      "\u001b[92mcmd2:\u001b[0m Using cached websocket_client-1.9.0-py3-none-any.whl (82 kB)\n",
      "\u001b[92mcmd2:\u001b[0m Using cached argon2_cffi_bindings-25.1.0-cp39-abi3-manylinux_2_26_x86_64.manylinux_2_28_x86_64.whl (87 kB)\n",
      "\u001b[92mcmd2:\u001b[0m Downloading cffi-2.0.0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (216 kB)\n",
      "\u001b[92mcmd2:\u001b[0m Using cached beautifulsoup4-4.14.3-py3-none-any.whl (107 kB)\n",
      "\u001b[92mcmd2:\u001b[0m Using cached soupsieve-2.8.1-py3-none-any.whl (36 kB)\n",
      "\u001b[92mcmd2:\u001b[0m Using cached defusedxml-0.7.1-py2.py3-none-any.whl (25 kB)\n",
      "\u001b[92mcmd2:\u001b[0m Using cached fqdn-1.5.1-py3-none-any.whl (9.1 kB)\n",
      "\u001b[92mcmd2:\u001b[0m Using cached isoduration-20.11.0-py3-none-any.whl (11 kB)\n",
      "\u001b[92mcmd2:\u001b[0m Using cached arrow-1.4.0-py3-none-any.whl (68 kB)\n",
      "\u001b[92mcmd2:\u001b[0m Using cached jupyterlab_pygments-0.3.0-py3-none-any.whl (15 kB)\n",
      "\u001b[92mcmd2:\u001b[0m Using cached notebook-7.5.1-py3-none-any.whl (14.5 MB)\n",
      "\u001b[92mcmd2:\u001b[0m Using cached pycparser-2.23-py3-none-any.whl (118 kB)\n",
      "\u001b[92mcmd2:\u001b[0m Using cached rfc3339_validator-0.1.4-py2.py3-none-any.whl (3.5 kB)\n",
      "\u001b[92mcmd2:\u001b[0m Using cached stack_data-0.6.3-py3-none-any.whl (24 kB)\n",
      "\u001b[92mcmd2:\u001b[0m Using cached asttokens-3.0.1-py3-none-any.whl (27 kB)\n",
      "\u001b[92mcmd2:\u001b[0m Using cached executing-2.2.1-py2.py3-none-any.whl (28 kB)\n",
      "\u001b[92mcmd2:\u001b[0m Using cached pure_eval-0.2.3-py3-none-any.whl (11 kB)\n",
      "\u001b[92mcmd2:\u001b[0m Using cached uri_template-1.3.0-py3-none-any.whl (11 kB)\n",
      "\u001b[92mcmd2:\u001b[0m Using cached wcwidth-0.2.14-py2.py3-none-any.whl (37 kB)\n",
      "\u001b[92mcmd2:\u001b[0m Building wheels for collected packages: nejm_b2txt_utils, antlr4-python3-runtime, distance\n",
      "\u001b[92mcmd2:\u001b[0m   Building editable for nejm_b2txt_utils (pyproject.toml): started\n",
      "\u001b[92mcmd2:\u001b[0m   Building editable for nejm_b2txt_utils (pyproject.toml): finished with status 'done'\n",
      "\u001b[92mcmd2:\u001b[0m   Created wheel for nejm_b2txt_utils: filename=nejm_b2txt_utils-0.0.0-0.editable-py3-none-any.whl size=2759 sha256=41ececdc80a5060b2ed8dbfa103b952abd3f3cd74023d17118994406e0abf49b\n",
      "\u001b[92mcmd2:\u001b[0m   Stored in directory: /tmp/pip-ephem-wheel-cache-pgybrkqj/wheels/f1/bb/ed/4c4e219a40e20301249801636520e56cac16d086b1b99a89cd\n",
      "\u001b[92mcmd2:\u001b[0m   Building wheel for antlr4-python3-runtime (pyproject.toml): started\n",
      "\u001b[92mcmd2:\u001b[0m   Building wheel for antlr4-python3-runtime (pyproject.toml): finished with status 'done'\n",
      "\u001b[92mcmd2:\u001b[0m   Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144591 sha256=f870527a8801f35a5db2f80473191a00aae60fcabfc26f84ccd98ae2fd307e7f\n",
      "\u001b[92mcmd2:\u001b[0m   Stored in directory: /root/.cache/pip/wheels/12/93/dd/1f6a127edc45659556564c5730f6d4e300888f4bca2d4c5a88\n",
      "\u001b[92mcmd2:\u001b[0m   Building wheel for distance (pyproject.toml): started\n",
      "\u001b[92mcmd2:\u001b[0m   Building wheel for distance (pyproject.toml): finished with status 'done'\n",
      "\u001b[92mcmd2:\u001b[0m   Created wheel for distance: filename=distance-0.1.3-py3-none-any.whl size=16321 sha256=8920ac90fac8e87fc39ce075c91b00bbc388e1c63003f6b14772af6d96034212\n",
      "\u001b[92mcmd2:\u001b[0m   Stored in directory: /root/.cache/pip/wheels/e8/bb/de/f71bf63559ea9a921059a5405806f7ff6ed612a9231c4a9309\n",
      "\u001b[92mcmd2:\u001b[0m Successfully built nejm_b2txt_utils antlr4-python3-runtime distance\n",
      "\u001b[92mcmd2:\u001b[0m Installing collected packages: webencodings, pytz, pure-eval, ptyprocess, nejm_b2txt_utils, fastjsonschema, distance, antlr4-python3-runtime, widgetsnbextension, websocket-client, webcolors, wcwidth, urllib3, uri-template, tzdata, typeguard, traitlets, tqdm, tornado, tomli, tinycss2, threadpoolctl, soupsieve, six, send2trash, safetensors, rpds-py, rfc3986-validator, regex, pyzmq, PyYAML, python-json-logger, pyparsing, pygments, pycparser, psutil, prometheus-client, platformdirs, pexpect, parso, pandocfilters, packaging, overrides, numpy, nest-asyncio, more_itertools, mistune, lark, kiwisolver, jupyterlab_widgets, jupyterlab-pygments, jsonpointer, json5, joblib, idna, hf-xet, h11, fqdn, fonttools, executing, exceptiongroup, editdistance, defusedxml, decorator, debugpy, cycler, comm, click, charset_normalizer, certifi, bleach, babel, attrs, async-timeout, async-lru, asttokens, terminado, stack_data, scipy, rfc3987-syntax, rfc3339-validator, requests, referencing, redis, python-dateutil, prompt_toolkit, omegaconf, nltk, matplotlib-inline, jupyter-core, jedi, inflect, httpcore, h5py, contourpy, cffi, beautifulsoup4, anyio, scikit-learn, pandas, matplotlib, jupyter-server-terminals, jupyter-client, jsonschema-specifications, ipython, huggingface-hub, httpx, g2p_en, arrow, argon2-cffi-bindings, tokenizers, jsonschema, isoduration, ipywidgets, ipykernel, bitsandbytes, argon2-cffi, accelerate, transformers, nbformat, jupyter-console, nbclient, jupyter-events, nbconvert, jupyter-server, notebook-shim, jupyterlab-server, jupyter-lsp, jupyterlab, notebook, jupyter\n",
      "\u001b[92mcmd2:\u001b[0m   Attempting uninstall: numpy\n",
      "\u001b[92mcmd2:\u001b[0m     Found existing installation: numpy 2.2.6\n",
      "\u001b[92mcmd2:\u001b[0m     Uninstalling numpy-2.2.6:\n",
      "\u001b[92mcmd2:\u001b[0m       Successfully uninstalled numpy-2.2.6\n",
      "\u001b[94mcmd1:\u001b[0m \n",
      "\u001b[94mcmd1:\u001b[0m Successfully installed MarkupSafe-3.0.3 PyYAML-6.0.3 accelerate-0.33.0 antlr4-python3-runtime-4.9.3 anyio-4.12.0 argon2-cffi-25.1.0 argon2-cffi-bindings-25.1.0 arrow-1.4.0 asttokens-3.0.1 async-lru-2.0.5 async-timeout-5.0.1 attrs-25.4.0 babel-2.17.0 beautifulsoup4-4.14.3 bitsandbytes-0.41.1 bleach-6.2.0 certifi-2025.11.12 cffi-2.0.0 charset_normalizer-3.4.4 click-8.1.8 comm-0.2.3 contourpy-1.3.0 cycler-0.12.1 debugpy-1.8.19 decorator-5.2.1 defusedxml-0.7.1 distance-0.1.3 exceptiongroup-1.3.1 executing-2.2.1 fastjsonschema-2.21.2 filelock-3.19.1 fonttools-4.60.2 fqdn-1.5.1 fsspec-2025.10.0 g2p_en-2.1.0 h11-0.16.0 httpcore-1.0.9 httpx-0.28.1 huggingface-hub-0.23.4 idna-3.11 importlib-resources-6.5.2 importlib_metadata-8.7.1 inflect-7.5.0 ipykernel-6.31.0 ipython-8.18.1 ipywidgets-8.1.8 isoduration-20.11.0 jedi-0.19.2 jinja2-3.1.6 joblib-1.5.3 json5-0.12.1 jsonpointer-3.0.0 jsonschema-4.25.1 jsonschema-specifications-2025.9.1 jupyter-1.1.1 jupyter-client-8.6.3 jupyter-console-6.6.3 jupyter-core-5.8.1 jupyter-events-0.12.0 jupyter-lsp-2.3.0 jupyter-server-2.17.0 jupyter-server-terminals-0.5.3 jupyterlab-4.5.1 jupyterlab-pygments-0.3.0 jupyterlab-server-2.28.0 jupyterlab_widgets-3.0.16 kiwisolver-1.4.7 lark-1.3.1 matplotlib-3.9.0 matplotlib-inline-0.2.1 mistune-3.2.0 more_itertools-10.8.0 nbclient-0.10.2 nbconvert-7.16.6 nbformat-5.10.4 nest-asyncio-1.6.0 nltk-3.9.2 notebook-7.5.1 notebook-shim-0.2.4 numpy-1.24.4 nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 omegaconf-2.3.0 overrides-7.7.0 packaging-25.0 pandocfilters-1.5.1 parso-0.8.5 pexpect-4.9.0 pillow-11.3.0 platformdirs-4.4.0 prometheus-client-0.23.1 prompt-toolkit-3.0.52 psutil-7.2.0 ptyprocess-0.7.0 pure-eval-0.2.3 pycparser-2.23 pygments-2.19.2 pyparsing-3.3.1 python-dateutil-2.9.0.post0 python-json-logger-4.0.0 pyzmq-27.1.0 redis-5.0.6 referencing-0.36.2 regex-2025.11.3 requests-2.32.5 rfc3339-validator-0.1.4 rfc3986-validator-0.1.1 rfc3987-syntax-1.1.0 rpds-py-0.27.1 safetensors-0.7.0 scikit-learn-1.6.1 scipy-1.11.1 send2trash-1.8.3 six-1.17.0 soupsieve-2.8.1 stack-data-0.6.3 terminado-0.18.1 threadpoolctl-3.6.0 tinycss2-1.4.0 tokenizers-0.19.1 tomli-2.3.0 torch-1.13.1 tornado-6.5.4 tqdm-4.66.4 traitlets-5.14.3 transformers-4.40.0 typeguard-4.4.4 typing-extensions-4.15.0 tzdata-2025.3 uri-template-1.3.0 urllib3-2.6.2 wcwidth-0.2.14 webcolors-24.11.1 webencodings-0.5.1 websocket-client-1.9.0 widgetsnbextension-4.0.15 zipp-3.23.0\n",
      "\u001b[94mcmd1:\u001b[0m running install\n",
      "\u001b[94mcmd1:\u001b[0m /root/miniconda3/envs/b2txt25_lm/lib/python3.9/site-packages/setuptools/_distutils/cmd.py:90: SetuptoolsDeprecationWarning: setup.py install is deprecated.\n",
      "\u001b[94mcmd1:\u001b[0m !!\n",
      "\u001b[94mcmd1:\u001b[0m \n",
      "\u001b[94mcmd1:\u001b[0m         ********************************************************************************\n",
      "\u001b[94mcmd1:\u001b[0m         Please avoid running ``setup.py`` directly.\n",
      "\u001b[94mcmd1:\u001b[0m         Instead, use pypa/build, pypa/installer or other\n",
      "\u001b[94mcmd1:\u001b[0m         standards-based tools.\n",
      "\u001b[94mcmd1:\u001b[0m \n",
      "\u001b[94mcmd1:\u001b[0m         This deprecation is overdue, please update your project and remove deprecated\n",
      "\u001b[94mcmd1:\u001b[0m         calls to avoid build errors in the future.\n",
      "\u001b[94mcmd1:\u001b[0m \n",
      "\u001b[94mcmd1:\u001b[0m         See https://blog.ganssle.io/articles/2021/10/setup-py-deprecated.html for details.\n",
      "\u001b[94mcmd1:\u001b[0m         ********************************************************************************\n",
      "\u001b[94mcmd1:\u001b[0m \n",
      "\u001b[94mcmd1:\u001b[0m !!\n",
      "\u001b[94mcmd1:\u001b[0m   self.initialize_options()\n",
      "\u001b[94mcmd1:\u001b[0m running build\n",
      "\u001b[94mcmd1:\u001b[0m running build_ext\n",
      "\u001b[94mcmd1:\u001b[0m -- The C compiler identification is GNU 11.4.0\n",
      "\u001b[94mcmd1:\u001b[0m -- The CXX compiler identification is GNU 11.4.0\n",
      "\u001b[94mcmd1:\u001b[0m -- Detecting C compiler ABI info\n",
      "\u001b[94mcmd1:\u001b[0m -- Detecting C compiler ABI info - done\n",
      "\u001b[94mcmd1:\u001b[0m -- Check for working C compiler: /usr/bin/cc - skipped\n",
      "\u001b[94mcmd1:\u001b[0m -- Detecting C compile features\n",
      "\u001b[94mcmd1:\u001b[0m -- Detecting C compile features - done\n",
      "\u001b[94mcmd1:\u001b[0m -- Detecting CXX compiler ABI info\n",
      "\u001b[94mcmd1:\u001b[0m -- Detecting CXX compiler ABI info - done\n",
      "\u001b[94mcmd1:\u001b[0m -- Check for working CXX compiler: /usr/bin/c++ - skipped\n",
      "\u001b[94mcmd1:\u001b[0m -- Detecting CXX compile features\n",
      "\u001b[94mcmd1:\u001b[0m -- Detecting CXX compile features - done\n",
      "\u001b[94mcmd1:\u001b[0m CMake Warning (dev) at /usr/local/lib/python3.11/dist-packages/cmake/data/share/cmake-3.31/Modules/FetchContent.cmake:1373 (message):\n",
      "\u001b[94mcmd1:\u001b[0m   The DOWNLOAD_EXTRACT_TIMESTAMP option was not given and policy CMP0135 is\n",
      "\u001b[94mcmd1:\u001b[0m   not set.  The policy's OLD behavior will be used.  When using a URL\n",
      "\u001b[94mcmd1:\u001b[0m   download, the timestamps of extracted files should preferably be that of\n",
      "\u001b[94mcmd1:\u001b[0m   the time of extraction, otherwise code that depends on the extracted\n",
      "\u001b[94mcmd1:\u001b[0m   contents might not be rebuilt if the URL changes.  The OLD behavior\n",
      "\u001b[94mcmd1:\u001b[0m   preserves the timestamps from the archive instead, but this is usually not\n",
      "\u001b[94mcmd1:\u001b[0m   what you want.  Update your project to the NEW behavior or specify the\n",
      "\u001b[94mcmd1:\u001b[0m   DOWNLOAD_EXTRACT_TIMESTAMP option with a value of true to avoid this\n",
      "\u001b[94mcmd1:\u001b[0m   robustness issue.\n",
      "\u001b[94mcmd1:\u001b[0m Call Stack (most recent call first):\n",
      "\u001b[94mcmd1:\u001b[0m   CMakeLists.txt:33 (FetchContent_Declare)\n",
      "\u001b[94mcmd1:\u001b[0m This warning is for project developers.  Use -Wno-dev to suppress it.\n",
      "\u001b[94mcmd1:\u001b[0m \n",
      "\u001b[94mcmd1:\u001b[0m -- Populating gflags\n",
      "\u001b[94mcmd1:\u001b[0m -- Configuring done (0.0s)\n",
      "\u001b[94mcmd1:\u001b[0m -- Generating done (0.0s)\n",
      "\u001b[94mcmd1:\u001b[0m -- Build files have been written to: /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-subbuild\n",
      "\u001b[94mcmd1:\u001b[0m [ 11%] Creating directories for 'gflags-populate'\n",
      "\u001b[94mcmd1:\u001b[0m [ 22%] Performing download step (download, verify and extract) for 'gflags-populate'\n",
      "\u001b[94mcmd1:\u001b[0m -- Downloading...\n",
      "\u001b[94mcmd1:\u001b[0m    dst='/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-subbuild/gflags-populate-prefix/src/v2.2.1.zip'\n",
      "\u001b[94mcmd1:\u001b[0m    timeout='none'\n",
      "\u001b[94mcmd1:\u001b[0m    inactivity timeout='none'\n",
      "\u001b[94mcmd1:\u001b[0m -- Using src='https://github.com/gflags/gflags/archive/v2.2.1.zip'\n",
      "\u001b[94mcmd1:\u001b[0m -- verifying file...\n",
      "\u001b[94mcmd1:\u001b[0m        file='/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-subbuild/gflags-populate-prefix/src/v2.2.1.zip'\n",
      "\u001b[94mcmd1:\u001b[0m -- Downloading... done\n",
      "\u001b[94mcmd1:\u001b[0m -- extracting...\n",
      "\u001b[94mcmd1:\u001b[0m      src='/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-subbuild/gflags-populate-prefix/src/v2.2.1.zip'\n",
      "\u001b[94mcmd1:\u001b[0m      dst='/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-src'\n",
      "\u001b[94mcmd1:\u001b[0m -- extracting... [tar xfz]\n",
      "\u001b[94mcmd1:\u001b[0m -- extracting... [analysis]\n",
      "\u001b[94mcmd1:\u001b[0m -- extracting... [rename]\n",
      "\u001b[94mcmd1:\u001b[0m -- extracting... [clean up]\n",
      "\u001b[94mcmd1:\u001b[0m -- extracting... done\n",
      "\u001b[94mcmd1:\u001b[0m [ 33%] No update step for 'gflags-populate'\n",
      "\u001b[94mcmd1:\u001b[0m [ 44%] No patch step for 'gflags-populate'\n",
      "\u001b[94mcmd1:\u001b[0m [ 55%] No configure step for 'gflags-populate'\n",
      "\u001b[94mcmd1:\u001b[0m [ 66%] No build step for 'gflags-populate'\n",
      "\u001b[94mcmd1:\u001b[0m [ 77%] No install step for 'gflags-populate'\n",
      "\u001b[94mcmd1:\u001b[0m [ 88%] No test step for 'gflags-populate'\n",
      "\u001b[94mcmd1:\u001b[0m [100%] Completed 'gflags-populate'\n",
      "\u001b[94mcmd1:\u001b[0m [100%] Built target gflags-populate\n",
      "\u001b[94mcmd1:\u001b[0m CMake Deprecation Warning at fc_base/gflags-src/CMakeLists.txt:73 (cmake_minimum_required):\n",
      "\u001b[94mcmd1:\u001b[0m   Compatibility with CMake < 3.10 will be removed from a future version of\n",
      "\u001b[94mcmd1:\u001b[0m   CMake.\n",
      "\u001b[94mcmd1:\u001b[0m \n",
      "\u001b[94mcmd1:\u001b[0m   Update the VERSION argument <min> value.  Or, use the <min>...<max> syntax\n",
      "\u001b[94mcmd1:\u001b[0m   to tell CMake that the project requires at least <min> but has been updated\n",
      "\u001b[94mcmd1:\u001b[0m   to work with policies introduced by <max> or earlier.\n",
      "\u001b[94mcmd1:\u001b[0m \n",
      "\u001b[94mcmd1:\u001b[0m \n",
      "\u001b[94mcmd1:\u001b[0m CMake Warning (dev) at fc_base/gflags-src/CMakeLists.txt:93 (project):\n",
      "\u001b[94mcmd1:\u001b[0m   Policy CMP0048 is not set: project() command manages VERSION variables.\n",
      "\u001b[94mcmd1:\u001b[0m   Run \"cmake --help-policy CMP0048\" for policy details.  Use the cmake_policy\n",
      "\u001b[94mcmd1:\u001b[0m   command to set the policy and suppress this warning.\n",
      "\u001b[94mcmd1:\u001b[0m \n",
      "\u001b[94mcmd1:\u001b[0m   The following variable(s) would be set to empty:\n",
      "\u001b[94mcmd1:\u001b[0m \n",
      "\u001b[94mcmd1:\u001b[0m     PROJECT_VERSION\n",
      "\u001b[94mcmd1:\u001b[0m     PROJECT_VERSION_MAJOR\n",
      "\u001b[94mcmd1:\u001b[0m     PROJECT_VERSION_MINOR\n",
      "\u001b[94mcmd1:\u001b[0m This warning is for project developers.  Use -Wno-dev to suppress it.\n",
      "\u001b[94mcmd1:\u001b[0m \n",
      "\u001b[94mcmd1:\u001b[0m -- Looking for C++ include unistd.h\n",
      "\u001b[94mcmd1:\u001b[0m -- Looking for C++ include unistd.h - found\n",
      "\u001b[94mcmd1:\u001b[0m -- Looking for C++ include stdint.h\n",
      "\u001b[94mcmd1:\u001b[0m -- Looking for C++ include stdint.h - found\n",
      "\u001b[94mcmd1:\u001b[0m -- Looking for C++ include inttypes.h\n",
      "\u001b[94mcmd1:\u001b[0m -- Looking for C++ include inttypes.h - found\n",
      "\u001b[94mcmd1:\u001b[0m -- Looking for C++ include sys/types.h\n",
      "\u001b[94mcmd1:\u001b[0m -- Looking for C++ include sys/types.h - found\n",
      "\u001b[94mcmd1:\u001b[0m -- Looking for C++ include sys/stat.h\n",
      "\u001b[94mcmd1:\u001b[0m -- Looking for C++ include sys/stat.h - found\n",
      "\u001b[94mcmd1:\u001b[0m -- Looking for C++ include fnmatch.h\n",
      "\u001b[94mcmd1:\u001b[0m -- Looking for C++ include fnmatch.h - found\n",
      "\u001b[94mcmd1:\u001b[0m -- Looking for C++ include stddef.h\n",
      "\u001b[94mcmd1:\u001b[0m -- Looking for C++ include stddef.h - found\n",
      "\u001b[94mcmd1:\u001b[0m -- Check size of uint32_t\n",
      "\u001b[94mcmd1:\u001b[0m -- Check size of uint32_t - done\n",
      "\u001b[94mcmd1:\u001b[0m -- Looking for strtoll\n",
      "\u001b[94mcmd1:\u001b[0m -- Looking for strtoll - found\n",
      "\u001b[94mcmd1:\u001b[0m CMake Warning (dev) at /usr/local/lib/python3.11/dist-packages/cmake/data/share/cmake-3.31/Modules/FetchContent.cmake:1373 (message):\n",
      "\u001b[94mcmd1:\u001b[0m   The DOWNLOAD_EXTRACT_TIMESTAMP option was not given and policy CMP0135 is\n",
      "\u001b[94mcmd1:\u001b[0m   not set.  The policy's OLD behavior will be used.  When using a URL\n",
      "\u001b[94mcmd1:\u001b[0m   download, the timestamps of extracted files should preferably be that of\n",
      "\u001b[94mcmd1:\u001b[0m   the time of extraction, otherwise code that depends on the extracted\n",
      "\u001b[94mcmd1:\u001b[0m   contents might not be rebuilt if the URL changes.  The OLD behavior\n",
      "\u001b[94mcmd1:\u001b[0m   preserves the timestamps from the archive instead, but this is usually not\n",
      "\u001b[94mcmd1:\u001b[0m   what you want.  Update your project to the NEW behavior or specify the\n",
      "\u001b[94mcmd1:\u001b[0m   DOWNLOAD_EXTRACT_TIMESTAMP option with a value of true to avoid this\n",
      "\u001b[94mcmd1:\u001b[0m   robustness issue.\n",
      "\u001b[94mcmd1:\u001b[0m Call Stack (most recent call first):\n",
      "\u001b[94mcmd1:\u001b[0m   CMakeLists.txt:41 (FetchContent_Declare)\n",
      "\u001b[94mcmd1:\u001b[0m This warning is for project developers.  Use -Wno-dev to suppress it.\n",
      "\u001b[94mcmd1:\u001b[0m \n",
      "\u001b[94mcmd1:\u001b[0m -- Populating glog\n",
      "\u001b[94mcmd1:\u001b[0m -- Configuring done (0.0s)\n",
      "\u001b[94mcmd1:\u001b[0m -- Generating done (0.0s)\n",
      "\u001b[94mcmd1:\u001b[0m -- Build files have been written to: /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-subbuild\n",
      "\u001b[94mcmd1:\u001b[0m [ 11%] Creating directories for 'glog-populate'\n",
      "\u001b[94mcmd1:\u001b[0m [ 22%] Performing download step (download, verify and extract) for 'glog-populate'\n",
      "\u001b[94mcmd1:\u001b[0m -- Downloading...\n",
      "\u001b[94mcmd1:\u001b[0m    dst='/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-subbuild/glog-populate-prefix/src/v0.4.0.zip'\n",
      "\u001b[94mcmd1:\u001b[0m    timeout='none'\n",
      "\u001b[94mcmd1:\u001b[0m    inactivity timeout='none'\n",
      "\u001b[94mcmd1:\u001b[0m -- Using src='https://github.com/google/glog/archive/v0.4.0.zip'\n",
      "\u001b[94mcmd1:\u001b[0m -- verifying file...\n",
      "\u001b[94mcmd1:\u001b[0m        file='/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-subbuild/glog-populate-prefix/src/v0.4.0.zip'\n",
      "\u001b[94mcmd1:\u001b[0m -- Downloading... done\n",
      "\u001b[94mcmd1:\u001b[0m -- extracting...\n",
      "\u001b[94mcmd1:\u001b[0m      src='/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-subbuild/glog-populate-prefix/src/v0.4.0.zip'\n",
      "\u001b[94mcmd1:\u001b[0m      dst='/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src'\n",
      "\u001b[94mcmd1:\u001b[0m -- extracting... [tar xfz]\n",
      "\u001b[94mcmd1:\u001b[0m -- extracting... [analysis]\n",
      "\u001b[94mcmd1:\u001b[0m -- extracting... [rename]\n",
      "\u001b[94mcmd1:\u001b[0m -- extracting... [clean up]\n",
      "\u001b[94mcmd1:\u001b[0m -- extracting... done\n",
      "\u001b[94mcmd1:\u001b[0m [ 33%] No update step for 'glog-populate'\n",
      "\u001b[94mcmd1:\u001b[0m [ 44%] No patch step for 'glog-populate'\n",
      "\u001b[94mcmd1:\u001b[0m [ 55%] No configure step for 'glog-populate'\n",
      "\u001b[94mcmd1:\u001b[0m [ 66%] No build step for 'glog-populate'\n",
      "\u001b[94mcmd1:\u001b[0m [ 77%] No install step for 'glog-populate'\n",
      "\u001b[94mcmd1:\u001b[0m [ 88%] No test step for 'glog-populate'\n",
      "\u001b[94mcmd1:\u001b[0m [100%] Completed 'glog-populate'\n",
      "\u001b[94mcmd1:\u001b[0m [100%] Built target glog-populate\n",
      "\u001b[94mcmd1:\u001b[0m CMake Deprecation Warning at fc_base/glog-src/CMakeLists.txt:1 (cmake_minimum_required):\n",
      "\u001b[94mcmd1:\u001b[0m   Compatibility with CMake < 3.10 will be removed from a future version of\n",
      "\u001b[94mcmd1:\u001b[0m   CMake.\n",
      "\u001b[94mcmd1:\u001b[0m \n",
      "\u001b[94mcmd1:\u001b[0m   Update the VERSION argument <min> value.  Or, use the <min>...<max> syntax\n",
      "\u001b[94mcmd1:\u001b[0m   to tell CMake that the project requires at least <min> but has been updated\n",
      "\u001b[94mcmd1:\u001b[0m   to work with policies introduced by <max> or earlier.\n",
      "\u001b[94mcmd1:\u001b[0m \n",
      "\u001b[94mcmd1:\u001b[0m \n",
      "\u001b[94mcmd1:\u001b[0m CMake Warning at fc_base/glog-src/CMakeLists.txt:51 (find_package):\n",
      "\u001b[94mcmd1:\u001b[0m   By not providing \"Findgflags.cmake\" in CMAKE_MODULE_PATH this project has\n",
      "\u001b[94mcmd1:\u001b[0m   asked CMake to find a package configuration file provided by \"gflags\", but\n",
      "\u001b[94mcmd1:\u001b[0m   CMake did not find one.\n",
      "\u001b[94mcmd1:\u001b[0m \n",
      "\u001b[94mcmd1:\u001b[0m   Could not find a package configuration file provided by \"gflags\" (requested\n",
      "\u001b[94mcmd1:\u001b[0m   version 2.2.0) with any of the following names:\n",
      "\u001b[94mcmd1:\u001b[0m \n",
      "\u001b[94mcmd1:\u001b[0m     gflagsConfig.cmake\n",
      "\u001b[94mcmd1:\u001b[0m     gflags-config.cmake\n",
      "\u001b[94mcmd1:\u001b[0m \n",
      "\u001b[94mcmd1:\u001b[0m   Add the installation prefix of \"gflags\" to CMAKE_PREFIX_PATH or set\n",
      "\u001b[94mcmd1:\u001b[0m   \"gflags_DIR\" to a directory containing one of the above files.  If \"gflags\"\n",
      "\u001b[94mcmd1:\u001b[0m   provides a separate development package or SDK, be sure it has been\n",
      "\u001b[94mcmd1:\u001b[0m   installed.\n",
      "\u001b[94mcmd1:\u001b[0m \n",
      "\u001b[94mcmd1:\u001b[0m \n",
      "\u001b[94mcmd1:\u001b[0m -- Performing Test CMAKE_HAVE_LIBC_PTHREAD\n",
      "\u001b[94mcmd1:\u001b[0m -- Performing Test CMAKE_HAVE_LIBC_PTHREAD - Success\n",
      "\u001b[94mcmd1:\u001b[0m -- Found Threads: TRUE\n",
      "\u001b[94mcmd1:\u001b[0m -- Looking for dlfcn.h\n",
      "\u001b[94mcmd1:\u001b[0m -- Looking for dlfcn.h - found\n",
      "\u001b[94mcmd1:\u001b[0m -- Looking for execinfo.h\n",
      "\u001b[94mcmd1:\u001b[0m -- Looking for execinfo.h - found\n",
      "\u001b[94mcmd1:\u001b[0m -- Looking for glob.h\n",
      "\u001b[94mcmd1:\u001b[0m -- Looking for glob.h - found\n",
      "\u001b[94mcmd1:\u001b[0m -- Looking for libunwind.h\n",
      "\u001b[94mcmd1:\u001b[0m -- Looking for libunwind.h - not found\n",
      "\u001b[94mcmd1:\u001b[0m -- Looking for memory.h\n",
      "\u001b[94mcmd1:\u001b[0m -- Looking for memory.h - found\n",
      "\u001b[94mcmd1:\u001b[0m -- Looking for pwd.h\n",
      "\u001b[94mcmd1:\u001b[0m -- Looking for pwd.h - found\n",
      "\u001b[94mcmd1:\u001b[0m -- Looking for stdlib.h\n",
      "\u001b[94mcmd1:\u001b[0m -- Looking for stdlib.h - found\n",
      "\u001b[94mcmd1:\u001b[0m -- Looking for string.h\n",
      "\u001b[94mcmd1:\u001b[0m -- Looking for string.h - found\n",
      "\u001b[94mcmd1:\u001b[0m -- Looking for strings.h\n",
      "\u001b[94mcmd1:\u001b[0m -- Looking for strings.h - found\n",
      "\u001b[94mcmd1:\u001b[0m -- Looking for sys/syscall.h\n",
      "\u001b[94mcmd1:\u001b[0m -- Looking for sys/syscall.h - found\n",
      "\u001b[94mcmd1:\u001b[0m -- Looking for sys/time.h\n",
      "\u001b[94mcmd1:\u001b[0m -- Looking for sys/time.h - found\n",
      "\u001b[94mcmd1:\u001b[0m -- Looking for sys/utsname.h\n",
      "\u001b[94mcmd1:\u001b[0m -- Looking for sys/utsname.h - found\n",
      "\u001b[94mcmd1:\u001b[0m -- Looking for syscall.h\n",
      "\u001b[94mcmd1:\u001b[0m -- Looking for syscall.h - found\n",
      "\u001b[94mcmd1:\u001b[0m -- Looking for syslog.h\n",
      "\u001b[94mcmd1:\u001b[0m -- Looking for syslog.h - found\n",
      "\u001b[94mcmd1:\u001b[0m -- Looking for ucontext.h\n",
      "\u001b[94mcmd1:\u001b[0m -- Looking for ucontext.h - found\n",
      "\u001b[94mcmd1:\u001b[0m -- Looking for unwind.h\n",
      "\u001b[94mcmd1:\u001b[0m -- Looking for unwind.h - found\n",
      "\u001b[94mcmd1:\u001b[0m -- Looking for C++ include ext/hash_map\n",
      "\u001b[94mcmd1:\u001b[0m -- Looking for C++ include ext/hash_map - found\n",
      "\u001b[94mcmd1:\u001b[0m -- Looking for C++ include ext/hash_set\n",
      "\u001b[94mcmd1:\u001b[0m -- Looking for C++ include ext/hash_set - found\n",
      "\u001b[94mcmd1:\u001b[0m -- Looking for C++ include ext/slist\n",
      "\u001b[94mcmd1:\u001b[0m -- Looking for C++ include ext/slist - found\n",
      "\u001b[94mcmd1:\u001b[0m -- Looking for C++ include tr1/unordered_map\n",
      "\u001b[94mcmd1:\u001b[0m -- Looking for C++ include tr1/unordered_map - found\n",
      "\u001b[94mcmd1:\u001b[0m -- Looking for C++ include tr1/unordered_set\n",
      "\u001b[94mcmd1:\u001b[0m -- Looking for C++ include tr1/unordered_set - found\n",
      "\u001b[94mcmd1:\u001b[0m -- Looking for C++ include unordered_map\n",
      "\u001b[94mcmd1:\u001b[0m -- Looking for C++ include unordered_map - found\n",
      "\u001b[94mcmd1:\u001b[0m -- Looking for C++ include unordered_set\n",
      "\u001b[94mcmd1:\u001b[0m -- Looking for C++ include unordered_set - found\n",
      "\u001b[94mcmd1:\u001b[0m -- Check size of unsigned __int16\n",
      "\u001b[94mcmd1:\u001b[0m -- Check size of unsigned __int16 - failed\n",
      "\u001b[94mcmd1:\u001b[0m -- Check size of u_int16_t\n",
      "\u001b[94mcmd1:\u001b[0m -- Check size of u_int16_t - done\n",
      "\u001b[94mcmd1:\u001b[0m -- Check size of uint16_t\n",
      "\u001b[94mcmd1:\u001b[0m -- Check size of uint16_t - done\n",
      "\u001b[94mcmd1:\u001b[0m -- Looking for dladdr\n",
      "\u001b[94mcmd1:\u001b[0m -- Looking for dladdr - found\n",
      "\u001b[94mcmd1:\u001b[0m -- Looking for fcntl\n",
      "\u001b[94mcmd1:\u001b[0m -- Looking for fcntl - found\n",
      "\u001b[94mcmd1:\u001b[0m -- Looking for pread\n",
      "\u001b[94mcmd1:\u001b[0m -- Looking for pread - found\n",
      "\u001b[94mcmd1:\u001b[0m -- Looking for pwrite\n",
      "\u001b[94mcmd1:\u001b[0m -- Looking for pwrite - found\n",
      "\u001b[94mcmd1:\u001b[0m -- Looking for sigaction\n",
      "\u001b[94mcmd1:\u001b[0m -- Looking for sigaction - found\n",
      "\u001b[94mcmd1:\u001b[0m -- Looking for sigaltstack\n",
      "\u001b[94mcmd1:\u001b[0m -- Looking for sigaltstack - found\n",
      "\u001b[94mcmd1:\u001b[0m -- Performing Test HAVE_NO_DEPRECATED\n",
      "\u001b[94mcmd1:\u001b[0m -- Performing Test HAVE_NO_DEPRECATED - Success\n",
      "\u001b[94mcmd1:\u001b[0m -- Performing Test HAVE_NO_UNNAMED_TYPE_TEMPLATE_ARGS\n",
      "\u001b[94mcmd1:\u001b[0m -- Performing Test HAVE_NO_UNNAMED_TYPE_TEMPLATE_ARGS - Failed\n",
      "\u001b[94mcmd1:\u001b[0m -- Looking for snprintf\n",
      "\u001b[94mcmd1:\u001b[0m -- Looking for snprintf - found\n",
      "\u001b[94mcmd1:\u001b[0m -- Looking for get_static_proc_name in unwind\n",
      "\u001b[94mcmd1:\u001b[0m -- Looking for get_static_proc_name in unwind - not found\n",
      "\u001b[94mcmd1:\u001b[0m -- Looking for UnDecorateSymbolName in dbghelp\n",
      "\u001b[94mcmd1:\u001b[0m -- Looking for UnDecorateSymbolName in dbghelp - not found\n",
      "\u001b[94mcmd1:\u001b[0m -- Performing Test HAVE___ATTRIBUTE__\n",
      "\u001b[94mcmd1:\u001b[0m -- Performing Test HAVE___ATTRIBUTE__ - Success\n",
      "\u001b[94mcmd1:\u001b[0m -- Performing Test HAVE___ATTRIBUTE__VISIBILITY_DEFAULT\n",
      "\u001b[94mcmd1:\u001b[0m -- Performing Test HAVE___ATTRIBUTE__VISIBILITY_DEFAULT - Success\n",
      "\u001b[94mcmd1:\u001b[0m -- Performing Test HAVE___ATTRIBUTE__VISIBILITY_HIDDEN\n",
      "\u001b[94mcmd1:\u001b[0m -- Performing Test HAVE___ATTRIBUTE__VISIBILITY_HIDDEN - Success\n",
      "\u001b[94mcmd1:\u001b[0m -- Performing Test HAVE___BUILTIN_EXPECT\n",
      "\u001b[94mcmd1:\u001b[0m -- Performing Test HAVE___BUILTIN_EXPECT - Success\n",
      "\u001b[94mcmd1:\u001b[0m -- Performing Test HAVE___SYNC_VAL_COMPARE_AND_SWAP\n",
      "\u001b[94mcmd1:\u001b[0m -- Performing Test HAVE___SYNC_VAL_COMPARE_AND_SWAP - Success\n",
      "\u001b[94mcmd1:\u001b[0m -- Performing Test HAVE_RWLOCK\n",
      "\u001b[94mcmd1:\u001b[0m -- Performing Test HAVE_RWLOCK - Success\n",
      "\u001b[94mcmd1:\u001b[0m -- Performing Test HAVE___DECLSPEC\n",
      "\u001b[94mcmd1:\u001b[0m -- Performing Test HAVE___DECLSPEC - Failed\n",
      "\u001b[94mcmd1:\u001b[0m -- Performing Test STL_NO_NAMESPACE\n",
      "\u001b[94mcmd1:\u001b[0m -- Performing Test STL_NO_NAMESPACE - Failed\n",
      "\u001b[94mcmd1:\u001b[0m -- Performing Test STL_STD_NAMESPACE\n",
      "\u001b[94mcmd1:\u001b[0m -- Performing Test STL_STD_NAMESPACE - Success\n",
      "\u001b[94mcmd1:\u001b[0m -- Performing Test HAVE_USING_OPERATOR\n",
      "\u001b[94mcmd1:\u001b[0m -- Performing Test HAVE_USING_OPERATOR - Success\n",
      "\u001b[94mcmd1:\u001b[0m -- Performing Test HAVE_NAMESPACES\n",
      "\u001b[94mcmd1:\u001b[0m -- Performing Test HAVE_NAMESPACES - Success\n",
      "\u001b[94mcmd1:\u001b[0m -- Performing Test HAVE_GCC_TLS\n",
      "\u001b[94mcmd1:\u001b[0m -- Performing Test HAVE_GCC_TLS - Success\n",
      "\u001b[94mcmd1:\u001b[0m -- Performing Test HAVE_MSVC_TLS\n",
      "\u001b[94mcmd1:\u001b[0m -- Performing Test HAVE_MSVC_TLS - Failed\n",
      "\u001b[94mcmd1:\u001b[0m -- Performing Test HAVE_CXX11_TLS\n",
      "\u001b[94mcmd1:\u001b[0m -- Performing Test HAVE_CXX11_TLS - Success\n",
      "\u001b[94mcmd1:\u001b[0m -- Performing Test HAVE_ALIGNED_STORAGE\n",
      "\u001b[94mcmd1:\u001b[0m -- Performing Test HAVE_ALIGNED_STORAGE - Success\n",
      "\u001b[94mcmd1:\u001b[0m -- Performing Test HAVE_LOCALTIME_R\n",
      "\u001b[94mcmd1:\u001b[0m -- Performing Test HAVE_LOCALTIME_R - Success\n",
      "\u001b[94mcmd1:\u001b[0m CMake Warning (dev) at /usr/local/lib/python3.11/dist-packages/cmake/data/share/cmake-3.31/Modules/FetchContent.cmake:1373 (message):\n",
      "\u001b[94mcmd1:\u001b[0m   The DOWNLOAD_EXTRACT_TIMESTAMP option was not given and policy CMP0135 is\n",
      "\u001b[94mcmd1:\u001b[0m   not set.  The policy's OLD behavior will be used.  When using a URL\n",
      "\u001b[94mcmd1:\u001b[0m   download, the timestamps of extracted files should preferably be that of\n",
      "\u001b[94mcmd1:\u001b[0m   the time of extraction, otherwise code that depends on the extracted\n",
      "\u001b[94mcmd1:\u001b[0m   contents might not be rebuilt if the URL changes.  The OLD behavior\n",
      "\u001b[94mcmd1:\u001b[0m   preserves the timestamps from the archive instead, but this is usually not\n",
      "\u001b[94mcmd1:\u001b[0m   what you want.  Update your project to the NEW behavior or specify the\n",
      "\u001b[94mcmd1:\u001b[0m   DOWNLOAD_EXTRACT_TIMESTAMP option with a value of true to avoid this\n",
      "\u001b[94mcmd1:\u001b[0m   robustness issue.\n",
      "\u001b[94mcmd1:\u001b[0m Call Stack (most recent call first):\n",
      "\u001b[94mcmd1:\u001b[0m   CMakeLists.txt:49 (FetchContent_Declare)\n",
      "\u001b[94mcmd1:\u001b[0m This warning is for project developers.  Use -Wno-dev to suppress it.\n",
      "\u001b[94mcmd1:\u001b[0m \n",
      "\u001b[94mcmd1:\u001b[0m -- Populating googletest\n",
      "\u001b[94mcmd1:\u001b[0m -- Configuring done (0.0s)\n",
      "\u001b[94mcmd1:\u001b[0m -- Generating done (0.0s)\n",
      "\u001b[94mcmd1:\u001b[0m -- Build files have been written to: /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/googletest-subbuild\n",
      "\u001b[94mcmd1:\u001b[0m [ 11%] Creating directories for 'googletest-populate'\n",
      "\u001b[94mcmd1:\u001b[0m [ 22%] Performing download step (download, verify and extract) for 'googletest-populate'\n",
      "\u001b[94mcmd1:\u001b[0m -- Downloading...\n",
      "\u001b[94mcmd1:\u001b[0m    dst='/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/googletest-subbuild/googletest-populate-prefix/src/release-1.10.0.zip'\n",
      "\u001b[94mcmd1:\u001b[0m    timeout='none'\n",
      "\u001b[94mcmd1:\u001b[0m    inactivity timeout='none'\n",
      "\u001b[94mcmd1:\u001b[0m -- Using src='https://github.com/google/googletest/archive/release-1.10.0.zip'\n",
      "\u001b[94mcmd1:\u001b[0m -- verifying file...\n",
      "\u001b[94mcmd1:\u001b[0m        file='/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/googletest-subbuild/googletest-populate-prefix/src/release-1.10.0.zip'\n",
      "\u001b[94mcmd1:\u001b[0m -- Downloading... done\n",
      "\u001b[94mcmd1:\u001b[0m -- extracting...\n",
      "\u001b[94mcmd1:\u001b[0m      src='/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/googletest-subbuild/googletest-populate-prefix/src/release-1.10.0.zip'\n",
      "\u001b[94mcmd1:\u001b[0m      dst='/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/googletest-src'\n",
      "\u001b[94mcmd1:\u001b[0m -- extracting... [tar xfz]\n",
      "\u001b[94mcmd1:\u001b[0m -- extracting... [analysis]\n",
      "\u001b[94mcmd1:\u001b[0m -- extracting... [rename]\n",
      "\u001b[94mcmd1:\u001b[0m -- extracting... [clean up]\n",
      "\u001b[94mcmd1:\u001b[0m -- extracting... done\n",
      "\u001b[94mcmd1:\u001b[0m [ 33%] No update step for 'googletest-populate'\n",
      "\u001b[94mcmd1:\u001b[0m [ 44%] No patch step for 'googletest-populate'\n",
      "\u001b[94mcmd1:\u001b[0m [ 55%] No configure step for 'googletest-populate'\n",
      "\u001b[94mcmd1:\u001b[0m [ 66%] No build step for 'googletest-populate'\n",
      "\u001b[94mcmd1:\u001b[0m [ 77%] No install step for 'googletest-populate'\n",
      "\u001b[94mcmd1:\u001b[0m [ 88%] No test step for 'googletest-populate'\n",
      "\u001b[94mcmd1:\u001b[0m [100%] Completed 'googletest-populate'\n",
      "\u001b[94mcmd1:\u001b[0m [100%] Built target googletest-populate\n",
      "\u001b[94mcmd1:\u001b[0m CMake Deprecation Warning at fc_base/googletest-src/CMakeLists.txt:4 (cmake_minimum_required):\n",
      "\u001b[94mcmd1:\u001b[0m   Compatibility with CMake < 3.10 will be removed from a future version of\n",
      "\u001b[94mcmd1:\u001b[0m   CMake.\n",
      "\u001b[94mcmd1:\u001b[0m \n",
      "\u001b[94mcmd1:\u001b[0m   Update the VERSION argument <min> value.  Or, use the <min>...<max> syntax\n",
      "\u001b[94mcmd1:\u001b[0m   to tell CMake that the project requires at least <min> but has been updated\n",
      "\u001b[94mcmd1:\u001b[0m   to work with policies introduced by <max> or earlier.\n",
      "\u001b[94mcmd1:\u001b[0m \n",
      "\u001b[94mcmd1:\u001b[0m \n",
      "\u001b[94mcmd1:\u001b[0m CMake Deprecation Warning at fc_base/googletest-src/googlemock/CMakeLists.txt:45 (cmake_minimum_required):\n",
      "\u001b[94mcmd1:\u001b[0m   Compatibility with CMake < 3.10 will be removed from a future version of\n",
      "\u001b[94mcmd1:\u001b[0m   CMake.\n",
      "\u001b[94mcmd1:\u001b[0m \n",
      "\u001b[94mcmd1:\u001b[0m   Update the VERSION argument <min> value.  Or, use the <min>...<max> syntax\n",
      "\u001b[94mcmd1:\u001b[0m   to tell CMake that the project requires at least <min> but has been updated\n",
      "\u001b[94mcmd1:\u001b[0m   to work with policies introduced by <max> or earlier.\n",
      "\u001b[94mcmd1:\u001b[0m \n",
      "\u001b[94mcmd1:\u001b[0m \n",
      "\u001b[94mcmd1:\u001b[0m CMake Deprecation Warning at fc_base/googletest-src/googletest/CMakeLists.txt:56 (cmake_minimum_required):\n",
      "\u001b[94mcmd1:\u001b[0m   Compatibility with CMake < 3.10 will be removed from a future version of\n",
      "\u001b[94mcmd1:\u001b[0m   CMake.\n",
      "\u001b[94mcmd1:\u001b[0m \n",
      "\u001b[94mcmd1:\u001b[0m   Update the VERSION argument <min> value.  Or, use the <min>...<max> syntax\n",
      "\u001b[94mcmd1:\u001b[0m   to tell CMake that the project requires at least <min> but has been updated\n",
      "\u001b[94mcmd1:\u001b[0m   to work with policies introduced by <max> or earlier.\n",
      "\u001b[94mcmd1:\u001b[0m \n",
      "\u001b[94mcmd1:\u001b[0m \n",
      "\u001b[94mcmd1:\u001b[0m CMake Warning (dev) at fc_base/googletest-src/googletest/cmake/internal_utils.cmake:243 (find_package):\n",
      "\u001b[94mcmd1:\u001b[0m   Policy CMP0148 is not set: The FindPythonInterp and FindPythonLibs modules\n",
      "\u001b[94mcmd1:\u001b[0m   are removed.  Run \"cmake --help-policy CMP0148\" for policy details.  Use\n",
      "\u001b[94mcmd1:\u001b[0m   the cmake_policy command to set the policy and suppress this warning.\n",
      "\u001b[94mcmd1:\u001b[0m \n",
      "\u001b[94mcmd1:\u001b[0m Call Stack (most recent call first):\n",
      "\u001b[94mcmd1:\u001b[0m   fc_base/googletest-src/googletest/CMakeLists.txt:91 (include)\n",
      "\u001b[94mcmd1:\u001b[0m This warning is for project developers.  Use -Wno-dev to suppress it.\n",
      "\u001b[94mcmd1:\u001b[0m \n",
      "\u001b[94mcmd1:\u001b[0m -- Found PythonInterp: /root/miniconda3/envs/b2txt25_lm/bin/python (found version \"3.9.25\")\n",
      "\u001b[94mcmd1:\u001b[0m CMake Warning (dev) at /usr/local/lib/python3.11/dist-packages/cmake/data/share/cmake-3.31/Modules/FetchContent.cmake:1373 (message):\n",
      "\u001b[94mcmd1:\u001b[0m   The DOWNLOAD_EXTRACT_TIMESTAMP option was not given and policy CMP0135 is\n",
      "\u001b[94mcmd1:\u001b[0m   not set.  The policy's OLD behavior will be used.  When using a URL\n",
      "\u001b[94mcmd1:\u001b[0m   download, the timestamps of extracted files should preferably be that of\n",
      "\u001b[94mcmd1:\u001b[0m   the time of extraction, otherwise code that depends on the extracted\n",
      "\u001b[94mcmd1:\u001b[0m   contents might not be rebuilt if the URL changes.  The OLD behavior\n",
      "\u001b[94mcmd1:\u001b[0m   preserves the timestamps from the archive instead, but this is usually not\n",
      "\u001b[94mcmd1:\u001b[0m   what you want.  Update your project to the NEW behavior or specify the\n",
      "\u001b[94mcmd1:\u001b[0m   DOWNLOAD_EXTRACT_TIMESTAMP option with a value of true to avoid this\n",
      "\u001b[94mcmd1:\u001b[0m   robustness issue.\n",
      "\u001b[94mcmd1:\u001b[0m Call Stack (most recent call first):\n",
      "\u001b[94mcmd1:\u001b[0m   CMakeLists.txt:56 (FetchContent_Declare)\n",
      "\u001b[94mcmd1:\u001b[0m This warning is for project developers.  Use -Wno-dev to suppress it.\n",
      "\u001b[94mcmd1:\u001b[0m \n",
      "\u001b[94mcmd1:\u001b[0m -- Populating boost\n",
      "\u001b[94mcmd1:\u001b[0m -- Configuring done (0.0s)\n",
      "\u001b[94mcmd1:\u001b[0m -- Generating done (0.0s)\n",
      "\u001b[94mcmd1:\u001b[0m -- Build files have been written to: /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/boost-subbuild\n",
      "\u001b[94mcmd1:\u001b[0m [ 11%] Creating directories for 'boost-populate'\n",
      "\u001b[94mcmd1:\u001b[0m [ 22%] Performing download step (download, verify and extract) for 'boost-populate'\n",
      "\u001b[94mcmd1:\u001b[0m -- Downloading...\n",
      "\u001b[94mcmd1:\u001b[0m    dst='/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/boost-subbuild/boost-populate-prefix/src/boost_1_75_0.tar.gz'\n",
      "\u001b[94mcmd1:\u001b[0m    timeout='none'\n",
      "\u001b[94mcmd1:\u001b[0m    inactivity timeout='none'\n",
      "\u001b[94mcmd1:\u001b[0m -- Using src='https://archives.boost.io/release/1.75.0/source/boost_1_75_0.tar.gz'\n",
      "\u001b[94mcmd1:\u001b[0m -- [download 0% complete]\n",
      "\u001b[94mcmd1:\u001b[0m -- [download 1% complete]\n",
      "\u001b[94mcmd1:\u001b[0m -- [download 2% complete]\n",
      "\u001b[94mcmd1:\u001b[0m -- [download 3% complete]\n",
      "\u001b[94mcmd1:\u001b[0m -- [download 4% complete]\n",
      "\u001b[94mcmd1:\u001b[0m -- [download 5% complete]\n",
      "\u001b[94mcmd1:\u001b[0m -- [download 6% complete]\n",
      "\u001b[94mcmd1:\u001b[0m -- [download 7% complete]\n",
      "\u001b[94mcmd1:\u001b[0m -- [download 8% complete]\n",
      "\u001b[94mcmd1:\u001b[0m -- [download 9% complete]\n",
      "\u001b[94mcmd1:\u001b[0m -- [download 10% complete]\n",
      "\u001b[94mcmd1:\u001b[0m -- [download 11% complete]\n",
      "\u001b[94mcmd1:\u001b[0m -- [download 12% complete]\n",
      "\u001b[94mcmd1:\u001b[0m -- [download 13% complete]\n",
      "\u001b[94mcmd1:\u001b[0m -- [download 14% complete]\n",
      "\u001b[94mcmd1:\u001b[0m -- [download 15% complete]\n",
      "\u001b[94mcmd1:\u001b[0m -- [download 16% complete]\n",
      "\u001b[94mcmd1:\u001b[0m -- [download 17% complete]\n",
      "\u001b[94mcmd1:\u001b[0m -- [download 18% complete]\n",
      "\u001b[94mcmd1:\u001b[0m -- [download 19% complete]\n",
      "\u001b[94mcmd1:\u001b[0m -- [download 20% complete]\n",
      "\u001b[94mcmd1:\u001b[0m -- [download 21% complete]\n",
      "\u001b[94mcmd1:\u001b[0m -- [download 22% complete]\n",
      "\u001b[94mcmd1:\u001b[0m -- [download 23% complete]\n",
      "\u001b[94mcmd1:\u001b[0m -- [download 24% complete]\n",
      "\u001b[94mcmd1:\u001b[0m -- [download 25% complete]\n",
      "\u001b[94mcmd1:\u001b[0m -- [download 26% complete]\n",
      "\u001b[94mcmd1:\u001b[0m -- [download 27% complete]\n",
      "\u001b[94mcmd1:\u001b[0m -- [download 28% complete]\n",
      "\u001b[94mcmd1:\u001b[0m -- [download 29% complete]\n",
      "\u001b[94mcmd1:\u001b[0m -- [download 30% complete]\n",
      "\u001b[94mcmd1:\u001b[0m -- [download 31% complete]\n",
      "\u001b[94mcmd1:\u001b[0m -- [download 32% complete]\n",
      "\u001b[94mcmd1:\u001b[0m -- [download 33% complete]\n",
      "\u001b[94mcmd1:\u001b[0m -- [download 34% complete]\n",
      "\u001b[94mcmd1:\u001b[0m -- [download 35% complete]\n",
      "\u001b[94mcmd1:\u001b[0m -- [download 36% complete]\n",
      "\u001b[94mcmd1:\u001b[0m -- [download 37% complete]\n",
      "\u001b[94mcmd1:\u001b[0m -- [download 38% complete]\n",
      "\u001b[94mcmd1:\u001b[0m -- [download 39% complete]\n",
      "\u001b[94mcmd1:\u001b[0m -- [download 40% complete]\n",
      "\u001b[94mcmd1:\u001b[0m -- [download 41% complete]\n",
      "\u001b[94mcmd1:\u001b[0m -- [download 42% complete]\n",
      "\u001b[94mcmd1:\u001b[0m -- [download 43% complete]\n",
      "\u001b[94mcmd1:\u001b[0m -- [download 44% complete]\n",
      "\u001b[94mcmd1:\u001b[0m -- [download 45% complete]\n",
      "\u001b[94mcmd1:\u001b[0m -- [download 46% complete]\n",
      "\u001b[94mcmd1:\u001b[0m -- [download 47% complete]\n",
      "\u001b[94mcmd1:\u001b[0m -- [download 48% complete]\n",
      "\u001b[94mcmd1:\u001b[0m -- [download 49% complete]\n",
      "\u001b[94mcmd1:\u001b[0m -- [download 50% complete]\n",
      "\u001b[94mcmd1:\u001b[0m -- [download 51% complete]\n",
      "\u001b[94mcmd1:\u001b[0m -- [download 52% complete]\n",
      "\u001b[94mcmd1:\u001b[0m -- [download 53% complete]\n",
      "\u001b[94mcmd1:\u001b[0m -- [download 54% complete]\n",
      "\u001b[94mcmd1:\u001b[0m -- [download 55% complete]\n",
      "\u001b[94mcmd1:\u001b[0m -- [download 56% complete]\n",
      "\u001b[94mcmd1:\u001b[0m -- [download 57% complete]\n",
      "\u001b[94mcmd1:\u001b[0m -- [download 58% complete]\n",
      "\u001b[94mcmd1:\u001b[0m -- [download 59% complete]\n",
      "\u001b[94mcmd1:\u001b[0m -- [download 60% complete]\n",
      "\u001b[94mcmd1:\u001b[0m -- [download 61% complete]\n",
      "\u001b[94mcmd1:\u001b[0m -- [download 62% complete]\n",
      "\u001b[94mcmd1:\u001b[0m -- [download 63% complete]\n",
      "\u001b[94mcmd1:\u001b[0m -- [download 64% complete]\n",
      "\u001b[94mcmd1:\u001b[0m -- [download 65% complete]\n",
      "\u001b[94mcmd1:\u001b[0m -- [download 66% complete]\n",
      "\u001b[94mcmd1:\u001b[0m -- [download 67% complete]\n",
      "\u001b[94mcmd1:\u001b[0m -- [download 68% complete]\n",
      "\u001b[94mcmd1:\u001b[0m -- [download 69% complete]\n",
      "\u001b[94mcmd1:\u001b[0m -- [download 70% complete]\n",
      "\u001b[94mcmd1:\u001b[0m -- [download 71% complete]\n",
      "\u001b[94mcmd1:\u001b[0m -- [download 72% complete]\n",
      "\u001b[94mcmd1:\u001b[0m -- [download 73% complete]\n",
      "\u001b[94mcmd1:\u001b[0m -- [download 74% complete]\n",
      "\u001b[94mcmd1:\u001b[0m -- [download 75% complete]\n",
      "\u001b[94mcmd1:\u001b[0m -- [download 76% complete]\n",
      "\u001b[94mcmd1:\u001b[0m -- [download 77% complete]\n",
      "\u001b[94mcmd1:\u001b[0m -- [download 78% complete]\n",
      "\u001b[94mcmd1:\u001b[0m -- [download 79% complete]\n",
      "\u001b[94mcmd1:\u001b[0m -- [download 80% complete]\n",
      "\u001b[94mcmd1:\u001b[0m -- [download 81% complete]\n",
      "\u001b[94mcmd1:\u001b[0m -- [download 82% complete]\n",
      "\u001b[94mcmd1:\u001b[0m -- [download 83% complete]\n",
      "\u001b[94mcmd1:\u001b[0m -- [download 84% complete]\n",
      "\u001b[94mcmd1:\u001b[0m -- [download 85% complete]\n",
      "\u001b[94mcmd1:\u001b[0m -- [download 86% complete]\n",
      "\u001b[94mcmd1:\u001b[0m -- [download 87% complete]\n",
      "\u001b[94mcmd1:\u001b[0m -- [download 88% complete]\n",
      "\u001b[94mcmd1:\u001b[0m -- [download 89% complete]\n",
      "\u001b[94mcmd1:\u001b[0m -- [download 90% complete]\n",
      "\u001b[94mcmd1:\u001b[0m -- [download 91% complete]\n",
      "\u001b[94mcmd1:\u001b[0m -- [download 92% complete]\n",
      "\u001b[94mcmd1:\u001b[0m -- [download 93% complete]\n",
      "\u001b[94mcmd1:\u001b[0m -- [download 94% complete]\n",
      "\u001b[94mcmd1:\u001b[0m -- [download 95% complete]\n",
      "\u001b[94mcmd1:\u001b[0m -- [download 96% complete]\n",
      "\u001b[94mcmd1:\u001b[0m -- [download 97% complete]\n",
      "\u001b[94mcmd1:\u001b[0m -- [download 98% complete]\n",
      "\u001b[94mcmd1:\u001b[0m -- [download 99% complete]\n",
      "\u001b[94mcmd1:\u001b[0m -- [download 100% complete]\n",
      "\u001b[94mcmd1:\u001b[0m -- verifying file...\n",
      "\u001b[94mcmd1:\u001b[0m        file='/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/boost-subbuild/boost-populate-prefix/src/boost_1_75_0.tar.gz'\n",
      "\u001b[94mcmd1:\u001b[0m -- Downloading... done\n",
      "\u001b[94mcmd1:\u001b[0m -- extracting...\n",
      "\u001b[94mcmd1:\u001b[0m      src='/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/boost-subbuild/boost-populate-prefix/src/boost_1_75_0.tar.gz'\n",
      "\u001b[94mcmd1:\u001b[0m      dst='/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/boost-src'\n",
      "\u001b[94mcmd1:\u001b[0m -- extracting... [tar xfz]\n",
      "\u001b[94mcmd1:\u001b[0m -- extracting... [analysis]\n",
      "\u001b[94mcmd1:\u001b[0m -- extracting... [rename]\n",
      "\u001b[94mcmd1:\u001b[0m -- extracting... [clean up]\n",
      "\u001b[94mcmd1:\u001b[0m -- extracting... done\n",
      "\u001b[94mcmd1:\u001b[0m [ 33%] No update step for 'boost-populate'\n",
      "\u001b[94mcmd1:\u001b[0m [ 44%] No patch step for 'boost-populate'\n",
      "\u001b[94mcmd1:\u001b[0m [ 55%] No configure step for 'boost-populate'\n",
      "\u001b[94mcmd1:\u001b[0m [ 66%] No build step for 'boost-populate'\n",
      "\u001b[94mcmd1:\u001b[0m [ 77%] No install step for 'boost-populate'\n",
      "\u001b[94mcmd1:\u001b[0m [ 88%] No test step for 'boost-populate'\n",
      "\u001b[94mcmd1:\u001b[0m [100%] Completed 'boost-populate'\n",
      "\u001b[94mcmd1:\u001b[0m [100%] Built target boost-populate\n",
      "\u001b[94mcmd1:\u001b[0m CMake Warning (dev) at /usr/local/lib/python3.11/dist-packages/cmake/data/share/cmake-3.31/Modules/FetchContent.cmake:1373 (message):\n",
      "\u001b[94mcmd1:\u001b[0m   The DOWNLOAD_EXTRACT_TIMESTAMP option was not given and policy CMP0135 is\n",
      "\u001b[94mcmd1:\u001b[0m   not set.  The policy's OLD behavior will be used.  When using a URL\n",
      "\u001b[94mcmd1:\u001b[0m   download, the timestamps of extracted files should preferably be that of\n",
      "\u001b[94mcmd1:\u001b[0m   the time of extraction, otherwise code that depends on the extracted\n",
      "\u001b[94mcmd1:\u001b[0m   contents might not be rebuilt if the URL changes.  The OLD behavior\n",
      "\u001b[94mcmd1:\u001b[0m   preserves the timestamps from the archive instead, but this is usually not\n",
      "\u001b[94mcmd1:\u001b[0m   what you want.  Update your project to the NEW behavior or specify the\n",
      "\u001b[94mcmd1:\u001b[0m   DOWNLOAD_EXTRACT_TIMESTAMP option with a value of true to avoid this\n",
      "\u001b[94mcmd1:\u001b[0m   robustness issue.\n",
      "\u001b[94mcmd1:\u001b[0m Call Stack (most recent call first):\n",
      "\u001b[94mcmd1:\u001b[0m   CMakeLists.txt:64 (FetchContent_Declare)\n",
      "\u001b[94mcmd1:\u001b[0m This warning is for project developers.  Use -Wno-dev to suppress it.\n",
      "\u001b[94mcmd1:\u001b[0m \n",
      "\u001b[94mcmd1:\u001b[0m -- Populating cnpy\n",
      "\u001b[94mcmd1:\u001b[0m -- Configuring done (0.0s)\n",
      "\u001b[94mcmd1:\u001b[0m -- Generating done (0.0s)\n",
      "\u001b[94mcmd1:\u001b[0m -- Build files have been written to: /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/cnpy-subbuild\n",
      "\u001b[94mcmd1:\u001b[0m [ 11%] Creating directories for 'cnpy-populate'\n",
      "\u001b[94mcmd1:\u001b[0m [ 22%] Performing download step (download, verify and extract) for 'cnpy-populate'\n",
      "\u001b[94mcmd1:\u001b[0m -- Downloading...\n",
      "\u001b[94mcmd1:\u001b[0m    dst='/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/cnpy-subbuild/cnpy-populate-prefix/src/master.zip'\n",
      "\u001b[94mcmd1:\u001b[0m    timeout='none'\n",
      "\u001b[94mcmd1:\u001b[0m    inactivity timeout='none'\n",
      "\u001b[94mcmd1:\u001b[0m -- Using src='https://github.com/rogersce/cnpy/archive/refs/heads/master.zip'\n",
      "\u001b[94mcmd1:\u001b[0m -- verifying file...\n",
      "\u001b[94mcmd1:\u001b[0m        file='/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/cnpy-subbuild/cnpy-populate-prefix/src/master.zip'\n",
      "\u001b[94mcmd1:\u001b[0m -- Downloading... done\n",
      "\u001b[94mcmd1:\u001b[0m -- extracting...\n",
      "\u001b[94mcmd1:\u001b[0m      src='/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/cnpy-subbuild/cnpy-populate-prefix/src/master.zip'\n",
      "\u001b[94mcmd1:\u001b[0m      dst='/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/cnpy-src'\n",
      "\u001b[94mcmd1:\u001b[0m -- extracting... [tar xfz]\n",
      "\u001b[94mcmd1:\u001b[0m -- extracting... [analysis]\n",
      "\u001b[94mcmd1:\u001b[0m -- extracting... [rename]\n",
      "\u001b[94mcmd1:\u001b[0m -- extracting... [clean up]\n",
      "\u001b[94mcmd1:\u001b[0m -- extracting... done\n",
      "\u001b[94mcmd1:\u001b[0m [ 33%] No update step for 'cnpy-populate'\n",
      "\u001b[94mcmd1:\u001b[0m [ 44%] No patch step for 'cnpy-populate'\n",
      "\u001b[94mcmd1:\u001b[0m [ 55%] No configure step for 'cnpy-populate'\n",
      "\u001b[94mcmd1:\u001b[0m [ 66%] No build step for 'cnpy-populate'\n",
      "\u001b[94mcmd1:\u001b[0m [ 77%] No install step for 'cnpy-populate'\n",
      "\u001b[94mcmd1:\u001b[0m [ 88%] No test step for 'cnpy-populate'\n",
      "\u001b[94mcmd1:\u001b[0m [100%] Completed 'cnpy-populate'\n",
      "\u001b[94mcmd1:\u001b[0m [100%] Built target cnpy-populate\n",
      "\u001b[94mcmd1:\u001b[0m CMake Deprecation Warning at fc_base/cnpy-src/CMakeLists.txt:1 (CMAKE_MINIMUM_REQUIRED):\n",
      "\u001b[94mcmd1:\u001b[0m   Compatibility with CMake < 3.10 will be removed from a future version of\n",
      "\u001b[94mcmd1:\u001b[0m   CMake.\n",
      "\u001b[94mcmd1:\u001b[0m \n",
      "\u001b[94mcmd1:\u001b[0m   Update the VERSION argument <min> value.  Or, use the <min>...<max> syntax\n",
      "\u001b[94mcmd1:\u001b[0m   to tell CMake that the project requires at least <min> but has been updated\n",
      "\u001b[94mcmd1:\u001b[0m   to work with policies introduced by <max> or earlier.\n",
      "\u001b[94mcmd1:\u001b[0m \n",
      "\u001b[94mcmd1:\u001b[0m \n",
      "\u001b[94mcmd1:\u001b[0m -- Found ZLIB: /usr/lib/x86_64-linux-gnu/libz.so (found version \"1.2.11\")\n",
      "\u001b[94mcmd1:\u001b[0m CMake Deprecation Warning at third_party/hiredis/CMakeLists.txt:1 (CMAKE_MINIMUM_REQUIRED):\n",
      "\u001b[94mcmd1:\u001b[0m   Compatibility with CMake < 3.10 will be removed from a future version of\n",
      "\u001b[94mcmd1:\u001b[0m   CMake.\n",
      "\u001b[94mcmd1:\u001b[0m \n",
      "\u001b[94mcmd1:\u001b[0m   Update the VERSION argument <min> value.  Or, use the <min>...<max> syntax\n",
      "\u001b[94mcmd1:\u001b[0m   to tell CMake that the project requires at least <min> but has been updated\n",
      "\u001b[94mcmd1:\u001b[0m   to work with policies introduced by <max> or earlier.\n",
      "\u001b[94mcmd1:\u001b[0m \n",
      "\u001b[94mcmd1:\u001b[0m \n",
      "\u001b[94mcmd1:\u001b[0m Detected version: 1.0.1\n",
      "\u001b[94mcmd1:\u001b[0m CMake Deprecation Warning at third_party/redis-plus-plus/CMakeLists.txt:1 (cmake_minimum_required):\n",
      "\u001b[94mcmd1:\u001b[0m   Compatibility with CMake < 3.10 will be removed from a future version of\n",
      "\u001b[94mcmd1:\u001b[0m   CMake.\n",
      "\u001b[94mcmd1:\u001b[0m \n",
      "\u001b[94mcmd1:\u001b[0m   Update the VERSION argument <min> value.  Or, use the <min>...<max> syntax\n",
      "\u001b[94mcmd1:\u001b[0m   to tell CMake that the project requires at least <min> but has been updated\n",
      "\u001b[94mcmd1:\u001b[0m   to work with policies introduced by <max> or earlier.\n",
      "\u001b[94mcmd1:\u001b[0m \n",
      "\u001b[94mcmd1:\u001b[0m \n",
      "\u001b[94mcmd1:\u001b[0m -- redis-plus-plus version: 1.3.1\n",
      "\u001b[94mcmd1:\u001b[0m -- redis-plus-plus build type: Release\n",
      "\u001b[94mcmd1:\u001b[0m -- redis-plus-plus build with CXX standard: c++14\n",
      "\u001b[94mcmd1:\u001b[0m -- redis-plus-plus TLS support: OFF\n",
      "\u001b[94mcmd1:\u001b[0m -- redis-plus-plus build static library: ON\n",
      "\u001b[94mcmd1:\u001b[0m -- redis-plus-plus build static library with position independent code: ON\n",
      "\u001b[94mcmd1:\u001b[0m -- redis-plus-plus build shared library: ON\n",
      "\u001b[94mcmd1:\u001b[0m -- redis-plus-plus build test: ON\n",
      "\u001b[94mcmd1:\u001b[0m CMake Deprecation Warning at third_party/redis-plus-plus/test/CMakeLists.txt:3 (cmake_minimum_required):\n",
      "\u001b[94mcmd1:\u001b[0m   Compatibility with CMake < 3.10 will be removed from a future version of\n",
      "\u001b[94mcmd1:\u001b[0m   CMake.\n",
      "\u001b[94mcmd1:\u001b[0m \n",
      "\u001b[94mcmd1:\u001b[0m   Update the VERSION argument <min> value.  Or, use the <min>...<max> syntax\n",
      "\u001b[94mcmd1:\u001b[0m   to tell CMake that the project requires at least <min> but has been updated\n",
      "\u001b[94mcmd1:\u001b[0m   to work with policies introduced by <max> or earlier.\n",
      "\u001b[94mcmd1:\u001b[0m \n",
      "\u001b[94mcmd1:\u001b[0m \n",
      "\u001b[94mcmd1:\u001b[0m -- Debian package name: .deb\n",
      "\u001b[94mcmd1:\u001b[0m CMake Warning (dev) at /usr/local/lib/python3.11/dist-packages/cmake/data/share/cmake-3.31/Modules/FetchContent.cmake:1373 (message):\n",
      "\u001b[94mcmd1:\u001b[0m   The DOWNLOAD_EXTRACT_TIMESTAMP option was not given and policy CMP0135 is\n",
      "\u001b[94mcmd1:\u001b[0m   not set.  The policy's OLD behavior will be used.  When using a URL\n",
      "\u001b[94mcmd1:\u001b[0m   download, the timestamps of extracted files should preferably be that of\n",
      "\u001b[94mcmd1:\u001b[0m   the time of extraction, otherwise code that depends on the extracted\n",
      "\u001b[94mcmd1:\u001b[0m   contents might not be rebuilt if the URL changes.  The OLD behavior\n",
      "\u001b[94mcmd1:\u001b[0m   preserves the timestamps from the archive instead, but this is usually not\n",
      "\u001b[94mcmd1:\u001b[0m   what you want.  Update your project to the NEW behavior or specify the\n",
      "\u001b[94mcmd1:\u001b[0m   DOWNLOAD_EXTRACT_TIMESTAMP option with a value of true to avoid this\n",
      "\u001b[94mcmd1:\u001b[0m   robustness issue.\n",
      "\u001b[94mcmd1:\u001b[0m Call Stack (most recent call first):\n",
      "\u001b[94mcmd1:\u001b[0m   CMakeLists.txt:88 (FetchContent_Declare)\n",
      "\u001b[94mcmd1:\u001b[0m This warning is for project developers.  Use -Wno-dev to suppress it.\n",
      "\u001b[94mcmd1:\u001b[0m \n",
      "\u001b[94mcmd1:\u001b[0m -- Populating libtorch\n",
      "\u001b[94mcmd1:\u001b[0m -- Configuring done (0.0s)\n",
      "\u001b[94mcmd1:\u001b[0m -- Generating done (0.0s)\n",
      "\u001b[94mcmd1:\u001b[0m -- Build files have been written to: /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/libtorch-subbuild\n",
      "\u001b[94mcmd1:\u001b[0m [ 11%] Creating directories for 'libtorch-populate'\n",
      "\u001b[94mcmd1:\u001b[0m [ 22%] Performing download step (download, verify and extract) for 'libtorch-populate'\n",
      "\u001b[94mcmd1:\u001b[0m -- Downloading...\n",
      "\u001b[94mcmd1:\u001b[0m    dst='/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/libtorch-subbuild/libtorch-populate-prefix/src/libtorch-shared-with-deps-1.13.1%2Bcpu.zip'\n",
      "\u001b[94mcmd1:\u001b[0m    timeout='none'\n",
      "\u001b[94mcmd1:\u001b[0m    inactivity timeout='none'\n",
      "\u001b[94mcmd1:\u001b[0m -- Using src='https://download.pytorch.org/libtorch/cpu/libtorch-shared-with-deps-1.13.1%2Bcpu.zip'\n",
      "\u001b[94mcmd1:\u001b[0m -- [download 0% complete]\n",
      "\u001b[94mcmd1:\u001b[0m -- [download 1% complete]\n",
      "\u001b[94mcmd1:\u001b[0m -- [download 2% complete]\n",
      "\u001b[94mcmd1:\u001b[0m -- [download 3% complete]\n",
      "\u001b[94mcmd1:\u001b[0m -- [download 4% complete]\n",
      "\u001b[94mcmd1:\u001b[0m -- [download 5% complete]\n",
      "\u001b[94mcmd1:\u001b[0m -- [download 6% complete]\n",
      "\u001b[94mcmd1:\u001b[0m -- [download 7% complete]\n",
      "\u001b[94mcmd1:\u001b[0m -- [download 8% complete]\n",
      "\u001b[94mcmd1:\u001b[0m -- [download 9% complete]\n",
      "\u001b[94mcmd1:\u001b[0m -- [download 10% complete]\n",
      "\u001b[94mcmd1:\u001b[0m -- [download 11% complete]\n",
      "\u001b[94mcmd1:\u001b[0m -- [download 12% complete]\n",
      "\u001b[94mcmd1:\u001b[0m -- [download 13% complete]\n",
      "\u001b[94mcmd1:\u001b[0m -- [download 14% complete]\n",
      "\u001b[94mcmd1:\u001b[0m -- [download 15% complete]\n",
      "\u001b[94mcmd1:\u001b[0m -- [download 16% complete]\n",
      "\u001b[94mcmd1:\u001b[0m -- [download 17% complete]\n",
      "\u001b[94mcmd1:\u001b[0m -- [download 18% complete]\n",
      "\u001b[94mcmd1:\u001b[0m -- [download 19% complete]\n",
      "\u001b[94mcmd1:\u001b[0m -- [download 20% complete]\n",
      "\u001b[94mcmd1:\u001b[0m -- [download 21% complete]\n",
      "\u001b[94mcmd1:\u001b[0m -- [download 22% complete]\n",
      "\u001b[94mcmd1:\u001b[0m -- [download 23% complete]\n",
      "\u001b[94mcmd1:\u001b[0m -- [download 24% complete]\n",
      "\u001b[94mcmd1:\u001b[0m -- [download 25% complete]\n",
      "\u001b[94mcmd1:\u001b[0m -- [download 26% complete]\n",
      "\u001b[94mcmd1:\u001b[0m -- [download 27% complete]\n",
      "\u001b[94mcmd1:\u001b[0m -- [download 28% complete]\n",
      "\u001b[94mcmd1:\u001b[0m -- [download 29% complete]\n",
      "\u001b[94mcmd1:\u001b[0m -- [download 30% complete]\n",
      "\u001b[94mcmd1:\u001b[0m -- [download 31% complete]\n",
      "\u001b[94mcmd1:\u001b[0m -- [download 32% complete]\n",
      "\u001b[94mcmd1:\u001b[0m -- [download 33% complete]\n",
      "\u001b[94mcmd1:\u001b[0m -- [download 34% complete]\n",
      "\u001b[94mcmd1:\u001b[0m -- [download 35% complete]\n",
      "\u001b[94mcmd1:\u001b[0m -- [download 36% complete]\n",
      "\u001b[94mcmd1:\u001b[0m -- [download 37% complete]\n",
      "\u001b[94mcmd1:\u001b[0m -- [download 38% complete]\n",
      "\u001b[94mcmd1:\u001b[0m -- [download 39% complete]\n",
      "\u001b[94mcmd1:\u001b[0m -- [download 40% complete]\n",
      "\u001b[94mcmd1:\u001b[0m -- [download 41% complete]\n",
      "\u001b[94mcmd1:\u001b[0m -- [download 42% complete]\n",
      "\u001b[94mcmd1:\u001b[0m -- [download 43% complete]\n",
      "\u001b[94mcmd1:\u001b[0m -- [download 44% complete]\n",
      "\u001b[94mcmd1:\u001b[0m -- [download 45% complete]\n",
      "\u001b[94mcmd1:\u001b[0m -- [download 46% complete]\n",
      "\u001b[94mcmd1:\u001b[0m -- [download 47% complete]\n",
      "\u001b[94mcmd1:\u001b[0m -- [download 48% complete]\n",
      "\u001b[94mcmd1:\u001b[0m -- [download 49% complete]\n",
      "\u001b[94mcmd1:\u001b[0m -- [download 50% complete]\n",
      "\u001b[94mcmd1:\u001b[0m -- [download 51% complete]\n",
      "\u001b[94mcmd1:\u001b[0m -- [download 52% complete]\n",
      "\u001b[94mcmd1:\u001b[0m -- [download 53% complete]\n",
      "\u001b[94mcmd1:\u001b[0m -- [download 54% complete]\n",
      "\u001b[94mcmd1:\u001b[0m -- [download 55% complete]\n",
      "\u001b[94mcmd1:\u001b[0m -- [download 56% complete]\n",
      "\u001b[94mcmd1:\u001b[0m -- [download 57% complete]\n",
      "\u001b[94mcmd1:\u001b[0m -- [download 58% complete]\n",
      "\u001b[94mcmd1:\u001b[0m -- [download 59% complete]\n",
      "\u001b[94mcmd1:\u001b[0m -- [download 60% complete]\n",
      "\u001b[94mcmd1:\u001b[0m -- [download 61% complete]\n",
      "\u001b[94mcmd1:\u001b[0m -- [download 62% complete]\n",
      "\u001b[94mcmd1:\u001b[0m -- [download 63% complete]\n",
      "\u001b[94mcmd1:\u001b[0m -- [download 64% complete]\n",
      "\u001b[94mcmd1:\u001b[0m -- [download 65% complete]\n",
      "\u001b[94mcmd1:\u001b[0m -- [download 66% complete]\n",
      "\u001b[94mcmd1:\u001b[0m -- [download 67% complete]\n",
      "\u001b[94mcmd1:\u001b[0m -- [download 68% complete]\n",
      "\u001b[94mcmd1:\u001b[0m -- [download 69% complete]\n",
      "\u001b[94mcmd1:\u001b[0m -- [download 70% complete]\n",
      "\u001b[94mcmd1:\u001b[0m -- [download 71% complete]\n",
      "\u001b[94mcmd1:\u001b[0m -- [download 72% complete]\n",
      "\u001b[94mcmd1:\u001b[0m -- [download 73% complete]\n",
      "\u001b[94mcmd1:\u001b[0m -- [download 74% complete]\n",
      "\u001b[94mcmd1:\u001b[0m -- [download 75% complete]\n",
      "\u001b[94mcmd1:\u001b[0m -- [download 76% complete]\n",
      "\u001b[94mcmd1:\u001b[0m -- [download 77% complete]\n",
      "\u001b[94mcmd1:\u001b[0m -- [download 78% complete]\n",
      "\u001b[94mcmd1:\u001b[0m -- [download 79% complete]\n",
      "\u001b[94mcmd1:\u001b[0m -- [download 80% complete]\n",
      "\u001b[94mcmd1:\u001b[0m -- [download 81% complete]\n",
      "\u001b[94mcmd1:\u001b[0m -- [download 82% complete]\n",
      "\u001b[94mcmd1:\u001b[0m -- [download 83% complete]\n",
      "\u001b[94mcmd1:\u001b[0m -- [download 84% complete]\n",
      "\u001b[94mcmd1:\u001b[0m -- [download 85% complete]\n",
      "\u001b[94mcmd1:\u001b[0m -- [download 86% complete]\n",
      "\u001b[94mcmd1:\u001b[0m -- [download 87% complete]\n",
      "\u001b[94mcmd1:\u001b[0m -- [download 88% complete]\n",
      "\u001b[94mcmd1:\u001b[0m -- [download 89% complete]\n",
      "\u001b[94mcmd1:\u001b[0m -- [download 90% complete]\n",
      "\u001b[94mcmd1:\u001b[0m -- [download 91% complete]\n",
      "\u001b[94mcmd1:\u001b[0m -- [download 92% complete]\n",
      "\u001b[94mcmd1:\u001b[0m -- [download 93% complete]\n",
      "\u001b[94mcmd1:\u001b[0m -- [download 94% complete]\n",
      "\u001b[94mcmd1:\u001b[0m -- [download 95% complete]\n",
      "\u001b[94mcmd1:\u001b[0m -- [download 96% complete]\n",
      "\u001b[94mcmd1:\u001b[0m -- [download 97% complete]\n",
      "\u001b[94mcmd1:\u001b[0m -- [download 98% complete]\n",
      "\u001b[94mcmd1:\u001b[0m -- [download 99% complete]\n",
      "\u001b[94mcmd1:\u001b[0m -- [download 100% complete]\n",
      "\u001b[94mcmd1:\u001b[0m -- verifying file...\n",
      "\u001b[94mcmd1:\u001b[0m        file='/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/libtorch-subbuild/libtorch-populate-prefix/src/libtorch-shared-with-deps-1.13.1%2Bcpu.zip'\n",
      "\u001b[94mcmd1:\u001b[0m -- Downloading... done\n",
      "\u001b[94mcmd1:\u001b[0m -- extracting...\n",
      "\u001b[94mcmd1:\u001b[0m      src='/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/libtorch-subbuild/libtorch-populate-prefix/src/libtorch-shared-with-deps-1.13.1%2Bcpu.zip'\n",
      "\u001b[94mcmd1:\u001b[0m      dst='/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/libtorch-src'\n",
      "\u001b[94mcmd1:\u001b[0m -- extracting... [tar xfz]\n",
      "\u001b[94mcmd1:\u001b[0m -- extracting... [analysis]\n",
      "\u001b[94mcmd1:\u001b[0m -- extracting... [rename]\n",
      "\u001b[94mcmd1:\u001b[0m -- extracting... [clean up]\n",
      "\u001b[94mcmd1:\u001b[0m -- extracting... done\n",
      "\u001b[94mcmd1:\u001b[0m [ 33%] No update step for 'libtorch-populate'\n",
      "\u001b[94mcmd1:\u001b[0m [ 44%] No patch step for 'libtorch-populate'\n",
      "\u001b[94mcmd1:\u001b[0m [ 55%] No configure step for 'libtorch-populate'\n",
      "\u001b[94mcmd1:\u001b[0m [ 66%] No build step for 'libtorch-populate'\n",
      "\u001b[94mcmd1:\u001b[0m [ 77%] No install step for 'libtorch-populate'\n",
      "\u001b[94mcmd1:\u001b[0m [ 88%] No test step for 'libtorch-populate'\n",
      "\u001b[94mcmd1:\u001b[0m [100%] Completed 'libtorch-populate'\n",
      "\u001b[94mcmd1:\u001b[0m [100%] Built target libtorch-populate\n",
      "\u001b[94mcmd1:\u001b[0m -- Found Torch: /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/libtorch-src/lib/libtorch.so\n",
      "\u001b[94mcmd1:\u001b[0m CMake Warning (dev) at /usr/local/lib/python3.11/dist-packages/cmake/data/share/cmake-3.31/Modules/ExternalProject/shared_internal_commands.cmake:1276 (message):\n",
      "\u001b[94mcmd1:\u001b[0m   The DOWNLOAD_EXTRACT_TIMESTAMP option was not given and policy CMP0135 is\n",
      "\u001b[94mcmd1:\u001b[0m   not set.  The policy's OLD behavior will be used.  When using a URL\n",
      "\u001b[94mcmd1:\u001b[0m   download, the timestamps of extracted files should preferably be that of\n",
      "\u001b[94mcmd1:\u001b[0m   the time of extraction, otherwise code that depends on the extracted\n",
      "\u001b[94mcmd1:\u001b[0m   contents might not be rebuilt if the URL changes.  The OLD behavior\n",
      "\u001b[94mcmd1:\u001b[0m   preserves the timestamps from the archive instead, but this is usually not\n",
      "\u001b[94mcmd1:\u001b[0m   what you want.  Update your project to the NEW behavior or specify the\n",
      "\u001b[94mcmd1:\u001b[0m   DOWNLOAD_EXTRACT_TIMESTAMP option with a value of true to avoid this\n",
      "\u001b[94mcmd1:\u001b[0m   robustness issue.\n",
      "\u001b[94mcmd1:\u001b[0m Call Stack (most recent call first):\n",
      "\u001b[94mcmd1:\u001b[0m   /usr/local/lib/python3.11/dist-packages/cmake/data/share/cmake-3.31/Modules/ExternalProject.cmake:3041 (_ep_add_download_command)\n",
      "\u001b[94mcmd1:\u001b[0m   CMakeLists.txt:111 (ExternalProject_Add)\n",
      "\u001b[94mcmd1:\u001b[0m This warning is for project developers.  Use -Wno-dev to suppress it.\n",
      "\u001b[94mcmd1:\u001b[0m \n",
      "\u001b[94mcmd1:\u001b[0m CMake Deprecation Warning at pybind11/CMakeLists.txt:8 (cmake_minimum_required):\n",
      "\u001b[94mcmd1:\u001b[0m   Compatibility with CMake < 3.10 will be removed from a future version of\n",
      "\u001b[94mcmd1:\u001b[0m   CMake.\n",
      "\u001b[94mcmd1:\u001b[0m \n",
      "\u001b[94mcmd1:\u001b[0m   Update the VERSION argument <min> value.  Or, use the <min>...<max> syntax\n",
      "\u001b[94mcmd1:\u001b[0m   to tell CMake that the project requires at least <min> but has been updated\n",
      "\u001b[94mcmd1:\u001b[0m   to work with policies introduced by <max> or earlier.\n",
      "\u001b[94mcmd1:\u001b[0m \n",
      "\u001b[94mcmd1:\u001b[0m \n",
      "\u001b[94mcmd1:\u001b[0m -- pybind11 v2.9.0 dev1\n",
      "\u001b[94mcmd1:\u001b[0m CMake Warning (dev) at pybind11/tools/FindPythonLibsNew.cmake:98 (find_package):\n",
      "\u001b[94mcmd1:\u001b[0m   Policy CMP0148 is not set: The FindPythonInterp and FindPythonLibs modules\n",
      "\u001b[94mcmd1:\u001b[0m   are removed.  Run \"cmake --help-policy CMP0148\" for policy details.  Use\n",
      "\u001b[94mcmd1:\u001b[0m   the cmake_policy command to set the policy and suppress this warning.\n",
      "\u001b[94mcmd1:\u001b[0m \n",
      "\u001b[94mcmd1:\u001b[0m Call Stack (most recent call first):\n",
      "\u001b[94mcmd1:\u001b[0m   pybind11/tools/pybind11Tools.cmake:50 (find_package)\n",
      "\u001b[94mcmd1:\u001b[0m   pybind11/tools/pybind11Common.cmake:206 (include)\n",
      "\u001b[94mcmd1:\u001b[0m   pybind11/CMakeLists.txt:198 (include)\n",
      "\u001b[94mcmd1:\u001b[0m This warning is for project developers.  Use -Wno-dev to suppress it.\n",
      "\u001b[94mcmd1:\u001b[0m \n",
      "\u001b[94mcmd1:\u001b[0m -- Found PythonLibs: /root/miniconda3/envs/b2txt25_lm/lib/libpython3.9.so\n",
      "\u001b[94mcmd1:\u001b[0m -- Performing Test HAS_FLTO\n",
      "\u001b[94mcmd1:\u001b[0m -- Performing Test HAS_FLTO - Success\n",
      "\u001b[94mcmd1:\u001b[0m -- Configuring done (27.2s)\n",
      "\u001b[94mcmd1:\u001b[0m -- Generating done (0.1s)\n",
      "\u001b[94mcmd1:\u001b[0m CMake Warning:\n",
      "\u001b[94mcmd1:\u001b[0m   Manually-specified variables were not used by the project:\n",
      "\u001b[94mcmd1:\u001b[0m \n",
      "\u001b[94mcmd1:\u001b[0m     EXAMPLE_VERSION_INFO\n",
      "\u001b[94mcmd1:\u001b[0m \n",
      "\u001b[94mcmd1:\u001b[0m \n",
      "\u001b[94mcmd1:\u001b[0m -- Build files have been written to: /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/build/temp.linux-x86_64-cpython-39\n",
      "\u001b[94mcmd1:\u001b[0m /usr/local/lib/python3.11/dist-packages/cmake/data/bin/cmake -S/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86 -B/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/build/temp.linux-x86_64-cpython-39 --check-build-system CMakeFiles/Makefile.cmake 0\n",
      "\u001b[94mcmd1:\u001b[0m /usr/bin/gmake  -f CMakeFiles/Makefile2 lm_decoder\n",
      "\u001b[94mcmd1:\u001b[0m gmake[1]: Entering directory '/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/build/temp.linux-x86_64-cpython-39'\n",
      "\u001b[94mcmd1:\u001b[0m /usr/local/lib/python3.11/dist-packages/cmake/data/bin/cmake -S/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86 -B/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/build/temp.linux-x86_64-cpython-39 --check-build-system CMakeFiles/Makefile.cmake 0\n",
      "\u001b[94mcmd1:\u001b[0m /usr/local/lib/python3.11/dist-packages/cmake/data/bin/cmake -E cmake_progress_start /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/build/temp.linux-x86_64-cpython-39/CMakeFiles 33\n",
      "\u001b[94mcmd1:\u001b[0m /usr/bin/gmake  -f CMakeFiles/Makefile2 CMakeFiles/lm_decoder.dir/all\n",
      "\u001b[94mcmd1:\u001b[0m gmake[2]: Entering directory '/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/build/temp.linux-x86_64-cpython-39'\n",
      "\u001b[94mcmd1:\u001b[0m /usr/bin/gmake  -f /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/CMakeFiles/gflags_nothreads_static.dir/build.make /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/CMakeFiles/gflags_nothreads_static.dir/depend\n",
      "\u001b[94mcmd1:\u001b[0m gmake[3]: Entering directory '/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/build/temp.linux-x86_64-cpython-39'\n",
      "\u001b[94mcmd1:\u001b[0m cd /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/build/temp.linux-x86_64-cpython-39 && /usr/local/lib/python3.11/dist-packages/cmake/data/bin/cmake -E cmake_depends \"Unix Makefiles\" /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86 /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-src /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/build/temp.linux-x86_64-cpython-39 /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/CMakeFiles/gflags_nothreads_static.dir/DependInfo.cmake \"--color=\"\n",
      "\u001b[94mcmd1:\u001b[0m gmake[3]: Leaving directory '/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/build/temp.linux-x86_64-cpython-39'\n",
      "\u001b[94mcmd1:\u001b[0m /usr/bin/gmake  -f /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/CMakeFiles/gflags_nothreads_static.dir/build.make /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/CMakeFiles/gflags_nothreads_static.dir/build\n",
      "\u001b[94mcmd1:\u001b[0m gmake[3]: Entering directory '/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/build/temp.linux-x86_64-cpython-39'\n",
      "\u001b[94mcmd1:\u001b[0m [  0%] Building CXX object /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/CMakeFiles/gflags_nothreads_static.dir/src/gflags.cc.o\n",
      "\u001b[94mcmd1:\u001b[0m cd /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build && /usr/bin/c++ -DGFLAGS_IS_A_DLL=0 -DNO_THREADS -D_GLIBCXX_USE_CXX11_ABI=0 -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86 -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/kaldi -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include/gflags -std=c++14 -pthread -fPIC -O3 -DNDEBUG -MD -MT /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/CMakeFiles/gflags_nothreads_static.dir/src/gflags.cc.o -MF CMakeFiles/gflags_nothreads_static.dir/src/gflags.cc.o.d -o CMakeFiles/gflags_nothreads_static.dir/src/gflags.cc.o -c /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-src/src/gflags.cc\n",
      "\u001b[94mcmd1:\u001b[0m [  3%] Building CXX object /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/CMakeFiles/gflags_nothreads_static.dir/src/gflags_reporting.cc.o\n",
      "\u001b[94mcmd1:\u001b[0m cd /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build && /usr/bin/c++ -DGFLAGS_IS_A_DLL=0 -DNO_THREADS -D_GLIBCXX_USE_CXX11_ABI=0 -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86 -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/kaldi -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include/gflags -std=c++14 -pthread -fPIC -O3 -DNDEBUG -MD -MT /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/CMakeFiles/gflags_nothreads_static.dir/src/gflags_reporting.cc.o -MF CMakeFiles/gflags_nothreads_static.dir/src/gflags_reporting.cc.o.d -o CMakeFiles/gflags_nothreads_static.dir/src/gflags_reporting.cc.o -c /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-src/src/gflags_reporting.cc\n",
      "\u001b[94mcmd1:\u001b[0m [  6%] Building CXX object /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/CMakeFiles/gflags_nothreads_static.dir/src/gflags_completions.cc.o\n",
      "\u001b[94mcmd1:\u001b[0m cd /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build && /usr/bin/c++ -DGFLAGS_IS_A_DLL=0 -DNO_THREADS -D_GLIBCXX_USE_CXX11_ABI=0 -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86 -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/kaldi -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include/gflags -std=c++14 -pthread -fPIC -O3 -DNDEBUG -MD -MT /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/CMakeFiles/gflags_nothreads_static.dir/src/gflags_completions.cc.o -MF CMakeFiles/gflags_nothreads_static.dir/src/gflags_completions.cc.o.d -o CMakeFiles/gflags_nothreads_static.dir/src/gflags_completions.cc.o -c /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-src/src/gflags_completions.cc\n",
      "\u001b[94mcmd1:\u001b[0m [  6%] Linking CXX static library libgflags_nothreads.a\n",
      "\u001b[94mcmd1:\u001b[0m cd /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build && /usr/local/lib/python3.11/dist-packages/cmake/data/bin/cmake -P CMakeFiles/gflags_nothreads_static.dir/cmake_clean_target.cmake\n",
      "\u001b[94mcmd1:\u001b[0m cd /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build && /usr/local/lib/python3.11/dist-packages/cmake/data/bin/cmake -E cmake_link_script CMakeFiles/gflags_nothreads_static.dir/link.txt --verbose=1\n",
      "\u001b[94mcmd1:\u001b[0m /usr/bin/ar qc libgflags_nothreads.a CMakeFiles/gflags_nothreads_static.dir/src/gflags.cc.o CMakeFiles/gflags_nothreads_static.dir/src/gflags_reporting.cc.o CMakeFiles/gflags_nothreads_static.dir/src/gflags_completions.cc.o\n",
      "\u001b[94mcmd1:\u001b[0m /usr/bin/ranlib libgflags_nothreads.a\n",
      "\u001b[94mcmd1:\u001b[0m gmake[3]: Leaving directory '/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/build/temp.linux-x86_64-cpython-39'\n",
      "\u001b[94mcmd1:\u001b[0m [  6%] Built target gflags_nothreads_static\n",
      "\u001b[94mcmd1:\u001b[0m /usr/bin/gmake  -f /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build/CMakeFiles/glog.dir/build.make /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build/CMakeFiles/glog.dir/depend\n",
      "\u001b[94mcmd1:\u001b[0m gmake[3]: Entering directory '/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/build/temp.linux-x86_64-cpython-39'\n",
      "\u001b[94mcmd1:\u001b[0m cd /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/build/temp.linux-x86_64-cpython-39 && /usr/local/lib/python3.11/dist-packages/cmake/data/bin/cmake -E cmake_depends \"Unix Makefiles\" /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86 /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/build/temp.linux-x86_64-cpython-39 /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build/CMakeFiles/glog.dir/DependInfo.cmake \"--color=\"\n",
      "\u001b[94mcmd1:\u001b[0m gmake[3]: Leaving directory '/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/build/temp.linux-x86_64-cpython-39'\n",
      "\u001b[94mcmd1:\u001b[0m /usr/bin/gmake  -f /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build/CMakeFiles/glog.dir/build.make /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build/CMakeFiles/glog.dir/build\n",
      "\u001b[94mcmd1:\u001b[0m gmake[3]: Entering directory '/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/build/temp.linux-x86_64-cpython-39'\n",
      "\u001b[94mcmd1:\u001b[0m [  9%] Building CXX object /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build/CMakeFiles/glog.dir/src/demangle.cc.o\n",
      "\u001b[94mcmd1:\u001b[0m cd /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build && /usr/bin/c++ -DGOOGLE_GLOG_DLL_DECL=\"\" -D_GLIBCXX_USE_CXX11_ABI=0 -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86 -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/kaldi -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -std=c++14 -pthread -fPIC -O3 -DNDEBUG -fPIC -fvisibility=default -fvisibility-inlines-hidden -MD -MT /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build/CMakeFiles/glog.dir/src/demangle.cc.o -MF CMakeFiles/glog.dir/src/demangle.cc.o.d -o CMakeFiles/glog.dir/src/demangle.cc.o -c /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src/demangle.cc\n",
      "\u001b[94mcmd1:\u001b[0m [ 12%] Building CXX object /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build/CMakeFiles/glog.dir/src/logging.cc.o\n",
      "\u001b[94mcmd1:\u001b[0m cd /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build && /usr/bin/c++ -DGOOGLE_GLOG_DLL_DECL=\"\" -D_GLIBCXX_USE_CXX11_ABI=0 -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86 -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/kaldi -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -std=c++14 -pthread -fPIC -O3 -DNDEBUG -fPIC -fvisibility=default -fvisibility-inlines-hidden -MD -MT /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build/CMakeFiles/glog.dir/src/logging.cc.o -MF CMakeFiles/glog.dir/src/logging.cc.o.d -o CMakeFiles/glog.dir/src/logging.cc.o -c /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src/logging.cc\n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Successfully installed PyYAML-6.0.3 accelerate-1.8.1 antlr4-python3-runtime-4.9.3 anyio-4.12.0 argon2-cffi-25.1.0 argon2-cffi-bindings-25.1.0 arrow-1.4.0 asttokens-3.0.1 async-lru-2.0.5 async-timeout-5.0.1 attrs-25.4.0 babel-2.17.0 beautifulsoup4-4.14.3 bitsandbytes-0.46.0 bleach-6.3.0 certifi-2025.11.12 cffi-2.0.0 charset_normalizer-3.4.4 click-8.3.1 comm-0.2.3 contourpy-1.3.2 cycler-0.12.1 debugpy-1.8.19 decorator-5.2.1 defusedxml-0.7.1 distance-0.1.3 editdistance-0.8.1 exceptiongroup-1.3.1 executing-2.2.1 fastjsonschema-2.21.2 fonttools-4.61.1 fqdn-1.5.1 g2p_en-2.1.0 h11-0.16.0 h5py-3.13.0 hf-xet-1.2.0 httpcore-1.0.9 httpx-0.28.1 huggingface-hub-0.33.1 idna-3.11 inflect-7.5.0 ipykernel-7.1.0 ipython-8.37.0 ipywidgets-8.1.8 isoduration-20.11.0 jedi-0.19.2 joblib-1.5.3 json5-0.12.1 jsonpointer-3.0.0 jsonschema-4.25.1 jsonschema-specifications-2025.9.1 jupyter-1.1.1 jupyter-client-8.7.0 jupyter-console-6.6.3 jupyter-core-5.9.1 jupyter-events-0.12.0 jupyter-lsp-2.3.0 jupyter-server-2.17.0 jupyter-server-terminals-0.5.3 jupyterlab-4.5.1 jupyterlab-pygments-0.3.0 jupyterlab-server-2.28.0 jupyterlab_widgets-3.0.16 kiwisolver-1.4.9 lark-1.3.1 matplotlib-3.10.1 matplotlib-inline-0.2.1 mistune-3.2.0 more_itertools-10.8.0 nbclient-0.10.4 nbconvert-7.16.6 nbformat-5.10.4 nejm_b2txt_utils-0.0.0 nest-asyncio-1.6.0 nltk-3.9.2 notebook-7.5.1 notebook-shim-0.2.4 numpy-2.1.2 omegaconf-2.3.0 overrides-7.7.0 packaging-25.0 pandas-2.3.0 pandocfilters-1.5.1 parso-0.8.5 pexpect-4.9.0 platformdirs-4.5.1 prometheus-client-0.23.1 prompt_toolkit-3.0.52 psutil-7.2.0 ptyprocess-0.7.0 pure-eval-0.2.3 pycparser-2.23 pygments-2.19.2 pyparsing-3.3.1 python-dateutil-2.9.0.post0 python-json-logger-4.0.0 pytz-2025.2 pyzmq-27.1.0 redis-5.2.1 referencing-0.37.0 regex-2025.11.3 requests-2.32.5 rfc3339-validator-0.1.4 rfc3986-validator-0.1.1 rfc3987-syntax-1.1.0 rpds-py-0.30.0 safetensors-0.7.0 scikit-learn-1.6.1 scipy-1.15.2 send2trash-1.8.3 six-1.17.0 soupsieve-2.8.1 stack_data-0.6.3 terminado-0.18.1 threadpoolctl-3.6.0 tinycss2-1.4.0 tokenizers-0.21.2 tomli-2.3.0 tornado-6.5.4 tqdm-4.67.1 traitlets-5.14.3 transformers-4.53.0 typeguard-4.4.4 tzdata-2025.3 uri-template-1.3.0 urllib3-2.6.2 wcwidth-0.2.14 webcolors-25.10.0 webencodings-0.5.1 websocket-client-1.9.0 widgetsnbextension-4.0.15\n",
      "\u001b[94mcmd1:\u001b[0m [ 12%] Building CXX object /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build/CMakeFiles/glog.dir/src/raw_logging.cc.o\n",
      "\u001b[94mcmd1:\u001b[0m cd /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build && /usr/bin/c++ -DGOOGLE_GLOG_DLL_DECL=\"\" -D_GLIBCXX_USE_CXX11_ABI=0 -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86 -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/kaldi -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -std=c++14 -pthread -fPIC -O3 -DNDEBUG -fPIC -fvisibility=default -fvisibility-inlines-hidden -MD -MT /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build/CMakeFiles/glog.dir/src/raw_logging.cc.o -MF CMakeFiles/glog.dir/src/raw_logging.cc.o.d -o CMakeFiles/glog.dir/src/raw_logging.cc.o -c /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src/raw_logging.cc\n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Setup complete! Verify it worked by activating the conda environment with the command 'conda activate b2txt25'.\n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[94mcmd1:\u001b[0m [ 15%] Building CXX object /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build/CMakeFiles/glog.dir/src/symbolize.cc.o\n",
      "\u001b[94mcmd1:\u001b[0m cd /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build && /usr/bin/c++ -DGOOGLE_GLOG_DLL_DECL=\"\" -D_GLIBCXX_USE_CXX11_ABI=0 -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86 -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/kaldi -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -std=c++14 -pthread -fPIC -O3 -DNDEBUG -fPIC -fvisibility=default -fvisibility-inlines-hidden -MD -MT /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build/CMakeFiles/glog.dir/src/symbolize.cc.o -MF CMakeFiles/glog.dir/src/symbolize.cc.o.d -o CMakeFiles/glog.dir/src/symbolize.cc.o -c /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src/symbolize.cc\n",
      "\u001b[94mcmd1:\u001b[0m [ 18%] Building CXX object /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build/CMakeFiles/glog.dir/src/utilities.cc.o\n",
      "\u001b[94mcmd1:\u001b[0m cd /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build && /usr/bin/c++ -DGOOGLE_GLOG_DLL_DECL=\"\" -D_GLIBCXX_USE_CXX11_ABI=0 -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86 -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/kaldi -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -std=c++14 -pthread -fPIC -O3 -DNDEBUG -fPIC -fvisibility=default -fvisibility-inlines-hidden -MD -MT /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build/CMakeFiles/glog.dir/src/utilities.cc.o -MF CMakeFiles/glog.dir/src/utilities.cc.o.d -o CMakeFiles/glog.dir/src/utilities.cc.o -c /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src/utilities.cc\n",
      "\u001b[94mcmd1:\u001b[0m [ 21%] Building CXX object /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build/CMakeFiles/glog.dir/src/vlog_is_on.cc.o\n",
      "\u001b[94mcmd1:\u001b[0m cd /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build && /usr/bin/c++ -DGOOGLE_GLOG_DLL_DECL=\"\" -D_GLIBCXX_USE_CXX11_ABI=0 -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86 -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/kaldi -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -std=c++14 -pthread -fPIC -O3 -DNDEBUG -fPIC -fvisibility=default -fvisibility-inlines-hidden -MD -MT /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build/CMakeFiles/glog.dir/src/vlog_is_on.cc.o -MF CMakeFiles/glog.dir/src/vlog_is_on.cc.o.d -o CMakeFiles/glog.dir/src/vlog_is_on.cc.o -c /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src/vlog_is_on.cc\n",
      "\u001b[94mcmd1:\u001b[0m [ 21%] Building CXX object /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build/CMakeFiles/glog.dir/src/signalhandler.cc.o\n",
      "\u001b[94mcmd1:\u001b[0m cd /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build && /usr/bin/c++ -DGOOGLE_GLOG_DLL_DECL=\"\" -D_GLIBCXX_USE_CXX11_ABI=0 -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86 -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/kaldi -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -std=c++14 -pthread -fPIC -O3 -DNDEBUG -fPIC -fvisibility=default -fvisibility-inlines-hidden -MD -MT /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build/CMakeFiles/glog.dir/src/signalhandler.cc.o -MF CMakeFiles/glog.dir/src/signalhandler.cc.o.d -o CMakeFiles/glog.dir/src/signalhandler.cc.o -c /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src/signalhandler.cc\n",
      "\u001b[94mcmd1:\u001b[0m [ 24%] Linking CXX static library libglog.a\n",
      "\u001b[94mcmd1:\u001b[0m cd /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build && /usr/local/lib/python3.11/dist-packages/cmake/data/bin/cmake -P CMakeFiles/glog.dir/cmake_clean_target.cmake\n",
      "\u001b[94mcmd1:\u001b[0m cd /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build && /usr/local/lib/python3.11/dist-packages/cmake/data/bin/cmake -E cmake_link_script CMakeFiles/glog.dir/link.txt --verbose=1\n",
      "\u001b[94mcmd1:\u001b[0m /usr/bin/ar qc libglog.a CMakeFiles/glog.dir/src/demangle.cc.o CMakeFiles/glog.dir/src/logging.cc.o CMakeFiles/glog.dir/src/raw_logging.cc.o CMakeFiles/glog.dir/src/symbolize.cc.o CMakeFiles/glog.dir/src/utilities.cc.o CMakeFiles/glog.dir/src/vlog_is_on.cc.o CMakeFiles/glog.dir/src/signalhandler.cc.o\n",
      "\u001b[94mcmd1:\u001b[0m /usr/bin/ranlib libglog.a\n",
      "\u001b[94mcmd1:\u001b[0m gmake[3]: Leaving directory '/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/build/temp.linux-x86_64-cpython-39'\n",
      "\u001b[94mcmd1:\u001b[0m [ 24%] Built target glog\n",
      "\u001b[94mcmd1:\u001b[0m /usr/bin/gmake  -f CMakeFiles/openfst.dir/build.make CMakeFiles/openfst.dir/depend\n",
      "\u001b[94mcmd1:\u001b[0m gmake[3]: Entering directory '/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/build/temp.linux-x86_64-cpython-39'\n",
      "\u001b[94mcmd1:\u001b[0m cd /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/build/temp.linux-x86_64-cpython-39 && /usr/local/lib/python3.11/dist-packages/cmake/data/bin/cmake -E cmake_depends \"Unix Makefiles\" /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86 /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86 /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/build/temp.linux-x86_64-cpython-39 /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/build/temp.linux-x86_64-cpython-39 /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/build/temp.linux-x86_64-cpython-39/CMakeFiles/openfst.dir/DependInfo.cmake \"--color=\"\n",
      "\u001b[94mcmd1:\u001b[0m gmake[3]: Leaving directory '/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/build/temp.linux-x86_64-cpython-39'\n",
      "\u001b[94mcmd1:\u001b[0m /usr/bin/gmake  -f CMakeFiles/openfst.dir/build.make CMakeFiles/openfst.dir/build\n",
      "\u001b[94mcmd1:\u001b[0m gmake[3]: Entering directory '/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/build/temp.linux-x86_64-cpython-39'\n",
      "\u001b[94mcmd1:\u001b[0m [ 24%] Creating directories for 'openfst'\n",
      "\u001b[94mcmd1:\u001b[0m /usr/local/lib/python3.11/dist-packages/cmake/data/bin/cmake -Dcfgdir= -P /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/build/temp.linux-x86_64-cpython-39/openfst-prefix/tmp/openfst-mkdirs.cmake\n",
      "\u001b[94mcmd1:\u001b[0m /usr/local/lib/python3.11/dist-packages/cmake/data/bin/cmake -E touch /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/build/temp.linux-x86_64-cpython-39/openfst-prefix/src/openfst-stamp/openfst-mkdir\n",
      "\u001b[94mcmd1:\u001b[0m [ 27%] Performing download step (download, verify and extract) for 'openfst'\n",
      "\u001b[94mcmd1:\u001b[0m cd /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base && /usr/local/lib/python3.11/dist-packages/cmake/data/bin/cmake -DCMAKE_MESSAGE_LOG_LEVEL=VERBOSE -P /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/build/temp.linux-x86_64-cpython-39/openfst-prefix/src/openfst-stamp/download-openfst.cmake\n",
      "\u001b[94mcmd1:\u001b[0m -- Downloading...\n",
      "\u001b[94mcmd1:\u001b[0m    dst='/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/build/temp.linux-x86_64-cpython-39/openfst-prefix/src/1.6.5.zip'\n",
      "\u001b[94mcmd1:\u001b[0m    timeout='none'\n",
      "\u001b[94mcmd1:\u001b[0m    inactivity timeout='none'\n",
      "\u001b[94mcmd1:\u001b[0m -- Using src='https://github.com/mjansche/openfst/archive/1.6.5.zip'\n",
      "\u001b[94mcmd1:\u001b[0m -- verifying file...\n",
      "\u001b[94mcmd1:\u001b[0m        file='/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/build/temp.linux-x86_64-cpython-39/openfst-prefix/src/1.6.5.zip'\n",
      "\u001b[94mcmd1:\u001b[0m -- Downloading... done\n",
      "\u001b[94mcmd1:\u001b[0m cd /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base && /usr/local/lib/python3.11/dist-packages/cmake/data/bin/cmake -DCMAKE_MESSAGE_LOG_LEVEL=VERBOSE -P /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/build/temp.linux-x86_64-cpython-39/openfst-prefix/src/openfst-stamp/verify-openfst.cmake\n",
      "\u001b[94mcmd1:\u001b[0m cd /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base && /usr/local/lib/python3.11/dist-packages/cmake/data/bin/cmake -DCMAKE_MESSAGE_LOG_LEVEL=VERBOSE -P /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/build/temp.linux-x86_64-cpython-39/openfst-prefix/src/openfst-stamp/extract-openfst.cmake\n",
      "\u001b[94mcmd1:\u001b[0m -- extracting...\n",
      "\u001b[94mcmd1:\u001b[0m      src='/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/build/temp.linux-x86_64-cpython-39/openfst-prefix/src/1.6.5.zip'\n",
      "\u001b[94mcmd1:\u001b[0m      dst='/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src'\n",
      "\u001b[94mcmd1:\u001b[0m -- extracting... [tar xfz]\n",
      "\u001b[94mcmd1:\u001b[0m -- extracting... [analysis]\n",
      "\u001b[94mcmd1:\u001b[0m -- extracting... [rename]\n",
      "\u001b[94mcmd1:\u001b[0m -- extracting... [clean up]\n",
      "\u001b[94mcmd1:\u001b[0m -- extracting... done\n",
      "\u001b[94mcmd1:\u001b[0m cd /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base && /usr/local/lib/python3.11/dist-packages/cmake/data/bin/cmake -E touch /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/build/temp.linux-x86_64-cpython-39/openfst-prefix/src/openfst-stamp/openfst-download\n",
      "\u001b[94mcmd1:\u001b[0m [ 30%] No update step for 'openfst'\n",
      "\u001b[94mcmd1:\u001b[0m /usr/local/lib/python3.11/dist-packages/cmake/data/bin/cmake -E echo_append\n",
      "\u001b[94mcmd1:\u001b[0m /usr/local/lib/python3.11/dist-packages/cmake/data/bin/cmake -E touch /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/build/temp.linux-x86_64-cpython-39/openfst-prefix/src/openfst-stamp/openfst-update\n",
      "\u001b[94mcmd1:\u001b[0m [ 33%] No patch step for 'openfst'\n",
      "\u001b[94mcmd1:\u001b[0m /usr/local/lib/python3.11/dist-packages/cmake/data/bin/cmake -E echo_append\n",
      "\u001b[94mcmd1:\u001b[0m /usr/local/lib/python3.11/dist-packages/cmake/data/bin/cmake -E touch /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/build/temp.linux-x86_64-cpython-39/openfst-prefix/src/openfst-stamp/openfst-patch\n",
      "\u001b[94mcmd1:\u001b[0m [ 33%] Performing configure step for 'openfst'\n",
      "\u001b[94mcmd1:\u001b[0m cd /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-build && /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/configure --prefix=/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-subbuild/openfst-populate-prefix \"CPPFLAGS=-I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0\" \"LDFLAGS=-L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build\" \"LIBS=-lgflags_nothreads -lglog -lpthread\"\n",
      "\u001b[94mcmd1:\u001b[0m checking for a BSD-compatible install... /usr/bin/install -c\n",
      "\u001b[94mcmd1:\u001b[0m checking whether build environment is sane... yes\n",
      "\u001b[94mcmd1:\u001b[0m checking for a thread-safe mkdir -p... /usr/bin/mkdir -p\n",
      "\u001b[94mcmd1:\u001b[0m checking for gawk... no\n",
      "\u001b[94mcmd1:\u001b[0m checking for mawk... mawk\n",
      "\u001b[94mcmd1:\u001b[0m checking whether make sets $(MAKE)... yes\n",
      "\u001b[94mcmd1:\u001b[0m checking whether make supports nested variables... yes\n",
      "\u001b[94mcmd1:\u001b[0m checking for style of include used by make... GNU\n",
      "\u001b[94mcmd1:\u001b[0m checking for gcc... gcc\n",
      "\u001b[94mcmd1:\u001b[0m checking whether the C compiler works... yes\n",
      "\u001b[94mcmd1:\u001b[0m checking for C compiler default output file name... a.out\n",
      "\u001b[94mcmd1:\u001b[0m checking for suffix of executables... \n",
      "\u001b[94mcmd1:\u001b[0m checking whether we are cross compiling... no\n",
      "\u001b[94mcmd1:\u001b[0m checking for suffix of object files... o\n",
      "\u001b[94mcmd1:\u001b[0m checking whether we are using the GNU C compiler... yes\n",
      "\u001b[94mcmd1:\u001b[0m checking whether gcc accepts -g... yes\n",
      "\u001b[94mcmd1:\u001b[0m checking for gcc option to accept ISO C89... none needed\n",
      "\u001b[94mcmd1:\u001b[0m checking whether gcc understands -c and -o together... yes\n",
      "\u001b[94mcmd1:\u001b[0m checking dependency style of gcc... gcc3\n",
      "\u001b[94mcmd1:\u001b[0m checking for ar... ar\n",
      "\u001b[94mcmd1:\u001b[0m checking the archiver (ar) interface... ar\n",
      "\u001b[94mcmd1:\u001b[0m checking for g++... g++\n",
      "\u001b[92mcmd2:\u001b[0m Using cuda:0 for model inference.\n",
      "\u001b[94mcmd1:\u001b[0m checking whether we are using the GNU C++ compiler... yes\n",
      "\u001b[94mcmd1:\u001b[0m checking whether g++ accepts -g... yes\n",
      "\u001b[94mcmd1:\u001b[0m checking dependency style of g++... gcc3\n",
      "\u001b[94mcmd1:\u001b[0m checking build system type... x86_64-unknown-linux-gnu\n",
      "\u001b[94mcmd1:\u001b[0m checking host system type... x86_64-unknown-linux-gnu\n",
      "\u001b[94mcmd1:\u001b[0m checking how to print strings... printf\n",
      "\u001b[94mcmd1:\u001b[0m checking for a sed that does not truncate output... /usr/bin/sed\n",
      "\u001b[94mcmd1:\u001b[0m checking for grep that handles long lines and -e... /usr/bin/grep\n",
      "\u001b[94mcmd1:\u001b[0m checking for egrep... /usr/bin/grep -E\n",
      "\u001b[94mcmd1:\u001b[0m checking for fgrep... /usr/bin/grep -F\n",
      "\u001b[94mcmd1:\u001b[0m checking for ld used by gcc... /usr/bin/ld\n",
      "\u001b[94mcmd1:\u001b[0m checking if the linker (/usr/bin/ld) is GNU ld... yes\n",
      "\u001b[94mcmd1:\u001b[0m checking for BSD- or MS-compatible name lister (nm)... /usr/bin/nm -B\n",
      "\u001b[94mcmd1:\u001b[0m checking the name lister (/usr/bin/nm -B) interface... BSD nm\n",
      "\u001b[94mcmd1:\u001b[0m checking whether ln -s works... yes\n",
      "\u001b[94mcmd1:\u001b[0m checking the maximum length of command line arguments... 1572864\n",
      "\u001b[94mcmd1:\u001b[0m checking whether the shell understands some XSI constructs... yes\n",
      "\u001b[94mcmd1:\u001b[0m checking whether the shell understands \"+=\"... yes\n",
      "\u001b[94mcmd1:\u001b[0m checking how to convert x86_64-unknown-linux-gnu file names to x86_64-unknown-linux-gnu format... func_convert_file_noop\n",
      "\u001b[94mcmd1:\u001b[0m checking how to convert x86_64-unknown-linux-gnu file names to toolchain format... func_convert_file_noop\n",
      "\u001b[94mcmd1:\u001b[0m checking for /usr/bin/ld option to reload object files... -r\n",
      "\u001b[94mcmd1:\u001b[0m checking for objdump... objdump\n",
      "\u001b[94mcmd1:\u001b[0m checking how to recognize dependent libraries... pass_all\n",
      "\u001b[94mcmd1:\u001b[0m checking for dlltool... no\n",
      "\u001b[94mcmd1:\u001b[0m checking how to associate runtime and link libraries... printf %s\\n\n",
      "\u001b[94mcmd1:\u001b[0m checking for archiver @FILE support... @\n",
      "\u001b[94mcmd1:\u001b[0m checking for strip... strip\n",
      "\u001b[94mcmd1:\u001b[0m checking for ranlib... ranlib\n",
      "\u001b[94mcmd1:\u001b[0m checking command to parse /usr/bin/nm -B output from gcc object... ok\n",
      "\u001b[94mcmd1:\u001b[0m checking for sysroot... no\n",
      "\u001b[94mcmd1:\u001b[0m checking for mt... no\n",
      "\u001b[94mcmd1:\u001b[0m checking if : is a manifest tool... no\n",
      "\u001b[94mcmd1:\u001b[0m checking how to run the C preprocessor... gcc -E\n",
      "\u001b[94mcmd1:\u001b[0m checking for ANSI C header files... yes\n",
      "\u001b[94mcmd1:\u001b[0m checking for sys/types.h... yes\n",
      "\u001b[94mcmd1:\u001b[0m checking for sys/stat.h... yes\n",
      "\u001b[94mcmd1:\u001b[0m checking for stdlib.h... yes\n",
      "\u001b[94mcmd1:\u001b[0m checking for string.h... yes\n",
      "\u001b[94mcmd1:\u001b[0m checking for memory.h... yes\n",
      "\u001b[94mcmd1:\u001b[0m checking for strings.h... yes\n",
      "\u001b[94mcmd1:\u001b[0m checking for inttypes.h... yes\n",
      "\u001b[94mcmd1:\u001b[0m checking for stdint.h... yes\n",
      "\u001b[94mcmd1:\u001b[0m checking for unistd.h... yes\n",
      "\u001b[94mcmd1:\u001b[0m checking for dlfcn.h... yes\n",
      "\u001b[94mcmd1:\u001b[0m checking for objdir... .libs\n",
      "\u001b[94mcmd1:\u001b[0m checking if gcc supports -fno-rtti -fno-exceptions... no\n",
      "\u001b[94mcmd1:\u001b[0m checking for gcc option to produce PIC... -fPIC -DPIC\n",
      "\u001b[94mcmd1:\u001b[0m checking if gcc PIC flag -fPIC -DPIC works... yes\n",
      "\u001b[94mcmd1:\u001b[0m checking if gcc static flag -static works... yes\n",
      "\u001b[94mcmd1:\u001b[0m checking if gcc supports -c -o file.o... yes\n",
      "\u001b[94mcmd1:\u001b[0m checking if gcc supports -c -o file.o... (cached) yes\n",
      "\u001b[94mcmd1:\u001b[0m checking whether the gcc linker (/usr/bin/ld -m elf_x86_64) supports shared libraries... yes\n",
      "\u001b[94mcmd1:\u001b[0m checking whether -lc should be explicitly linked in... no\n",
      "\u001b[94mcmd1:\u001b[0m checking dynamic linker characteristics... GNU/Linux ld.so\n",
      "\u001b[94mcmd1:\u001b[0m checking how to hardcode library paths into programs... immediate\n",
      "\u001b[94mcmd1:\u001b[0m checking whether stripping libraries is possible... yes\n",
      "\u001b[94mcmd1:\u001b[0m checking if libtool supports shared libraries... yes\n",
      "\u001b[94mcmd1:\u001b[0m checking whether to build shared libraries... yes\n",
      "\u001b[94mcmd1:\u001b[0m checking whether to build static libraries... no\n",
      "\u001b[94mcmd1:\u001b[0m checking how to run the C++ preprocessor... g++ -E\n",
      "\u001b[94mcmd1:\u001b[0m checking for ld used by g++... /usr/bin/ld -m elf_x86_64\n",
      "\u001b[94mcmd1:\u001b[0m checking if the linker (/usr/bin/ld -m elf_x86_64) is GNU ld... yes\n",
      "\u001b[94mcmd1:\u001b[0m checking whether the g++ linker (/usr/bin/ld -m elf_x86_64) supports shared libraries... yes\n",
      "\u001b[94mcmd1:\u001b[0m checking for g++ option to produce PIC... -fPIC -DPIC\n",
      "\u001b[94mcmd1:\u001b[0m checking if g++ PIC flag -fPIC -DPIC works... yes\n",
      "\u001b[94mcmd1:\u001b[0m checking if g++ static flag -static works... yes\n",
      "\u001b[94mcmd1:\u001b[0m checking if g++ supports -c -o file.o... yes\n",
      "\u001b[94mcmd1:\u001b[0m checking if g++ supports -c -o file.o... (cached) yes\n",
      "\u001b[94mcmd1:\u001b[0m checking whether the g++ linker (/usr/bin/ld -m elf_x86_64) supports shared libraries... yes\n",
      "\u001b[94mcmd1:\u001b[0m checking dynamic linker characteristics... (cached) GNU/Linux ld.so\n",
      "\u001b[94mcmd1:\u001b[0m checking how to hardcode library paths into programs... immediate\n",
      "\u001b[94mcmd1:\u001b[0m checking for dlopen in -ldl... yes\n",
      "\u001b[94mcmd1:\u001b[0m checking that generated files are newer than configure... done\n",
      "\u001b[94mcmd1:\u001b[0m configure: creating ./config.status\n",
      "\u001b[94mcmd1:\u001b[0m config.status: creating Makefile\n",
      "\u001b[94mcmd1:\u001b[0m config.status: creating src/Makefile\n",
      "\u001b[94mcmd1:\u001b[0m config.status: creating src/include/Makefile\n",
      "\u001b[94mcmd1:\u001b[0m config.status: creating src/lib/Makefile\n",
      "\u001b[94mcmd1:\u001b[0m config.status: creating src/bin/Makefile\n",
      "\u001b[94mcmd1:\u001b[0m config.status: creating src/test/Makefile\n",
      "\u001b[94mcmd1:\u001b[0m config.status: creating src/extensions/Makefile\n",
      "\u001b[94mcmd1:\u001b[0m config.status: creating src/extensions/compact/Makefile\n",
      "\u001b[94mcmd1:\u001b[0m config.status: creating src/extensions/compress/Makefile\n",
      "\u001b[94mcmd1:\u001b[0m config.status: creating src/extensions/const/Makefile\n",
      "\u001b[94mcmd1:\u001b[0m config.status: creating src/extensions/far/Makefile\n",
      "\u001b[94mcmd1:\u001b[0m config.status: creating src/extensions/linear/Makefile\n",
      "\u001b[94mcmd1:\u001b[0m config.status: creating src/extensions/lookahead/Makefile\n",
      "\u001b[94mcmd1:\u001b[0m config.status: creating src/extensions/mpdt/Makefile\n",
      "\u001b[94mcmd1:\u001b[0m config.status: creating src/extensions/ngram/Makefile\n",
      "\u001b[94mcmd1:\u001b[0m config.status: creating src/extensions/pdt/Makefile\n",
      "\u001b[94mcmd1:\u001b[0m config.status: creating src/extensions/python/Makefile\n",
      "\u001b[94mcmd1:\u001b[0m config.status: creating src/extensions/special/Makefile\n",
      "\u001b[94mcmd1:\u001b[0m config.status: creating src/script/Makefile\n",
      "\u001b[94mcmd1:\u001b[0m config.status: creating config.h\n",
      "\u001b[94mcmd1:\u001b[0m config.status: creating src/include/fst/config.h\n",
      "\u001b[94mcmd1:\u001b[0m config.status: executing depfiles commands\n",
      "\u001b[94mcmd1:\u001b[0m config.status: executing libtool commands\n",
      "\u001b[94mcmd1:\u001b[0m cd /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-build && /usr/local/lib/python3.11/dist-packages/cmake/data/bin/cmake -E copy_directory /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/patch/openfst /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src\n",
      "\u001b[94mcmd1:\u001b[0m cd /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-build && /usr/local/lib/python3.11/dist-packages/cmake/data/bin/cmake -E touch /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/build/temp.linux-x86_64-cpython-39/openfst-prefix/src/openfst-stamp/openfst-configure\n",
      "\u001b[94mcmd1:\u001b[0m [ 36%] Performing build step for 'openfst'\n",
      "\u001b[94mcmd1:\u001b[0m cd /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-build && make -j 4\n",
      "\u001b[94mcmd1:\u001b[0m make[4]: Entering directory '/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-build'\n",
      "\u001b[94mcmd1:\u001b[0m make  all-recursive\n",
      "\u001b[94mcmd1:\u001b[0m make[5]: Entering directory '/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-build'\n",
      "\u001b[94mcmd1:\u001b[0m Making all in src\n",
      "\u001b[94mcmd1:\u001b[0m make[6]: Entering directory '/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-build/src'\n",
      "\u001b[94mcmd1:\u001b[0m Making all in include\n",
      "\u001b[94mcmd1:\u001b[0m make[7]: Entering directory '/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-build/src/include'\n",
      "\u001b[94mcmd1:\u001b[0m make[7]: Nothing to be done for 'all'.\n",
      "\u001b[94mcmd1:\u001b[0m make[7]: Leaving directory '/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-build/src/include'\n",
      "\u001b[94mcmd1:\u001b[0m Making all in lib\n",
      "\u001b[94mcmd1:\u001b[0m make[7]: Entering directory '/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-build/src/lib'\n",
      "\u001b[94mcmd1:\u001b[0m depbase=`echo compat.lo | sed 's|[^/]*$|.deps/&|;s|\\.lo$||'`;\\\n",
      "\u001b[94mcmd1:\u001b[0m /bin/bash ../../libtool  --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H   -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/lib/../include  -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char  -std=c++11 -MT compat.lo -MD -MP -MF $depbase.Tpo -c -o compat.lo /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/lib/compat.cc &&\\\n",
      "\u001b[94mcmd1:\u001b[0m mv -f $depbase.Tpo $depbase.Plo\n",
      "\u001b[94mcmd1:\u001b[0m depbase=`echo flags.lo | sed 's|[^/]*$|.deps/&|;s|\\.lo$||'`;\\\n",
      "\u001b[94mcmd1:\u001b[0m /bin/bash ../../libtool  --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H   -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/lib/../include  -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char  -std=c++11 -MT flags.lo -MD -MP -MF $depbase.Tpo -c -o flags.lo /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/lib/flags.cc &&\\\n",
      "\u001b[94mcmd1:\u001b[0m mv -f $depbase.Tpo $depbase.Plo\n",
      "\u001b[94mcmd1:\u001b[0m depbase=`echo fst.lo | sed 's|[^/]*$|.deps/&|;s|\\.lo$||'`;\\\n",
      "\u001b[94mcmd1:\u001b[0m /bin/bash ../../libtool  --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H   -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/lib/../include  -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char  -std=c++11 -MT fst.lo -MD -MP -MF $depbase.Tpo -c -o fst.lo /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/lib/fst.cc &&\\\n",
      "\u001b[94mcmd1:\u001b[0m mv -f $depbase.Tpo $depbase.Plo\n",
      "\u001b[94mcmd1:\u001b[0m depbase=`echo mapped-file.lo | sed 's|[^/]*$|.deps/&|;s|\\.lo$||'`;\\\n",
      "\u001b[94mcmd1:\u001b[0m /bin/bash ../../libtool  --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H   -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/lib/../include  -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char  -std=c++11 -MT mapped-file.lo -MD -MP -MF $depbase.Tpo -c -o mapped-file.lo /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/lib/mapped-file.cc &&\\\n",
      "\u001b[94mcmd1:\u001b[0m mv -f $depbase.Tpo $depbase.Plo\n",
      "\u001b[94mcmd1:\u001b[0m libtool: compile:  g++ -DHAVE_CONFIG_H -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/lib/../include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char -std=c++11 -MT compat.lo -MD -MP -MF .deps/compat.Tpo -c /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/lib/compat.cc  -fPIC -DPIC -o .libs/compat.o\n",
      "\u001b[94mcmd1:\u001b[0m libtool: compile:  g++ -DHAVE_CONFIG_H -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/lib/../include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char -std=c++11 -MT flags.lo -MD -MP -MF .deps/flags.Tpo -c /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/lib/flags.cc  -fPIC -DPIC -o .libs/flags.o\n",
      "\u001b[94mcmd1:\u001b[0m libtool: compile:  g++ -DHAVE_CONFIG_H -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/lib/../include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char -std=c++11 -MT fst.lo -MD -MP -MF .deps/fst.Tpo -c /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/lib/fst.cc  -fPIC -DPIC -o .libs/fst.o\n",
      "\u001b[94mcmd1:\u001b[0m libtool: compile:  g++ -DHAVE_CONFIG_H -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/lib/../include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char -std=c++11 -MT mapped-file.lo -MD -MP -MF .deps/mapped-file.Tpo -c /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/lib/mapped-file.cc  -fPIC -DPIC -o .libs/mapped-file.o\n",
      "\u001b[94mcmd1:\u001b[0m depbase=`echo properties.lo | sed 's|[^/]*$|.deps/&|;s|\\.lo$||'`;\\\n",
      "\u001b[94mcmd1:\u001b[0m /bin/bash ../../libtool  --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H   -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/lib/../include  -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char  -std=c++11 -MT properties.lo -MD -MP -MF $depbase.Tpo -c -o properties.lo /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/lib/properties.cc &&\\\n",
      "\u001b[94mcmd1:\u001b[0m mv -f $depbase.Tpo $depbase.Plo\n",
      "\u001b[94mcmd1:\u001b[0m libtool: compile:  g++ -DHAVE_CONFIG_H -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/lib/../include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char -std=c++11 -MT properties.lo -MD -MP -MF .deps/properties.Tpo -c /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/lib/properties.cc  -fPIC -DPIC -o .libs/properties.o\n",
      "\u001b[94mcmd1:\u001b[0m depbase=`echo symbol-table.lo | sed 's|[^/]*$|.deps/&|;s|\\.lo$||'`;\\\n",
      "\u001b[94mcmd1:\u001b[0m /bin/bash ../../libtool  --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H   -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/lib/../include  -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char  -std=c++11 -MT symbol-table.lo -MD -MP -MF $depbase.Tpo -c -o symbol-table.lo /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/lib/symbol-table.cc &&\\\n",
      "\u001b[94mcmd1:\u001b[0m mv -f $depbase.Tpo $depbase.Plo\n",
      "\u001b[94mcmd1:\u001b[0m libtool: compile:  g++ -DHAVE_CONFIG_H -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/lib/../include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char -std=c++11 -MT symbol-table.lo -MD -MP -MF .deps/symbol-table.Tpo -c /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/lib/symbol-table.cc  -fPIC -DPIC -o .libs/symbol-table.o\n",
      "\u001b[94mcmd1:\u001b[0m depbase=`echo symbol-table-ops.lo | sed 's|[^/]*$|.deps/&|;s|\\.lo$||'`;\\\n",
      "\u001b[94mcmd1:\u001b[0m /bin/bash ../../libtool  --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H   -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/lib/../include  -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char  -std=c++11 -MT symbol-table-ops.lo -MD -MP -MF $depbase.Tpo -c -o symbol-table-ops.lo /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/lib/symbol-table-ops.cc &&\\\n",
      "\u001b[94mcmd1:\u001b[0m mv -f $depbase.Tpo $depbase.Plo\n",
      "\u001b[94mcmd1:\u001b[0m libtool: compile:  g++ -DHAVE_CONFIG_H -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/lib/../include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char -std=c++11 -MT symbol-table-ops.lo -MD -MP -MF .deps/symbol-table-ops.Tpo -c /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/lib/symbol-table-ops.cc  -fPIC -DPIC -o .libs/symbol-table-ops.o\n",
      "\u001b[94mcmd1:\u001b[0m depbase=`echo weight.lo | sed 's|[^/]*$|.deps/&|;s|\\.lo$||'`;\\\n",
      "\u001b[94mcmd1:\u001b[0m /bin/bash ../../libtool  --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H   -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/lib/../include  -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char  -std=c++11 -MT weight.lo -MD -MP -MF $depbase.Tpo -c -o weight.lo /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/lib/weight.cc &&\\\n",
      "\u001b[94mcmd1:\u001b[0m mv -f $depbase.Tpo $depbase.Plo\n",
      "\u001b[94mcmd1:\u001b[0m libtool: compile:  g++ -DHAVE_CONFIG_H -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/lib/../include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char -std=c++11 -MT weight.lo -MD -MP -MF .deps/weight.Tpo -c /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/lib/weight.cc  -fPIC -DPIC -o .libs/weight.o\n",
      "\u001b[94mcmd1:\u001b[0m depbase=`echo util.lo | sed 's|[^/]*$|.deps/&|;s|\\.lo$||'`;\\\n",
      "\u001b[94mcmd1:\u001b[0m /bin/bash ../../libtool  --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H   -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/lib/../include  -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char  -std=c++11 -MT util.lo -MD -MP -MF $depbase.Tpo -c -o util.lo /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/lib/util.cc &&\\\n",
      "\u001b[94mcmd1:\u001b[0m mv -f $depbase.Tpo $depbase.Plo\n",
      "\u001b[94mcmd1:\u001b[0m libtool: compile:  g++ -DHAVE_CONFIG_H -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/lib/../include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char -std=c++11 -MT util.lo -MD -MP -MF .deps/util.Tpo -c /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/lib/util.cc  -fPIC -DPIC -o .libs/util.o\n",
      "\u001b[92mcmd2:\u001b[0m Loaded 35 test trials for session t15.2023.08.13.\n",
      "\u001b[92mcmd2:\u001b[0m Loaded 50 test trials for session t15.2023.08.18.\n",
      "\u001b[92mcmd2:\u001b[0m Loaded 49 test trials for session t15.2023.08.20.\n",
      "\u001b[92mcmd2:\u001b[0m Loaded 25 test trials for session t15.2023.08.25.\n",
      "\u001b[92mcmd2:\u001b[0m Loaded 25 test trials for session t15.2023.08.27.\n",
      "\u001b[92mcmd2:\u001b[0m Loaded 50 test trials for session t15.2023.09.01.\n",
      "\u001b[92mcmd2:\u001b[0m Loaded 35 test trials for session t15.2023.09.03.\n",
      "\u001b[92mcmd2:\u001b[0m Loaded 35 test trials for session t15.2023.09.24.\n",
      "\u001b[92mcmd2:\u001b[0m Loaded 49 test trials for session t15.2023.09.29.\n",
      "\u001b[92mcmd2:\u001b[0m Loaded 45 test trials for session t15.2023.10.01.\n",
      "\u001b[92mcmd2:\u001b[0m Loaded 37 test trials for session t15.2023.10.06.\n",
      "\u001b[92mcmd2:\u001b[0m Loaded 18 test trials for session t15.2023.10.08.\n",
      "\u001b[94mcmd1:\u001b[0m /bin/bash ../../libtool  --tag=CXX   --mode=link g++  -std=c++11 -version-info 8:0:0 -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -o libfst.la -rpath /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-subbuild/openfst-populate-prefix/lib compat.lo flags.lo fst.lo mapped-file.lo properties.lo symbol-table.lo symbol-table-ops.lo weight.lo util.lo -ldl -lgflags_nothreads -lglog -lpthread\n",
      "\u001b[94mcmd1:\u001b[0m libtool: link: g++  -fPIC -DPIC -shared -nostdlib /usr/lib/gcc/x86_64-linux-gnu/11/../../../x86_64-linux-gnu/crti.o /usr/lib/gcc/x86_64-linux-gnu/11/crtbeginS.o  .libs/compat.o .libs/flags.o .libs/fst.o .libs/mapped-file.o .libs/properties.o .libs/symbol-table.o .libs/symbol-table-ops.o .libs/weight.o .libs/util.o   -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -ldl -lgflags_nothreads -lglog -lpthread -L/usr/lib/gcc/x86_64-linux-gnu/11 -L/usr/lib/gcc/x86_64-linux-gnu/11/../../../x86_64-linux-gnu -L/usr/lib/gcc/x86_64-linux-gnu/11/../../../../lib -L/lib/x86_64-linux-gnu -L/lib/../lib -L/usr/lib/x86_64-linux-gnu -L/usr/lib/../lib -L/usr/local/cuda/lib64/stubs -L/usr/lib/gcc/x86_64-linux-gnu/11/../../.. -lstdc++ -lm -lc -lgcc_s /usr/lib/gcc/x86_64-linux-gnu/11/crtendS.o /usr/lib/gcc/x86_64-linux-gnu/11/../../../x86_64-linux-gnu/crtn.o    -Wl,-soname -Wl,libfst.so.8 -o .libs/libfst.so.8.0.0\n",
      "\u001b[94mcmd1:\u001b[0m libtool: link: (cd \".libs\" && rm -f \"libfst.so.8\" && ln -s \"libfst.so.8.0.0\" \"libfst.so.8\")\n",
      "\u001b[94mcmd1:\u001b[0m libtool: link: (cd \".libs\" && rm -f \"libfst.so\" && ln -s \"libfst.so.8.0.0\" \"libfst.so\")\n",
      "\u001b[92mcmd2:\u001b[0m Loaded 45 test trials for session t15.2023.10.13.\n",
      "\u001b[94mcmd1:\u001b[0m libtool: link: ( cd \".libs\" && rm -f \"libfst.la\" && ln -s \"../libfst.la\" \"libfst.la\" )\n",
      "\u001b[94mcmd1:\u001b[0m make[7]: Leaving directory '/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-build/src/lib'\n",
      "\u001b[94mcmd1:\u001b[0m Making all in script\n",
      "\u001b[94mcmd1:\u001b[0m make[7]: Entering directory '/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-build/src/script'\n",
      "\u001b[94mcmd1:\u001b[0m depbase=`echo arciterator-class.lo | sed 's|[^/]*$|.deps/&|;s|\\.lo$||'`;\\\n",
      "\u001b[94mcmd1:\u001b[0m /bin/bash ../../libtool  --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H   -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/../include  -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char  -std=c++11 -MT arciterator-class.lo -MD -MP -MF $depbase.Tpo -c -o arciterator-class.lo /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/arciterator-class.cc &&\\\n",
      "\u001b[94mcmd1:\u001b[0m mv -f $depbase.Tpo $depbase.Plo\n",
      "\u001b[94mcmd1:\u001b[0m depbase=`echo arcsort.lo | sed 's|[^/]*$|.deps/&|;s|\\.lo$||'`;\\\n",
      "\u001b[94mcmd1:\u001b[0m /bin/bash ../../libtool  --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H   -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/../include  -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char  -std=c++11 -MT arcsort.lo -MD -MP -MF $depbase.Tpo -c -o arcsort.lo /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/arcsort.cc &&\\\n",
      "\u001b[94mcmd1:\u001b[0m mv -f $depbase.Tpo $depbase.Plo\n",
      "\u001b[94mcmd1:\u001b[0m depbase=`echo closure.lo | sed 's|[^/]*$|.deps/&|;s|\\.lo$||'`;\\\n",
      "\u001b[94mcmd1:\u001b[0m /bin/bash ../../libtool  --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H   -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/../include  -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char  -std=c++11 -MT closure.lo -MD -MP -MF $depbase.Tpo -c -o closure.lo /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/closure.cc &&\\\n",
      "\u001b[94mcmd1:\u001b[0m mv -f $depbase.Tpo $depbase.Plo\n",
      "\u001b[94mcmd1:\u001b[0m depbase=`echo compile.lo | sed 's|[^/]*$|.deps/&|;s|\\.lo$||'`;\\\n",
      "\u001b[94mcmd1:\u001b[0m /bin/bash ../../libtool  --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H   -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/../include  -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char  -std=c++11 -MT compile.lo -MD -MP -MF $depbase.Tpo -c -o compile.lo /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/compile.cc &&\\\n",
      "\u001b[94mcmd1:\u001b[0m mv -f $depbase.Tpo $depbase.Plo\n",
      "\u001b[94mcmd1:\u001b[0m libtool: compile:  g++ -DHAVE_CONFIG_H -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/../include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char -std=c++11 -MT closure.lo -MD -MP -MF .deps/closure.Tpo -c /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/closure.cc  -fPIC -DPIC -o .libs/closure.o\n",
      "\u001b[94mcmd1:\u001b[0m libtool: compile:  g++ -DHAVE_CONFIG_H -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/../include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char -std=c++11 -MT arciterator-class.lo -MD -MP -MF .deps/arciterator-class.Tpo -c /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/arciterator-class.cc  -fPIC -DPIC -o .libs/arciterator-class.o\n",
      "\u001b[94mcmd1:\u001b[0m libtool: compile:  g++ -DHAVE_CONFIG_H -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/../include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char -std=c++11 -MT compile.lo -MD -MP -MF .deps/compile.Tpo -c /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/compile.cc  -fPIC -DPIC -o .libs/compile.o\n",
      "\u001b[94mcmd1:\u001b[0m libtool: compile:  g++ -DHAVE_CONFIG_H -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/../include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char -std=c++11 -MT arcsort.lo -MD -MP -MF .deps/arcsort.Tpo -c /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/arcsort.cc  -fPIC -DPIC -o .libs/arcsort.o\n",
      "\u001b[92mcmd2:\u001b[0m Loaded 45 test trials for session t15.2023.10.15.\n",
      "\u001b[94mcmd1:\u001b[0m depbase=`echo compose.lo | sed 's|[^/]*$|.deps/&|;s|\\.lo$||'`;\\\n",
      "\u001b[94mcmd1:\u001b[0m /bin/bash ../../libtool  --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H   -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/../include  -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char  -std=c++11 -MT compose.lo -MD -MP -MF $depbase.Tpo -c -o compose.lo /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/compose.cc &&\\\n",
      "\u001b[94mcmd1:\u001b[0m mv -f $depbase.Tpo $depbase.Plo\n",
      "\u001b[92mcmd2:\u001b[0m Loaded 9 test trials for session t15.2023.10.20.\n",
      "\u001b[94mcmd1:\u001b[0m libtool: compile:  g++ -DHAVE_CONFIG_H -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/../include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char -std=c++11 -MT compose.lo -MD -MP -MF .deps/compose.Tpo -c /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/compose.cc  -fPIC -DPIC -o .libs/compose.o\n",
      "\u001b[94mcmd1:\u001b[0m depbase=`echo concat.lo | sed 's|[^/]*$|.deps/&|;s|\\.lo$||'`;\\\n",
      "\u001b[94mcmd1:\u001b[0m /bin/bash ../../libtool  --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H   -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/../include  -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char  -std=c++11 -MT concat.lo -MD -MP -MF $depbase.Tpo -c -o concat.lo /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/concat.cc &&\\\n",
      "\u001b[94mcmd1:\u001b[0m mv -f $depbase.Tpo $depbase.Plo\n",
      "\u001b[94mcmd1:\u001b[0m libtool: compile:  g++ -DHAVE_CONFIG_H -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/../include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char -std=c++11 -MT concat.lo -MD -MP -MF .deps/concat.Tpo -c /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/concat.cc  -fPIC -DPIC -o .libs/concat.o\n",
      "\u001b[94mcmd1:\u001b[0m depbase=`echo connect.lo | sed 's|[^/]*$|.deps/&|;s|\\.lo$||'`;\\\n",
      "\u001b[94mcmd1:\u001b[0m /bin/bash ../../libtool  --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H   -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/../include  -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char  -std=c++11 -MT connect.lo -MD -MP -MF $depbase.Tpo -c -o connect.lo /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/connect.cc &&\\\n",
      "\u001b[94mcmd1:\u001b[0m mv -f $depbase.Tpo $depbase.Plo\n",
      "\u001b[94mcmd1:\u001b[0m libtool: compile:  g++ -DHAVE_CONFIG_H -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/../include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char -std=c++11 -MT connect.lo -MD -MP -MF .deps/connect.Tpo -c /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/connect.cc  -fPIC -DPIC -o .libs/connect.o\n",
      "\u001b[92mcmd2:\u001b[0m Loaded 35 test trials for session t15.2023.10.22.\n",
      "\u001b[94mcmd1:\u001b[0m depbase=`echo convert.lo | sed 's|[^/]*$|.deps/&|;s|\\.lo$||'`;\\\n",
      "\u001b[94mcmd1:\u001b[0m /bin/bash ../../libtool  --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H   -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/../include  -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char  -std=c++11 -MT convert.lo -MD -MP -MF $depbase.Tpo -c -o convert.lo /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/convert.cc &&\\\n",
      "\u001b[94mcmd1:\u001b[0m mv -f $depbase.Tpo $depbase.Plo\n",
      "\u001b[94mcmd1:\u001b[0m libtool: compile:  g++ -DHAVE_CONFIG_H -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/../include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char -std=c++11 -MT convert.lo -MD -MP -MF .deps/convert.Tpo -c /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/convert.cc  -fPIC -DPIC -o .libs/convert.o\n",
      "\u001b[94mcmd1:\u001b[0m depbase=`echo decode.lo | sed 's|[^/]*$|.deps/&|;s|\\.lo$||'`;\\\n",
      "\u001b[94mcmd1:\u001b[0m /bin/bash ../../libtool  --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H   -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/../include  -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char  -std=c++11 -MT decode.lo -MD -MP -MF $depbase.Tpo -c -o decode.lo /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/decode.cc &&\\\n",
      "\u001b[94mcmd1:\u001b[0m mv -f $depbase.Tpo $depbase.Plo\n",
      "\u001b[94mcmd1:\u001b[0m libtool: compile:  g++ -DHAVE_CONFIG_H -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/../include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char -std=c++11 -MT decode.lo -MD -MP -MF .deps/decode.Tpo -c /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/decode.cc  -fPIC -DPIC -o .libs/decode.o\n",
      "\u001b[92mcmd2:\u001b[0m Loaded 50 test trials for session t15.2023.11.03.\n",
      "\u001b[94mcmd1:\u001b[0m depbase=`echo determinize.lo | sed 's|[^/]*$|.deps/&|;s|\\.lo$||'`;\\\n",
      "\u001b[94mcmd1:\u001b[0m /bin/bash ../../libtool  --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H   -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/../include  -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char  -std=c++11 -MT determinize.lo -MD -MP -MF $depbase.Tpo -c -o determinize.lo /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/determinize.cc &&\\\n",
      "\u001b[94mcmd1:\u001b[0m mv -f $depbase.Tpo $depbase.Plo\n",
      "\u001b[94mcmd1:\u001b[0m libtool: compile:  g++ -DHAVE_CONFIG_H -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/../include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char -std=c++11 -MT determinize.lo -MD -MP -MF .deps/determinize.Tpo -c /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/determinize.cc  -fPIC -DPIC -o .libs/determinize.o\n",
      "\u001b[92mcmd2:\u001b[0m Loaded 15 test trials for session t15.2023.11.04.\n",
      "\u001b[94mcmd1:\u001b[0m depbase=`echo difference.lo | sed 's|[^/]*$|.deps/&|;s|\\.lo$||'`;\\\n",
      "\u001b[94mcmd1:\u001b[0m /bin/bash ../../libtool  --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H   -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/../include  -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char  -std=c++11 -MT difference.lo -MD -MP -MF $depbase.Tpo -c -o difference.lo /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/difference.cc &&\\\n",
      "\u001b[94mcmd1:\u001b[0m mv -f $depbase.Tpo $depbase.Plo\n",
      "\u001b[94mcmd1:\u001b[0m libtool: compile:  g++ -DHAVE_CONFIG_H -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/../include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char -std=c++11 -MT difference.lo -MD -MP -MF .deps/difference.Tpo -c /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/difference.cc  -fPIC -DPIC -o .libs/difference.o\n",
      "\u001b[92mcmd2:\u001b[0m Loaded 25 test trials for session t15.2023.11.17.\n",
      "\u001b[92mcmd2:\u001b[0m Loaded 20 test trials for session t15.2023.11.19.\n",
      "\u001b[92mcmd2:\u001b[0m Loaded 45 test trials for session t15.2023.11.26.\n",
      "\u001b[92mcmd2:\u001b[0m Loaded 34 test trials for session t15.2023.12.03.\n",
      "\u001b[94mcmd1:\u001b[0m depbase=`echo disambiguate.lo | sed 's|[^/]*$|.deps/&|;s|\\.lo$||'`;\\\n",
      "\u001b[94mcmd1:\u001b[0m /bin/bash ../../libtool  --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H   -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/../include  -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char  -std=c++11 -MT disambiguate.lo -MD -MP -MF $depbase.Tpo -c -o disambiguate.lo /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/disambiguate.cc &&\\\n",
      "\u001b[94mcmd1:\u001b[0m mv -f $depbase.Tpo $depbase.Plo\n",
      "\u001b[94mcmd1:\u001b[0m libtool: compile:  g++ -DHAVE_CONFIG_H -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/../include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char -std=c++11 -MT disambiguate.lo -MD -MP -MF .deps/disambiguate.Tpo -c /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/disambiguate.cc  -fPIC -DPIC -o .libs/disambiguate.o\n",
      "\u001b[92mcmd2:\u001b[0m Loaded 50 test trials for session t15.2023.12.08.\n",
      "\u001b[92mcmd2:\u001b[0m Loaded 25 test trials for session t15.2023.12.10.\n",
      "\u001b[94mcmd1:\u001b[0m depbase=`echo draw.lo | sed 's|[^/]*$|.deps/&|;s|\\.lo$||'`;\\\n",
      "\u001b[94mcmd1:\u001b[0m /bin/bash ../../libtool  --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H   -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/../include  -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char  -std=c++11 -MT draw.lo -MD -MP -MF $depbase.Tpo -c -o draw.lo /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/draw.cc &&\\\n",
      "\u001b[94mcmd1:\u001b[0m mv -f $depbase.Tpo $depbase.Plo\n",
      "\u001b[94mcmd1:\u001b[0m libtool: compile:  g++ -DHAVE_CONFIG_H -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/../include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char -std=c++11 -MT draw.lo -MD -MP -MF .deps/draw.Tpo -c /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/draw.cc  -fPIC -DPIC -o .libs/draw.o\n",
      "\u001b[94mcmd1:\u001b[0m depbase=`echo encode.lo | sed 's|[^/]*$|.deps/&|;s|\\.lo$||'`;\\\n",
      "\u001b[94mcmd1:\u001b[0m /bin/bash ../../libtool  --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H   -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/../include  -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char  -std=c++11 -MT encode.lo -MD -MP -MF $depbase.Tpo -c -o encode.lo /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/encode.cc &&\\\n",
      "\u001b[94mcmd1:\u001b[0m mv -f $depbase.Tpo $depbase.Plo\n",
      "\u001b[94mcmd1:\u001b[0m libtool: compile:  g++ -DHAVE_CONFIG_H -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/../include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char -std=c++11 -MT encode.lo -MD -MP -MF .deps/encode.Tpo -c /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/encode.cc  -fPIC -DPIC -o .libs/encode.o\n",
      "\u001b[92mcmd2:\u001b[0m Loaded 30 test trials for session t15.2023.12.17.\n",
      "\u001b[94mcmd1:\u001b[0m depbase=`echo encodemapper-class.lo | sed 's|[^/]*$|.deps/&|;s|\\.lo$||'`;\\\n",
      "\u001b[94mcmd1:\u001b[0m /bin/bash ../../libtool  --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H   -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/../include  -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char  -std=c++11 -MT encodemapper-class.lo -MD -MP -MF $depbase.Tpo -c -o encodemapper-class.lo /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/encodemapper-class.cc &&\\\n",
      "\u001b[94mcmd1:\u001b[0m mv -f $depbase.Tpo $depbase.Plo\n",
      "\u001b[94mcmd1:\u001b[0m libtool: compile:  g++ -DHAVE_CONFIG_H -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/../include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char -std=c++11 -MT encodemapper-class.lo -MD -MP -MF .deps/encodemapper-class.Tpo -c /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/encodemapper-class.cc  -fPIC -DPIC -o .libs/encodemapper-class.o\n",
      "\u001b[92mcmd2:\u001b[0m Loaded 50 test trials for session t15.2023.12.29.\n",
      "\u001b[92mcmd2:\u001b[0m Loaded 24 test trials for session t15.2024.02.25.\n",
      "\u001b[92mcmd2:\u001b[0m Loaded 25 test trials for session t15.2024.03.08.\n",
      "\u001b[94mcmd1:\u001b[0m depbase=`echo epsnormalize.lo | sed 's|[^/]*$|.deps/&|;s|\\.lo$||'`;\\\n",
      "\u001b[94mcmd1:\u001b[0m /bin/bash ../../libtool  --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H   -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/../include  -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char  -std=c++11 -MT epsnormalize.lo -MD -MP -MF $depbase.Tpo -c -o epsnormalize.lo /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/epsnormalize.cc &&\\\n",
      "\u001b[94mcmd1:\u001b[0m mv -f $depbase.Tpo $depbase.Plo\n",
      "\u001b[94mcmd1:\u001b[0m libtool: compile:  g++ -DHAVE_CONFIG_H -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/../include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char -std=c++11 -MT epsnormalize.lo -MD -MP -MF .deps/epsnormalize.Tpo -c /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/epsnormalize.cc  -fPIC -DPIC -o .libs/epsnormalize.o\n",
      "\u001b[94mcmd1:\u001b[0m depbase=`echo equal.lo | sed 's|[^/]*$|.deps/&|;s|\\.lo$||'`;\\\n",
      "\u001b[94mcmd1:\u001b[0m /bin/bash ../../libtool  --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H   -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/../include  -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char  -std=c++11 -MT equal.lo -MD -MP -MF $depbase.Tpo -c -o equal.lo /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/equal.cc &&\\\n",
      "\u001b[94mcmd1:\u001b[0m mv -f $depbase.Tpo $depbase.Plo\n",
      "\u001b[94mcmd1:\u001b[0m libtool: compile:  g++ -DHAVE_CONFIG_H -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/../include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char -std=c++11 -MT equal.lo -MD -MP -MF .deps/equal.Tpo -c /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/equal.cc  -fPIC -DPIC -o .libs/equal.o\n",
      "\u001b[92mcmd2:\u001b[0m Loaded 50 test trials for session t15.2024.03.15.\n",
      "\u001b[94mcmd1:\u001b[0m depbase=`echo equivalent.lo | sed 's|[^/]*$|.deps/&|;s|\\.lo$||'`;\\\n",
      "\u001b[94mcmd1:\u001b[0m /bin/bash ../../libtool  --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H   -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/../include  -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char  -std=c++11 -MT equivalent.lo -MD -MP -MF $depbase.Tpo -c -o equivalent.lo /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/equivalent.cc &&\\\n",
      "\u001b[94mcmd1:\u001b[0m mv -f $depbase.Tpo $depbase.Plo\n",
      "\u001b[94mcmd1:\u001b[0m libtool: compile:  g++ -DHAVE_CONFIG_H -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/../include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char -std=c++11 -MT equivalent.lo -MD -MP -MF .deps/equivalent.Tpo -c /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/equivalent.cc  -fPIC -DPIC -o .libs/equivalent.o\n",
      "\u001b[92mcmd2:\u001b[0m Loaded 49 test trials for session t15.2024.03.17.\n",
      "\u001b[92mcmd2:\u001b[0m Loaded 25 test trials for session t15.2024.05.10.\n",
      "\u001b[92mcmd2:\u001b[0m Loaded 25 test trials for session t15.2024.06.14.\n",
      "\u001b[92mcmd2:\u001b[0m Loaded 49 test trials for session t15.2024.07.19.\n",
      "\u001b[92mcmd2:\u001b[0m Loaded 47 test trials for session t15.2024.07.21.\n",
      "\u001b[92mcmd2:\u001b[0m Loaded 49 test trials for session t15.2024.07.28.\n",
      "\u001b[92mcmd2:\u001b[0m Loaded 24 test trials for session t15.2025.01.10.\n",
      "\u001b[92mcmd2:\u001b[0m Loaded 47 test trials for session t15.2025.01.12.\n",
      "\u001b[94mcmd1:\u001b[0m depbase=`echo fst-class.lo | sed 's|[^/]*$|.deps/&|;s|\\.lo$||'`;\\\n",
      "\u001b[94mcmd1:\u001b[0m /bin/bash ../../libtool  --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H   -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/../include  -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char  -std=c++11 -MT fst-class.lo -MD -MP -MF $depbase.Tpo -c -o fst-class.lo /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/fst-class.cc &&\\\n",
      "\u001b[94mcmd1:\u001b[0m mv -f $depbase.Tpo $depbase.Plo\n",
      "\u001b[94mcmd1:\u001b[0m libtool: compile:  g++ -DHAVE_CONFIG_H -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/../include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char -std=c++11 -MT fst-class.lo -MD -MP -MF .deps/fst-class.Tpo -c /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/fst-class.cc  -fPIC -DPIC -o .libs/fst-class.o\n",
      "\u001b[92mcmd2:\u001b[0m Loaded 26 test trials for session t15.2025.03.14.\n",
      "\u001b[92mcmd2:\u001b[0m Loaded 24 test trials for session t15.2025.03.16.\n",
      "\u001b[92mcmd2:\u001b[0m Loaded 30 test trials for session t15.2025.03.30.\n",
      "\u001b[92mcmd2:\u001b[0m Loaded 25 test trials for session t15.2025.04.13.\n",
      "\u001b[92mcmd2:\u001b[0m Total number of test trials: 1450\n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:   0%|          | 0/1450 [00:00<?, ?trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:   0%|          | 1/1450 [00:00<19:27,  1.24trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:   0%|          | 4/1450 [00:00<04:26,  5.42trial/s]\n",
      "\u001b[94mcmd1:\u001b[0m depbase=`echo getters.lo | sed 's|[^/]*$|.deps/&|;s|\\.lo$||'`;\\\n",
      "\u001b[94mcmd1:\u001b[0m /bin/bash ../../libtool  --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H   -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/../include  -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char  -std=c++11 -MT getters.lo -MD -MP -MF $depbase.Tpo -c -o getters.lo /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/getters.cc &&\\\n",
      "\u001b[94mcmd1:\u001b[0m mv -f $depbase.Tpo $depbase.Plo\n",
      "\u001b[94mcmd1:\u001b[0m libtool: compile:  g++ -DHAVE_CONFIG_H -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/../include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char -std=c++11 -MT getters.lo -MD -MP -MF .deps/getters.Tpo -c /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/getters.cc  -fPIC -DPIC -o .libs/getters.o\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:   1%|          | 9/1450 [00:01<01:53, 12.68trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:   1%|          | 13/1450 [00:01<01:28, 16.28trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:   1%|          | 18/1450 [00:01<01:02, 22.91trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:   2%|▏         | 22/1450 [00:01<00:53, 26.64trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:   2%|▏         | 27/1450 [00:01<00:45, 31.50trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:   2%|▏         | 31/1450 [00:01<00:44, 31.81trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:   2%|▏         | 35/1450 [00:01<00:44, 31.95trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:   3%|▎         | 40/1450 [00:01<00:39, 35.76trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:   3%|▎         | 44/1450 [00:02<00:41, 33.79trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:   3%|▎         | 48/1450 [00:02<00:41, 33.88trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:   4%|▎         | 53/1450 [00:02<00:39, 35.21trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:   4%|▍         | 57/1450 [00:02<00:38, 36.38trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:   4%|▍         | 62/1450 [00:02<00:36, 37.98trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:   5%|▍         | 66/1450 [00:02<00:38, 36.34trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:   5%|▍         | 70/1450 [00:02<00:40, 33.78trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:   5%|▌         | 75/1450 [00:02<00:37, 36.95trial/s]\n",
      "\u001b[94mcmd1:\u001b[0m depbase=`echo info-impl.lo | sed 's|[^/]*$|.deps/&|;s|\\.lo$||'`;\\\n",
      "\u001b[94mcmd1:\u001b[0m /bin/bash ../../libtool  --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H   -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/../include  -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char  -std=c++11 -MT info-impl.lo -MD -MP -MF $depbase.Tpo -c -o info-impl.lo /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/info-impl.cc &&\\\n",
      "\u001b[94mcmd1:\u001b[0m mv -f $depbase.Tpo $depbase.Plo\n",
      "\u001b[94mcmd1:\u001b[0m libtool: compile:  g++ -DHAVE_CONFIG_H -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/../include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char -std=c++11 -MT info-impl.lo -MD -MP -MF .deps/info-impl.Tpo -c /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/info-impl.cc  -fPIC -DPIC -o .libs/info-impl.o\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:   5%|▌         | 79/1450 [00:02<00:40, 33.55trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:   6%|▌         | 83/1450 [00:03<00:42, 31.94trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:   6%|▌         | 87/1450 [00:03<00:45, 30.06trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:   6%|▋         | 91/1450 [00:03<00:45, 29.78trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:   7%|▋         | 96/1450 [00:03<00:41, 32.94trial/s]\n",
      "\u001b[94mcmd1:\u001b[0m depbase=`echo info.lo | sed 's|[^/]*$|.deps/&|;s|\\.lo$||'`;\\\n",
      "\u001b[94mcmd1:\u001b[0m /bin/bash ../../libtool  --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H   -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/../include  -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char  -std=c++11 -MT info.lo -MD -MP -MF $depbase.Tpo -c -o info.lo /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/info.cc &&\\\n",
      "\u001b[94mcmd1:\u001b[0m mv -f $depbase.Tpo $depbase.Plo\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:   7%|▋         | 100/1450 [00:03<00:41, 32.24trial/s]\n",
      "\u001b[94mcmd1:\u001b[0m libtool: compile:  g++ -DHAVE_CONFIG_H -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/../include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char -std=c++11 -MT info.lo -MD -MP -MF .deps/info.Tpo -c /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/info.cc  -fPIC -DPIC -o .libs/info.o\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:   7%|▋         | 104/1450 [00:03<00:41, 32.75trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:   7%|▋         | 108/1450 [00:03<00:39, 33.56trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:   8%|▊         | 113/1450 [00:04<00:36, 36.18trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:   8%|▊         | 118/1450 [00:04<00:34, 38.13trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:   8%|▊         | 122/1450 [00:04<00:34, 37.95trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:   9%|▉         | 128/1450 [00:04<00:30, 42.86trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:   9%|▉         | 133/1450 [00:04<00:31, 42.11trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  10%|▉         | 138/1450 [00:04<00:32, 40.31trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  10%|▉         | 144/1450 [00:04<00:29, 43.96trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  10%|█         | 149/1450 [00:04<00:34, 37.49trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  11%|█         | 153/1450 [00:05<00:35, 36.38trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  11%|█         | 157/1450 [00:05<00:37, 34.57trial/s]\n",
      "\u001b[94mcmd1:\u001b[0m depbase=`echo intersect.lo | sed 's|[^/]*$|.deps/&|;s|\\.lo$||'`;\\\n",
      "\u001b[94mcmd1:\u001b[0m /bin/bash ../../libtool  --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H   -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/../include  -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char  -std=c++11 -MT intersect.lo -MD -MP -MF $depbase.Tpo -c -o intersect.lo /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/intersect.cc &&\\\n",
      "\u001b[94mcmd1:\u001b[0m mv -f $depbase.Tpo $depbase.Plo\n",
      "\u001b[94mcmd1:\u001b[0m libtool: compile:  g++ -DHAVE_CONFIG_H -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/../include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char -std=c++11 -MT intersect.lo -MD -MP -MF .deps/intersect.Tpo -c /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/intersect.cc  -fPIC -DPIC -o .libs/intersect.o\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  11%|█         | 162/1450 [00:05<00:34, 37.77trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  11%|█▏        | 166/1450 [00:05<00:34, 36.78trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  12%|█▏        | 171/1450 [00:05<00:33, 37.63trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  12%|█▏        | 175/1450 [00:05<00:34, 37.07trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  12%|█▏        | 179/1450 [00:05<00:35, 35.37trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  13%|█▎        | 183/1450 [00:05<00:35, 35.71trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  13%|█▎        | 187/1450 [00:05<00:34, 36.47trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  13%|█▎        | 193/1450 [00:06<00:31, 39.82trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  14%|█▎        | 198/1450 [00:06<00:31, 40.38trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  14%|█▍        | 203/1450 [00:06<00:30, 40.67trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  14%|█▍        | 208/1450 [00:06<00:33, 37.18trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  15%|█▍        | 213/1450 [00:06<00:31, 39.32trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  15%|█▌        | 218/1450 [00:06<00:30, 40.71trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  15%|█▌        | 223/1450 [00:06<00:30, 39.97trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  16%|█▌        | 228/1450 [00:06<00:28, 42.31trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  16%|█▌        | 233/1450 [00:07<00:33, 35.99trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  16%|█▋        | 237/1450 [00:07<00:32, 36.83trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  17%|█▋        | 241/1450 [00:07<00:39, 30.94trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  17%|█▋        | 246/1450 [00:07<00:36, 33.32trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  17%|█▋        | 250/1450 [00:07<00:34, 34.46trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  18%|█▊        | 255/1450 [00:07<00:31, 37.90trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  18%|█▊        | 260/1450 [00:07<00:29, 40.56trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  18%|█▊        | 265/1450 [00:07<00:28, 41.82trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  19%|█▊        | 270/1450 [00:08<00:29, 40.01trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  19%|█▉        | 275/1450 [00:08<00:29, 39.93trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  19%|█▉        | 280/1450 [00:08<00:29, 39.99trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  20%|█▉        | 285/1450 [00:08<00:33, 34.45trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  20%|█▉        | 289/1450 [00:08<00:36, 31.49trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  20%|██        | 293/1450 [00:08<00:40, 28.45trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  20%|██        | 296/1450 [00:09<00:43, 26.79trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  21%|██        | 299/1450 [00:09<00:42, 26.90trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  21%|██        | 304/1450 [00:09<00:37, 30.49trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  21%|██        | 308/1450 [00:09<00:39, 29.06trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  21%|██▏       | 311/1450 [00:09<00:40, 28.21trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  22%|██▏       | 315/1450 [00:09<00:38, 29.29trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  22%|██▏       | 319/1450 [00:09<00:35, 31.74trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  22%|██▏       | 323/1450 [00:09<00:35, 31.57trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  23%|██▎       | 327/1450 [00:10<00:40, 27.78trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  23%|██▎       | 330/1450 [00:10<00:41, 26.87trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  23%|██▎       | 333/1450 [00:10<00:48, 23.16trial/s]\n",
      "\u001b[94mcmd1:\u001b[0m depbase=`echo invert.lo | sed 's|[^/]*$|.deps/&|;s|\\.lo$||'`;\\\n",
      "\u001b[94mcmd1:\u001b[0m /bin/bash ../../libtool  --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H   -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/../include  -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char  -std=c++11 -MT invert.lo -MD -MP -MF $depbase.Tpo -c -o invert.lo /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/invert.cc &&\\\n",
      "\u001b[94mcmd1:\u001b[0m mv -f $depbase.Tpo $depbase.Plo\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  23%|██▎       | 336/1450 [00:10<00:49, 22.66trial/s]\n",
      "\u001b[94mcmd1:\u001b[0m libtool: compile:  g++ -DHAVE_CONFIG_H -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/../include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char -std=c++11 -MT invert.lo -MD -MP -MF .deps/invert.Tpo -c /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/invert.cc  -fPIC -DPIC -o .libs/invert.o\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  23%|██▎       | 339/1450 [00:10<00:50, 21.90trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  24%|██▎       | 342/1450 [00:10<00:51, 21.69trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  24%|██▍       | 345/1450 [00:10<00:50, 21.92trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  24%|██▍       | 348/1450 [00:11<00:46, 23.53trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  24%|██▍       | 351/1450 [00:11<00:47, 23.32trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  24%|██▍       | 354/1450 [00:11<00:44, 24.54trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  25%|██▍       | 357/1450 [00:11<00:42, 25.56trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  25%|██▍       | 362/1450 [00:11<00:34, 31.40trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  25%|██▌       | 368/1450 [00:11<00:30, 36.03trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  26%|██▌       | 374/1450 [00:11<00:26, 40.04trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  26%|██▌       | 379/1450 [00:11<00:28, 37.38trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  26%|██▋       | 383/1450 [00:12<00:29, 36.74trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  27%|██▋       | 387/1450 [00:12<00:33, 31.81trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  27%|██▋       | 391/1450 [00:12<00:34, 30.84trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  27%|██▋       | 395/1450 [00:12<00:36, 28.57trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  28%|██▊       | 399/1450 [00:12<00:36, 29.13trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  28%|██▊       | 402/1450 [00:12<00:37, 28.04trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  28%|██▊       | 405/1450 [00:12<00:38, 26.91trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  28%|██▊       | 408/1450 [00:13<00:41, 25.12trial/s]\n",
      "\u001b[94mcmd1:\u001b[0m depbase=`echo isomorphic.lo | sed 's|[^/]*$|.deps/&|;s|\\.lo$||'`;\\\n",
      "\u001b[94mcmd1:\u001b[0m /bin/bash ../../libtool  --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H   -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/../include  -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char  -std=c++11 -MT isomorphic.lo -MD -MP -MF $depbase.Tpo -c -o isomorphic.lo /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/isomorphic.cc &&\\\n",
      "\u001b[94mcmd1:\u001b[0m mv -f $depbase.Tpo $depbase.Plo\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  28%|██▊       | 411/1450 [00:13<00:41, 24.77trial/s]\n",
      "\u001b[94mcmd1:\u001b[0m libtool: compile:  g++ -DHAVE_CONFIG_H -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/../include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char -std=c++11 -MT isomorphic.lo -MD -MP -MF .deps/isomorphic.Tpo -c /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/isomorphic.cc  -fPIC -DPIC -o .libs/isomorphic.o\n",
      "\u001b[94mcmd1:\u001b[0m depbase=`echo map.lo | sed 's|[^/]*$|.deps/&|;s|\\.lo$||'`;\\\n",
      "\u001b[94mcmd1:\u001b[0m /bin/bash ../../libtool  --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H   -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/../include  -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char  -std=c++11 -MT map.lo -MD -MP -MF $depbase.Tpo -c -o map.lo /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/map.cc &&\\\n",
      "\u001b[94mcmd1:\u001b[0m mv -f $depbase.Tpo $depbase.Plo\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  29%|██▉       | 417/1450 [00:13<00:32, 32.11trial/s]\n",
      "\u001b[94mcmd1:\u001b[0m libtool: compile:  g++ -DHAVE_CONFIG_H -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/../include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char -std=c++11 -MT map.lo -MD -MP -MF .deps/map.Tpo -c /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/map.cc  -fPIC -DPIC -o .libs/map.o\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  29%|██▉       | 422/1450 [00:13<00:29, 34.99trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  29%|██▉       | 426/1450 [00:13<00:34, 29.45trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  30%|██▉       | 431/1450 [00:13<00:31, 32.15trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  30%|███       | 435/1450 [00:13<00:31, 32.43trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  30%|███       | 439/1450 [00:13<00:35, 28.85trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  31%|███       | 443/1450 [00:14<00:33, 30.33trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  31%|███       | 447/1450 [00:14<00:34, 28.85trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  31%|███       | 450/1450 [00:14<00:34, 28.85trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  31%|███▏      | 454/1450 [00:14<00:33, 29.72trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  32%|███▏      | 458/1450 [00:14<00:35, 28.17trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  32%|███▏      | 462/1450 [00:14<00:32, 30.79trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  32%|███▏      | 466/1450 [00:14<00:32, 30.55trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  32%|███▏      | 471/1450 [00:14<00:27, 34.97trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  33%|███▎      | 475/1450 [00:15<00:27, 34.99trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  33%|███▎      | 479/1450 [00:15<00:30, 32.13trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  33%|███▎      | 483/1450 [00:15<00:31, 30.60trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  34%|███▎      | 487/1450 [00:15<00:32, 29.58trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  34%|███▍      | 491/1450 [00:15<00:33, 28.28trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  34%|███▍      | 495/1450 [00:15<00:32, 29.27trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  34%|███▍      | 498/1450 [00:15<00:34, 27.39trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  35%|███▍      | 502/1450 [00:16<00:31, 29.70trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  35%|███▍      | 507/1450 [00:16<00:27, 34.71trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  35%|███▌      | 511/1450 [00:16<00:27, 34.40trial/s]\n",
      "\u001b[94mcmd1:\u001b[0m depbase=`echo minimize.lo | sed 's|[^/]*$|.deps/&|;s|\\.lo$||'`;\\\n",
      "\u001b[94mcmd1:\u001b[0m /bin/bash ../../libtool  --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H   -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/../include  -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char  -std=c++11 -MT minimize.lo -MD -MP -MF $depbase.Tpo -c -o minimize.lo /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/minimize.cc &&\\\n",
      "\u001b[94mcmd1:\u001b[0m mv -f $depbase.Tpo $depbase.Plo\n",
      "\u001b[94mcmd1:\u001b[0m libtool: compile:  g++ -DHAVE_CONFIG_H -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/../include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char -std=c++11 -MT minimize.lo -MD -MP -MF .deps/minimize.Tpo -c /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/minimize.cc  -fPIC -DPIC -o .libs/minimize.o\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  36%|███▌      | 515/1450 [00:16<00:28, 33.11trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  36%|███▌      | 520/1450 [00:16<00:25, 36.20trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  36%|███▌      | 525/1450 [00:16<00:24, 37.98trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  36%|███▋      | 529/1450 [00:16<00:28, 32.20trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  37%|███▋      | 533/1450 [00:17<00:33, 27.57trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  37%|███▋      | 536/1450 [00:17<00:34, 26.58trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  37%|███▋      | 539/1450 [00:17<00:37, 24.25trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  37%|███▋      | 542/1450 [00:17<00:38, 23.39trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  38%|███▊      | 545/1450 [00:17<00:44, 20.51trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  38%|███▊      | 548/1450 [00:17<00:40, 22.02trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  38%|███▊      | 552/1450 [00:17<00:37, 23.88trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  38%|███▊      | 555/1450 [00:17<00:35, 25.11trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  38%|███▊      | 558/1450 [00:18<00:35, 25.16trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  39%|███▊      | 561/1450 [00:18<00:36, 24.58trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  39%|███▉      | 564/1450 [00:18<00:36, 24.26trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  39%|███▉      | 567/1450 [00:18<00:36, 23.93trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  39%|███▉      | 570/1450 [00:18<00:35, 24.45trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  40%|███▉      | 574/1450 [00:18<00:31, 28.19trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  40%|███▉      | 578/1450 [00:18<00:29, 29.16trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  40%|████      | 581/1450 [00:18<00:31, 27.92trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  40%|████      | 586/1450 [00:19<00:27, 31.21trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  41%|████      | 590/1450 [00:19<00:29, 28.98trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  41%|████      | 593/1450 [00:19<00:30, 28.47trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  41%|████      | 596/1450 [00:19<00:30, 28.15trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  41%|████▏     | 600/1450 [00:19<00:29, 28.87trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  42%|████▏     | 604/1450 [00:19<00:28, 29.59trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  42%|████▏     | 607/1450 [00:19<00:29, 28.92trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  42%|████▏     | 610/1450 [00:19<00:30, 27.30trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  42%|████▏     | 614/1450 [00:20<00:29, 28.79trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  43%|████▎     | 618/1450 [00:20<00:27, 30.53trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  43%|████▎     | 622/1450 [00:20<00:26, 31.72trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  43%|████▎     | 626/1450 [00:20<00:24, 33.05trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  43%|████▎     | 630/1450 [00:20<00:27, 29.57trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  44%|████▍     | 635/1450 [00:20<00:25, 32.35trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  44%|████▍     | 639/1450 [00:20<00:24, 32.86trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  44%|████▍     | 643/1450 [00:20<00:26, 30.91trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  45%|████▍     | 647/1450 [00:21<00:26, 30.65trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  45%|████▍     | 651/1450 [00:21<00:25, 31.08trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  45%|████▌     | 655/1450 [00:21<00:24, 32.26trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  45%|████▌     | 659/1450 [00:21<00:25, 31.48trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  46%|████▌     | 663/1450 [00:21<00:25, 31.12trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  46%|████▌     | 667/1450 [00:21<00:29, 26.79trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  46%|████▌     | 670/1450 [00:21<00:30, 25.34trial/s]\n",
      "\u001b[94mcmd1:\u001b[0m depbase=`echo print.lo | sed 's|[^/]*$|.deps/&|;s|\\.lo$||'`;\\\n",
      "\u001b[94mcmd1:\u001b[0m /bin/bash ../../libtool  --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H   -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/../include  -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char  -std=c++11 -MT print.lo -MD -MP -MF $depbase.Tpo -c -o print.lo /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/print.cc &&\\\n",
      "\u001b[94mcmd1:\u001b[0m mv -f $depbase.Tpo $depbase.Plo\n",
      "\u001b[94mcmd1:\u001b[0m libtool: compile:  g++ -DHAVE_CONFIG_H -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/../include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char -std=c++11 -MT print.lo -MD -MP -MF .deps/print.Tpo -c /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/print.cc  -fPIC -DPIC -o .libs/print.o\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  46%|████▋     | 673/1450 [00:22<00:31, 24.37trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  47%|████▋     | 676/1450 [00:22<00:33, 23.36trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  47%|████▋     | 679/1450 [00:22<00:32, 23.57trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  47%|████▋     | 683/1450 [00:22<00:28, 26.54trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  47%|████▋     | 686/1450 [00:22<00:29, 26.34trial/s]\n",
      "\u001b[94mcmd1:\u001b[0m depbase=`echo project.lo | sed 's|[^/]*$|.deps/&|;s|\\.lo$||'`;\\\n",
      "\u001b[94mcmd1:\u001b[0m /bin/bash ../../libtool  --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H   -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/../include  -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char  -std=c++11 -MT project.lo -MD -MP -MF $depbase.Tpo -c -o project.lo /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/project.cc &&\\\n",
      "\u001b[94mcmd1:\u001b[0m mv -f $depbase.Tpo $depbase.Plo\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  48%|████▊     | 689/1450 [00:22<00:29, 25.74trial/s]\n",
      "\u001b[94mcmd1:\u001b[0m libtool: compile:  g++ -DHAVE_CONFIG_H -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/../include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char -std=c++11 -MT project.lo -MD -MP -MF .deps/project.Tpo -c /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/project.cc  -fPIC -DPIC -o .libs/project.o\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  48%|████▊     | 692/1450 [00:22<00:30, 25.05trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  48%|████▊     | 696/1450 [00:22<00:27, 27.58trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  48%|████▊     | 699/1450 [00:23<00:27, 26.96trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  48%|████▊     | 702/1450 [00:23<00:29, 25.12trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  49%|████▊     | 705/1450 [00:23<00:31, 23.38trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  49%|████▉     | 708/1450 [00:23<00:32, 22.89trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  49%|████▉     | 711/1450 [00:23<00:33, 22.24trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  49%|████▉     | 714/1450 [00:23<00:33, 22.00trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  49%|████▉     | 717/1450 [00:23<00:37, 19.80trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  50%|████▉     | 720/1450 [00:24<00:36, 19.81trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  50%|████▉     | 723/1450 [00:24<00:36, 19.75trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  50%|█████     | 727/1450 [00:24<00:31, 22.96trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  50%|█████     | 731/1450 [00:24<00:29, 24.14trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  51%|█████     | 734/1450 [00:24<00:31, 23.05trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  51%|█████     | 737/1450 [00:24<00:30, 23.16trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  51%|█████     | 741/1450 [00:24<00:27, 26.08trial/s]\n",
      "\u001b[94mcmd1:\u001b[0m depbase=`echo prune.lo | sed 's|[^/]*$|.deps/&|;s|\\.lo$||'`;\\\n",
      "\u001b[94mcmd1:\u001b[0m /bin/bash ../../libtool  --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H   -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/../include  -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char  -std=c++11 -MT prune.lo -MD -MP -MF $depbase.Tpo -c -o prune.lo /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/prune.cc &&\\\n",
      "\u001b[94mcmd1:\u001b[0m mv -f $depbase.Tpo $depbase.Plo\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  51%|█████▏    | 745/1450 [00:25<00:24, 28.34trial/s]\n",
      "\u001b[94mcmd1:\u001b[0m libtool: compile:  g++ -DHAVE_CONFIG_H -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/../include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char -std=c++11 -MT prune.lo -MD -MP -MF .deps/prune.Tpo -c /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/prune.cc  -fPIC -DPIC -o .libs/prune.o\n",
      "\u001b[94mcmd1:\u001b[0m depbase=`echo push.lo | sed 's|[^/]*$|.deps/&|;s|\\.lo$||'`;\\\n",
      "\u001b[94mcmd1:\u001b[0m /bin/bash ../../libtool  --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H   -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/../include  -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char  -std=c++11 -MT push.lo -MD -MP -MF $depbase.Tpo -c -o push.lo /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/push.cc &&\\\n",
      "\u001b[94mcmd1:\u001b[0m mv -f $depbase.Tpo $depbase.Plo\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  52%|█████▏    | 749/1450 [00:25<00:23, 29.62trial/s]\n",
      "\u001b[94mcmd1:\u001b[0m libtool: compile:  g++ -DHAVE_CONFIG_H -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/../include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char -std=c++11 -MT push.lo -MD -MP -MF .deps/push.Tpo -c /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/push.cc  -fPIC -DPIC -o .libs/push.o\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  52%|█████▏    | 753/1450 [00:25<00:22, 30.45trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  52%|█████▏    | 757/1450 [00:25<00:24, 28.68trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  52%|█████▏    | 761/1450 [00:25<00:21, 31.40trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  53%|█████▎    | 765/1450 [00:25<00:22, 30.67trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  53%|█████▎    | 769/1450 [00:25<00:21, 31.78trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  53%|█████▎    | 773/1450 [00:26<00:23, 28.50trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  54%|█████▎    | 776/1450 [00:26<00:23, 28.72trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  54%|█████▎    | 779/1450 [00:26<00:24, 27.89trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  54%|█████▍    | 782/1450 [00:26<00:25, 26.47trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  54%|█████▍    | 785/1450 [00:26<00:25, 26.09trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  54%|█████▍    | 788/1450 [00:26<00:26, 25.13trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  55%|█████▍    | 792/1450 [00:26<00:22, 28.65trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  55%|█████▍    | 795/1450 [00:26<00:23, 27.45trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  55%|█████▌    | 799/1450 [00:26<00:21, 30.10trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  55%|█████▌    | 803/1450 [00:27<00:20, 31.70trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  56%|█████▌    | 807/1450 [00:27<00:20, 32.10trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  56%|█████▌    | 811/1450 [00:27<00:22, 27.98trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  56%|█████▌    | 815/1450 [00:27<00:20, 30.67trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  57%|█████▋    | 820/1450 [00:27<00:18, 33.41trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  57%|█████▋    | 824/1450 [00:27<00:19, 31.46trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  57%|█████▋    | 828/1450 [00:27<00:22, 28.10trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  57%|█████▋    | 831/1450 [00:28<00:25, 24.50trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  58%|█████▊    | 834/1450 [00:28<00:25, 23.83trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  58%|█████▊    | 838/1450 [00:28<00:24, 25.29trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  58%|█████▊    | 841/1450 [00:28<00:23, 25.49trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  58%|█████▊    | 844/1450 [00:28<00:23, 25.95trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  58%|█████▊    | 847/1450 [00:28<00:27, 21.61trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  59%|█████▊    | 850/1450 [00:28<00:28, 21.02trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  59%|█████▉    | 854/1450 [00:29<00:25, 23.67trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  59%|█████▉    | 857/1450 [00:29<00:24, 24.19trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  59%|█████▉    | 861/1450 [00:29<00:21, 27.01trial/s]\n",
      "\u001b[94mcmd1:\u001b[0m depbase=`echo randequivalent.lo | sed 's|[^/]*$|.deps/&|;s|\\.lo$||'`;\\\n",
      "\u001b[94mcmd1:\u001b[0m /bin/bash ../../libtool  --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H   -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/../include  -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char  -std=c++11 -MT randequivalent.lo -MD -MP -MF $depbase.Tpo -c -o randequivalent.lo /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/randequivalent.cc &&\\\n",
      "\u001b[94mcmd1:\u001b[0m mv -f $depbase.Tpo $depbase.Plo\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  60%|█████▉    | 864/1450 [00:29<00:22, 26.42trial/s]\n",
      "\u001b[94mcmd1:\u001b[0m libtool: compile:  g++ -DHAVE_CONFIG_H -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/../include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char -std=c++11 -MT randequivalent.lo -MD -MP -MF .deps/randequivalent.Tpo -c /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/randequivalent.cc  -fPIC -DPIC -o .libs/randequivalent.o\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  60%|█████▉    | 867/1450 [00:29<00:22, 25.55trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  60%|██████    | 870/1450 [00:29<00:22, 26.29trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  60%|██████    | 874/1450 [00:29<00:20, 28.70trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  60%|██████    | 877/1450 [00:29<00:20, 28.26trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  61%|██████    | 880/1450 [00:30<00:21, 26.49trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  61%|██████    | 885/1450 [00:30<00:17, 32.02trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  61%|██████▏   | 889/1450 [00:30<00:17, 31.36trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  62%|██████▏   | 893/1450 [00:30<00:16, 32.92trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  62%|██████▏   | 898/1450 [00:30<00:15, 36.17trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  62%|██████▏   | 902/1450 [00:30<00:17, 31.35trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  62%|██████▏   | 906/1450 [00:30<00:17, 31.40trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  63%|██████▎   | 910/1450 [00:30<00:19, 27.18trial/s]\n",
      "\u001b[94mcmd1:\u001b[0m depbase=`echo randgen.lo | sed 's|[^/]*$|.deps/&|;s|\\.lo$||'`;\\\n",
      "\u001b[94mcmd1:\u001b[0m /bin/bash ../../libtool  --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H   -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/../include  -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char  -std=c++11 -MT randgen.lo -MD -MP -MF $depbase.Tpo -c -o randgen.lo /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/randgen.cc &&\\\n",
      "\u001b[94mcmd1:\u001b[0m mv -f $depbase.Tpo $depbase.Plo\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  63%|██████▎   | 913/1450 [00:31<00:20, 25.94trial/s]\n",
      "\u001b[94mcmd1:\u001b[0m libtool: compile:  g++ -DHAVE_CONFIG_H -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/../include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char -std=c++11 -MT randgen.lo -MD -MP -MF .deps/randgen.Tpo -c /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/randgen.cc  -fPIC -DPIC -o .libs/randgen.o\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  63%|██████▎   | 916/1450 [00:31<00:20, 26.41trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  63%|██████▎   | 919/1450 [00:31<00:19, 26.92trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  64%|██████▎   | 923/1450 [00:31<00:18, 28.38trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  64%|██████▍   | 926/1450 [00:31<00:19, 27.17trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  64%|██████▍   | 930/1450 [00:31<00:17, 30.21trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  64%|██████▍   | 934/1450 [00:31<00:16, 30.89trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  65%|██████▍   | 938/1450 [00:31<00:18, 27.29trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  65%|██████▍   | 942/1450 [00:32<00:17, 29.20trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  65%|██████▌   | 946/1450 [00:32<00:19, 25.77trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  66%|██████▌   | 950/1450 [00:32<00:18, 27.51trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  66%|██████▌   | 954/1450 [00:32<00:17, 29.03trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  66%|██████▌   | 958/1450 [00:32<00:18, 27.30trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  66%|██████▋   | 963/1450 [00:32<00:15, 31.63trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  67%|██████▋   | 968/1450 [00:32<00:13, 35.07trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  67%|██████▋   | 972/1450 [00:33<00:14, 32.56trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  67%|██████▋   | 976/1450 [00:33<00:15, 30.18trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  68%|██████▊   | 980/1450 [00:33<00:15, 29.71trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  68%|██████▊   | 984/1450 [00:33<00:15, 30.02trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  68%|██████▊   | 988/1450 [00:33<00:17, 26.73trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  68%|██████▊   | 991/1450 [00:33<00:19, 23.73trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  69%|██████▊   | 995/1450 [00:33<00:18, 25.14trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  69%|██████▉   | 998/1450 [00:34<00:18, 24.97trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  69%|██████▉   | 1002/1450 [00:34<00:16, 26.53trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  69%|██████▉   | 1005/1450 [00:34<00:16, 27.14trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  70%|██████▉   | 1009/1450 [00:34<00:14, 29.61trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  70%|██████▉   | 1014/1450 [00:34<00:13, 33.31trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  70%|███████   | 1018/1450 [00:34<00:12, 33.67trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  70%|███████   | 1022/1450 [00:34<00:13, 32.50trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  71%|███████   | 1026/1450 [00:34<00:13, 31.42trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  71%|███████   | 1030/1450 [00:35<00:13, 30.53trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  71%|███████▏  | 1034/1450 [00:35<00:14, 28.47trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  72%|███████▏  | 1037/1450 [00:35<00:15, 27.37trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  72%|███████▏  | 1040/1450 [00:35<00:14, 27.57trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  72%|███████▏  | 1043/1450 [00:35<00:14, 28.13trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  72%|███████▏  | 1046/1450 [00:35<00:14, 27.41trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  72%|███████▏  | 1049/1450 [00:35<00:15, 26.39trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  73%|███████▎  | 1052/1450 [00:35<00:14, 27.00trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  73%|███████▎  | 1056/1450 [00:36<00:13, 28.57trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  73%|███████▎  | 1059/1450 [00:36<00:13, 28.05trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  73%|███████▎  | 1062/1450 [00:36<00:13, 28.57trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  74%|███████▎  | 1067/1450 [00:36<00:11, 33.39trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  74%|███████▍  | 1071/1450 [00:36<00:11, 32.16trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  74%|███████▍  | 1076/1450 [00:36<00:10, 36.17trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  74%|███████▍  | 1080/1450 [00:36<00:10, 36.71trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  75%|███████▍  | 1085/1450 [00:36<00:09, 39.77trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  75%|███████▌  | 1090/1450 [00:36<00:08, 41.40trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  76%|███████▌  | 1095/1450 [00:37<00:10, 35.32trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  76%|███████▌  | 1099/1450 [00:37<00:09, 35.63trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  76%|███████▌  | 1103/1450 [00:37<00:11, 31.18trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  76%|███████▋  | 1108/1450 [00:37<00:10, 33.40trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  77%|███████▋  | 1112/1450 [00:37<00:11, 28.22trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  77%|███████▋  | 1116/1450 [00:37<00:11, 28.19trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  77%|███████▋  | 1120/1450 [00:37<00:11, 29.26trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  78%|███████▊  | 1124/1450 [00:38<00:10, 31.57trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  78%|███████▊  | 1128/1450 [00:38<00:09, 33.23trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  78%|███████▊  | 1132/1450 [00:38<00:09, 31.93trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  78%|███████▊  | 1136/1450 [00:38<00:10, 30.75trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  79%|███████▊  | 1140/1450 [00:38<00:10, 28.73trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  79%|███████▉  | 1143/1450 [00:38<00:10, 27.99trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  79%|███████▉  | 1146/1450 [00:38<00:10, 28.36trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  79%|███████▉  | 1149/1450 [00:38<00:10, 28.19trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  79%|███████▉  | 1152/1450 [00:39<00:10, 27.72trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  80%|███████▉  | 1155/1450 [00:39<00:11, 26.61trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  80%|███████▉  | 1158/1450 [00:39<00:10, 26.93trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  80%|████████  | 1162/1450 [00:39<00:10, 27.94trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  80%|████████  | 1166/1450 [00:39<00:10, 27.48trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  81%|████████  | 1169/1450 [00:39<00:10, 27.05trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  81%|████████  | 1172/1450 [00:39<00:10, 26.49trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  81%|████████  | 1175/1450 [00:39<00:10, 26.32trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  81%|████████  | 1178/1450 [00:40<00:10, 26.29trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  82%|████████▏ | 1182/1450 [00:40<00:09, 27.42trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  82%|████████▏ | 1186/1450 [00:40<00:09, 28.62trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  82%|████████▏ | 1190/1450 [00:40<00:08, 30.08trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  82%|████████▏ | 1194/1450 [00:40<00:08, 30.57trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  83%|████████▎ | 1198/1450 [00:40<00:09, 27.78trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  83%|████████▎ | 1201/1450 [00:40<00:09, 26.01trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  83%|████████▎ | 1204/1450 [00:41<00:10, 23.93trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  83%|████████▎ | 1208/1450 [00:41<00:09, 25.30trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  84%|████████▎ | 1211/1450 [00:41<00:10, 23.13trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  84%|████████▎ | 1214/1450 [00:41<00:10, 23.49trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  84%|████████▍ | 1218/1450 [00:41<00:09, 25.55trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  84%|████████▍ | 1221/1450 [00:41<00:08, 26.47trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  84%|████████▍ | 1225/1450 [00:41<00:08, 26.61trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  85%|████████▍ | 1228/1450 [00:41<00:08, 25.61trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  85%|████████▍ | 1231/1450 [00:42<00:08, 25.18trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  85%|████████▌ | 1234/1450 [00:42<00:09, 21.97trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  85%|████████▌ | 1237/1450 [00:42<00:10, 20.71trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  86%|████████▌ | 1240/1450 [00:42<00:10, 20.33trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  86%|████████▌ | 1243/1450 [00:42<00:11, 18.23trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  86%|████████▌ | 1245/1450 [00:42<00:11, 18.23trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  86%|████████▌ | 1248/1450 [00:43<00:10, 18.90trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  86%|████████▋ | 1251/1450 [00:43<00:09, 21.07trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  86%|████████▋ | 1254/1450 [00:43<00:08, 22.37trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  87%|████████▋ | 1257/1450 [00:43<00:08, 23.00trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  87%|████████▋ | 1260/1450 [00:43<00:08, 23.28trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  87%|████████▋ | 1264/1450 [00:43<00:07, 25.46trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  87%|████████▋ | 1268/1450 [00:43<00:06, 27.42trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  88%|████████▊ | 1271/1450 [00:43<00:06, 25.96trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  88%|████████▊ | 1274/1450 [00:44<00:06, 25.39trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  88%|████████▊ | 1279/1450 [00:44<00:05, 29.68trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  88%|████████▊ | 1282/1450 [00:44<00:05, 29.76trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  89%|████████▊ | 1286/1450 [00:44<00:05, 32.10trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  89%|████████▉ | 1290/1450 [00:44<00:05, 30.42trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  89%|████████▉ | 1294/1450 [00:44<00:05, 29.31trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  90%|████████▉ | 1298/1450 [00:44<00:04, 31.32trial/s]\n",
      "\u001b[94mcmd1:\u001b[0m depbase=`echo relabel.lo | sed 's|[^/]*$|.deps/&|;s|\\.lo$||'`;\\\n",
      "\u001b[94mcmd1:\u001b[0m /bin/bash ../../libtool  --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H   -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/../include  -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char  -std=c++11 -MT relabel.lo -MD -MP -MF $depbase.Tpo -c -o relabel.lo /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/relabel.cc &&\\\n",
      "\u001b[94mcmd1:\u001b[0m mv -f $depbase.Tpo $depbase.Plo\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  90%|████████▉ | 1303/1450 [00:44<00:04, 34.25trial/s]\n",
      "\u001b[94mcmd1:\u001b[0m libtool: compile:  g++ -DHAVE_CONFIG_H -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/../include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char -std=c++11 -MT relabel.lo -MD -MP -MF .deps/relabel.Tpo -c /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/relabel.cc  -fPIC -DPIC -o .libs/relabel.o\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  90%|█████████ | 1307/1450 [00:45<00:04, 29.75trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  90%|█████████ | 1311/1450 [00:45<00:05, 26.70trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  91%|█████████ | 1314/1450 [00:45<00:05, 25.76trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  91%|█████████ | 1317/1450 [00:45<00:05, 25.97trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  91%|█████████ | 1320/1450 [00:45<00:05, 25.54trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  91%|█████████ | 1323/1450 [00:45<00:05, 25.27trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  92%|█████████▏| 1327/1450 [00:45<00:04, 26.59trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  92%|█████████▏| 1330/1450 [00:46<00:04, 25.27trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  92%|█████████▏| 1333/1450 [00:46<00:04, 26.25trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  92%|█████████▏| 1336/1450 [00:46<00:04, 25.21trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  92%|█████████▏| 1339/1450 [00:46<00:04, 24.82trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  93%|█████████▎| 1342/1450 [00:46<00:04, 24.43trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  93%|█████████▎| 1345/1450 [00:46<00:04, 25.13trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  93%|█████████▎| 1348/1450 [00:46<00:03, 25.69trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  93%|█████████▎| 1351/1450 [00:46<00:03, 25.89trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  94%|█████████▎| 1356/1450 [00:46<00:02, 31.43trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  94%|█████████▍| 1361/1450 [00:47<00:02, 35.18trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  94%|█████████▍| 1365/1450 [00:47<00:02, 34.80trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  94%|█████████▍| 1369/1450 [00:47<00:02, 31.60trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  95%|█████████▍| 1373/1450 [00:47<00:02, 29.88trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  95%|█████████▍| 1377/1450 [00:47<00:02, 26.44trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  95%|█████████▌| 1380/1450 [00:47<00:02, 25.31trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  95%|█████████▌| 1383/1450 [00:47<00:02, 25.21trial/s]\n",
      "\u001b[94mcmd1:\u001b[0m depbase=`echo replace.lo | sed 's|[^/]*$|.deps/&|;s|\\.lo$||'`;\\\n",
      "\u001b[94mcmd1:\u001b[0m /bin/bash ../../libtool  --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H   -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/../include  -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char  -std=c++11 -MT replace.lo -MD -MP -MF $depbase.Tpo -c -o replace.lo /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/replace.cc &&\\\n",
      "\u001b[94mcmd1:\u001b[0m mv -f $depbase.Tpo $depbase.Plo\n",
      "\u001b[94mcmd1:\u001b[0m libtool: compile:  g++ -DHAVE_CONFIG_H -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/../include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char -std=c++11 -MT replace.lo -MD -MP -MF .deps/replace.Tpo -c /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/replace.cc  -fPIC -DPIC -o .libs/replace.o\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  96%|█████████▌| 1386/1450 [00:48<00:02, 23.77trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  96%|█████████▌| 1389/1450 [00:48<00:02, 23.47trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  96%|█████████▌| 1392/1450 [00:48<00:02, 22.23trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  96%|█████████▌| 1395/1450 [00:48<00:02, 22.08trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  96%|█████████▋| 1398/1450 [00:48<00:02, 22.35trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  97%|█████████▋| 1401/1450 [00:48<00:02, 22.63trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  97%|█████████▋| 1404/1450 [00:48<00:01, 23.61trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  97%|█████████▋| 1408/1450 [00:48<00:01, 25.96trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  97%|█████████▋| 1411/1450 [00:49<00:01, 26.45trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  98%|█████████▊| 1414/1450 [00:49<00:01, 25.01trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  98%|█████████▊| 1417/1450 [00:49<00:01, 26.04trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  98%|█████████▊| 1420/1450 [00:49<00:01, 26.85trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  98%|█████████▊| 1423/1450 [00:49<00:01, 26.42trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  98%|█████████▊| 1426/1450 [00:49<00:00, 25.77trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  99%|█████████▊| 1431/1450 [00:49<00:00, 30.41trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  99%|█████████▉| 1435/1450 [00:49<00:00, 27.95trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  99%|█████████▉| 1438/1450 [00:50<00:00, 26.31trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences:  99%|█████████▉| 1442/1450 [00:50<00:00, 27.17trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences: 100%|█████████▉| 1445/1450 [00:50<00:00, 26.11trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences: 100%|█████████▉| 1448/1450 [00:50<00:00, 25.31trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Predicting phoneme sequences: 100%|██████████| 1450/1450 [00:50<00:00, 28.66trial/s]\n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.08.13, Block: 8, Trial: 20\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AY  |  G EH T  |  T AY ER D  |  W IH DH  |  DH AH  |  S AO NG  |  AH N D  |  D EY K S  |  R IH T UW N  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.08.13, Block: 8, Trial: 21\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  IH M ER JH AH S IY  |  K EH R  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.08.13, Block: 8, Trial: 22\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  Y UW  |  K R IY EH N T  |  AH  |  B IH G ER  |  S ER P R AY Z  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.08.13, Block: 8, Trial: 23\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AY  |  TH IH NG K  |  M EY B IY  |  Y UW  |  L UH K  |  AE T  |  IH T  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.08.13, Block: 8, Trial: 24\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  SH OW  |  DH AE T  |  DH EY  |  D UW  |  HH AE V  |  P R AA B L AH M Z  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.08.13, Block: 8, Trial: 25\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AY  |  EH N JH OY  |  DH AE T  |  T UW  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.08.13, Block: 8, Trial: 26\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AY  |  M UW V D  |  T UW  |  G EH Z AH S T  |  S IH T IY  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.08.13, Block: 8, Trial: 27\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  M EY B IY  |  F AO R  |  T AY M Z  |  AH  |  W IY K  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.08.13, Block: 8, Trial: 28\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  W EH N  |  HH IY  |  S IY D Z  |  IH T  |  T UW  |  HH IH Z  |  IH V EH N AH S T  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.08.13, Block: 8, Trial: 29\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  DH EH R Z  |  JH AH S T  |  N OW  |  W AH N  |  ER AW N D  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.08.13, Block: 8, Trial: 30\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  DH AH  |  S IH S T AH M  |  R AY T  |  N AW  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.08.13, Block: 8, Trial: 31\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  IY DH ER  |  W AH N  |  AH V  |  DH EH M  |  W UH D  |  B IY  |  AH  |  T IY SH AH N  |  CH OY S  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.08.13, Block: 8, Trial: 32\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  TH IH NG Z  |  L AY K  |  DH AE T  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.08.13, Block: 8, Trial: 33\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AY  |  L AY V D  |  IH N  |  P L EY S AH Z  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.08.13, Block: 8, Trial: 34\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  Y UW  |  HH AE D  |  T UW  |  CH EY N JH  |  IH T  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.08.13, Block: 8, Trial: 35\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  IH T  |  JH AH S T  |  S AO R T  |  AH V  |  HH AE P AH N Z  |  AH N AH M AE T IH K L IY  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.08.13, Block: 8, Trial: 36\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  M IH N AH S T  |  Y AO R  |  AH P  |  IH N  |  DH AH  |  AH S IH UW  |  P AA R T AH L  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.08.13, Block: 8, Trial: 37\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  IH T S  |  AH  |  JH OW K IH NG  |  HH AE Z ER D  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.08.13, Block: 8, Trial: 38\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  IY V IH N  |  AE F T ER  |  Y UW  |  W EY T  |  Y AO R  |  DH AE N  |  N EH K S  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.08.13, Block: 8, Trial: 39\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AY  |  G EH S  |  DH EY  |  M AH CH  |  B IY  |  V IH N IH S T  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.08.13, Block: 9, Trial: 15\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  DH EY  |  K EY M  |  B AE K  |  L IH T ER  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.08.13, Block: 9, Trial: 16\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  W EH L  |  W AH T  |  D UW  |  Y UW  |  D UW  |  AA N  |  Y AO R  |  Y AA R D  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.08.13, Block: 9, Trial: 17\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  DH AE T S  |  W AY  |  DH EY  |  K AO L  |  DH EH M  |  S W OW M IH NG  |  B UW L Z  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.08.13, Block: 9, Trial: 18\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  IH T  |  K AH V ER Z  |  DH AH  |  B UH K  |  AH V  |  DH AH  |  N IY T AH L  |  IH K S EH N S AH S  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.08.13, Block: 9, Trial: 19\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  T AO K  |  T UW  |  AW ER  |  W IH K T ER  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.08.13, Block: 9, Trial: 20\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  Y UW  |  W ER  |  JH AH S T  |  AH P  |  DH EH R  |  DH EH N  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.08.13, Block: 9, Trial: 21\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  L AE S T  |  Y IH R  |  AO R  |  DH AH  |  Y IH R  |  B IH F AO R\n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.08.13, Block: 9, Trial: 22\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  K UW  |  TH IH NG  |  S AH NG  |  AH V  |  Y AO R  |  CH OY S  |  F R AH M  |  DH AE T  |  SH OW  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.08.13, Block: 9, Trial: 23\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  L AY K  |  B L AE K  |  AY D  |  B IY  |  AH N D  |  DH AE T  |  K AY N D  |  AH V  |  TH IH NG  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.08.13, Block: 9, Trial: 24\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  IH F  |  HH IY  |  D IH D  |  S AH M TH IH NG  |  B AE D  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.08.13, Block: 9, Trial: 25\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AY  |  TH IH NG K  |  DH EH R  |  AH  |  G UH D  |  T IY M  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.08.13, Block: 9, Trial: 26\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AY  |  K AE N T  |  TH IH NG K  |  AH V  |  DH AH  |  N EY M  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.08.13, Block: 9, Trial: 27\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AH  |  L AA R JH  |  S AY L D  |  K EH R  |  F AH S IH L AH T IY  |  N AW  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.08.13, Block: 9, Trial: 28\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AA R  |  Y UW  |  R IH M AH N  |  K AH TH L IY  |  AO R  |  S AH M TH IH NG  |  EH L S  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.08.13, Block: 9, Trial: 29\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  DH AE T  |  K AY N D  |  Y UW V  |  R EH D  |  R IY S AH N T L IY  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.08.18, Block: 6, Trial: 24\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  IH T  |  IH Z  |  R IH L IY  |  G UH D  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.08.18, Block: 6, Trial: 25\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AY  |  D UW  |  P L EY  |  DH AH  |  P IY AE N OW  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.08.18, Block: 6, Trial: 26\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  K AH M AH N T  |  AH N D  |  JH OY N  |  DH AH  |  K AA N F ER S IH SH AH N  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.08.18, Block: 6, Trial: 27\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  DH AE T  |  IH Z  |  DH AH  |  P OY N T  |  AH V  |  DH IH S  |  AA R D AH L  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.08.18, Block: 6, Trial: 28\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  W IY V  |  R IH M AA L D AH L D  |  AO L  |  AW ER  |  Y UW N AH T S  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.08.18, Block: 6, Trial: 29\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AH N AH DH ER  |  R IY L  |  G UH D  |  W AH N  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.08.18, Block: 6, Trial: 30\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  IH T S  |  M AO R  |  IH F IH SH AH N T  |  T UW  |  D UW  |  TH IH NG Z  |  S AH S EH L F  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.08.18, Block: 6, Trial: 31\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AY  |  G EH S  |  DH AE T  |  AY  |  R IH L IY  |  D OW N T  |  N OW  |  DH AE T  |  M AH CH  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.08.18, Block: 6, Trial: 32\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  D OW N T  |  T EH L  |  DH AE T  |  T UW  |  AH  |  N EH D AH F  |  T EH K S AH N  |  N OW  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.08.18, Block: 6, Trial: 33\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AY  |  W IH SH  |  AY  |  K UH D  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.08.18, Block: 6, Trial: 34\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AY  |  K AE N  |  AA R D L IY  |  W EY T  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.08.18, Block: 6, Trial: 35\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  DH EH R  |  G OW IH NG  |  T UW  |  B IY  |  IH N  |  IY V IH N  |  W ER S  |  SH EH P  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.08.18, Block: 6, Trial: 36\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  DH EY  |  B L AO  |  DH AH  |  W EY SH AH L  |  AA N  |  IH T  |  AH DH ER  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.08.18, Block: 6, Trial: 37\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AY  |  W UH D  |  M AH CH  |  R AE DH ER  |  OW N  |  M AY  |  OW N  |  HH OW M  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.08.18, Block: 6, Trial: 38\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  N AA T  |  IY V IH N  |  AH  |  T R EH S IY  |  S L AH K  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.08.18, Block: 6, Trial: 39\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  JH R AO  |  EH N IY  |  K AH N K L UW ZH AH N Z  |  B EY K S T  |  AA N  |  R IY L  |  IH N T EH L AH S AH N S  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.08.18, Block: 6, Trial: 41\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  JH AH S T  |  T UW  |  F AO T  |  IH T  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.08.18, Block: 6, Trial: 42\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  DH AE T  |  IH Z  |  JH AH S T  |  P ER S IH N AH L  |  F IY L IH NG  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.08.18, Block: 6, Trial: 43\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  DH EY  |  D OW N T  |  S IY  |  IH CH  |  AH DH ER  |  V EH R IY  |  HH AO F AH N  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.08.18, Block: 6, Trial: 44\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  IH T  |  HH AE Z  |  B IH N  |  R IY L  |  G UH D  |  T AO K IH NG  |  T UW  |  Y UW  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.08.18, Block: 6, Trial: 45\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  R EH D IH NG  |  AH N D  |  TH IH NG Z  |  L AY K  |  DH IH S  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.08.18, Block: 6, Trial: 46\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  DH EY  |  T R AY  |  T UW  |  DH OW  |  IH N  |  G UH D  |  S T AH F  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.08.18, Block: 6, Trial: 47\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  IH F  |  Y UW  |  G EH T  |  P L EY S  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.08.18, Block: 6, Trial: 48\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AY  |  TH IH NG K  |  DH IH S  |  IH Z  |  L AY K  |  T UW  |  Y IH R Z  |  AH G OW  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.08.18, Block: 6, Trial: 49\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  DH AH  |  B IY P  |  IH N  |  DH AH  |  B R EH G R AE M  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.08.18, Block: 7, Trial: 25\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  HH IY  |  HH AE S  |  IH T  |  R IH L IY  |  N AY S  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.08.18, Block: 7, Trial: 26\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  IH Z  |  HH IY  |  AH  |  P R AA B L AH M  |  T R AY L D  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.08.18, Block: 7, Trial: 27\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  T UW  |  G R OW  |  AH P  |  AH N D  |  T UW  |  D IH S AY D  |  W AH T  |  DH EY  |  W AA N T  |  T UW  |  D UW  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.08.18, Block: 7, Trial: 28\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  DH EY  |  HH AE D  |  N OW  |  CH OY S  |  B AH T  |  T UW  |  L IY V  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.08.18, Block: 7, Trial: 29\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  S EH N D L IY  |  DH EH R  |  HH AE Z K  |  T UW  |  B IY  |  AH  |  K AH L IH ZH AH N  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.08.18, Block: 7, Trial: 30\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  Y UW  |  G EH T  |  M AO R  |  S T AH F  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.08.18, Block: 7, Trial: 31\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  SH IY  |  S EH D  |  DH AE T  |  DH AH  |  K L OW ZH R ER Z  |  W UH D  |  B IY  |  P R ER M AH N AH N T  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.08.18, Block: 7, Trial: 32\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  DH EY  |  AO L  |  L EH P T  |  AE Z  |  HH IY  |  JH AA L D  |  AW T  |  T UW  |  JH OY N  |  DH EH M  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.08.18, Block: 7, Trial: 33\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AY  |  TH IH NG K  |  IH T  |  W AH N  |  D UW  |  S AH M TH IH NG  |  F AO R  |  IH T  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.08.18, Block: 7, Trial: 34\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AY  |  D OW N T  |  L AY V  |  IH N  |  AH  |  HH AW S  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.08.18, Block: 7, Trial: 35\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  S OW  |  HH IY Z  |  AH  |  F AE N  |  AH V  |  IH N S T UW IY  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.08.18, Block: 7, Trial: 36\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  DH AE T  |  W AA Z  |  AO L M OW S T  |  AE N  |  IH N S AE M P AH L  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.08.18, Block: 7, Trial: 37\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AH P T EH SH AH N  |  IH Z  |  W AH T  |  M OW S T  |  AH V  |  DH EH M  |  N IY D  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.08.18, Block: 7, Trial: 38\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AE N  |  IH N D AH AE SH AH N AH L  |  P AH K Y AH L EY SH AH N  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.08.18, Block: 7, Trial: 39\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  W AH T  |  T UW  |  G OW  |  AE K T IH NG  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.08.18, Block: 7, Trial: 40\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  N OW  |  AH M IY D IY AH  |  R IH P AO R D S  |  AH V  |  K AE ZH AH L T IY Z  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.08.18, Block: 7, Trial: 41\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  Y UW  |  HH AE V  |  T UW  |  W ER K  |  ER AW N D  |  IH T  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.08.18, Block: 7, Trial: 42\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  K AH N F Y UW ZH AH N  |  AH N D  |  AH P S OW T AH N T IY  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.08.18, Block: 7, Trial: 43\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  DH EH R  |  IH Z  |  N OW  |  K OW B  |  B IH G  |  AH P  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.08.18, Block: 7, Trial: 44\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  W AH T  |  HH AE P AH Z  |  IH F  |  W IY  |  L UW Z  |  W ER S  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.08.18, Block: 7, Trial: 45\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  DH EH R  |  W AA Z  |  N OW  |  P OY N T  |  IH N  |  D EH L IH NG  |  W IH DH  |  HH IH M  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.08.18, Block: 7, Trial: 46\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  N AA T  |  K W AY T  |  DH AE T  |  AO F AH N  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.08.18, Block: 7, Trial: 47\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  D OW N T  |  T R AE V AH L  |  T UW  |  M AH CH  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.08.18, Block: 7, Trial: 48\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  W AH T S  |  IH N  |  L AY K  |  F R AH M  |  AE N  |  AA R D IH S T S  |  P OY N T  |  AH V  |  V Y UW  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.08.18, Block: 7, Trial: 49\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  IH T  |  L UH K S  |  L AY K  |  DH EY V  |  G AA T  |  AH  |  W IH P AH N  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.08.20, Block: 7, Trial: 25\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AY  |  HH AE V  |  TH R IY  |  L EH F T  |  IH N  |  DH AH  |  HH AW S  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.08.20, Block: 7, Trial: 26\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  DH AE T  |  AY D IY AH  |  F IH K S  |  M IY  |  IH G Z AE K T L IY  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.08.20, Block: 7, Trial: 27\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  IH F  |  AY  |  HH AE D  |  T UW  |  B IH G  |  AH  |  F EY V ER IH T  |  T IY M  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.08.20, Block: 7, Trial: 28\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  B R IH NG IH NG  |  S AH M TH IH NG  |  F AO R  |  AH  |  P AH B L IH K  |  P IH G N AH K  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.08.20, Block: 7, Trial: 29\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AY M  |  B IY IH NG  |  V EH R IY  |  G UH D  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.08.20, Block: 7, Trial: 30\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  HH IY  |  W ER K S  |  AA N  |  DH AH  |  R AW R AH N D  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.08.20, Block: 7, Trial: 31\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AY  |  G OW  |  W IH DH  |  G UH D  |  IH N T IH SH AH N Z  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.08.20, Block: 7, Trial: 32\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  N OW  |  DH EH R Z  |  N OW  |  W EY  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.08.20, Block: 7, Trial: 33\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  DH AE T  |  W IH L  |  S EH D  |  W AH N D ER F AH L  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.08.20, Block: 7, Trial: 34\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  Y AO R  |  K AA R  |  IH Z  |  F AY N  |  AH N D  |  EH V R IY TH IH NG  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.08.20, Block: 7, Trial: 35\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  L AY K  |  S EH K AH N D  |  JH AA B Z  |  DH AE T  |  DH EY  |  W ER K  |  IH N  |  DH AH  |  AE K T ER D ER N Z  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.08.20, Block: 7, Trial: 36\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  W UH D AH N T  |  DH AE T  |  B IY  |  AO F AH L  |  IH F  |  Y UW  |  W ER  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.08.20, Block: 7, Trial: 37\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  W IY R  |  S AH P OW S T  |  T UW  |  B IY  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.08.20, Block: 7, Trial: 38\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  G OW  |  T UW  |  T EY K  |  AH  |  SH AW ER  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.08.20, Block: 7, Trial: 39\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  HH AW EH V ER  |  DH EH R  |  IH Z  |  N OW  |  AE K CH UW AH L  |  W EY  |  T UW  |  M EH ZH ER  |  DH IH S  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.08.20, Block: 7, Trial: 40\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  R IH L IY  |  W EH L  |  R EH G Y AH L EY T AH D  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.08.20, Block: 7, Trial: 41\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  DH EH R Z  |  N AH TH IH NG  |  R AO NG  |  W IH DH  |  DH AE T  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.08.20, Block: 7, Trial: 42\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AH DH ER  |  S T EY T S  |  HH AE V  |  T EY K AH N  |  S T R AA G ER  |  M V IH ZH ER Z  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.08.20, Block: 7, Trial: 43\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  W IH CH  |  AY  |  TH AO T  |  W AA Z  |  AH  |  R IY L  |  IH N T AH R EH S T IH NG  |  K W AA S AH N  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.08.20, Block: 7, Trial: 44\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  IH T S  |  AE Z  |  M AH CH  |  R IY S ER Z  |  AE Z  |  DH EY  |  K AE N  |  P AA S AH B L IY  |  D UW  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.08.20, Block: 7, Trial: 45\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  Y UH R  |  N AA L AH JH AH B AH L  |  AA N  |  DH AE T  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.08.20, Block: 7, Trial: 46\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  D UW  |  Y UW  |  S EH L  |  DH EH M  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.08.20, Block: 7, Trial: 47\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  N EH V ER  |  B EY T IH D  |  DH AH  |  AW T S AY D  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.08.20, Block: 7, Trial: 48\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  N AW  |  IH T S  |  B AE K  |  AH G EH N  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.08.20, Block: 7, Trial: 49\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  W IY R  |  N EH V ER  |  G OW IH NG  |  T UW  |  G EH T  |  DH AE T  |  B AE K  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.08.20, Block: 8, Trial: 25\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AY  |  D OW N T  |  S IY  |  TH IH NG Z  |  CH EY N JH IH NG  |  R IH L IY  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.08.20, Block: 8, Trial: 26\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  HH UW  |  Y UW  |  N EH V ER  |  IH K S P EH K T  |  T UW  |  W EH N  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.08.20, Block: 8, Trial: 27\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  D IH D  |  Y UW  |  S IY  |  P AH S IH F IH K  |  AY S  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.08.20, Block: 8, Trial: 28\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  DH EH R  |  W AA Z  |  S AH M  |  R IH L IY  |  N EH S T IY  |  P ER P AH N AY Z IH NG  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.08.20, Block: 8, Trial: 29\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  DH AH  |  D IH S IH ZH AH N  |  AH P IH L D  |  AH  |  L OW ER  |  K AA R T  |  R IH L IH NG  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.08.20, Block: 8, Trial: 30\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AY  |  TH IH NG K  |  DH AE T  |  IH Z  |  AE N  |  AE K S AH L AH N T  |  P R OW G R AE M  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.08.20, Block: 8, Trial: 31\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  DH AH  |  P AH L IH T AH K AH L  |  AE K S P IH K T  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.08.20, Block: 8, Trial: 32\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  S IH N S  |  AY  |  D UW  |  AH  |  L AA T  |  AH V  |  P R AA JH EH K S  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.08.20, Block: 8, Trial: 33\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  DH EY  |  D IH D AH N T  |  K AH T  |  AH S  |  AO F  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.08.20, Block: 8, Trial: 34\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  EH V ER IY  |  M EY JH ER  |  S IH T IY  |  HH AE Z  |  AH  |  TH IY D AH  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.08.20, Block: 8, Trial: 35\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  DH AH  |  R OW L  |  IH N  |  DH AH  |  F AE M AH L IY  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.08.20, Block: 8, Trial: 36\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  W IY  |  D OW N T  |  R IH L IY  |  IH T  |  AW T  |  T UW  |  M AH CH  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.08.20, Block: 8, Trial: 38\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  G IH V  |  AH N D  |  IH N S EH D AH V  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.08.20, Block: 8, Trial: 39\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  DH EY  |  L AY V  |  IH T  |  AH P  |  T UW  |  Y UW  |  AH N D  |  Y AO R  |  JH AH B M IH K T  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.08.20, Block: 8, Trial: 40\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  T UW  |  B AE K S  |  S T UW P L EY S  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.08.20, Block: 8, Trial: 41\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  K UH D  |  Y UW  |  HH AE V  |  S N OW  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.08.20, Block: 8, Trial: 42\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  W EH N  |  DH EY  |  W ER  |  Y AH NG G ER  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.08.20, Block: 8, Trial: 43\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AY  |  HH OW P  |  Y UW  |  EH N JH OY D  |  DH IH S  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.08.20, Block: 8, Trial: 44\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AY  |  W AA Z  |  P R IH T IY  |  SH AA K T  |  AE T  |  DH AE T  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.08.20, Block: 8, Trial: 45\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  N AA T  |  DH AE T  |  AY V  |  B IH N  |  AH W EH R  |  AH V  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.08.20, Block: 8, Trial: 46\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AY  |  W AA Z  |  G OW IH NG  |  T UW  |  S EY  |  AY  |  AO L W EY Z  |  EH N JH OY D  |  DH AE T  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.08.20, Block: 8, Trial: 47\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  IH T S  |  N AA T  |  L AY K  |  AY M  |  G OW IH NG  |  HH OW M  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.08.20, Block: 8, Trial: 48\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  D UW  |  DH EY  |  AO L  |  L IY V  |  IH N  |  DH AH  |  EH R IY AH  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.08.20, Block: 8, Trial: 49\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AA R  |  R OW D  |  B AY  |  DH EH R  |  K IH D Z  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.08.25, Block: 1, Trial: 25\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  IH T S  |  AH  |  M IH N IY AH\n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.08.25, Block: 1, Trial: 26\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  DH EY  |  HH AE V  |  DH AH  |  M EH R AH\n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.08.25, Block: 1, Trial: 27\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AH L T AH M AH T L IY  |  W AH T  |  Y UW  |  D UW  |  IH Z  |  Y AO R  |  D IH S IH ZH AH N\n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.08.25, Block: 1, Trial: 28\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AY  |  TH IH NG K  |  DH EY  |  G OW  |  T UW  |  F AA R\n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.08.25, Block: 1, Trial: 29\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  DH AH  |  B EH S T  |  IH N Z AE M P AH L  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.08.25, Block: 1, Trial: 30\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  S OW L ER  |  P AW ER  |  S AE T AH L IH\n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.08.25, Block: 1, Trial: 31\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  B IH F AO R  |  AY  |  R IH T AY R D\n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.08.25, Block: 1, Trial: 32\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  DH EY  |  K AE N  |  B IY  |  S AH L EH K T IH V  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.08.25, Block: 1, Trial: 33\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AY  |  W EH R  |  L AA T S  |  AH V  |  CH AO R T S\n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.08.25, Block: 1, Trial: 34\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  M EY B IY  |  F AY V  |  AO R  |  S IH K S  |  Y IH R Z  |  AH G OW  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.08.25, Block: 1, Trial: 35\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AY V  |  D AH N  |  P R IH T IY  |  G UH D  |  AE T  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.08.25, Block: 1, Trial: 36\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  DH AH  |  M AO R  |  R UW V  |  DH EY  |  N IY D  |  T UW  |  IH N S T ER S AY\n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.08.25, Block: 1, Trial: 37\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  W IY  |  W IH L  |  AH P IY L  |  DH IH S  |  D IH S IH ZH AH N\n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.08.25, Block: 1, Trial: 38\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AH N D  |  HH IY  |  DH AE T  |  L IY K S  |  AH S  |  T UW  |  AW ER  |  N EH K S T  |  P OY N T  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.08.25, Block: 1, Trial: 39\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AH S EH N T L IY  |  W EH N  |  Y UW  |  G EH T  |  D AH N  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.08.25, Block: 1, Trial: 40\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AY  |  N UW  |  R AY T  |  AH W EY  |  HH IY  |  S IH UH D AH N T  |  T R AY  |  T UW  |  N AH CH  |  DH AH  |  T AO T ER  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.08.25, Block: 1, Trial: 41\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  HH AW  |  SH UH D  |  DH EY  |  D UW  |  IH\n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.08.25, Block: 1, Trial: 42\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  M AY  |  W AY F  |  K AY N D  |  AH V  |  L AH P S  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.08.25, Block: 1, Trial: 43\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AE F T ER  |  F AY V  |  Y UW Z  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.08.25, Block: 1, Trial: 44\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  D UW  |  S AH M TH IH NG  |  T UW  |  P IH T AH F AY  |  DH AH  |  S K UW L  |  P R AA P AH T IY\n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.08.25, Block: 1, Trial: 45\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  JH AH S T  |  T UW  |  G EH T  |  AH  |  T AY M  |  DH AE T  |  W IY  |  K AE N  |  B OW TH  |  G OW  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.08.25, Block: 1, Trial: 46\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  DH EH N  |  Y UW  |  HH AE V  |  T UW  |  M EY K  |  AH  |  S AE L AH\n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.08.25, Block: 1, Trial: 47\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  B AH T  |  IH T S  |  AH L AO NG  |  DH AH  |  L AY K S\n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.08.25, Block: 1, Trial: 48\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  DH AE T S  |  N IY T  |  DH AH M Y UW  |  L AY K  |  W ER S  |  T IH CH IH NG  |  AO L S OW  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.08.25, Block: 1, Trial: 49\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AY M  |  AO L R EH D IY  |  AA N  |  M AY  |  JH AA B\n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.08.27, Block: 1, Trial: 25\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AH  |  L IH T AH L  |  T R EY K AH N  |  F AO R  |  IY CH  |  D\n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.08.27, Block: 1, Trial: 26\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  N OW IH NG  |  Y AO R  |  CH OY S AH Z\n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.08.27, Block: 1, Trial: 27\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  K R AY D  |  L AH V Z  |  HH IH D  |  AH G EH N S T  |  T EH S\n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.08.27, Block: 1, Trial: 28\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  Y UW  |  G AE T  |  P L IY M  |  DH EH M  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.08.27, Block: 1, Trial: 29\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  P R AA B AH B L IY  |  M IH L AH T S  |  AH V  |  D AA L ER Z\n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.08.27, Block: 1, Trial: 30\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  S OW  |  AY  |  G AA T  |  AH N D ER  |  DH EH R  |  AH N D  |  M EH S T  |  W IH DH  |  DH AH  |  V\n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.08.27, Block: 1, Trial: 31\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AE Z  |  F AA R  |  AE Z  |  JH AH S T  |  HH AE V IH NG  |  HH AH N D AH Z  |  ER AW N D  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.08.27, Block: 1, Trial: 32\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  IH T  |  W UH D  |  D IH P EH N D  |  AH B AW N  |  W IH CH  |  W AH N  |  Y UW  |  W AA N\n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.08.27, Block: 1, Trial: 33\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  DH AE T  |  W AH N  |  W AA Z IH N T  |  R IH L IY  |  W EH L  |  T R EY D\n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.08.27, Block: 1, Trial: 34\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  HH IY  |  AO L S OW  |  W AH T S  |  T UW  |  S IY  |  M AO R  |  S K UW L  |  S EH P T IY  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.08.27, Block: 1, Trial: 35\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  L EH S  |  S EY  |  T IH P AH K AH L\n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.08.27, Block: 1, Trial: 36\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  D UW  |  Y UW  |  K AH N T IH N IY UW  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.08.27, Block: 1, Trial: 37\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AY  |  P UH T  |  AO L  |  DH AH  |  M AH N IY  |  IH N T UW  |  IH T  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.08.27, Block: 1, Trial: 38\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AH N D  |  IH T S  |  JH AH S T  |  IH N EH D AH B\n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.08.27, Block: 1, Trial: 39\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  IH T S  |  F AH N IY  |  AY  |  W AA Z  |  R EY D\n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.08.27, Block: 1, Trial: 40\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AY  |  S T IH L  |  G AA T  |  AH  |  K AH P AH L  |  AH V  |  Y IH R Z  |  AA N  |  IH N  |  T UW  |  G OW  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.08.27, Block: 1, Trial: 41\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  W IY  |  D OW N T  |  HH AE V  |  EH N IY W EH R  |  T UW  |  G OW  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.08.27, Block: 1, Trial: 42\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AH N D  |  IH T S  |  D IH S IH ZH AH N  |  K AE N  |  L IY N  |  T UW  |  AH  |  D IH F ER AH N T  |  R IY Z\n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.08.27, Block: 1, Trial: 43\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  W AH N  |  IH N  |  DH AH  |  M AO R N IH NG  |  AH N D  |  W AH N  |  IH N  |  DH AH  |  IY V N IH NG  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.08.27, Block: 1, Trial: 44\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  K AE N  |  Y UW  |  IH M AE JH AH N\n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.08.27, Block: 1, Trial: 45\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  IH T S  |  AH B AW T  |  TH ER D IY  |  S IH N S  |  M AY L Z  |  AH W EY  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.08.27, Block: 1, Trial: 46\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AY  |  K AE N  |  G AA T  |  DH AE T  |  M AH CH  |  AO F  |  DH AH  |  EH N D  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.08.27, Block: 1, Trial: 47\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AE Z  |  L AO NG  |  AE Z  |  HH IY  |  P AH S T  |  IH N  |  DH AH  |  AW ER Z  |  HH IY  |  N IY D S  |  T UW  |  D UW  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.08.27, Block: 1, Trial: 48\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  DH AE T  |  W AH N  |  DH AE T  |  Y UW  |  HH AE D  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.08.27, Block: 1, Trial: 49\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  B OW TH  |  AH V  |  DH AH  |  CH IH L D R AH N  |  W ER  |  IH N  |  K AA L IH JH  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.09.01, Block: 8, Trial: 25\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  Y UW  |  K AE N  |  G EH T  |  DH AH  |  EH N F ER R M EY SH AH N  |  T UW  |  S EH T  |  IH T  |  AH P  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.09.01, Block: 8, Trial: 26\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  F AY N D  |  AH  |  P L EY S  |  DH AE T  |  HH AE Z  |  AH  |  N AY S  |  JH AA B  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.09.01, Block: 8, Trial: 27\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  T UW  |  B IH K  |  DH AH  |  R AY T  |  P ER S AH N  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.09.01, Block: 8, Trial: 28\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AY  |  G EH T  |  K AO L Z  |  AE T  |  HH OW M  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.09.01, Block: 8, Trial: 29\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  S AH M B AA D IY  |  W AA Z  |  T EH L IH NG  |  M IY  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.09.01, Block: 8, Trial: 30\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AH  |  K AH P AH L  |  AH V  |  P R AA B L AH M Z  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.09.01, Block: 8, Trial: 31\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  B AH T  |  DH AE T  |  W AA Z  |  AH  |  R IH L IY  |  F AH N  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.09.01, Block: 8, Trial: 32\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  IH T  |  S AW M Z  |  L AY K  |  IH T S  |  G UH D  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.09.01, Block: 8, Trial: 33\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AY  |  V OW T  |  R IH L IH JH AH K L IY  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.09.01, Block: 8, Trial: 34\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  DH EH R  |  EH K S AH L AH N T  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.09.01, Block: 8, Trial: 35\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  N EH K  |  HH AE Z  |  G R EY T  |  V IH ZH AH N  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.09.01, Block: 8, Trial: 36\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  DH AE T S  |  JH AH S T  |  AE N  |  IH K S T R IY M  |  IH K S EH P AH L  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.09.01, Block: 8, Trial: 37\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AH  |  L AA T  |  AH V  |  TH IH NG Z  |  AA R  |  R IH L IY  |  V AE L AH N T  |  T AY P  |  M UW V IY Z  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.09.01, Block: 8, Trial: 38\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AY  |  TH IH NG K  |  DH AE T  |  B IY  |  N IY T  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.09.01, Block: 8, Trial: 39\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  P UH T  |  AO L  |  Y AO R  |  R IY S AY K AH B AH L Z  |  IH N  |  DH AE T  |  W AH N  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.09.01, Block: 8, Trial: 40\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  Y UH R  |  P R IH Z AH N T  |  L OW K EY SH AH N  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.09.01, Block: 8, Trial: 41\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AY L  |  T EY K  |  IH T  |  AW T  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.09.01, Block: 8, Trial: 42\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  P IY P AH L  |  G OW IH NG  |  IH N T UW  |  D IH F ER AH N T  |  F IY L D Z  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.09.01, Block: 8, Trial: 43\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AY  |  G EH S  |  DH AH  |  K W EH S CH AH N  |  IH Z  |  IH N  |  M AY  |  M AY N D  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.09.01, Block: 8, Trial: 44\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  L EH T S  |  T AO K  |  AH B AW T  |  HH IY R  |  P AH L UW SH AH N  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.09.01, Block: 8, Trial: 45\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AY  |  W OW N T  |  B IY  |  D R AY V IH NG  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.09.01, Block: 8, Trial: 46\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  W IH CH  |  IH Z  |  AH  |  G UH D  |  D IY L  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.09.01, Block: 8, Trial: 47\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AY  |  N OW  |  L AA T S  |  AH V  |  W IH M AH N  |  W UH D  |  D UW  |  IH T  |  AO L  |  DH AH  |  T AY M  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.09.01, Block: 8, Trial: 48\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  DH IH S  |  IH Z  |  M AY  |  D EY D S  |  P AA R T  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.09.01, Block: 8, Trial: 49\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  Y UW  |  K UH D  |  S T IH K  |  T UW  |  DH AE T  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.09.01, Block: 9, Trial: 25\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  EH N JH OY  |  DH AH  |  IH N V EH K SH ER  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.09.01, Block: 9, Trial: 26\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AY  |  D OW N T  |  HH AE V  |  AE K S EH S  |  AH DH ER  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.09.01, Block: 9, Trial: 27\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  S ER T AH N L IY  |  IH F  |  Y UW  |  W AA CH  |  IH T  |  EH N IY  |  AH M AW N T  |  AH V  |  T AY M  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.09.01, Block: 9, Trial: 28\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  N OW  |  IH N K AH M  |  T AE K S AH Z  |  IH N  |  T EH K S AH Z  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.09.01, Block: 9, Trial: 29\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AY  |  D OW N T  |  N OW  |  IH F  |  Y UW  |  HH AE V  |  W AH N  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.09.01, Block: 9, Trial: 30\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  W AY  |  AA R  |  AW ER  |  P R IH Z AH N Z  |  OW V ER AW N D IH D  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.09.01, Block: 9, Trial: 31\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  DH EY  |  W UH D  |  V OW T  |  P T R UW  |  CH OY S  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.09.01, Block: 9, Trial: 32\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  W EH N  |  HH IY  |  G OW Z  |  T UW  |  S K UW L  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.09.01, Block: 9, Trial: 33\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  IH T  |  W AA Z  |  L AY K  |  F AY V  |  AO R  |  S IH K S  |  D AA L ER Z  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.09.01, Block: 9, Trial: 34\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AY  |  JH AH S T  |  TH AO T  |  DH AE T  |  DH EY  |  B R AH G  |  AH P  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.09.01, Block: 9, Trial: 35\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  IH T S  |  OW N L IY  |  L AY K  |  IH L EH V AH N T  |  HH AH N D R AH D  |  S K W EH R  |  F IY T  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.09.01, Block: 9, Trial: 36\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  D OW N T  |  B L AO  |  DH EH R  |  AE N D  |  AH V  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.09.01, Block: 9, Trial: 37\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  W EH N  |  HH IY  |  K AH M Z  |  DH AH  |  F AY N AH L  |  D IH S IH ZH AH N  |  W IH L  |  B IY  |  M EY D  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.09.01, Block: 9, Trial: 38\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  DH AH  |  K AA R P AH N IH NG  |  IH Z  |  G R OW Z  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.09.01, Block: 9, Trial: 39\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  K IY  |  P OY N T S  |  F R AH M  |  DH AH  |  M EY N Z  |  R IH P AO R T  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.09.01, Block: 9, Trial: 40\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  K DH EH R  |  AW T  |  AW ER  |  B IH S N M AH N T  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.09.01, Block: 9, Trial: 41\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  N UW  |  K AA M P AH N T  |  AH N D  |  EH V R IY TH IH NG  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.09.01, Block: 9, Trial: 42\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  DH EY  |  W UH D  |  HH AE V  |  HH AE D  |  K IH D Z  |  R AH N IH NG  |  ER AW N D  |  B AY  |  DH EH N  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.09.01, Block: 9, Trial: 43\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AY  |  TH IH NG K  |  AW ER  |  N EH K S T  |  K AA R  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.09.01, Block: 9, Trial: 44\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AY  |  TH IH NG K  |  IH T S  |  DH EH R  |  W EY  |  AH V  |  S EY IH NG  |  HH AW  |  W EH L  |  Y UW  |  D UW  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.09.01, Block: 9, Trial: 45\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AO L  |  AH V  |  AH  |  S AH T AH D  |  Y UW  |  L UH K  |  AH N D  |  DH EH R Z  |  TH R IY  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.09.01, Block: 9, Trial: 46\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  HH IY  |  B EH T ER  |  N AA T  |  B IY  |  M AY N  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.09.01, Block: 9, Trial: 47\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AH  |  M EY D  |  D IY SH  |  AH N D  |  AH  |  D IH S ER T  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.09.01, Block: 9, Trial: 48\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  HH AW  |  M EH N IY  |  D IH V IH ZH AH N Z  |  D AH Z  |  HH IY  |  HH AE V  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.09.01, Block: 9, Trial: 49\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  L AO NG  |  T ER M  |  K AA N S AH K W EY S SH AH Z  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.09.03, Block: 8, Trial: 25\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AY  |  N OW  |  AH  |  G ER L  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.09.03, Block: 8, Trial: 26\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  W IY  |  S EH T  |  AH  |  R EH D ER  |  S EH S T IH D  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.09.03, Block: 8, Trial: 27\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AY  |  D OW N T  |  HH AE V  |  EH N IY  |  P R AA B AH M  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.09.03, Block: 8, Trial: 28\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AY  |  HH AE D  |  AH  |  HH AA R D  |  T AY M  |  G EH T IH NG  |  S IH T IY  |  AA N  |  AH  |  JH UH R IY  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.09.03, Block: 8, Trial: 29\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  D OW N T  |  IY T  |  DH AH  |  Y AO NG K  |  AE T  |  AO L  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.09.03, Block: 8, Trial: 30\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  DH EY  |  HH AE S K T  |  AH S  |  T UW  |  B AH L D ER L  |  AW ER  |  N UW Z P EY P T ER K Z  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.09.03, Block: 8, Trial: 31\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  DH EY  |  M EY K  |  AH  |  K AH L EH K SH AH N  |  AA N  |  M AH N D IY  |  F AO R  |  Y AO R D  |  W EY T S\n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.09.03, Block: 8, Trial: 32\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  K UH D AH N T  |  K AE CH  |  W AH N  |  T UW  |  S EY M  |  Y AO R  |  L AY F  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.09.03, Block: 8, Trial: 33\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  IH T  |  W AH Z  |  AH  |  G R EY T  |  P L EH S ER  |  S P IY K IH NG  |  W IH DH  |  Y UW  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.09.03, Block: 8, Trial: 34\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  D UW  |  W IY  |  JH AH S T  |  G OW  |  AH HH EH D  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.09.03, Block: 8, Trial: 35\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AY  |  F EH L T  |  K AY N D  |  AH V  |  S T AH B AH D  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.09.03, Block: 8, Trial: 36\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AY  |  TH IH NG Z  |  IH T S  |  G R EY D  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.09.03, Block: 8, Trial: 37\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AH  |  M IH JH ER AH IY  |  AH V  |  DH AH  |  JH UH R IY  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.09.03, Block: 8, Trial: 38\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  Y UW  |  N OW  |  W AH T  |  AY  |  AE M  |  S EY IH NG  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.09.03, Block: 8, Trial: 39\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  DH EY  |  T ER N  |  DH EH M  |  L UW S  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.09.03, Block: 8, Trial: 40\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  HH IY  |  W EH N T  |  T UW  |  V IY N AA F  |  W AH N  |  M AY N  |  AE N D  |  K EY M  |  B AE K  |  AH N AH DH ER  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.09.03, Block: 8, Trial: 41\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  M AO R  |  AO R  |  L EH S  |  AE T  |  HH OW M  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.09.03, Block: 8, Trial: 42\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  Y UW  |  K AE N  |  AH V OY D  |  DH IH S  |  P R AA B L AH M  |  IH N  |  T UW  |  W\n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.09.03, Block: 8, Trial: 43\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  W AH T S  |  DH AH  |  S P EH N SH IH L T IY  |  DH AE T  |  Y UH R  |  L UH K IH NG  |  F AO R\n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.09.03, Block: 8, Trial: 44\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  JH ER B AH N IY  |  IH Z  |  AH  |  G EH S  |  IH N  |  P OY N T  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.09.03, Block: 8, Trial: 45\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  S AH M T ER  |  IH T  |  W AA Z  |  IY Z IY  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.09.03, Block: 8, Trial: 46\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AY V  |  D AH N  |  DH OW Z  |  T UW  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.09.03, Block: 8, Trial: 47\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  IH T S  |  AH  |  HH OW L  |  IH K S P R IH EH R AH IH S  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.09.03, Block: 8, Trial: 48\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  IH N  |  AO R D ER  |  T UW  |  B AA L IH JH  |  DH AH  |  D IH V IH ZH AH N  |  DH AH  |  S K UW L Z  |  M AH CH  |  B IY  |  S P L AE N T  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.09.03, Block: 8, Trial: 49\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  T R IH D AH B AH L  |  D EH S P AH  |  S IH SH IH N  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.09.03, Block: 9, Trial: 9\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  IH T S  |  AO L  |  R OW D  |  AH P  |  IH N T UW  |  W AH N  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.09.03, Block: 9, Trial: 10\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  Y UW  |  D UW  |  HH AE V  |  AH  |  S EH P ER R IH T  |  EH R IY AH  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.09.03, Block: 9, Trial: 11\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  TH IH NG K  |  AH B AW T  |  HH AW  |  M EH N IY  |  AO T AH M OW B IY L Z  |  DH EH R  |  AA R  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.09.03, Block: 9, Trial: 12\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  W AH T  |  AA R  |  DH AH  |  AH DH ER Z  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.09.03, Block: 9, Trial: 13\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  IH T S  |  R IH L IY  |  K AY N D  |  AH V  |  K R EY Z IY\n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.09.03, Block: 9, Trial: 14\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  DH AH  |  L EY T AH S T  |  AE N D R OY D  |  F OW D Z  |  F AO R  |  L EH S\n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.09.03, Block: 9, Trial: 15\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AH G EH N  |  AW ER  |  CH OY S AH Z  |  AA R  |  N AA T  |  M EY D  |  IH N  |  AH  |  F AE K Y UW M  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.09.03, Block: 9, Trial: 17\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  B EY B AH Z  |  AH V  |  K AH N D R AH S  |  SH UH D  |  HH AE V  |  N OW  |  IH L UW ZH AH N Z  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.09.03, Block: 9, Trial: 18\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  DH EY  |  AH S AY D  |  Y UW  |  AH  |  T AA P IH K  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.09.03, Block: 9, Trial: 19\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  DH EH R Z  |  DH IH S  |  W AH N  |  AE K T ER  |  EH V R IY W AH N  |  L AY K S  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.09.24, Block: 8, Trial: 10\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AE Z  |  HH IY  |  G AA T  |  T UW  |  B IY  |  AH  |  T EH N AH JH AH ER  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.09.24, Block: 8, Trial: 11\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AY  |  W EH D  |  L AH V  |  T UW  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.09.24, Block: 8, Trial: 12\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AO L  |  DH IY Z  |  AH DH ER  |  P IY P AH L  |  AA R  |  AW T  |  R AH N IH NG  |  ER AW N D  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.09.24, Block: 8, Trial: 13\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AH  |  L AA T  |  AH V  |  M UW V ER D ER  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.09.24, Block: 8, Trial: 14\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  W IY  |  HH AE D  |  AE N  |  OW K EY N AH N  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.09.24, Block: 8, Trial: 15\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  DH AE T  |  IH Z  |  T R UW  |  IH N  |  AH L AH N T AY  |  AH N D  |  AH K R AO S  |  DH IH S  |  T EY SH AH N  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.09.24, Block: 8, Trial: 16\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  IH Z AH N  |  DH AE T  |  F AH N IY  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.09.24, Block: 8, Trial: 17\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  W IH DH  |  T EY M Z  |  K AE N JH ER L  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.09.24, Block: 8, Trial: 18\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  DH AH  |  ER L IY  |  R IH M P AH B L B IH IY  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.09.24, Block: 8, Trial: 19\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  D UW  |  Y UW  |  G OW  |  F AO R  |  L AH NG  |  V EY K IH K T EY SH Z  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.09.24, Block: 9, Trial: 25\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AH N D  |  HH AH N D AH S T  |  AH M AW N T  |  AH V  |  T AY M  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.09.24, Block: 9, Trial: 26\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  B R EY IH NG  |  M AO R  |  AO F T AH D  |  DH AE N  |  Y UW ZH AH W AH L  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.09.24, Block: 9, Trial: 27\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AY  |  TH AO T  |  IH T  |  W AA Z  |  P R IH T IY  |  G UH D  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.09.24, Block: 9, Trial: 28\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  R EY S  |  AO R IY AH T AH D  |  R AE DH ER  |  DH AE N  |  CH IH N D ER  |  B EY S  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.09.24, Block: 9, Trial: 29\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  DH EH R  |  N IY D Z  |  T UW  |  B IY  |  AH  |  L AA N  |  D JH R AH N  |  S AH M W EH R  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.09.24, Block: 9, Trial: 30\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  HH AW  |  S T R AH NG  |  IH Z  |  IH T  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.09.24, Block: 9, Trial: 31\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AY  |  W EH L  |  AH G R IY  |  T UW  |  DH AE T  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.09.24, Block: 9, Trial: 32\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  IH F  |  Y UH R  |  IH N V AA L D  |  Y ER S EH L F  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.09.24, Block: 9, Trial: 33\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  DH EY  |  K AE N  |  AO L W EY Z  |  M EY B IY  |  G EH T  |  S AH M B AA D IY  |  AW S  |  T UW  |  K UH K  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.09.24, Block: 9, Trial: 34\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AY  |  K UH D  |  D UW  |  IH T  |  N AW  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.09.24, Block: 9, Trial: 35\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  D UW  |  Y UW  |  HH AE V  |  AH  |  R OW N T OW  |  D EH L ER  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.09.24, Block: 9, Trial: 36\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  IH F  |  DH EY  |  D UW  |  K AH M  |  B AE K  |  DH AE S  |  Y IH R  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.09.24, Block: 9, Trial: 37\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AY  |  TH IH NG K  |  SH IY  |  HH AE Z  |  P R AA B L AH M Z  |  W IH DH  |  DH AE T  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.09.24, Block: 9, Trial: 38\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  IH T S  |  S AH T  |  AH  |  T R AH B AH L  |  HH IY R  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.09.24, Block: 9, Trial: 39\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  DH EY  |  T R EY T  |  DH AH  |  N UW S L IY Z  |  AH V  |  DH EH R  |  P EH ER  |  R AY T  |  N AW  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.09.24, Block: 9, Trial: 40\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AE F T ER  |  DH AE T  |  S IY Z AH N  |  AA L AH Z  |  HH AE D  |  AH  |  D IH S IH ZH AH N  |  T UW  |  M EY K  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.09.24, Block: 9, Trial: 41\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  HH IY Z  |  D AH N  |  AH  |  B AH N CH  |  AH V  |  P AA K T AH M AO R  |  M UW V IY Z  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.09.24, Block: 9, Trial: 42\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AH N D  |  W AH T  |  W AA Z  |  DH AH  |  P OY N T  |  AH V  |  IH T  |  AO L  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.09.24, Block: 9, Trial: 43\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  P IY P AH L  |  G EH T  |  V EH R IY  |  AH B F S EH T  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.09.24, Block: 9, Trial: 44\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  IH T S  |  D UW IH NG  |  AH  |  L AA T  |  AH V  |  D EH M AH S  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.09.24, Block: 9, Trial: 45\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  HH AE V  |  Y UW  |  EH V ER  |  HH AE D  |  AH V  |  HH ER  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.09.24, Block: 9, Trial: 46\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  DH EH R  |  P R IH T IY  |  F ER G IH M IH NG  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.09.24, Block: 9, Trial: 47\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  W EH R  |  Y UW  |  F R AH M  |  ER IH JH AH N AH L IY  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.09.24, Block: 9, Trial: 48\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  W IY  |  M AE N AH JH Z  |  T UW  |  G EH T  |  T UW  |  W AH N  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.09.24, Block: 9, Trial: 49\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  W EH N  |  Y UW  |  W AA CH  |  DH EH M  |  G OW  |  AH P  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.09.29, Block: 3, Trial: 25\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  DH AH  |  G R IY N  |  T AE K S  |  AH B AH V  |  IH Z  |  AH  |  M AE T ER  |  AH V  |  CH OY S  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.09.29, Block: 3, Trial: 26\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  L AA T  |  AH V  |  F IH L IH S AE L F IH K AH L  |  K AA N T EH N T  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.09.29, Block: 3, Trial: 27\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  L EH T S  |  DH AE N  |  HH AE V  |  DH AH  |  T R AY AH L Z  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.09.29, Block: 3, Trial: 28\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  IY V IH N  |  IH F  |  IH T S  |  S M OW K IH NG  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.09.29, Block: 3, Trial: 29\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AY  |  G EH T  |  TH IH NG Z  |  D AH N  |  F AE N T D ER  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.09.29, Block: 3, Trial: 30\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  IH T  |  W AA Z  |  F AH N  |  T UW  |  W ER K  |  W IH DH  |  HH IH M  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.09.29, Block: 3, Trial: 31\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AY  |  TH IH NG K  |  M AH S T  |  P IY P AH L  |  W AH N  |  T UW  |  B IY  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.09.29, Block: 3, Trial: 32\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  T R AY V IH NG  |  AH  |  K AA R  |  F AO R  |  L AO NG G ER  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.09.29, Block: 3, Trial: 33\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  DH AH  |  K L AE S IH K AH L  |  TH IH NG K  |  DH AE T  |  Y UW  |  S IY  |  AA N  |  T IY V IY  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.09.29, Block: 3, Trial: 34\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  IH T  |  IH Z  |  N EH R F AO R  |  D IH S AH P OY R T IH NG  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.09.29, Block: 3, Trial: 35\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  D OW N T  |  G EH T  |  T UW  |  M AH CH  |  M AH N IY  |  F AO R  |  DH EH M  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.09.29, Block: 3, Trial: 36\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AY V  |  B IH N  |  HH IY R  |  S EH N S  |  S EH V AH N T IY  |  F AO R  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.09.29, Block: 3, Trial: 37\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AY  |  HH AE V AH N T  |  HH AE D  |  T UW  |  R IH P L EY S  |  DH AH  |  TH IH NG  |  Y EH T  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.09.29, Block: 3, Trial: 38\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AY  |  AE L IY  |  R EH K AH M AH N D  |  IH T  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.09.29, Block: 3, Trial: 39\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AE T  |  L IY S T  |  D IH D IH SH AH N AH L IY  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.09.29, Block: 3, Trial: 40\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  W IY R  |  K AY N D  |  AH V  |  AE T  |  DH AH  |  EH N D  |  AH V  |  DH AE T  |  T R IH L  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.09.29, Block: 3, Trial: 41\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AY  |  K AE N  |  G EH T  |  DH IH S  |  Y AA R D  |  IH N  |  SH EY P  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.09.29, Block: 3, Trial: 42\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  SH IY Z  |  R IH L IY  |  AH  |  G UH D  |  F IH SH ER  |  W UH M AH N  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.09.29, Block: 3, Trial: 43\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  IH N  |  AW ER  |  P AH T IH K Y AH L ER  |  S IH CH UW EY SH AH N  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.09.29, Block: 3, Trial: 44\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AY  |  Y UW ZH AH W AH L IY  |  W AA N T  |  M AY  |  D AO G  |  IH N  |  DH AH  |  P OY R K  |  N IH R  |  M AY  |  HH OW M  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.09.29, Block: 3, Trial: 45\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AY  |  D IH D  |  DH AE T  |  W IH DH  |  DH AH  |  S T EH K T AH N  |  B EY B IY  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.09.29, Block: 3, Trial: 46\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  IH T S  |  D IH S AH P OY R T IH NG  |  HH AW  |  DH IH S  |  W AA Z  |  HH AE N D AH L D  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.09.29, Block: 3, Trial: 47\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  HH IY  |  T OW L D  |  AH S  |  T UW  |  G EH T  |  IH K S AY D  |  AW ER  |  K AA R  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.09.29, Block: 3, Trial: 48\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AY  |  G EH S  |  W EH N  |  Y UH R  |  F IH L IH NG  |  D IH F IH D IH D  |  D OW N T  |  G IH V  |  AH P  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.09.29, Block: 3, Trial: 49\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  DH AE T  |  W UH D  |  B IY  |  AO L  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.09.29, Block: 4, Trial: 25\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  L AH V  |  IH Z  |  EH N AH JH IY  |  B IY T AH F AH L  |  EH N ER S IY  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.09.29, Block: 4, Trial: 26\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  M EY B IY  |  DH AH  |  K AE B P  |  R IY K  |  M EY D  |  W AA Z  |  B IH T W IY N  |  HH IH M  |  AH N D  |  DH AH  |  AA N IY AH F L OY M AH N T  |  L AY N  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.09.29, Block: 4, Trial: 27\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  HH IY  |  T R AY D  |  T UW  |  HH AY D  |  IH N  |  DH AH  |  B AE K  |  AH V  |  DH AH  |  R UW M  |  R UW M  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.09.29, Block: 4, Trial: 29\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  SH IY  |  IH Z  |  AO L S OW  |  K L AE S Z  |  T UW  |  DH AH  |  T R AE P  |  IH M AH N AH S T R EY SH AH N  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.09.29, Block: 4, Trial: 30\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AH  |  D IH T EH R IY AH L  |  AA N  |  AH M P L OY IH NG  |  DH AH  |  P R EH N S AH B AH L Z  |  AH V  |  EH N IY AE D IY  |  K UH D  |  S T IH L  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.09.29, Block: 4, Trial: 31\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  G EH T  |  B R EY NG IH NG  |  N OW Z  |  AH L ER Z  |  AH N D  |  S P EH SH AH L  |  R IY P AO R T S  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.09.29, Block: 4, Trial: 32\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  DH AH  |  T AY M  |  F AO R  |  JH R UW V IY AH L  |  F AY N Z  |  IH Z  |  B IH HH AY N D  |  AH S  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.09.29, Block: 4, Trial: 33\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  DH EH R  |  W AA Z  |  T AO K  |  AE T  |  DH AH  |  S IH T ER  |  AA N  |  M EH S T IH NG  |  AH V  |  DH AH  |  T R AH P  |  T R AE JH AH D IY  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.09.29, Block: 4, Trial: 34\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  SH IY  |  IH Z  |  DH AH  |  OW N L IY  |  G ER L  |  HH UW  |  K AH M Z  |  T UW  |  AW ER  |  S K UW L  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.09.29, Block: 4, Trial: 35\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  DH EH R  |  N UW  |  HH AW S  |  K AA S T  |  JH AH S T  |  AE Z  |  M AH CH  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.09.29, Block: 4, Trial: 36\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  DH AE T  |  M AA R T  |  IH T S  |  HH AY ER AH N D  |  L EH V ER  |  AA N  |  R EH K ER D  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.09.29, Block: 4, Trial: 37\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  P L IY Z  |  S IY  |  AW ER  |  P R AY V AH S IY  |  N OW T ER Z  |  F AO R  |  D IY T ER L Z  |  AH V  |  Y AO R  |  D EY T AH  |  P R AH T EH SH AH N  |  R AY T S  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.09.29, Block: 4, Trial: 38\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AE T  |  DH AH  |  EH N D  |  DH AH  |  W ER K ER Z  |  T ER N D  |  ER AW N D  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.09.29, Block: 4, Trial: 39\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  S T IH L  |  OW N L IY  |  L AA T S  |  AH V  |  CH IY D ER Z  |  AH N D  |  S AH M  |  IH V ER S AH T IY  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.09.29, Block: 4, Trial: 40\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  JH AH S T  |  K AH N V ER N  |  DH IH S  |  W IH DH  |  Y AO R  |  F IH N D ER  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.09.29, Block: 4, Trial: 41\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  S T IH L  |  M AY L Z  |  Y UW Z  |  W AO T ER  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.09.29, Block: 4, Trial: 42\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  B EH T ER  |  T AH G EH DH ER  |  HH AE V  |  S IH R IY AH N S  |  K W EH S CH AH N Z  |  T UW  |  EH K S ER  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.09.29, Block: 4, Trial: 43\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  S EH D  |  AH  |  R IY P AO R T  |  DH AE T  |  DH IH S  |  B UH G  |  L AO NG  |  K AH N T EH N D Z  |  S P AE M  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.09.29, Block: 4, Trial: 44\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  DH IH S  |  IH Z  |  AH  |  V EH R IY  |  IH M P AO R T AH N T  |  G EY S  |  F R AH M  |  AW ER  |  P OY N T  |  AH V  |  V Y UW  |  HH IY  |  AE D AH D  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.09.29, Block: 4, Trial: 45\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  W IY  |  B AA T  |  Y UW  |  B UH S  |  AH N D  |  T OY Z S  |  T UW  |  F IY D  |  Y AO R  |  AE P AH T AY N T  |  F AO R  |  S P EY S  |  IH K S T L ER EY SH AH N  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.09.29, Block: 4, Trial: 46\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AY  |  K AE N T  |  P UH T  |  IH T  |  D AW N  |  AH N D  |  AY  |  K UH D  |  L AH K  |  AE T  |  IH T  |  F AO R  |  D EY Z  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.09.29, Block: 4, Trial: 47\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  DH AH  |  OW N L IY  |  TH IH NG  |  L EH F  |  T UW  |  D UW  |  IH Z  |  T UW  |  HH AE D  |  OW V ER  |  DH AH  |  K AH N T R UW L Z  |  T UW  |  EH Z UW OW  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.09.29, Block: 4, Trial: 48\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AH N D  |  HH IY  |  W OW N T  |  T EY K  |  IH T  |  F R EH R L IY  |  AH IH L EH K S  |  Y UW  |  G EY V  |  IH T  |  T UW  |  HH IH M  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.09.29, Block: 4, Trial: 49\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AH N D  |  Y UW  |  S IY  |  W AH T  |  HH AE P AH N D  |  R IY S AH N T L IY  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.10.01, Block: 7, Trial: 25\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  W IY V  |  G AA T  |  S AH M  |  G AY Z  |  HH IY R  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.10.01, Block: 7, Trial: 26\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  HH IY  |  G EH S  |  HH OW M  |  F R AH M  |  W ER K  |  L EY T  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.10.01, Block: 7, Trial: 27\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  M AY  |  T AE K S AH Z  |  HH AE V  |  G AO N  |  AH P  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.10.01, Block: 7, Trial: 28\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  IH T S  |  W AH N S  |  IH M P AO R T AH N T  |  T UW  |  Y UW  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.10.01, Block: 7, Trial: 29\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  W IY  |  EH N JH OY  |  D UW IH NG  |  IH T  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.10.01, Block: 7, Trial: 30\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  D IH D  |  P ER S EH N T  |  AO R  |  TH ER T IY N  |  P ER S EH N T  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.10.01, Block: 7, Trial: 31\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  DH AH  |  D IH T R OY T  |  N UW Z  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.10.01, Block: 7, Trial: 32\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  HH AE Z  |  W EH L  |  AE Z  |  Y UW  |  D UW  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.10.01, Block: 7, Trial: 33\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  HH UW  |  D IH D  |  Y UW  |  V OW T  |  F AO R  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.10.01, Block: 7, Trial: 34\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AY  |  R IH L IY  |  L AH V  |  IH T  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.10.01, Block: 7, Trial: 35\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  DH EY  |  HH AE V  |  DH IH S  |  W ER L D  |  F UH T B AO L  |  L IH NG K  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.10.01, Block: 7, Trial: 36\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AH  |  V OY S  |  F R AH M  |  DH AH  |  G R AW D  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.10.01, Block: 7, Trial: 37\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  DH AH  |  W AH N Z  |  DH AE T  |  K IH R D  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.10.01, Block: 7, Trial: 38\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AY  |  L AY K  |  DH AH  |  W EY  |  DH AE T  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.10.01, Block: 7, Trial: 39\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  V IH ZH AH N  |  IH Z  |  W AH N  |  AH V  |  DH AH  |  F AH N D EY N AH N AH L  |  P L EY G Z  |  F AO R  |  EH N IY  |  AE N T R AH B AH T UW IY  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.10.01, Block: 7, Trial: 40\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  DH AE T  |  W AA Z AH N T  |  AH  |  S T EH N D ER D  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.10.01, Block: 7, Trial: 41\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  DH AH  |  P L EY N D Z  |  AH N D  |  AO L  |  DH AE T  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.10.01, Block: 7, Trial: 42\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  W IY  |  M UW V D  |  T UW  |  HH AY W EY  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.10.01, Block: 7, Trial: 43\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  N OW  |  D IH S IH ZH AH N Z  |  HH AE V  |  B IH N  |  M EY D  |  AE T  |  DH IH S  |  T AY M  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.10.01, Block: 7, Trial: 44\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  B IH K AO Z  |  Y UH R  |  R AY T  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.10.01, Block: 7, Trial: 45\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  N AA T  |  D AH N  |  EH N IY TH IH NG  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.10.01, Block: 7, Trial: 46\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  W AH T  |  D UW  |  DH EY  |  K AO L  |  IH T  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.10.01, Block: 7, Trial: 47\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  L AY V T  |  AA N  |  AH  |  F AA R M  |  F AO R  |  S IH S T IH NG  |  Y IH R Z  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.10.01, Block: 7, Trial: 48\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AH DH ER  |  S AY N D  |  AH V  |  DH AH  |  K OY N  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.10.01, Block: 7, Trial: 49\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  B AH T  |  AY  |  TH IH NG K  |  IH T S  |  S AE L AH D  |  AH N D  |  DH IH S  |  P OY N T  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.10.01, Block: 8, Trial: 20\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  P L AA Z  |  HH IY  |  Y UW Z D  |  T UW  |  L IH L EH V ER  |  P IY IH Z AH N Z  |  B IH F AO R  |  DH AH  |  AH B AE K L AH L IY V Z  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.10.01, Block: 8, Trial: 21\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  D UW  |  N AA T  |  K AE M P IY  |  R ER D Z  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.10.01, Block: 8, Trial: 22\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AH N D  |  DH EH R  |  AA R  |  AH DH ER  |  V IH CH ER Z  |  IH N  |  DH AH  |  P R AA B IH K S  |  T UW  |  N OW T  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.10.01, Block: 8, Trial: 23\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  L AH V IH K ER Z  |  IH N  |  B OW TH  |  M AA R T IY Z  |  HH AE V  |  K AO L D  |  F AO R  |  S EY B AH L AY Z IH NG  |  DH AH  |  R AY D AH M P L EY S AH Z  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.10.01, Block: 8, Trial: 24\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  SH IY  |  K L AE N Z  |  AY L AH V IY  |  N EH V ER  |  SH UH D  |  S AY N Z  |  AH V  |  DH AH  |  EH N V EH K SH AH N  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.10.01, Block: 8, Trial: 25\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  HH IY R  |  IH Z  |  DH AH  |  V EH D IY OW  |  AH V  |  DH AH  |  CH AY L IY  |  R OW Z  |  S AH M B IH D  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.10.01, Block: 8, Trial: 26\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  DH IH S  |  IH Z  |  S OW  |  B Y UW T AH F AH L  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.10.01, Block: 8, Trial: 27\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  G OW D AH L Z  |  W IH SH AH N  |  T UW  |  P IY D  |  AH P  |  DH AH  |  W EY M P  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.10.01, Block: 8, Trial: 28\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  HH IY  |  S EH D  |  B IH L IY S  |  R IY S P AA N D IH D  |  S W EH M L IY  |  T UW  |  DH AE T  |  IH N SH AH D AH D  |  F AO R  |  DH AH  |  D R AY V ER Z  |  S EH M P T IY NG  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.10.01, Block: 8, Trial: 29\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  W IH TH EH N  |  M ER D ER Z T  |  DH EY  |  S EY  |  DH AH  |  F AY ER D  |  W AA Z  |  AH N D ER  |  K AH N T R OW L  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.10.01, Block: 8, Trial: 30\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  HH IY  |  L UH K T  |  AH P  |  T UW  |  F AY N D  |  DH AH  |  TH R AO NG  |  F L IY IH NG  |  IH N T UW  |  DH AH  |  V EH R AH N S  |  AH V  |  B OW TH  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.10.01, Block: 8, Trial: 31\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  DH AH  |  T UW  |  AH V  |  DH EH M  |  IH T EH M D  |  T UW  |  M EY K  |  AH  |  B R IH NG  |  F AO R  |  IH N  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.10.01, Block: 8, Trial: 32\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  W IY  |  B R AO T  |  G R EY T  |  N UW Z  |  F AO R  |  Y UW  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.10.01, Block: 8, Trial: 33\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AE N  |  AE K T AH M AH T  |  AH N D  |  T EH N D ER  |  D R ER V ER  |  AH B AW T  |  K EH R IH NG  |  AA N  |  AH G EY S  |  L AY K S  |  HH AH NG P G R AH Z  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.10.01, Block: 8, Trial: 34\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  S OW IH NG  |  IY S T  |  K AE N Z IH S  |  AH N AH DH ER  |  S P EH SH AH L  |  V AE L AH JH S  |  IH N  |  DH AH  |  T AW N  |  AH V  |  S AH N D AH L AY N  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.10.01, Block: 8, Trial: 35\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AY  |  M UW V D  |  T UW  |  L AO N D IH D  |  IH N  |  S ER CH  |  AH V  |  B AA S IH L  |  B AH T  |  F R EH N D Z  |  W ER  |  HH AA R D  |  T UW  |  K AH M  |  M AY  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.10.01, Block: 8, Trial: 36\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  SH OW L IY  |  DH AH  |  S AW N D  |  AH V  |  S AE L IH Z  |  W AA Z  |  DH AH  |  OW N L IY  |  AH P R OW B AH T  |  W AH N  |  HH IY R  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.10.01, Block: 8, Trial: 37\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  S OW  |  DH AH  |  W ER R L D  |  K AE N  |  S AE L AH B R EY N  |  D IH S EH DH ER  |  HH IY R  |  HH IY  |  AE D IH D  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.10.01, Block: 8, Trial: 38\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AH  |  G R IH N CH ER  |  IH N  |  DH AH  |  HH AY S  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.10.01, Block: 8, Trial: 39\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AO L  |  DH AH  |  L AY V  |  AH N D  |  DH AH  |  P R IH R Z  |  G AO N D  |  W IH L IH NG  |  HH IY L  |  B IY  |  F AY N  |  S UW N  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.10.06, Block: 6, Trial: 15\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  IH T  |  M IY  |  B IY  |  IH N  |  DH AH  |  F Y IH SH ER  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.10.06, Block: 6, Trial: 16\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  ER N IH NG  |  IH Z  |  M AH N IY  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.10.06, Block: 6, Trial: 17\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AH N D  |  DH EH R  |  AA R D ER  |  T UW  |  G EH T  |  R EH D  |  AH V  |  F AO R  |  DH AH  |  W IY K EH N D  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.10.06, Block: 6, Trial: 18\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AY  |  TH IH NG K  |  IH T S  |  JH AH S T  |  AH  |  K R AY IH NG  |  S EY M  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.10.06, Block: 6, Trial: 19\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  S EH L  |  P R AA D AH K T S  |  AH B OY R D  |  AE Z  |  M AH CH  |  AE Z  |  W IY  |  B R IH NG  |  IH N  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.10.06, Block: 6, Trial: 20\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  DH IH S  |  Y IH R  |  AH N D  |  L AE S T  |  Y IH R  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.10.06, Block: 6, Trial: 21\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AY  |  D OW N T  |  HH OW N  |  M AY  |  HH OW M  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.10.06, Block: 6, Trial: 22\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  DH EH R L  |  D UW  |  F AY N D  |  IH N  |  DH EH R  |  S T AH D IY Z  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.10.06, Block: 6, Trial: 23\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  DH AE T S  |  DH AH  |  B EH S T  |  W EY  |  T UW  |  D UW  |  IH T  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.10.06, Block: 6, Trial: 24\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  IH T  |  W AA Z  |  HH AA R D  |  T UW  |  EH K S EH P T  |  DH AE T  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.10.06, Block: 6, Trial: 25\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  M AY  |  F AA DH ER  |  D IY Z AH Z  |  M IY  |  AH B AW T  |  K AO R M IH NG  |  K AA R K IH NG  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.10.06, Block: 6, Trial: 26\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  Y UW  |  N OW  |  IH T S  |  S OW  |  IH K S AE T IH NG  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.10.06, Block: 6, Trial: 27\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  IH T  |  W AA Z  |  P R IH T IY  |  S EH V AH L ER  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.10.06, Block: 6, Trial: 28\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  IH T  |  W AA Z  |  W EH N  |  AY  |  W AA Z  |  AH  |  CH AY L D  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.10.06, Block: 6, Trial: 29\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AY  |  HH AE V AH N T  |  HH AE D  |  AH  |  CH EY N JH S  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.10.06, Block: 7, Trial: 21\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  HH AE V  |  Y UW  |  S IY N  |  G OW Z  |  Y EH T  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.10.06, Block: 7, Trial: 22\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  HH IY  |  M EY D  |  M IY  |  L AE F  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.10.06, Block: 7, Trial: 23\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  W EH R  |  W IY  |  W EH N T  |  F R AH M  |  DH EH R  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.10.06, Block: 7, Trial: 24\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  DH AH  |  M IH T ER EY T  |  CH OY S  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.10.06, Block: 7, Trial: 25\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  SH IY  |  W AA Z  |  IH N AE L Y ER AH T IH D  |  IH N  |  CH AE N ER AH IY  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.10.06, Block: 7, Trial: 26\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  W EH L  |  W IY R  |  R IH L IY  |  OW F ER B OW T AH N T  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.10.06, Block: 7, Trial: 27\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AY  |  B IH L IY V  |  IH T  |  IH Z  |  T UW  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.10.06, Block: 7, Trial: 28\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  G EY V  |  Y UW  |  AH  |  R AH N  |  F AO R  |  Y AO R  |  M AH N IY  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.10.06, Block: 7, Trial: 29\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AY  |  D OW T IH S T  |  DH AE T  |  IH Z  |  V OY S  |  T R IH B L AH L D  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.10.06, Block: 7, Trial: 30\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  S OW  |  AY  |  K AE N  |  G OW  |  AW T  |  AH N D  |  G OW  |  T UW  |  DH AH  |  B AA R  |  DH IH S  |  L EY T  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.10.06, Block: 7, Trial: 31\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  M AY  |  R UW M AH N T  |  S AY N D  |  M IY  |  AH P  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.10.06, Block: 7, Trial: 32\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AY  |  W AA Z  |  L AE N D  |  T UW  |  G EH T  |  R EH D  |  AH V  |  L IH T IH D  |  K AE S AH L AH N  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.10.06, Block: 7, Trial: 33\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  DH EY  |  W ER  |  SH OW IH NG  |  S AH M  |  AH N D  |  AY  |  W AA Z  |  W AA CH IH NG  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.10.06, Block: 7, Trial: 34\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  HH AW  |  W IH L  |  Y UW  |  M EH ZH ER  |  Y AO R  |  L AY F  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.10.06, Block: 7, Trial: 35\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AY  |  L AY K  |  AO R K AH N JH  |  M Y UW Z IH K  |  T UW  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.10.06, Block: 7, Trial: 36\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  DH EH R  |  G AA T IH NG  |  S AH M  |  AH V  |  DH AE T  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.10.06, Block: 7, Trial: 37\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AY  |  D OW N T  |  N OW  |  IH F  |  Y UH R  |  L AY K  |  M IY  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.10.06, Block: 7, Trial: 38\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  W IY  |  R IH Z AH L F  |  DH AH  |  R AY T  |  T UW  |  M EY K  |  DH AH  |  F AY N AH L  |  D IH S IH ZH AH N  |  AA N  |  AO L  |  N EY M  |  CH IH N S T AH Z  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.10.06, Block: 7, Trial: 39\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  EH V ER IY  |  T AY M  |  S AH M TH IH NG  |  N UW  |  K EY M  |  AH P  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.10.06, Block: 7, Trial: 40\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AH N D  |  HH IY  |  D AH Z T  |  IH T  |  AO L  |  W IH DH  |  AH  |  S M AY L  |  AH N D  |  AH  |  K W AY AH T  |  T JH OY  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.10.06, Block: 7, Trial: 41\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  IH T  |  IH Z  |  AH  |  Y UW Z JH D  |  P L EY S  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.10.06, Block: 7, Trial: 42\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  IH T  |  L EH T S  |  AH  |  L AO NG  |  T AY M  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.10.08, Block: 11, Trial: 10\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  HH IY  |  JH AH S T  |  HH AE Z  |  T UW  |  B IY  |  K AA N F AH D AH  |  IH N  |  IH K S EH L F  |  AH N D  |  AY  |  TH IH NG K  |  AH  |  IH Z  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.10.08, Block: 11, Trial: 11\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  F AO R  |  DH IY Z  |  R IY Z AH N Z  |  AH  |  F AE K T  |  IH Z  |  DH AH  |  B EH S T  |  K AH N F Y IH N Y UW EY SH AH N  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.10.08, Block: 11, Trial: 12\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  HH AE V  |  DH EY  |  R IH T ER T  |  IH T  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.10.08, Block: 11, Trial: 13\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  W AH T  |  D IH D  |  DH AH  |  S AH P R IY M  |  K AO R T  |  D IH S AY D  |  AH B AW T  |  W EY T AH N  |  K AA L IH JH  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.10.08, Block: 11, Trial: 14\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  Y UW  |  G EH T  |  T UW  |  L ER N  |  AH N D  |  R EY Z  |  Y AO R  |  K IH D Z  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.10.08, Block: 11, Trial: 15\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  DH EY  |  HH AE V  |  N OW  |  ER IH JH AH N AH L  |  AY D IY AH Z  |  K Y UH R IY EY S AH T  |  T AH T IY  |  AO R  |  AE S ER EY SH IH N Z  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.10.08, Block: 11, Trial: 16\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  S OW  |  B EY S IH K L IY  |  HH IY  |  JH AH S T  |  M IY D  |  F UW L Z  |  AH V  |  Y UW  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.10.08, Block: 11, Trial: 17\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AH  |  TH AW Z AH N D  |  M AY L Z  |  AH W EY  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.10.08, Block: 11, Trial: 18\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  IH N  |  DH IH S  |  F AO R M  |  SH IY  |  W AA Z  |  L IH T ER  |  S EH T  |  AW T  |  T UW  |  AH V EH N CH T  |  HH ER  |  F AA DH ER  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.10.08, Block: 11, Trial: 19\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  DH IH S  |  W UH D  |  IH N K L UW D N  |  K W IH P S  |  S AH S T  |  AE Z  |  P AA T AH N IH T IY  |  S UW T S  |  F AO R  |  IH N S T EH N S  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.10.08, Block: 12, Trial: 7\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  F AE K T ER Z  |  AA R T AH S IY  |  AH V  |  AE K S IH Z  |  F AA R M  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.10.08, Block: 12, Trial: 8\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  DH AH  |  M AE N D  |  W AA Z  |  AH T AE K T  |  AH N D  |  S T AE P  |  M AA L T AH B AH L  |  T AY M Z  |  DH AH  |  F AE M AH L IY  |  M EY M B ER  |  IH L EH K T D  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.10.08, Block: 12, Trial: 9\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  W AH D  |  B IY  |  AH  |  SH EY M  |  IH F  |  DH AE T  |  CH EY N JH D  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.10.08, Block: 12, Trial: 10\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AH D M AE T AH S T R EY SH AH N  |  AH V  |  JH AH S T AH S  |  B IH K AO M Z  |  AH  |  S T EY T  |  F AA K SH AH N  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.10.08, Block: 12, Trial: 11\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  DH AH  |  AY D IY AH  |  IH Z  |  F AY N  |  IH N  |  P R IH S AH B AH L  |  B AH T  |  DH AH  |  D IH S AY D  |  IH Z  |  AO L  |  R AO NG  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.10.08, Block: 12, Trial: 12\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  IH F  |  Y UW  |  F AY N D  |  DH IH S  |  AA R T AH K AH L  |  Y UW Z F AH L  |  DH AE T  |  P L EY Z  |  SH EH R  |  IH T  |  W IH DH  |  AH DH ER Z  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.10.08, Block: 12, Trial: 13\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  B AH T  |  B IH HH AY N D  |  DH AH  |  S IY N D Z  |  DH AH  |  W AY T  |  HH AW S  |  T UH K  |  AH  |  L EH S  |  F R EH N D L IY  |  AH P R OW CH T  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.10.08, Block: 12, Trial: 14\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  W AA Z  |  DH EH R  |  EH N IY TH IH NG  |  P AH S IH F ER  |  Y UW  |  S EH D  |  T UW  |  DH EH M  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.10.13, Block: 5, Trial: 25\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  IH T  |  HH AE D  |  AO L  |  DH AH  |  F AE JH T AH B AH L Z  |  IH N  |  IH T  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.10.13, Block: 5, Trial: 26\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  HH IY  |  HH AE D  |  CH OY S AH Z  |  T UW  |  M EY K  |  DH AH  |  K AE L S L ER  |  T OW L D  |  HH IH M  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.10.13, Block: 5, Trial: 27\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  G EH T IH NG  |  P L EY JH  |  CH IY N S Z  |  F AO R  |  DH AH  |  B OY  |  S K IH R T S  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.10.13, Block: 5, Trial: 28\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AY V  |  D AW N D  |  DH AH  |  P R AA B L AH M  |  D AW N  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.10.13, Block: 5, Trial: 29\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  F R AH M  |  EY T S  |  T UW  |  S IH N S T IH N Z  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.10.13, Block: 5, Trial: 30\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  N AW  |  DH AE T  |  DH AH  |  G R EY N T IY N Z  |  AA R  |  HH IY R  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.10.13, Block: 5, Trial: 31\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  D UW  |  Y UW  |  W AA CH  |  S T AA R  |  T R AH K  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.10.13, Block: 5, Trial: 32\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  W IY  |  S EH T  |  ER AW N D  |  AH N D  |  IY T  |  P AA P F AH N  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.10.13, Block: 5, Trial: 33\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AW T  |  AH V  |  AO F EY S  |  EH V ER IY  |  D EY  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.10.13, Block: 5, Trial: 34\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  S OW  |  DH AE T  |  L IY V Z  |  M IY  |  W IH DH  |  AH  |  CH OY S  |  T UW  |  M EY K  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.10.13, Block: 5, Trial: 35\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  Y UW  |  N OW  |  DH AE  |  B IH N  |  AE F V ER T AA N IH NG  |  DH AE T  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.10.13, Block: 5, Trial: 36\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  W UH D  |  Y UW  |  K AH N S IH D ER  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.10.13, Block: 5, Trial: 37\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  DH EY  |  D UW  |  EH V R IY TH IH NG  |  W EH L  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.10.13, Block: 5, Trial: 38\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  DH EY  |  HH AE V  |  AH  |  L IH T AH L  |  K AH N IH K Y AH L AH V  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.10.13, Block: 5, Trial: 39\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  DH AE T  |  W AA Z  |  IH M P R EH SH AH N  |  AY  |  G AA T  |  W EH N  |  AY  |  W AA Z  |  DH EH R  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.10.13, Block: 5, Trial: 40\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AA S T AH D  |  IH Z  |  S OW  |  P R IH T IY  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.10.13, Block: 5, Trial: 41\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AY  |  D UW  |  S AH M  |  EH V ER IY  |  N AW  |  AE T  |  DH EH N  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.10.13, Block: 5, Trial: 42\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  DH AE T S  |  W AH T  |  AY  |  N IY D AH D  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.10.13, Block: 5, Trial: 43\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  IH Z  |  D UW IH NG  |  S AH M  |  AH DH ER  |  M UW V IY  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.10.13, Block: 5, Trial: 44\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AY  |  R IH L IY  |  D OW N T  |  W AA N T  |  T UW  |  S T EY  |  IH N  |  N UW Z  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.10.13, Block: 5, Trial: 45\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  W IY R  |  P AH T IH NG  |  AH P  |  W IH DH  |  AO L  |  HH ER  |  AE K S AH D AH Z S  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.10.13, Block: 5, Trial: 46\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AY M  |  F AE R AH L IY  |  N UW  |  T UW  |  IH T  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.10.13, Block: 5, Trial: 47\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AY  |  N OW  |  DH EH R Z  |  N AA T  |  EH N IY  |  F UW D  |  DH AE T  |  Y UW  |  K AE N  |  G EH T  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.10.13, Block: 5, Trial: 48\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  Y UW  |  HH AE V  |  Y AO R  |  K ER EH R  |  AH N D  |  Y AO R  |  HH OW M  |  L AY F  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.10.13, Block: 5, Trial: 49\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AO R AH B AH L  |  S T AH F  |  L AY K  |  DH AE T  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.10.13, Block: 6, Trial: 20\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  B IY S IY  |  IH N V EY D AH D  |  K AW L S AH L  |  S T AO L Z  |  F AH N T AE S IH K L IY  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.10.13, Block: 6, Trial: 21\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  S IH S T  |  B EH N  |  AH V EH K T  |  K AA M OW S T  |  IH N T ER IH SH AH N Z  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.10.13, Block: 6, Trial: 22\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  D AH M AH N UW Z  |  D IH S AO T AH N IH NG  |  S T AA R  |  W EH R  |  D EH R Z  |  T R EH ZH ER IY Z  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.10.13, Block: 6, Trial: 23\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  IH T AE L AH JH IH N Z  |  K R AA M P EH R AH N T S  |  V IH ZH AH N Z  |  P R EH D AH D  |  S T IH K  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.10.13, Block: 6, Trial: 24\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  M AE S AH K AH T  |  B IH AE N  |  K IY T IH NG  |  W EY T  |  AE T  |  SH AY N AH  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.10.13, Block: 6, Trial: 25\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  K AH V EY N D  |  L DH AE S  |  AO L F W EY  |  AA B V IY AH L IY  |  M IH N AH T ER  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.10.13, Block: 6, Trial: 26\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  T  |  AH P OW M IY  |  P EY P ER  |  V AY S  |  S OW AY AH T IY  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.10.13, Block: 6, Trial: 27\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  DH TH OW L IY  |  AH P AO R IH T IH NG  |  N AA T  |  K R EH S T AH N  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.10.13, Block: 6, Trial: 28\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  M EY K  |  D IH S IY Z  |  W AH N EH V ER  |  T EH M P AH L Z  |  K AE R AH T UW Z  |  L AE T AH T IH L IY  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.10.13, Block: 6, Trial: 29\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  T AO K AO Z  |  R IY HH AH B IH L AH  |  T IH S AH N  |  L AO S  |  D IY L  |  D ER EH K T ER IY  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.10.13, Block: 6, Trial: 30\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  IH L EH K SH ER  |  F IH SH ER  |  M AH DH ER Z  |  B R IH R  |  AW AH Z  |  D AH N AH K AE F AH Z  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.10.13, Block: 6, Trial: 31\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AH K IH ZH AH N AH L IY  |  F L OY N D IH NG  |  S AY N IH NG  |  W IY N Z  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.10.13, Block: 6, Trial: 32\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  EH N AH AA Z  |  AO V ER  |  AW N D R AH D  |  OW V ER G R EY Z D  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.10.13, Block: 6, Trial: 33\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AH D T EH L AH JH IH S T  |  S AE M AH L ER  |  F IY  |  P ER S EH S  |  AE T  |  S T IH L  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.10.13, Block: 6, Trial: 34\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  IH N AH F  |  K AO R S  |  S UW T  |  AH L AW N D  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.10.13, Block: 6, Trial: 35\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  B AE N D AH L  |  D IH S EH K SH ER AH S  |  D AH L UW ZH AH N  |  B R IH NG K  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.10.13, Block: 6, Trial: 36\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  B IH G IH N IH NG  |  IH K S T R EH S  |  L AE S AH B AH L  |  P R AA S EH S K T L IY  |  SH UW Z  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.10.13, Block: 6, Trial: 37\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  IH M AH T R EY SH AH N  |  L AO NG CH IH NG  |  K AH M P AO N  |  AH B Y UW S  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.10.13, Block: 6, Trial: 38\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  K Y UW Z D  |  IH K S EH L F  |  CH AE IH L IY  |  K AH N S ER M IH NG  |  AH T AE K IH NG  |  S AO R T  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.10.13, Block: 6, Trial: 39\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  L AA T  |  IH N AH S AH D  |  AW L D  |  K AH M P AH N EY SH AH N  |  IH M P EH R AH N S T  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.10.15, Block: 9, Trial: 24\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  DH EY  |  AA R  |  L AH V L IY  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.10.15, Block: 9, Trial: 25\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  HH IY R Z  |  W AH T  |  Y UW  |  HH AE V  |  G AA T  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.10.15, Block: 9, Trial: 26\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  W AH N  |  DH AE T  |  AY  |  Y UW Z  |  JH AH S T  |  F AO R  |  IH M ER JH AH N S T IY Z  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.10.15, Block: 9, Trial: 27\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  DH EH R  |  IH N  |  T UW N  |  W IH DH  |  DH AE T  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.10.15, Block: 9, Trial: 28\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  D UW  |  Y UW  |  R IH L IY  |  N AA T  |  R IH M EH M B ER  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.10.15, Block: 9, Trial: 29\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  W IY  |  D OW N T  |  AE F T AH L  |  DH EH M  |  V EH R IY  |  W EH L  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.10.15, Block: 9, Trial: 30\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  DH AE T S  |  AH N AH DH ER  |  TH IH NG  |  AY  |  D OW N T  |  AH N T ER S T AE D  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.10.15, Block: 9, Trial: 31\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AY  |  B IH F AO R  |  AH  |  S W IH M IH NG  |  P UW L  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.10.15, Block: 9, Trial: 32\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AO L  |  R AY T  |  AY M  |  R EH D IY  |  T UW  |  G OW  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.10.15, Block: 9, Trial: 33\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AY  |  K AE N  |  R IH L EY T  |  T UW  |  DH AE T  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.10.15, Block: 9, Trial: 34\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  Y UW  |  G OW  |  T UW  |  W ER K  |  EH V ER IY  |  W IY K EH N D  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.10.15, Block: 9, Trial: 35\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AY M  |  N AA T  |  F AO R  |  K AH N T R OY L IH NG  |  HH AW  |  M AH CH  |  IH Z  |  P EH T  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.10.15, Block: 9, Trial: 36\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  DH AH  |  Y UW N EY T IH D  |  S T EY T S  |  AE N  |  K AE N AH D AH  |  AA R  |  S OW  |  D IH F ER AH N T  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.10.15, Block: 9, Trial: 37\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  W EH L  |  T UW  |  Y UW  |  N OW  |  S AH M TH IH NG  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.10.15, Block: 9, Trial: 38\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  N AA T  |  EH V ER IY  |  G EY M  |  S EH T S  |  AW T  |  T UW  |  M EY K  |  AH  |  P OY N T  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.10.15, Block: 9, Trial: 39\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  N AY S  |  IH Z AH N T  |  DH AH  |  W ER D  |  AY D  |  CH UW Z  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.10.15, Block: 9, Trial: 40\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  TH R IY  |  AO R  |  F AO R  |  N EY Z  |  AH N D  |  DH AE T  |  W UH D  |  B IY  |  IH T  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.10.15, Block: 9, Trial: 41\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  IH T S  |  AH  |  B EY S AH L  |  AH K EY ZH AH N  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.10.15, Block: 9, Trial: 42\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  W AH T  |  L EH V AH L  |  AH V  |  K EH R  |  T UW  |  Y UW  |  N IY D  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.10.15, Block: 9, Trial: 44\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AY M  |  Y AO R  |  K AH S T ER AH M B ER  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.10.15, Block: 9, Trial: 45\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  D IH D  |  DH EY  |  HH AE V  |  S AH M  |  P R IH T IY  |  G UH D  |  S P EH S SH AH L  |  IH F EH K T  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.10.15, Block: 9, Trial: 46\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  SH IY  |  G EH T S  |  R AY T  |  IH N T UW  |  IH T  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.10.15, Block: 9, Trial: 47\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  B AH T  |  W IY  |  HH AE V AH N T  |  S IY N  |  DH AE T  |  W AH N  |  IY DH ER  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.10.15, Block: 9, Trial: 48\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AE F T ER  |  W IY  |  HH AE D  |  DH EH M  |  F AO R  |  S EH V ER AH L  |  Y IH R Z  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.10.15, Block: 9, Trial: 49\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AY  |  HH AE V  |  AH  |  D AO G  |  DH AE T  |  G AY D  |  G IH V  |  AH S  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.10.15, Block: 10, Trial: 20\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  T R EY N  |  Y AO R  |  D AO G  |  F AO R  |  K AH N F AH N IY Z S  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.10.15, Block: 10, Trial: 21\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  F AY N D  |  DH AH  |  M IH S IH NG  |  K L UW  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.10.15, Block: 10, Trial: 22\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AE Z  |  IH Z  |  N AW  |  W EH L  |  N OW N  |  K AE T AH T IY  |  HH AE D  |  N UW V ER AH S  |  EH K JH AH L AH T AH L  |  AH V OY R D Z  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.10.15, Block: 10, Trial: 23\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  R AH K AO R D IH D  |  AH N D  |  IH T AH T AH D  |  B AY  |  B IH N  |  W OY AH N Z  |  F AO R  |  P L EY S IH V  |  P R AH D AH K SH AH N S  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.10.15, Block: 10, Trial: 24\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  HH AY ER  |  Y AO R  |  F R EH K S AY Z  |  S T AA F  |  IH N  |  IH N V EH N S T  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.10.15, Block: 10, Trial: 25\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  S OW  |  AY  |  W AA Z  |  S AH P AO Z D  |  W EH N  |  AY  |  G AA T  |  DH IH S  |  M EH SH AH N  |  AW T  |  AH V  |  DH AH  |  B L UW  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.10.15, Block: 10, Trial: 26\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AA N  |  IH K AH M UW M IH NG  |  HH IH SH AH Z  |  P IH T ER  |  SH IH F  |  IH Z  |  B AA T  |  AA N  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.10.15, Block: 10, Trial: 27\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  IH F  |  Y UW  |  AA R  |  N AA T  |  AH W EY  |  AH V  |  IH T  |  DH AE T  |  HH IY R  |  IH Z  |  AH  |  R IH V IY  |  IH N  |  SH AO R T  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.10.15, Block: 10, Trial: 28\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  R EH D IY  |  T UW  |  IH T  |  B AE K  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.10.15, Block: 10, Trial: 29\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  D IH S P AY R T  |  DH AE T  |  S K W AO R  |  S AE Z  |  IH T  |  W AA Z  |  AA N D IY M B AH L  |  T UW  |  AH D AH T AH F AY  |  AO R  |  K AA N T IH K T  |  DH AH  |  F AE M AH L IY  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.10.15, Block: 10, Trial: 30\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  SH EH R AH T IY  |  IH Z  |  N OW  |  L AO K IH NG  |  S OW  |  IY Z IY  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.10.15, Block: 10, Trial: 31\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  IH N  |  DH AH  |  S T AY Z  |  OW V ER  |  AH M EH R IH K AH  |  DH AH  |  S K W IH NG Z  |  IH Z  |  AA N  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.10.15, Block: 10, Trial: 32\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  Y UW  |  AA R  |  R EH D IH NG  |  OW N  |  DH AH  |  F AE K T  |  DH AE T  |  Y UW  |  AA R  |  R EH D IY  |  AH N D  |  G EH T  |  T UW  |  W ER K  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.10.15, Block: 10, Trial: 33\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AY  |  W IH Z AH N S  |  D IH S P R AE M Z  |  B AO L  |  AH V  |  P L EY T S  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.10.15, Block: 10, Trial: 34\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  HH IY  |  P AH B L IH K  |  HH IY R IH NG  |  IH Z  |  P L AE N D  |  F AO R  |  N AH M EH M B ER  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.10.15, Block: 10, Trial: 35\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  W IY  |  W AA N T  |  T UW  |  S AH P AO R T  |  AW ER  |  L OW K AH L  |  P R AH D IH S IH Z  |  S AH P AO R T  |  IY CH  |  AH DH ER  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.10.15, Block: 10, Trial: 36\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  DH AH  |  F R AH F EY T IH NG  |  IH N T ER IY  |  IH Z  |  IH S P EH K L IY  |  F R AE L AH V AH T  |  T AH D EY  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.10.15, Block: 10, Trial: 37\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  K AH N IY N IY AH Z  |  AA R  |  AO L R EH D IY  |  F AH M IH L Y ER  |  W IH DH  |  DH IH S  |  S IH S T AH M  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.10.15, Block: 10, Trial: 38\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AO R  |  B IH R ER  |  IH M B AH Z IY Z  |  AH V  |  DH AE T  |  G AY  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.10.15, Block: 10, Trial: 39\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AE N  |  AH P AH N D  |  AH  |  L AO  |  K AE N SH AH L IY  |  AO F AH S  |  AE T  |  HH OW M  |  AE F T ER  |  G R AE JH UW W EY T IH NG  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.10.20, Block: 3, Trial: 9\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AH  |  L AA R JH  |  S AY Z  |  IH N  |  S AA K IH NG N Z  |  IH Z  |  HH AA R D  |  T UW  |  S EH L  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.10.20, Block: 3, Trial: 11\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AH  |  R AY N D  |  IH Z  |  Y UW Z D  |  T UW  |  K AE CH  |  P IH K  |  S EH V AH N  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.10.20, Block: 3, Trial: 13\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  K IH K  |  DH AH  |  B AO L  |  S T R IY T  |  AH N D  |  F AA L OW  |  TH R UW  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.10.20, Block: 3, Trial: 14\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  HH EH L P  |  DH AH  |  W UH M AH N  |  G EH T  |  B AE K  |  T UW  |  HH ER  |  F IY T  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.10.20, Block: 3, Trial: 15\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AH  |  P AA T  |  AH V  |  T IY  |  EH L P S  |  T UW  |  P AE S  |  DH AH  |  IY V N IH NG  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.10.20, Block: 3, Trial: 16\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  M ER K IY  |  F AY R ER Z  |  L AY K  |  F L EY M  |  AH N D  |  IY T  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.10.20, Block: 3, Trial: 17\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  DH AH  |  S AH F  |  K AH SH AH N  |  B R OW K  |  DH AH  |  M EY N D Z  |  F AO L  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.10.20, Block: 3, Trial: 18\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  DH AH  |  S AO L T  |  B R IY NG Z  |  K EY M  |  AH K R AO S  |  F R AH M  |  DH AH  |  S IY  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.10.20, Block: 3, Trial: 19\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  DH AH  |  G ER L  |  AH N D  |  DH AH  |  B UH K TH  |  S OW L D  |  F IH F T IY  |  P OY N T Z  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.10.22, Block: 5, Trial: 11\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  T EY K  |  DH AH  |  W AH N D IH NG  |  B AE TH  |  T UW  |  W IH CH  |  DH AH  |  L AY K  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.10.22, Block: 5, Trial: 12\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  N OW T  |  K L OW S L IY  |  DH AH  |  S AY Z  |  AH V  |  DH AH  |  G EH S  |  T EY K  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.10.22, Block: 5, Trial: 13\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  W EH P  |  DH AH  |  R EY S  |  AH V  |  IH Z  |  D AO T IY  |  F IH S  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.10.22, Block: 5, Trial: 14\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  M EH D  |  DH AH  |  K UH D  |  B IH F AO R  |  Y UW  |  G OW  |  AW T  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.10.22, Block: 5, Trial: 15\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  DH AH  |  R EY S T  |  W AA Z  |  B IH B L IY  |  S T R EY D  |  AH N D  |  HH OW L  |  L IH P  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.10.22, Block: 5, Trial: 16\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  DH AH  |  T R IY  |  K AE T  |  G IH V  |  B OW TH  |  T UW  |  D IH T AH N Z  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.10.22, Block: 5, Trial: 17\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  DH AH  |  Y AH NG  |  G ER L  |  G IH V  |  N OW  |  K L IH R  |  R IH S P EH N S  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.10.22, Block: 5, Trial: 18\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  DH AH  |  M IY L  |  W AA Z  |  K UH K T  |  B IH F AO R  |  DH AH  |  B AY L  |  R AE NG  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.10.22, Block: 5, Trial: 26\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  DH AH  |  R UW P  |  W IH L  |  B AY N D  |  DH AH  |  S EH V AH N  |  B UH K S  |  AE T  |  W AH N S  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.10.22, Block: 5, Trial: 27\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  HH AE L P  |  OW V ER  |  DH AH  |  F IH K S  |  AH N D  |  P L AA CH  |  IH N  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.10.22, Block: 5, Trial: 28\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  DH AH  |  F R EH N AH L IY  |  G IH NG  |  L EH F  |  DH AH  |  D R AH G  |  S T AO R  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.10.22, Block: 5, Trial: 29\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  M EH S CH  |  W AY ER  |  K IH P S  |  T EH S  |  IH N S AY D  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.10.22, Block: 9, Trial: 22\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  DH EY  |  S AW N D  |  P AH L IH L Y ER  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.10.22, Block: 9, Trial: 23\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  IH N  |  DH IH S  |  W EY  |  EH V ER IY  |  D IH S IH ZH AH N  |  Y UW  |  M EY K  |  M AH CH  |  B IY  |  K AH N F AH L IY  |  K AH N S IH D AH N T  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.10.22, Block: 9, Trial: 24\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  D UW  |  DH OW Z  |  K AE N  |  K R OW S AH Z  |  W ER K  |  W EH L  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.10.22, Block: 9, Trial: 25\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AY  |  D OW N T  |  R IH L IY  |  K EH R  |  W AH T  |  IH T  |  T EY K S  |  T UW  |  W AA L AH F AY  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.10.22, Block: 9, Trial: 26\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  IH T S  |  DH AH  |  D EH S AH S  |  HH IY R  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.10.22, Block: 9, Trial: 27\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  IH F  |  IH T S  |  P IY P AH L  |  IH T  |  W IH L  |  P R AA B AH B L IY  |  SH R EH D  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.10.22, Block: 9, Trial: 28\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  W AH T S  |  DH AH  |  W ER D  |  AY M  |  L UH K IH NG  |  F AO R  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.10.22, Block: 9, Trial: 29\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  DH AE T S  |  AH B AW T  |  W EH R  |  AY  |  S T EH D  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.10.22, Block: 9, Trial: 30\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  IH T  |  JH AH S T  |  D IH D AH N T  |  F IY T  |  DH AH  |  K AA R  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.10.22, Block: 9, Trial: 31\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  W AH T  |  D UW  |  Y UW  |  TH IH NG K  |  K AE N  |  B IY  |  D AH N  |  AH B AW T  |  DH AE T  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.10.22, Block: 9, Trial: 32\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  W IY  |  Y UW ZH W AH L IY  |  AO R D ER  |  AW ER  |  T IH K AH Z  |  W EY  |  IH N  |  IH D V EH N T S  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.10.22, Block: 9, Trial: 33\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AY  |  L AH V  |  T UW  |  R AH N  |  IH N  |  DH AH  |  R EH N  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.10.22, Block: 9, Trial: 34\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  M AY  |  L IH V AH L  |  AH V  |  EH K M P ER T IH Z  |  IH Z  |  IH K R IY S IH NG  |  AO L M OW S T  |  D EY L IY  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.10.22, Block: 9, Trial: 35\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  Y UW  |  S AO  |  DH AH  |  B AE S AH N  |  AH V  |  DH AH  |  S EY V AH L  |  R AY T S  |  AE T  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.10.22, Block: 9, Trial: 36\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AY D  |  R AE DH ER  |  B IY  |  D UW IH NG  |  DH AE T  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.10.22, Block: 9, Trial: 37\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  G OW IH NG  |  B AE K  |  T UW  |  DH AH  |  B EY S AH Z  |  IH N  |  DH AH  |  ER L IY  |  G R EY T S  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.10.22, Block: 9, Trial: 38\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  W AH T EH V ER  |  P AH P  |  W IY  |  T R IH K  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.10.22, Block: 9, Trial: 39\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  R IY P AO R D T S  |  AA N  |  DH AH  |  AH K EY ZH AH N  |  AH V  |  DH AH  |  S IH K S  |  EH N IY AH V EH ZH SH AH IY  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.10.22, Block: 9, Trial: 40\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AY  |  HH AE V  |  T UW  |  TH IH NG K  |  AH B AW T  |  IH T  |  S AH M  |  M AO R  |  N AW  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.10.22, Block: 9, Trial: 41\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  B AY  |  AH  |  S OW IH NG  |  M AH S IY N  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.10.22, Block: 9, Trial: 42\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  Y UW  |  T EY K  |  AH W EY  |  AH  |  B ER S AH N Z  |  F R IY D AH M  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.10.22, Block: 9, Trial: 43\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  M AY  |  HH EH M P L OY IY AH  |  F IY L Z  |  DH AE T  |  HH IY  |  W AA N Z  |  T UW  |  K AH N T R OW L  |  AH S  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.10.22, Block: 9, Trial: 44\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AY  |  F AW N D  |  DH AE T  |  AO L  |  AY  |  T AO K T  |  AH B AW T  |  W AA Z  |  M AY  |  B EY B IY  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.11.03, Block: 5, Trial: 25\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AH  |  T EY M  |  S K UW L  |  M EY K S  |  AH  |  N AY S  |  B IH T  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.11.03, Block: 5, Trial: 26\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  DH AH  |  HH AA R D  |  AH V  |  DH AH  |  K AA R  |  W ER K  |  DH AH  |  L IY P IH NG  |  K AH M P  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.11.03, Block: 5, Trial: 27\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  DH AH  |  HH AA R T  |  B IY T  |  CH R AE R L IY  |  AH N D  |  W IH DH  |  F OW M  |  CH R AH S  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.11.03, Block: 5, Trial: 28\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  DH AH  |  B IY L  |  W AA Z  |  W AO R D  |  IH T  |  AH  |  DH EH N  |  S EH V ER  |  R IY K  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.11.03, Block: 5, Trial: 29\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  DH AH  |  R EH T  |  B IY L  |  W AA Z  |  G AA T  |  IH N  |  TH IH NG K  |  L AY S AH Z  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.11.03, Block: 5, Trial: 30\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  DH AH  |  N EY V IY  |  AH T AW EH N D  |  DH AH  |  B IH G  |  T AE S T  |  F AO S  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.11.03, Block: 5, Trial: 31\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  SH IY  |  DH AH  |  G EH T  |  L IH NG  |  AH N  |  DH AH  |  S K EH R D  |  M AH S  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.11.03, Block: 5, Trial: 32\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  DH EH R  |  AA R  |  M AO R  |  DH AE T  |  D UW  |  F IH F T ER D  |  HH IY R  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.11.03, Block: 5, Trial: 33\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  DH AH  |  HH AE T  |  P R IH M  |  W AA Z  |  W AY N D  |  AH N D  |  T UW  |  T R UW P IH NG  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.11.03, Block: 5, Trial: 34\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  DH AH  |  L AO NG ER  |  T CH AY D  |  T UW  |  L UW Z  |  IH Z  |  G EH S  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.11.03, Block: 5, Trial: 35\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  DH AH  |  D R EH S  |  K AA L D  |  AH AW N D  |  DH AH  |  F IH N S T  |  P OW S T  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.11.03, Block: 5, Trial: 36\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  K AH T  |  DH AH  |  P AY  |  IH N T UW  |  L AA R JH  |  P AA N T S  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.11.03, Block: 5, Trial: 37\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  M EH N  |  D R AY V  |  W AH T  |  S AH M AH M  |  G EH T  |  W IH CH  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.11.03, Block: 5, Trial: 38\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AO L W EY Z  |  L OW S  |  DH P AA R T  |  N AO R  |  T EY T  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.11.03, Block: 5, Trial: 39\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  HH IY  |  L EY  |  P R OW N  |  AH N D  |  OW N L IY  |  M UW V D  |  AH  |  L AY M  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.11.03, Block: 5, Trial: 40\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  DH AH  |  K L AH S  |  L AY K  |  G IY P  |  AH L AO NG  |  DH AH  |  T R IY T  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.11.03, Block: 5, Trial: 41\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AH  |  W IH K S  |  AH V  |  L AW D  |  HH OW NG  |  IH N  |  DH AH  |  B L IH L  |  HH EH R  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.11.03, Block: 5, Trial: 42\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AH  |  P AW N D  |  AH V  |  S ER T ER  |  K AA S T S  |  M AO R  |  DH AE N  |  EH N JH  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.11.03, Block: 5, Trial: 43\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  DH AH  |  F IY N  |  W AA Z  |  SH AA P  |  AH N D  |  G AA T  |  DH AH  |  L IH R  |  W AO T ER  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.11.03, Block: 5, Trial: 44\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  DH AH  |  P L EY  |  S IY M Z  |  T EH L  |  AH N D  |  K W AY T  |  S UW P AH N  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.11.03, Block: 5, Trial: 45\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  B EH L  |  DH AH  |  P UH T  |  T UW  |  S AH M  |  IH T  |  F R AH M  |  S IH K IH NG  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.11.03, Block: 5, Trial: 46\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  DH AH  |  T AH M  |  IH N T ER D  |  IH N  |  L EH T  |  SH UH N  |  DH AE T  |  HH IY R  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.11.03, Block: 5, Trial: 47\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AH  |  JH AH S T  |  IH Z  |  Y UW Z  |  T UW  |  M EY K  |  K AH N D L IY  |  G IH V Z  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.11.03, Block: 5, Trial: 48\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  D IH D  |  M EH N S Z  |  W ER  |  S EH D  |  IH N  |  IH N  |  AO R D ER  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.11.03, Block: 5, Trial: 49\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  DH AH  |  B IH L  |  W AA Z  |  EY D  |  EH V ER IY  |  TH ER T  |  W IY K  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.11.03, Block: 6, Trial: 25\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  DH AE T S  |  W AH T  |  AY  |  HH AE D  |  DH AH  |  AA P AH T AH T IH D  |  T UW  |  D UW  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.11.03, Block: 6, Trial: 26\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  B IH K AO Z  |  IH T  |  AE K CH UW AH L IY  |  D AH Z AH N T  |  B EH T ER  |  HH UW  |  SH OW Z  |  AH P  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.11.03, Block: 6, Trial: 27\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  DH EY  |  HH AE V  |  DH AH  |  B EH S T  |  AH V  |  B OW TH  |  W ER S Z  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.11.03, Block: 6, Trial: 28\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  W IY  |  F AY N D  |  IH T  |  IY Z IY ER  |  T UW  |  D IH V AY N D  |  DH AH  |  M EH ZH ER  |  B OY L Z  |  HH AH P  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.11.03, Block: 6, Trial: 29\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  P AH M AH N AH T L IY  |  AH T EH S T  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.11.03, Block: 6, Trial: 30\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AY  |  D OW N T  |  N OW  |  AH B AW T  |  N EY N T IY  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.11.03, Block: 6, Trial: 31\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  G UH D  |  R AH DH ER  |  S IY  |  IH T  |  HH AA R D ER  |  T UW  |  K AH M EY N T  |  S AH M B AA D IY  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.11.03, Block: 6, Trial: 32\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  M AO R  |  AH N T IH V AH T IY  |  AA N  |  AW ER  |  P AA R T  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.11.03, Block: 6, Trial: 33\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  K IY P  |  CH IY K AH N Z  |  IH N  |  AH  |  G ER AA ZH  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.11.03, Block: 6, Trial: 34\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  SH IY D Z  |  L AY V  |  W IH DH  |  AH S  |  F AO R  |  L AY K  |  F AY V  |  Y IH R Z  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.11.03, Block: 6, Trial: 35\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  IH T S  |  L AY K  |  S EH V AH D IY  |  D ER W IY S  |  HH IY R  |  R AY T  |  N AW  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.11.03, Block: 6, Trial: 36\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  B IH K  |  DH AE T  |  K AA R  |  AW T  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.11.03, Block: 6, Trial: 37\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  W IY  |  HH AE D  |  T UW  |  G IH V  |  HH IH M  |  AH  |  D AH M EH T ER  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.11.03, Block: 6, Trial: 38\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  IH T S  |  R IY L  |  HH AA R D  |  T UW  |  M EY K  |  DH EH M  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.11.03, Block: 6, Trial: 39\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  W EH N  |  AY  |  F ER S T  |  S T AO T ER D  |  W ER K IH NG  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.11.03, Block: 6, Trial: 40\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  DH EY  |  TH IH NG K  |  DH AE T S  |  AH  |  F AE M AH L IY  |  IH N T IH V AH D IY  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.11.03, Block: 6, Trial: 41\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  IH T  |  S IY M Z  |  L AY K  |  DH EY  |  TH IH NG K  |  DH AH  |  N OW  |  W AH T  |  DH EY  |  W AA N T  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.11.03, Block: 6, Trial: 42\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  HH IY  |  P R IH T IY  |  M AH CH  |  JH AA B  |  AW T  |  AH V  |  P AH B L IH K  |  L AH V  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.11.03, Block: 6, Trial: 43\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AH  |  L AA T  |  AH V  |  G UH D  |  AE Z  |  K AH M  |  F R AH M  |  DH IH S  |  W AH N  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.11.03, Block: 6, Trial: 44\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  DH AE T S  |  W AH T  |  DH EY  |  S EY  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.11.03, Block: 6, Trial: 45\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  N AA T  |  W IH TH AW T  |  Y AO R  |  P ER F IH SH AH N  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.11.03, Block: 6, Trial: 46\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  DH AY S  |  JH AH S T  |  S AH M TH IH NG  |  AH B AW T  |  DH AE T  |  T EH L AH L IH K  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.11.03, Block: 6, Trial: 47\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  HH AW  |  D UW  |  Y UW  |  F IY L  |  AH B AW T  |  S P AA R T  |  T EH S T  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.11.03, Block: 6, Trial: 48\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  N AA T  |  B IH K AO Z  |  AY  |  HH AE V AH N T  |  G AA T  |  DH AH  |  D IH S AY R ER  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.11.03, Block: 6, Trial: 49\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  R IH M EH M B ER  |  M EY K  |  D IH S IH ZH AH N Z  |  AH N D  |  S T IH K  |  T UW  |  DH EH M  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.11.04, Block: 4, Trial: 15\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  DH AE T S  |  JH AH S T  |  N AA T  |  AW ER  |  TH IH NG K  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.11.04, Block: 4, Trial: 16\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AY  |  L AH V  |  IH T  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.11.04, Block: 4, Trial: 17\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AY  |  JH AH S T  |  W AH T  |  T UW  |  T EH L  |  Y UW  |  DH IH S  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.11.04, Block: 4, Trial: 18\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  W IY  |  SH UH D  |  G OW  |  D IH F ER AH N T  |  W EY  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.11.04, Block: 4, Trial: 19\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AY  |  HH OW P  |  Y UW  |  HH ER D  |  W AH T  |  DH EY  |  S EH D  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.11.04, Block: 4, Trial: 20\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AA R  |  Y UW  |  SH UH R  |  Y UW  |  S AO  |  IH T  |  DH EH R  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.11.04, Block: 4, Trial: 21\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  W AH T  |  S AO R T  |  AH V  |  W ER K  |  D UW  |  Y UW  |  D UW  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.11.04, Block: 4, Trial: 22\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AY  |  W UH D  |  L AY K  |  T UW  |  B AY  |  AH  |  K AA R  |  N EH K S T  |  Y IH R  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.11.04, Block: 4, Trial: 23\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  EH N IY TH IH NG  |  OW L D  |  IH Z  |  N AA T  |  AO L W EY Z  |  G UH D  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.11.04, Block: 4, Trial: 24\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  SH IY  |  JH AH S T  |  S EH D  |  N OW  |  T UW  |  D UW  |  M AY  |  W ER K  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.11.04, Block: 4, Trial: 25\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AE T  |  DH AH  |  EH N D  |  EH V R IY TH IH NG  |  W AA Z  |  N AY S  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.11.04, Block: 4, Trial: 26\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  DH IH S  |  IH Z  |  AH  |  HH AA R D  |  P R AA B L AH M  |  T UW  |  W ER K  |  AA N  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.11.04, Block: 4, Trial: 27\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AY  |  W AA Z  |  N AA T  |  EY B AH L  |  T UW  |  W ER K  |  V EH R IY  |  F AA R  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.11.04, Block: 4, Trial: 28\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  Y AO R  |  N EY M  |  IH Z  |  IY Z IY  |  T UW  |  R IH M EH M B ER  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.11.04, Block: 4, Trial: 29\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  S AH M W AH N  |  M AH S T  |  T EH L  |  HH ER  |  DH AE T  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.11.17, Block: 3, Trial: 25\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  W AH T  |  M EY K S  |  Y UW  |  TH IH NG K  |  DH AE T  |  IH Z  |  T R UW  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.11.17, Block: 3, Trial: 26\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AY M  |  N AA T  |  T AO K IH NG  |  T UW  |  Y UW  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.11.17, Block: 3, Trial: 27\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AY  |  HH AE D  |  T UW  |  G OW  |  F ER S T  |  W IH DH  |  DH EH M  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.11.17, Block: 3, Trial: 28\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  Y UW  |  SH UH D  |  T EY K  |  S AH M  |  B R IH NG K  |  F R AH M  |  W ER K  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.11.17, Block: 3, Trial: 29\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  W AH T  |  P AA R T  |  AH V  |  DH IH S  |  IH Z  |  R IH L IY  |  T R UW  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.11.17, Block: 3, Trial: 30\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  W AH D  |  Y UW  |  L AY K  |  T UW  |  JH OY N  |  M IY  |  N EH K S T  |  W IY K  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.11.17, Block: 3, Trial: 31\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  HH AW  |  AA R  |  TH IH NG Z  |  OW V ER  |  DH EH R  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.11.17, Block: 3, Trial: 32\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  DH IH S  |  IH Z  |  W AH T  |  AY  |  W UH N AH D  |  T UW  |  N OW  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.11.17, Block: 3, Trial: 33\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  EH N IY  |  N UW  |  N UW Z  |  AA N  |  DH IH S  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.11.17, Block: 3, Trial: 34\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  T EH L  |  M IY  |  Y AO R  |  D IH S IH ZH AH N  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.11.17, Block: 3, Trial: 35\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AY  |  K AE N  |  K AH M  |  P EY  |  HH OW M  |  W IH DH  |  K IH D Z  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.11.17, Block: 3, Trial: 36\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AO L  |  DH IH S  |  IH Z  |  S OW  |  IH N T AH R EH S T IH NG  |  T UW  |  M IY  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.11.17, Block: 3, Trial: 37\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AY  |  L AH V  |  T UW  |  T UW  |  W ER K  |  AH V  |  HH AY N D  |  P R AA B L AH M Z  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.11.17, Block: 3, Trial: 38\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  DH AE T  |  M EY K S  |  IH T  |  M AO R  |  IH N T AH R EH S T IH NG  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.11.17, Block: 3, Trial: 39\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AY  |  TH IH NG K  |  DH IH S  |  W IH L  |  K AH M  |  ER AW N D  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.11.17, Block: 3, Trial: 40\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AY  |  HH AE V  |  N EH V ER  |  ER N  |  AH V  |  DH IH S  |  B IH B IH F AO R  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.11.17, Block: 3, Trial: 41\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AY  |  HH OW P  |  Y UW  |  L UH K  |  IH T  |  DH AH  |  HH OW L  |  HH AW S  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.11.17, Block: 3, Trial: 42\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  EH N JH OY  |  Y AO R  |  T AY M  |  AH W EY  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.11.17, Block: 3, Trial: 43\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  W AH T  |  IH Z  |  DH AH  |  M EY K  |  AH V  |  Y AO R  |  K AA R  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.11.17, Block: 3, Trial: 44\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  S AH M TH IH NG  |  IH Z  |  R AO NG  |  HH IY R  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.11.17, Block: 3, Trial: 45\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  D IH D  |  Y UW  |  G EH T  |  EH V R IY TH IH NG  |  AY  |  S EH D  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.11.17, Block: 3, Trial: 46\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  W AH T  |  AH  |  F AH N  |  P L EY S  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.11.17, Block: 3, Trial: 47\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  S AH M  |  AH V  |  AH S  |  W IH L  |  P EY  |  DH AH  |  M AH N IY  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.11.17, Block: 3, Trial: 48\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  DH AE T  |  IH Z  |  L UH K IH NG  |  V EH R IY  |  IY Z IY  |  T UW  |  M IY  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.11.17, Block: 3, Trial: 49\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  W IH L  |  Y UW  |  JH OY N  |  DH AH  |  K AA L IH JH  |  N EH K S T  |  Y IH R  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.11.19, Block: 4, Trial: 20\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AA R  |  Y UW  |  S T IH L  |  DH EH R  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.11.19, Block: 4, Trial: 21\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AY  |  W IH L  |  W EY T  |  F AO R  |  AH  |  K AH P AH L  |  AH V  |  D EY Z  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.11.19, Block: 4, Trial: 22\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  DH EY  |  K EY M  |  TH R UW  |  JH AH S T  |  N AW  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.11.19, Block: 4, Trial: 23\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  D UW  |  Y UW  |  EH V ER  |  G OW  |  DH EH R  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.11.19, Block: 4, Trial: 24\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AY  |  HH OW P  |  DH IH S  |  W IH L  |  L UH K  |  G UH D  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.11.19, Block: 4, Trial: 25\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  HH UW  |  N EH S  |  M AO R  |  AH B AW T  |  DH IH S  |  DH AE N  |  Y UW  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.11.19, Block: 4, Trial: 26\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AY  |  N OW  |  DH IH S  |  W IH L  |  AO L  |  W IY K  |  AW T  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.11.19, Block: 4, Trial: 27\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  HH AW  |  M EH N IY  |  P IY P AH L  |  AA R  |  K AH M IH NG  |  HH IY R  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.11.19, Block: 4, Trial: 28\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AE T  |  DH AH  |  EH N D  |  IH T  |  W AA Z  |  L UH K IH NG  |  V EH R IY  |  G UH D  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.11.19, Block: 4, Trial: 29\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  DH EY  |  W IH L  |  OW N L IY  |  L EH T  |  DH IH S  |  K AH P AH L  |  IH N  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.11.19, Block: 4, Trial: 30\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  S OW  |  W AH T S  |  N EH K S T  |  F AO R  |  Y UW  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.11.19, Block: 4, Trial: 31\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  IH T S  |  AH  |  P L EH ZH ER  |  W ER K IH NG  |  W IH DH  |  Y UW  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.11.19, Block: 4, Trial: 32\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AY  |  TH IH NG K  |  IH T S  |  AH B AW T  |  DH AH  |  S EY M  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.11.19, Block: 4, Trial: 33\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  SH IY  |  K AO L D  |  M IY  |  DH AH  |  AH DH ER  |  D EY  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.11.19, Block: 4, Trial: 34\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  G EH S  |  W AH T  |  W IY  |  AA R  |  D UW IH NG  |  N EH K S T  |  Y IH R  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.11.19, Block: 4, Trial: 35\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  D UW  |  Y UW  |  B IH L IY V  |  DH AE T  |  B OY  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.11.19, Block: 4, Trial: 36\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AY  |  N AA T  |  W AA N T  |  T UW  |  G OW  |  DH EH R  |  AH G EH N  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.11.19, Block: 4, Trial: 37\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  HH AE V IH NG  |  CH IH L D R AH N  |  ER EY N D  |  IH Z  |  F AH N  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.11.19, Block: 4, Trial: 38\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  DH IH S  |  IH Z  |  S AH CH  |  AH  |  G R EY T  |  AH G IY AH  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.11.19, Block: 4, Trial: 39\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  B OW TH  |  AH V  |  Y UW  |  AA R  |  D UW IH NG  |  S OW  |  W EH L  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.11.26, Block: 7, Trial: 20\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  S OW SH AH L  |  G R UW P  |  IH K S P IH R IY AH N S  |  S AH P EH Z D  |  S AY N  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.11.26, Block: 7, Trial: 21\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  K AE T  |  N OY  |  T AE P IH K  |  B EY S IH K L IY  |  K EH R  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.11.26, Block: 7, Trial: 22\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  JH UH R IY  |  N ER S IH NG  |  D IH P EH N D Z  |  L EY  |  W AH T EH V ER  |  Y UW ZH AH W AH L  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.11.26, Block: 7, Trial: 23\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  M IH D AH L  |  AW ER Z  |  N AO R TH  |  W AO N T IH D  |  S EH V AH N  |  L AA R JH  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.11.26, Block: 7, Trial: 24\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  K R AY M  |  B EH N AH F IH T S  |  L IH V Z  |  G AY  |  K AH M IH NG  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.11.26, Block: 7, Trial: 25\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  IH P AH N D  |  L IY S T  |  AH Z B AH N D  |  K AH M Z  |  W IH TH AW T  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.11.26, Block: 7, Trial: 26\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  B EY S B AO L  |  B AH JH IH T  |  HH AH Z B AH N D  |  V IH ZH ER  |  B OY Z  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.11.26, Block: 7, Trial: 27\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  TH R UW  |  W AH T EH V ER  |  S UW P ER  |  S AW N D Z  |  K UH K  |  W ER T  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.11.26, Block: 7, Trial: 28\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  TH IH NG K  |  EH N IY M AO R  |  Y UW ZH AH W AH L  |  S AW N D  |  AE N  |  R IY S IH S T IH ER  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.11.26, Block: 7, Trial: 29\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  M EH R IY D  |  V IH ZH AH W AH L  |  B IH G AH T S  |  N OY Z  |  R IY P AO R T  |  IH K S P IH R IY AH N S  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.11.26, Block: 7, Trial: 30\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  S IH T  |  S EH V AH N  |  M AY N  |  S EH K AH N D  |  D AE L AH S  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.11.26, Block: 7, Trial: 31\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  L UH K  |  W EH K ER D  |  T AA P IH K  |  P AA L AH S IY  |  G ER L  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.11.26, Block: 7, Trial: 32\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AH G R IY  |  K AE ZH AH W AH L T IY Z  |  EH M P L OY IY Z  |  S N OW  |  HH EH L P S  |  W UH M AH N  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.11.26, Block: 7, Trial: 33\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  DH EH Z  |  P AW ER  |  B EY B IY  |  K AO R S  |  M AY L Z  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.11.26, Block: 7, Trial: 34\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  W AY F  |  T IY M Z  |  W EY Z  |  L IH V IH NG  |  S EH N S  |  G AY  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.11.26, Block: 7, Trial: 35\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  IY V N IH NG  |  TH ER D IH NG  |  Y IH R Z  |  D EH TH  |  TH IH NG K IH NG  |  F AE T  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.11.26, Block: 7, Trial: 36\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  B EH N AH F IH T S  |  V OW T  |  T AH D EY  |  F Y UW CH ER  |  V AO R W AH D  |  IH K S P IH R IY AH N S  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.11.26, Block: 7, Trial: 37\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  Y UW R Z  |  T AE K S  |  G AH V ER M AH N T  |  D IY L  |  G R UW  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.11.26, Block: 7, Trial: 38\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  CH OY S AH Z  |  HH UW Z  |  W AH T EH V ER  |  M AH DH ER  |  EH N D  |  R EH G Y AH L ER  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.11.26, Block: 7, Trial: 39\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  T AH K T  |  L IH V Z  |  S OW SH AH L  |  P AH N IH SH M AH N T  |  T R AH B AH L  |  L AA S  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.11.26, Block: 9, Trial: 25\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  B EY S IH K L IY  |  DH IH S  |  IH Z  |  L OW  |  IH N  |  M AY  |  B UH K S  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.11.26, Block: 9, Trial: 26\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AE Z  |  Y UW ZH AH W AH L  |  AW ER  |  T ER N  |  K AH M Z  |  W EH N  |  W IY  |  W ER  |  AH B AW T  |  T UW  |  L IY V  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.11.26, Block: 9, Trial: 27\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  S AH M T AY M Z  |  AY  |  EH N JH OY  |  F AH N IY  |  M UW V IY Z  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.11.26, Block: 9, Trial: 28\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  D OW N T  |  M EH ZH ER  |  Y ER S EH L F  |  AH G EH N S T  |  DH IH S  |  Y AA R D  |  S T IH K  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.11.26, Block: 9, Trial: 29\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AY  |  T OW L D  |  Y UW  |  T UW  |  S EH L  |  DH AE T  |  P AA T  |  AH V  |  DH AH  |  K AH M P AH N IY  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.11.26, Block: 9, Trial: 30\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  DH EH R Z  |  AH  |  L AA T  |  AH V  |  S N OW  |  AH N D ER  |  M AY  |  K AA R  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.11.26, Block: 9, Trial: 31\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AY  |  K UH D AH N T  |  W EY T  |  F AO R  |  DH IH S  |  V ER ZH AH N  |  AH V  |  DH AH  |  G EY M  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.11.26, Block: 9, Trial: 32\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AY  |  IH K S P EH N T AH D  |  Y UW  |  HH IY R  |  W AH N  |  AW ER  |  AH G OW  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.11.26, Block: 9, Trial: 33\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  K AE N  |  Y UW  |  CH EH K  |  DH AH  |  R EH D IH NG  |  AA N  |  DH AH  |  K AH M P Y UW T ER  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.11.26, Block: 9, Trial: 34\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AW ER  |  S IH CH UW EY SH AH N  |  IH Z  |  N AA T  |  V EH R IY  |  D IH F ER AH N T  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.11.26, Block: 9, Trial: 35\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  D UW  |  Y UW  |  N OW  |  HH AW  |  T UW  |  R EH D  |  M Y UW Z IH K  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.11.26, Block: 9, Trial: 36\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AY  |  JH AH S T  |  W AO N T IH D  |  AW ER  |  Y UW ZH AH W AH L  |  F UW D  |  T UW  |  IY T  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.11.26, Block: 9, Trial: 37\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  HH AW  |  M EH N IY  |  K AE ZH AH W AH L T IY Z  |  W ER  |  DH EH R  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.11.26, Block: 9, Trial: 38\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  L IH V IH NG  |  W IH DH  |  DH IH S  |  G R UW P  |  AH V  |  F R EH N D Z  |  F AE L T  |  W AH N D ER F AH L  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.11.26, Block: 9, Trial: 39\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  W AH T  |  B R IH NG Z  |  Y UW  |  T UW  |  AW ER  |  HH OW M  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.11.26, Block: 9, Trial: 40\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  SH IY  |  S EH T  |  SH IY  |  IH K S P EH SH L IY  |  W UH D AH N T  |  T UW  |  T AO K  |  T UW  |  Y UW  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.11.26, Block: 9, Trial: 41\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  B R IH NG  |  M IY  |  DH AH  |  N OY Z  |  R IY P AO R T  |  P L IY Z  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.11.26, Block: 9, Trial: 42\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  D UW  |  Y UW  |  AH N D ER S T AE N D  |  DH AE T  |  R IY S AY K AH L IY  |  IH Z  |  IH M P AO R T AH N T  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.11.26, Block: 9, Trial: 43\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  M AY  |  K AH M P Y UW T ER  |  IH Z  |  K W AY T  |  IH K S P EH N S IH V  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.11.26, Block: 9, Trial: 44\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  EH V R IY W AH N  |  SH UH D  |  R EH D  |  N UW Z P EY P ER  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.11.26, Block: 9, Trial: 45\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AY  |  HH AE V  |  S ER T AH N L IY  |  M EY D  |  F R EH N D Z  |  HH IY R  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.11.26, Block: 9, Trial: 46\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  N AH TH IH NG  |  T UW  |  IH K S P EH N S IH V  |  P L IY Z  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.11.26, Block: 9, Trial: 47\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  M EH N IY  |  L OW K AH L  |  P IY P AH L  |  W ER K T  |  AE T  |  DH IH S  |  K AH M P AH N IY  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.11.26, Block: 9, Trial: 48\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  P IH K  |  AH P  |  Y AO R  |  B IH G AH S T  |  B UH K  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.11.26, Block: 9, Trial: 49\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  W AH T  |  D IH F ER AH N S  |  D AH Z  |  DH IH S  |  M EY K  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.12.03, Block: 4, Trial: 24\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  DH AE T AH L  |  B IY  |  N AY S  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.12.03, Block: 4, Trial: 25\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  P EY S T S  |  DH AH  |  F ER S T  |  L EH AH V  |  G EY M  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.12.03, Block: 4, Trial: 26\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  W ER  |  Y UW  |  HH IY R  |  L AE S T  |  S AH M ER  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.12.03, Block: 4, Trial: 27\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  DH AE T S  |  V AA V AH L AH N S  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.12.03, Block: 4, Trial: 28\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AY  |  T R AY D  |  T UW  |  HH AE V  |  AH  |  K AH M P AH SH  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.12.03, Block: 4, Trial: 29\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AH N D  |  D R AH P  |  DH OW Z  |  AO F  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.12.03, Block: 4, Trial: 31\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  W IY  |  HH AE V  |  AH  |  L AA T  |  AH V  |  P IY P AH L  |  HH UW  |  W ER K  |  AA N  |  DH AH  |  L AY T  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.12.03, Block: 4, Trial: 32\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  DH AE T S  |  R IH L IY  |  IH M P AO R T AH N T  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.12.03, Block: 4, Trial: 33\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  Y UW ZH AH L IY  |  SH IY  |  W IH L  |  AH T AW N T  |  T UW  |  S EH D  |  AH V  |  DH AH  |  V IH JH T ER  |  AH P  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.12.03, Block: 4, Trial: 34\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  IH T  |  M EY D  |  AH  |  P IH G  |  D IH F ER AH N S  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.12.03, Block: 4, Trial: 35\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  DH IH S  |  AO R AH JH SH AH P  |  K AE N  |  S EH T  |  AH V  |  N UW  |  D IH G EH SH AH N  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.12.03, Block: 4, Trial: 36\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  Y UW  |  R IH L IY  |  K AE N  |  K AW T  |  TH AH Z  |  AH V  |  S T AO R Z  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.12.03, Block: 4, Trial: 37\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AW ER  |  K R AY M  |  R AY T  |  HH AE Z  |  IH N K R EH S T  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.12.03, Block: 4, Trial: 38\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AA N  |  T AA P  |  AH V  |  DH AH  |  F IH D ER AH  |  D AE S  |  AA N  |  K AE S AH L IY  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.12.03, Block: 4, Trial: 39\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  IH T S  |  G OW IH NG  |  T UW  |  B IY  |  HH AA R D  |  T UW  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.12.03, Block: 4, Trial: 40\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  T R EH N S  |  AA R  |  B IH L T  |  EH K CH T R EH AH  |  S T AH D IY  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.12.03, Block: 4, Trial: 41\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  S AH M B AA D IY  |  W UH D  |  S IY  |  IH T  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.12.03, Block: 4, Trial: 42\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  IH Z  |  K AH L IH SH UW AH L  |  B IH N  |  F AO R  |  Y UW  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.12.03, Block: 4, Trial: 43\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  M AO R  |  AH V  |  DH AH  |  V AA L IH T IH R  |  N IH K ER AH K  |  S ER V AH S  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.12.03, Block: 4, Trial: 44\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  Y UW  |  W L AY K  |  IH T  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.12.03, Block: 4, Trial: 45\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  DH AE T S  |  P R AH V AH V AH D AH D  |  W EH R  |  W IY  |  W ER K  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.12.03, Block: 4, Trial: 46\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  B AH T  |  DH AH  |  TH IH NG K  |  W AA Z  |  DH AE T  |  AY  |  K UH D  |  D UW  |  DH AH  |  JH AA B  |  M AY S IH L  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.12.03, Block: 4, Trial: 48\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  W IY  |  W ER  |  S IH T IH NG  |  DH EH R  |  W AH N D ER IH NG  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.12.03, Block: 4, Trial: 49\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  DH EY V  |  K AH M  |  AH  |  L AO NG  |  W EY  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.12.03, Block: 8, Trial: 10\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  DH EY  |  W IH L  |  AO R D ER  |  EH V R IY W AH N  |  T UW  |  G OW  |  AH L AO NG  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.12.03, Block: 8, Trial: 11\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  B EY S IH K L IY  |  AY  |  W IH L  |  JH AH S T  |  S T IH K  |  ER AW N D  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.12.03, Block: 8, Trial: 12\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  DH IH S  |  K AE M P IH NG  |  S P EY S  |  IH Z  |  IH K S P EH N S IH V  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.12.03, Block: 8, Trial: 13\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  W AH T  |  W AA Z  |  IH N  |  DH AH  |  L OW K AH L  |  N UW Z P EY P ER  |  T AH D EY  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.12.03, Block: 8, Trial: 14\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  DH IH S  |  S IY Z AH N  |  W IH L  |  B R IH NG  |  M AO R  |  S AH N  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.12.03, Block: 8, Trial: 15\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  W AH T  |  AA R  |  Y UW  |  W AA CH IH NG  |  DH IH S  |  S IY Z AH N  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.12.03, Block: 8, Trial: 16\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  W AH T S  |  DH AH  |  D IY L  |  W IH DH  |  EH V R IY W AH N  |  IH N  |  DH IH S  |  K AH M P AH N IY  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.12.03, Block: 8, Trial: 17\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  M AO R N IH NG  |  AW ER Z  |  W IH DH  |  S AH N  |  AA R  |  K W AY T  |  W AH N D ER F AH L  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.12.03, Block: 8, Trial: 18\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  P IY P AH L  |  Y UW Z D  |  W AY T  |  K L OW DH Z  |  F AO R  |  DH IH S  |  G EY M  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.12.03, Block: 8, Trial: 19\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  SH OW SH AH L  |  S IH CH UW EY SH AH N  |  HH IY R  |  IH Z  |  G EH T IH NG  |  B EH T ER  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.12.08, Block: 8, Trial: 25\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  DH AE T  |  OW L D  |  M Y UW Z IH K  |  R EH K ER N D  |  IH Z  |  S T IH L  |  V EH R IY  |  G UH D  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.12.08, Block: 8, Trial: 26\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  T EH N  |  G AY Z  |  K EY M  |  IH N  |  F AO R  |  K AA R D Z  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.12.08, Block: 8, Trial: 27\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  DH IH S  |  P AA L AH S IY  |  W IH L  |  CH EY N JH  |  DH AH  |  L AO  |  IH N  |  M EH N IY  |  S T EY T S  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.12.08, Block: 8, Trial: 28\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  IH T  |  IH Z  |  AH  |  G R EY T  |  AO K EY ZH AH N  |  T UW  |  S T AA R T  |  R ER IH NG  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.12.08, Block: 8, Trial: 29\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  DH IH S  |  S IH CH UW EY SH AH N  |  IH Z  |  N AA T  |  D IH S AH S IH K AH L IY  |  S P EH SH AH L  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.12.08, Block: 8, Trial: 30\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  DH EH R  |  IH Z  |  AH  |  B IH G  |  K AE M P IH NG  |  S P EY S  |  OW V ER  |  HH IY R  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.12.08, Block: 8, Trial: 31\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  M AY  |  W ER D  |  IH Z  |  F AY N AH L  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.12.08, Block: 8, Trial: 32\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  P AH B L IH K  |  EH JH AH K EY SH AH N  |  IH Z  |  G EH T IH NG  |  B EH T ER  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.12.08, Block: 8, Trial: 33\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  DH IH S  |  IH Z  |  S ER T AH N L IY  |  N AA T  |  W IH DH  |  TH AW Z D AH N D  |  D AA L ER Z  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.12.08, Block: 8, Trial: 34\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  DH IH S  |  L UH K S  |  S UW P ER  |  IH K S P EH N S IH V  |  B AH T  |  IH T S  |  N AA T  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.12.08, Block: 8, Trial: 35\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AY  |  TH IH NG K  |  DH EH R  |  IH Z  |  S T IH L  |  S AH M  |  K AH N F Y UW ZH AH N  |  AH B AW T  |  DH IH S  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.12.08, Block: 8, Trial: 36\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AY  |  W IH L  |  N AA T  |  M IH S  |  AH N AH DH ER  |  G EY M  |  DH IH S  |  S IY Z AH N  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.12.08, Block: 8, Trial: 37\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  IH T  |  F EH L T  |  K W AY T  |  AH N Y UW ZH UW AH L  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.12.08, Block: 8, Trial: 38\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  W AH T S  |  B IH T EH N  |  M AY  |  HH OW M  |  AH N  |  DH IH S  |  N UW  |  S IH T IY  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.12.08, Block: 8, Trial: 39\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  R IY S AY K AH L IH NG  |  M AO R  |  W IH L  |  S ER T AH N L IY  |  HH EH L P  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.12.08, Block: 8, Trial: 40\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  F AY V  |  V AY L Z  |  N AO R TH  |  AH V  |  HH IY R  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.12.08, Block: 8, Trial: 41\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AY  |  AH V OY D  |  W AY T  |  K L OW DH Z  |  F AO R  |  DH IH S  |  G EY M  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.12.08, Block: 8, Trial: 42\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  W IH CH  |  EH R IY AH Z  |  AH V  |  DH AH  |  S IH T IY  |  AA R  |  G UH D  |  F AO R  |  L IH V IH NG  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.12.08, Block: 8, Trial: 43\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  HH IY  |  IH Z  |  B IH N  |  AH  |  G UH D  |  CH AE L D  |  S OW  |  F AO R  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.12.08, Block: 8, Trial: 44\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  Y UW  |  HH AE V  |  T UW  |  B IY  |  K W AY T  |  S OW SH AH L  |  T UW  |  M EY K  |  F R EH N D Z  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.12.08, Block: 8, Trial: 45\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  IH T  |  IH Z  |  B EH T ER  |  DH AE T  |  Y UW  |  AA R  |  HH OW M  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.12.08, Block: 8, Trial: 46\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  S OW SH AH L  |  K AH N T R IY Z  |  AA R  |  W AH N D ER F AH L  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.12.08, Block: 8, Trial: 47\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AA R  |  Y UW  |  W ER K IH NG  |  DH IH S  |  F UH L  |  G EY M  |  S IY Z AH N  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.12.08, Block: 8, Trial: 48\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  P L IY Z  |  P L EY  |  M AY  |  F EY V IH T  |  M Y UW Z IH K  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.12.08, Block: 8, Trial: 49\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  DH AH  |  S AH N  |  SH UH D  |  P OY N T  |  AH S  |  T UW  |  DH AH  |  N AO R TH  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.12.08, Block: 9, Trial: 25\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AY  |  W AA Z  |  S EY IH NG  |  IH K Z AE K T L IY  |  DH IH S  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.12.08, Block: 9, Trial: 26\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  SH IY  |  L AH V D  |  N AH TH IH NG  |  M AO R  |  DH AE N  |  HH ER  |  F EY V ER IH T  |  B UH K  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.12.08, Block: 9, Trial: 27\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  T EH S T IH NG  |  IH Z  |  IH M P AO R T AH N T  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.12.08, Block: 9, Trial: 28\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  DH EY  |  R IH K AO R D  |  M Y UW Z IH K  |  IH N  |  S M AO L  |  R UW M  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.12.08, Block: 9, Trial: 29\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  DH EY  |  AA R  |  F Y UW CH ER  |  HH AH Z B AH N D  |  AH N D  |  W AY F  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.12.08, Block: 9, Trial: 30\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  K L AH N ZH ER IY  |  K L OW DH Z  |  AA R  |  IH K S P EH N S IH V  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.12.08, Block: 9, Trial: 31\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  T EH L  |  M IY  |  AH B AW T  |  N AY S  |  P L EY S AH Z  |  N IH R  |  Y UW  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.12.08, Block: 9, Trial: 32\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  DH IH S  |  IH Z  |  N AA T  |  D IH S AH S EH L AH L IY  |  T R UW  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.12.08, Block: 9, Trial: 33\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AY  |  D OW N T  |  AH N D ER S T AE N D  |  W AH T  |  Y UW  |  AA R  |  S EY IH NG  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.12.08, Block: 9, Trial: 34\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AY  |  P EY D  |  W IH DH  |  M AY  |  Y UW ZH AH W AH L  |  K R EH D AH T  |  K AA R D  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.12.08, Block: 9, Trial: 35\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  W AH T  |  IH Z  |  Y AO R  |  N EH K S T  |  L AY N  |  IH N  |  DH AH  |  P L EY  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.12.08, Block: 9, Trial: 36\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  M AY  |  F AA DH ER  |  W AA Z  |  TH AE NG K IH NG  |  AH B AW T  |  IH T  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.12.08, Block: 9, Trial: 37\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  B AH T  |  DH AE T  |  AH K R AO S  |  DH AH  |  R UW M  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.12.08, Block: 9, Trial: 38\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  M AY  |  HH AA R T  |  IH Z  |  W IH DH  |  Y UW  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.12.08, Block: 9, Trial: 39\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  W AH T  |  IH G Z AE K T L IY  |  D UW  |  Y UW  |  N OW  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.12.08, Block: 9, Trial: 40\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  Y UW V  |  AO L R EH D IY  |  T AO K T  |  AH N AH F T  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.12.08, Block: 9, Trial: 41\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  M AY  |  D AO T ER  |  L EH K S  |  HH ER  |  K AA R  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.12.08, Block: 9, Trial: 42\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  DH AE T  |  S IY M Z  |  L AY K  |  AH N AH F  |  W ER K  |  F AO R  |  T AH D EY  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.12.08, Block: 9, Trial: 43\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  HH AE F  |  AH V  |  M AY  |  F R EH N D Z  |  L AY V  |  K L UH K S  |  T UW  |  M IY  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.12.08, Block: 9, Trial: 44\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  Y AO R  |  S OW SH AH L  |  S IH CH UW EY SH AH N  |  IH Z  |  N AA T  |  V EH R IY  |  D IH F ER AH N T  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.12.08, Block: 9, Trial: 45\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  W IY  |  M AH S T  |  R IH K AO R D  |  EH V R IY TH IH NG  |  DH AE T  |  HH AE P AH N D  |  T AH D EY  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.12.08, Block: 9, Trial: 46\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  L EH T S  |  G OW  |  CH EH K  |  DH IH S  |  N UW  |  P L EY S  |  AW T  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.12.08, Block: 9, Trial: 47\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AY  |  AE M  |  SH UH R  |  AY  |  K AE N  |  D UW  |  DH IH S  |  W IH TH AW T  |  Y AO R  |  HH EH L P  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.12.08, Block: 9, Trial: 48\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  D UW  |  N AA T  |  P UH T  |  OY L  |  IH N  |  DH AH  |  W AO T ER  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.12.08, Block: 9, Trial: 49\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  IH T  |  IH Z  |  AH N UW ZH UW AH L  |  F AO R  |  M AY  |  P EH R AH N T  |  T UW  |  T IY M  |  AH P  |  W IH DH  |  DH EH M  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.12.10, Block: 7, Trial: 25\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  L IH V IH NG  |  AA N  |  AH  |  B AH JH IH T  |  IH Z  |  K W AY T  |  D IH F AH K AH L T  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.12.10, Block: 7, Trial: 26\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  P L IY Z  |  T EY K  |  K EH R  |  AH V  |  Y AO R  |  CH AY L D  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.12.10, Block: 7, Trial: 27\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AY  |  W AA Z  |  AH S P EH SH L IY  |  L UH K IH NG  |  F AO R W ER D  |  T UW  |  IH T  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.12.10, Block: 7, Trial: 28\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  T W EH L V  |  N IY D Z  |  T UW  |  G OW  |  F AO R  |  DH AH  |  F IH N AH L  |  G EY M  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.12.10, Block: 7, Trial: 29\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AY  |  HH AE D  |  DH IH S  |  V IH ZH AH N  |  W AH N S  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.12.10, Block: 7, Trial: 30\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AY  |  W IH L  |  G EH T  |  M AY  |  B EH S T  |  K L OW DH Z  |  AW T  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.12.10, Block: 7, Trial: 31\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  IH Z  |  DH IH S  |  DH AH  |  P L EY S  |  Y UW  |  Y UW ZH AH W AH L IY  |  V IH Z IH T  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.12.10, Block: 7, Trial: 32\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  M AY  |  P EH R AH N T S  |  G IH V  |  M IY  |  K W AA L AH T IY  |  AE N JH D AH K AE K SH AH N  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.12.10, Block: 7, Trial: 33\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  SH IY  |  S OW L D  |  M IY  |  DH IH S  |  B UH K  |  AH N D  |  AY  |  P EY D  |  F AO R  |  IH T  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.12.10, Block: 7, Trial: 34\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  DH IH S  |  W AA Z  |  AH  |  B IH Z N AH S  |  D IH S IH ZH AH N  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.12.10, Block: 7, Trial: 35\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AY  |  L AY K  |  D R AY V IH NG  |  S T IH T K  |  IH T S  |  IY Z IY  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.12.10, Block: 7, Trial: 36\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  DH IH S  |  P R OW G R AE M  |  IH Z  |  V EH R IY  |  IH N T AH R EH S T IH NG  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.12.10, Block: 7, Trial: 37\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AA R  |  Y UW  |  S ER T AH N  |  Y AO R  |  P EH R AH N T S  |  W IH L  |  L AA T  |  Y UW  |  G OW  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.12.10, Block: 7, Trial: 38\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  DH AH  |  S IH T  |  AH V  |  CH IH L D R AH N  |  IH N  |  DH IH S  |  K AH N T R IY  |  IH Z  |  AO F AH L  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.12.10, Block: 7, Trial: 39\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  K AH M P AH N IY Z  |  AA R  |  L UH K IH NG  |  F AO R  |  M AO R  |  EH M P L OY IY Z  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.12.10, Block: 7, Trial: 40\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AY  |  W UH D  |  TH AE DH ER  |  B IY  |  W IH DH  |  M AY  |  F R EH N D Z  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.12.10, Block: 7, Trial: 41\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  W IY  |  AA R  |  S AH P OW Z D  |  T UW  |  HH EH L P  |  AW ER  |  F AE M AH L IY  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.12.10, Block: 7, Trial: 42\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  DH AH  |  S IH T IY  |  HH AE Z  |  AH  |  D R AH G  |  P R AA B L AH M  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.12.10, Block: 7, Trial: 43\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AY  |  D UW  |  N AA T  |  G EH T  |  P EY D  |  IH N AH F  |  F AO R  |  DH IH S  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.12.10, Block: 7, Trial: 44\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  B IY IH NG  |  AH  |  M AH DH ER  |  IH Z  |  N AA T  |  AO L W EY Z  |  IY Z IY  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.12.10, Block: 7, Trial: 45\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  HH IY  |  D AH Z  |  N AA T  |  S IY M  |  L AY K  |  AH  |  P ER S AH N  |  HH UW  |  W UH D  |  M EY K  |  DH AE T  |  CH OY S  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.12.10, Block: 7, Trial: 46\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AY  |  D OW N T  |  B IH L IY V  |  DH AE T  |  K AH P AH L  |  W EH N T  |  ER T  |  S OW  |  L EY T  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.12.10, Block: 7, Trial: 47\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  DH IH S  |  IH Z  |  AH  |  G UH D  |  S IY Z AH N  |  F AO R  |  AW ER  |  B IH Z N AH S  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.12.10, Block: 7, Trial: 48\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AA R  |  Y UW  |  F R IY  |  T UW  |  W ER K  |  AA N  |  DH IH S  |  T AH G AY T  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.12.10, Block: 7, Trial: 49\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  L EH T S  |  CH EH K  |  W IH DH  |  IY CH  |  AH DH ER  |  EH V ER IY  |  HH AE F  |  AW ER  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.12.17, Block: 11, Trial: 30\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  D UW  |  Y UW  |  HH EH V IH N  |  N OW  |  DH AH  |  K IH F ER AH N S  |  B IH IY N  |  DH IH S  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.12.17, Block: 11, Trial: 31\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  SH IY  |  L EH F  |  HH OW M  |  F IH F T IH K  |  M IH N AH Z  |  AH G OW  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.12.17, Block: 11, Trial: 32\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AH  |  D AW L D  |  DH IH NG Z  |  DH EH R  |  R IH M L IY  |  IH N  |  DH AH  |  AH N L IH NG  |  AH S  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.12.17, Block: 11, Trial: 33\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  DH IH S  |  S IH CH UW EY SH AH N  |  IH Z  |  N AA T  |  DH AE T  |  M AY N  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.12.17, Block: 11, Trial: 34\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  W AH T  |  T AY P  |  AH V  |  P EH Z AH N  |  D UW  |  Y UW  |  W AA N T  |  T UW  |  K AO L  |  AH P  |  T UW  |  B IY  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.12.17, Block: 11, Trial: 35\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  W IY  |  G UH D  |  AH G AH V  |  F R IY  |  S T AH F  |  F AO  |  DH AH  |  S T AO R  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.12.17, Block: 11, Trial: 36\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  W IH SH  |  V ER ZH AH N  |  AH V  |  DH AH  |  S T AO R IY  |  IH Z  |  D R OW  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.12.17, Block: 11, Trial: 37\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  S AH M B AA D IY  |  M AH S T  |  AE V  |  K AA R D  |  AH  |  IH N  |  DH AH  |  IY V N IH NG  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.12.17, Block: 11, Trial: 38\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  B IH G  |  Y AO R  |  F EY V ER IH T  |  B UH G  |  F R AH M  |  S K UW L  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.12.17, Block: 11, Trial: 39\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  HH AW  |  M EH N IY  |  AW ER Z  |  D IH D  |  Y UW  |  W EY T  |  AW G S EH N D T  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.12.17, Block: 11, Trial: 40\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  W IY  |  T AA T IH D  |  DH IH S  |  W ER K  |  S EH S  |  DH AH  |  P EY B ER  |  K EY N  |  AW T  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.12.17, Block: 11, Trial: 41\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AY  |  K UH D AH N T  |  AH V OY D  |  G OW IH NG  |  T UW  |  DH AH  |  K AH N T R IY  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.12.17, Block: 11, Trial: 42\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  HH AW  |  M EH N IY  |  D AA L ER Z  |  T UW  |  Y UW  |  N IY D  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.12.17, Block: 11, Trial: 43\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  T W EH N T IY  |  F AO R  |  AW ER Z  |  W AH N  |  B AY  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.12.17, Block: 11, Trial: 44\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  B EY B IY  |  F UW D  |  F R AH M  |  DH AH  |  S T AO R  |  IH Z  |  N AA T  |  B AE D  |  IH T  |  AO L  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.12.17, Block: 11, Trial: 45\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  W AH T  |  M UW V IY Z  |  AA R  |  DH AH  |  M EY K IH NG  |  DH IH S  |  Y IH R  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.12.17, Block: 11, Trial: 46\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  IH N  |  DH AH  |  S EH K IH NG  |  S IY Z AH N  |  AH V  |  DH AE T  |  F AH N  |  SH OW  |  K AH M IH NG  |  S UW N  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.12.17, Block: 11, Trial: 47\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  DH AE T  |  CH AY L D  |  IH Z  |  L IY S T  |  L AH N CH  |  M AY N IY  |  DH AE N  |  DH AH  |  AH DH ER  |  K IH D Z  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.12.17, Block: 11, Trial: 48\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  L EH T S T  |  S T EH K  |  T UW  |  S AH M W AH T  |  IY Z IY ER  |  JH AA F  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.12.17, Block: 11, Trial: 49\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  M AY  |  D AO T ER  |  L AH V D  |  DH AH  |  CH IH Z AH Z  |  W IY  |  M EY D  |  T UW  |  DH AH  |  HH AW S  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.12.17, Block: 11, Trial: 50\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  P AH B L IH K  |  P L EY S AH Z  |  AA R  |  F AO R  |  EH V R IY W AH N T  |  T UW  |  EH N JH OY  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.12.17, Block: 11, Trial: 51\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AY  |  HH OW P  |  Y UW  |  AH N T ER S T AE N D  |  DH AH  |  K AH S T  |  AH V  |  D UW IH NG  |  DH IH S  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.12.17, Block: 11, Trial: 52\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AW ER  |  K AH M P AH N IY  |  W IH L  |  P EY  |  DH AH  |  S P AO R T S  |  G IH V  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.12.17, Block: 11, Trial: 53\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  L IH Z AH N  |  T UW  |  DH AH  |  HH EH D  |  K UH K  |  IH N  |  DH AH  |  HH AW S  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.12.17, Block: 11, Trial: 54\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  DH AE T  |  M UW Z IH K  |  IH Z  |  K AO R  |  M AY  |  AW R T  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.12.17, Block: 11, Trial: 55\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  DH AH  |  L AO  |  S EH Z  |  DH IH S  |  IH Z  |  N AA T  |  W AY T  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.12.17, Block: 11, Trial: 56\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  Y UW  |  S IY M  |  T UW  |  B IY  |  AH  |  R EH G Y AH L ER  |  IH N  |  DH IH S  |  P L EY S  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.12.17, Block: 11, Trial: 57\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  W AH T  |  IH G Z AE K T L IY  |  D IH D  |  Y AO R  |  F R EH N  |  T EH L  |  Y UW  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.12.17, Block: 11, Trial: 58\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  DH IH S  |  S IH CH UW EY SH AH N  |  IH Z  |  N AA T  |  AH N UW ZH UW AH L  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.12.17, Block: 11, Trial: 59\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  W AH T EH V ER  |  Y UW  |  S EY  |  DH AH  |  F AE N D  |  W IH L  |  N AA T  |  CH EY N JH  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.12.29, Block: 4, Trial: 25\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  DH EY V  |  N AA T  |  TH R IY  |  D AH S ER Z  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.12.29, Block: 4, Trial: 26\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  G EH T  |  AW T  |  AA N  |  DH AH  |  R UH D  |  T UW  |  B UH T D  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.12.29, Block: 4, Trial: 27\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  DH AE T S  |  HH AW  |  W IY  |  K UH N  |  S T AA R T IH D  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.12.29, Block: 4, Trial: 28\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  W IY R  |  B AE K IH NG  |  IH T  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.12.29, Block: 4, Trial: 29\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  DH EY  |  HH AE V  |  DH AH  |  N OW  |  CH OY S  |  S D IY L  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.12.29, Block: 4, Trial: 30\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  IH T S  |  N AY S  |  T UW  |  G EH T  |  AW T  |  IH N  |  DH AH  |  OW P AH N  |  HH IY R  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.12.29, Block: 4, Trial: 31\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  M AY  |  B R OW DH ER  |  K L IH V Z  |  W EH R  |  AY  |  W ER K  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.12.29, Block: 4, Trial: 32\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  DH EY  |  W ER L  |  L UH K IH NG  |  IH N AH F  |  T UW  |  HH AE V  |  S AH M  |  OY L  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.12.29, Block: 4, Trial: 33\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  DH AH  |  F AE S T  |  B IH K S  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.12.29, Block: 4, Trial: 34\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AH B AW T  |  F AO R  |  TH AW Z AH N D  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.12.29, Block: 4, Trial: 35\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  Y UW  |  HH AE V  |  W AH N  |  L IH L  |  AO L  |  T UW  |  Y ER S EH L F  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.12.29, Block: 4, Trial: 36\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  DH AH  |  T R IY  |  W ER  |  S OW  |  B OY N IH T  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.12.29, Block: 4, Trial: 37\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  D UW  |  Y UW  |  W AA CH  |  M Y UW Z IH K  |  T EH L AH V IH ZH AH N  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.12.29, Block: 4, Trial: 38\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AY  |  P L AE N D  |  DH AE T  |  M Y UW Z IH K  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.12.29, Block: 4, Trial: 39\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  DH AH  |  S T EY P IH NG  |  B AY K  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.12.29, Block: 4, Trial: 40\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  B OW TH  |  B OY Z  |  HH AE V  |  P L AE K  |  IY R  |  AH N D  |  B R AW N  |  AW S  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.12.29, Block: 4, Trial: 41\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  DH AE T S  |  IH G Z AE K T L IY  |  DH AH  |  P R AA B L AH M  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.12.29, Block: 4, Trial: 42\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  P L EY N  |  M AO R  |  T R IY Z  |  IH N  |  AH P AH N  |  EH R IY AH Z  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.12.29, Block: 4, Trial: 43\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  IH T  |  IH Z  |  N AA T  |  G OW  |  T UW  |  HH AE P AH N  |  DH AE T  |  W EY  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.12.29, Block: 4, Trial: 44\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  DH EH R  |  HH AE Z  |  AO L S OW  |  B IH N  |  AH  |  D IH V IH ZH AH N  |  AH V  |  IY V AH N B AO IY  |  T UW  |  DH AH  |  P L AE K  |  M AA R IH D  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.12.29, Block: 4, Trial: 45\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  DH AE T S  |  W UH D  |  T UW  |  HH IY R  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.12.29, Block: 4, Trial: 46\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AY  |  S T IH L  |  D IH D AH N T  |  W AA N T  |  HH ER  |  T UW  |  G OW  |  T UW  |  AH  |  D EY  |  K EH R  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.12.29, Block: 4, Trial: 47\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  DH EH N  |  IH T  |  G OW Z  |  T UW  |  DH AH  |  N EH K S T  |  P OY N T  |  AH N D  |  S OW  |  AA N  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.12.29, Block: 4, Trial: 48\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AH N D  |  AY  |  JH AH S T  |  EH N D AH N  |  AH P  |  HH AE V IH NG  |  T UW  |  D R AA B  |  DH AH  |  K L EY S  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.12.29, Block: 4, Trial: 49\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  DH AE T  |  IH Z  |  AY  |  W IH L  |  G UH D  |  N OW  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.12.29, Block: 5, Trial: 25\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AY  |  DH AE T  |  DH EY  |  AE T  |  CH EY N JH  |  DH EH R  |  P AA L AH S IY  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.12.29, Block: 5, Trial: 26\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AY  |  K AE N AA T  |  T EH L  |  K IH D Z  |  N AA T  |  T UW  |  P L EY  |  AW T S AY D  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.12.29, Block: 5, Trial: 27\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  CH IH L D R AH N  |  K AE N  |  JH OY N  |  DH AE T  |  R EH D IH NG  |  G R UW P  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.12.29, Block: 5, Trial: 28\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AY  |  W UH D  |  R AE DH ER  |  W AH N  |  DH IH S  |  B IH Z N AH S  |  W IH DH  |  DH EH M  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.12.29, Block: 5, Trial: 29\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AY  |  F AY N D  |  DH IH S  |  K AA AO R S  |  R IH L IY  |  IH N T AH R EH S T IH NG  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.12.29, Block: 5, Trial: 30\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AY  |  AH N D ER S T AE N D  |  DH AH  |  D IH V AH N S  |  F AY N T  |  W EH L  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.12.29, Block: 5, Trial: 31\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  W IY  |  AA R  |  T EH S IH NG  |  DH AH  |  L IH S T  |  G R UW  |  N AW  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.12.29, Block: 5, Trial: 32\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  G AH B AH D N IY  |  N UW  |  W AH T  |  HH AE P AH N D  |  DH EH R  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.12.29, Block: 5, Trial: 33\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  DH IH S  |  K AH M P AH N IY  |  W EH N T  |  P AH B L IH K  |  DH AE S T  |  Y IH R  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.12.29, Block: 5, Trial: 34\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  IH T  |  W IH L  |  P IY  |  AE N  |  IH M P AO R T AH N T  |  S T AO R IY  |  T UW  |  D EH L  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.12.29, Block: 5, Trial: 35\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AY  |  AE M  |  AH W EY  |  AA N  |  DH AH  |  F ER S T  |  W IY K EH N D  |  AH V  |  N EH K S T  |  M AH N TH  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.12.29, Block: 5, Trial: 36\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AY  |  HH AE V  |  B IH N  |  T UW  |  N ER S IH NG  |  S K UW L  |  ER R EH D IY  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.12.29, Block: 5, Trial: 37\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  DH EH R  |  S ER V AH N S  |  IH Z  |  B AE D  |  AH N D  |  DH AH  |  F UW D  |  IH Z AH N T  |  G UH D  |  IY DH ER  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.12.29, Block: 5, Trial: 38\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  W IY  |  S T AO R  |  DH IH S  |  S T AH F  |  IH N  |  DH AH  |  R UW M  |  AE T  |  DH AH  |  B AE K  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.12.29, Block: 5, Trial: 39\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  IH T  |  IH Z  |  AE N  |  EH M P L OY IY  |  EH JH AH K EY SH AH N  |  P R OW G R AE M  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.12.29, Block: 5, Trial: 40\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  W IY  |  D OW N T  |  W AA N T  |  EH N IY  |  T R AH B AH L  |  IH N  |  P AH B L IH K  |  P L EY S AH Z  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.12.29, Block: 5, Trial: 41\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  K UH D  |  Y UW  |  G EH T  |  W IY  |  DH AE T  |  W AY T  |  B UH K  |  P L IY Z  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.12.29, Block: 5, Trial: 42\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  DH IH S  |  M UW V IY  |  IH Z  |  M AY  |  F EY V ER IH T  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.12.29, Block: 5, Trial: 43\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  Y AE NG  |  P IY P AH L  |  G EH T  |  T UW  |  HH IY R  |  DH AE T  |  AH  |  L AA T  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.12.29, Block: 5, Trial: 44\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AY  |  EH N JH OY  |  R AH N IH NG  |  F AO R  |  M AY L Z  |  AA N  |  AH  |  K OW L D  |  M AO R N IH NG  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.12.29, Block: 5, Trial: 45\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  G UH D  |  W ER K  |  AO F AH N  |  B R IH NG Z  |  JH OY  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.12.29, Block: 5, Trial: 46\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AY  |  K AE N AA T  |  S IY  |  DH AH  |  D IH F ER AH N S  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.12.29, Block: 5, Trial: 47\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  DH AE T  |  IH Z  |  AH  |  W AH N D ER F AH L  |  K AA R D  |  TH AE NG K  |  Y UW  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.12.29, Block: 5, Trial: 48\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AY  |  W IH L  |  S P EH N D  |  DH AH  |  W IY K EH N D  |  W IH DH  |  M AY  |  P EH R AH N T S  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2023.12.29, Block: 5, Trial: 49\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  Y UW  |  G EH T  |  HH AE V  |  AH V  |  DH AH  |  K R EH D AH T  |  F AO R  |  DH IH S  |  W ER K  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.02.25, Block: 6, Trial: 23\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  DH EY  |  L IY V Z  |  AA R  |  AO L  |  D  |  AH N D  |  B R AW N  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.02.25, Block: 6, Trial: 25\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AE N  |  ER L IY  |  V ER ZH AH N  |  AH V  |  DH IH S  |  AA R T AH K AH L  |  W AA Z  |  P AH B L IH SH T  |  L AE S T  |  M AH N TH  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.02.25, Block: 6, Trial: 26\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  B IH K AO Z  |  DH EY  |  D OW N T  |  W AA N T  |  T UW  |  N OW  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.02.25, Block: 6, Trial: 27\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AY  |  TH IH NG K  |  EH V R IY W AH N  |  W UH D  |  AH G R IY  |  HH IY  |  W AA Z  |  AH  |  V IH N AH N EH R IY  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.02.25, Block: 6, Trial: 28\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AY  |  R IH M EH M B ER  |  IH T  |  T UH K  |  M IY  |  AH  |  L AO NG  |  T AY M  |  T UW  |  AH N D ER S T EH N T  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.02.25, Block: 6, Trial: 29\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AY  |  G EH S  |  IH T  |  IH Z  |  T UW  |  ER L IY  |  T UW  |  N OW  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.02.25, Block: 6, Trial: 30\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  DH IY Z  |  T AY M Z  |  AH V  |  HH IH N S T AH D AH N D Z  |  AA R  |  N AA T  |  AH N Y UW ZH UW AH L  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.02.25, Block: 6, Trial: 31\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  Y UW  |  HH AE V  |  AH  |  K AH P AH L  |  AH V  |  CH OY S AH Z  |  HH IY R  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.02.25, Block: 6, Trial: 32\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  IH T  |  IH Z  |  ER L IY  |  IH N  |  DH AH  |  M AO R N IH NG  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.02.25, Block: 6, Trial: 33\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  W EH R  |  IH N  |  B IH N S AH L EY N Y AH  |  AA R  |  Y UW  |  F R AH M  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.02.25, Block: 6, Trial: 34\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  SH IY  |  D AH Z  |  HH AE V  |  AH  |  JH AA B  |  AH N D  |  AH  |  K AH IH R  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.02.25, Block: 6, Trial: 35\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  DH AE T  |  IH N EH N S SH M AH N T  |  W AA Z  |  M IH N AH L IY  |  F AO R  |  P IY P AH L  |  IH N  |  B AH B AH L  |  HH OW M Z  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.02.25, Block: 6, Trial: 36\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AY  |  K UH D  |  P R AA B AH B L IY  |  S T AA R T  |  P L EY IH NG  |  B EY S B AO L  |  N EH K S T  |  S AH M ER  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.02.25, Block: 6, Trial: 37\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  W IY  |  L AY K  |  B IY IH NG  |  W IH DH  |  AW ER  |  K IH D Z  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.02.25, Block: 6, Trial: 38\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  IH T  |  IH Z  |  AH N Y UW ZH UW AH L  |  F AO R  |  AH S  |  T UW  |  N AA T  |  HH AE V  |  R EY N  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.02.25, Block: 6, Trial: 39\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  IH T S  |  AW ER Z  |  T UW  |  K IY P  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.02.25, Block: 6, Trial: 41\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  DH EH R  |  AA R  |  DH AE T S  |  AH V  |  S AH CH  |  D IH V IH ZH AH N Z  |  IH N  |  DH IH S  |  K AH N T R IY  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.02.25, Block: 6, Trial: 42\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  HH IY  |  IH Z  |  AH  |  P R AH D EH K SH AH N  |  P L EY N ER  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.02.25, Block: 6, Trial: 43\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  IH T S  |  JH AH S T  |  DH AH  |  EH D IY AH  |  DH AE T  |  M EY K S  |  M IY  |  S AW D  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.02.25, Block: 6, Trial: 44\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  DH EY  |  D UW  |  K AH V ER  |  AH  |  V IY AY IH D IY  |  AH V  |  T AA P IH K S  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.02.25, Block: 6, Trial: 45\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  JH OY N  |  AH S  |  N AW  |  F AO R  |  AH  |  T EH S K AE T  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.02.25, Block: 6, Trial: 46\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  DH EY  |  JH AH S T  |  N IY D  |  T UW  |  D UW  |  S AH M TH IH NG  |  W IH DH  |  HH IH M  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.02.25, Block: 6, Trial: 47\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  W AH T  |  IH Z  |  DH AH  |  S AH B JH IH K T  |  M AE T ER  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.02.25, Block: 6, Trial: 49\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  W AH T  |  AA R  |  Y UW  |  D UW IH NG  |  HH IY R  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.03.08, Block: 8, Trial: 24\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AY  |  F IY L  |  DH AE  |  S EY M  |  W EY  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.03.08, Block: 8, Trial: 25\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  DH EY  |  W IH N D IH D  |  W AO ER  |  F IH L D IY  |  F AY V  |  M IH N AH T S  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.03.08, Block: 8, Trial: 26\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AY  |  JH AH S T  |  G EH T  |  G OW AH N T  |  IH T  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.03.08, Block: 8, Trial: 27\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  W IY  |  R AY T  |  T UW  |  D UW  |  IH T  |  EH V ER IY  |  AH DH ER  |  M AH N TH  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.03.08, Block: 8, Trial: 28\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AY  |  HH AE V  |  Y UW  |  AO N S OY  |  DH EH M  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.03.08, Block: 8, Trial: 29\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AY  |  TH IH NG K  |  IH T  |  AE Z  |  DH AH  |  B EH S T  |  L IH V ER  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.03.08, Block: 8, Trial: 30\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AY  |  AE M  |  EH N JH OY IH NG  |  DH AE T  |  S AY D  |  AH V  |  IH T  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.03.08, Block: 8, Trial: 31\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  W AH T  |  AY  |  S IY  |  IH N  |  DH AH  |  K IH S T AH P AH  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.03.08, Block: 8, Trial: 32\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  W AH T  |  EH V R IY TH IH NG  |  IH Z  |  AA N  |  DH AH  |  L AY N  |  HH IY  |  D IH L IH V AH N Z  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.03.08, Block: 8, Trial: 33\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  W IY  |  D OW N T  |  HH AE V  |  AH  |  R IY L  |  S T R EH K T  |  M AH JH IH T  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.03.08, Block: 8, Trial: 34\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  DH AE T  |  B EY S AH N  |  R EH SH AH N  |  Y UW  |  T UW  |  M AH CH  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.03.08, Block: 8, Trial: 35\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  M AO R  |  P IY P AH L  |  K AO L  |  AA N  |  F R EH N T IH N Z  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.03.08, Block: 8, Trial: 36\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  W AH T  |  T UW  |  L AY N  |  S AH M TH IH NG  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.03.08, Block: 8, Trial: 37\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  W IY  |  AA R  |  P AO R  |  IH N  |  DH EH R  |  L EH V AH L  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.03.08, Block: 8, Trial: 38\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  HH AW  |  L AO NG  |  D AH S T  |  IH T  |  T EY K  |  T UW  |  G EH T  |  M AY  |  P OY N T S  |  B AE T K  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.03.08, Block: 8, Trial: 39\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AY  |  D OW N T  |  N OW  |  AW  |  L AY K  |  Y UW V  |  B IH N  |  HH IY R  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.03.08, Block: 8, Trial: 41\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  S AH M  |  HH AE V  |  DH AH  |  AH P S P IH R AH N M AH N T S  |  F EY L  |  W AH DH AW N T  |  EH K S P R IH D EY SH AH N  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.03.08, Block: 8, Trial: 42\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AY D  |  P R AA B AH B L IY  |  B AE  |  AH N AH DH ER  |  W AA N T  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.03.08, Block: 8, Trial: 43\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AY  |  TH IH NG K  |  HH IY  |  W IH L  |  P IH B L IY  |  B AE K  |  IH T  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.03.08, Block: 8, Trial: 44\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AY  |  D OW N T  |  N OW  |  IH F  |  Y UW  |  L AY K  |  DH AH  |  P EH R IY AH  |  IH N  |  DH IH S  |  T AW N  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.03.08, Block: 8, Trial: 45\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  DH AH  |  D IH S IH ZH AH N Z  |  AA R  |  N AA T  |  IH N  |  DH EH R  |  HH AW S  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.03.08, Block: 8, Trial: 46\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  P R AE K T IH Z  |  K IY P IH NG  |  Y UW  |  S IH K S AH Z  |  AH B AW T  |  Y UW  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.03.08, Block: 8, Trial: 47\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  W IY  |  L AY K  |  M EH S AH K AH N  |  M OW T  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.03.08, Block: 8, Trial: 48\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  B IY  |  CH EH N T AH L  |  T UW  |  HH EH P V R ER B AA B AH L  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.03.08, Block: 8, Trial: 49\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AY V  |  D AA N T  |  DH AE T  |  B IH F AO R  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.03.15, Block: 7, Trial: 24\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  Y UW  |  AA R  |  IH L AW N D  |  T UW  |  L EH T  |  DH AH  |  CH IH L D R AH N  |  SH OW  |  DH EH R  |  K EH R AH T ER  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.03.15, Block: 7, Trial: 25\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AY  |  W EH L K AH M  |  DH AH  |  D IH S IH ZH AH N  |  AH V  |  DH AH  |  K AA R T  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.03.15, Block: 7, Trial: 26\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  JH AH S T  |  S IH T  |  D AW N  |  AA N  |  DH AH  |  T EY K  |  AH N D  |  EH N JH OY  |  Y ER S EH L F  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.03.15, Block: 7, Trial: 28\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AY  |  B AA T  |  AH  |  K AH M P IH  |  AH V  |  HH ER  |  N UW  |  B UH K  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.03.15, Block: 7, Trial: 29\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  Y UW  |  K AE N T  |  S T AH P  |  P IY P AH L  |  F R AH M  |  D UW IH NG  |  W AH T  |  DH EY  |  W AA N T  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.03.15, Block: 7, Trial: 30\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AY  |  M UW V D  |  T UW  |  AH  |  B IH G ER  |  S IH T IY  |  L AE S T  |  Y IH R  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.03.15, Block: 7, Trial: 31\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  DH EY  |  HH AE V  |  T UW  |  S T EY  |  IH N S AY D  |  T AH D EY  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.03.15, Block: 7, Trial: 32\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  IH Z  |  DH AH  |  P R IH Z AH N  |  R IH S T IH K T AH D  |  T UW  |  S EH T AH D  |  T AE P S  |  AH V  |  K R IH M AH N AH L Z  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.03.15, Block: 7, Trial: 33\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  DH EY  |  D OW N T  |  M EY K  |  P R AA M AE N IY  |  D IH S IH ZH AH N Z  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.03.15, Block: 7, Trial: 34\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AY  |  V IH Z IH T AH T  |  AE N  |  IH G Z AE T IH NG  |  P EH T  |  SH AA P  |  AW T  |  IH N  |  K AE L AH F AO R N Y AH  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.03.15, Block: 7, Trial: 35\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  DH AE T  |  W AA Z  |  AH  |  G UH D  |  W ER K AA D  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.03.15, Block: 7, Trial: 36\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  M EY B IY  |  B AH T  |  P R AA B AH B L IY  |  N AA T  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.03.15, Block: 7, Trial: 37\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  DH AH  |  K AH M IH T IY  |  W IH L  |  D IH S AY D  |  AA N  |  W EH R  |  DH AH  |  M AH N IY  |  IH Z  |  B EH S T  |  S P EH N T  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.03.15, Block: 7, Trial: 38\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AY  |  AO L S OW  |  L AY K  |  JH AE Z  |  M Y UW Z IH K  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.03.15, Block: 7, Trial: 39\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  DH EY  |  B OW TH  |  M UW V D  |  W EY  |  AW T  |  IH N T UW  |  DH AH  |  K AH N T R IY  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.03.15, Block: 7, Trial: 40\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  IH T S  |  W AY T  |  AH  |  B IH T  |  D IH F ER AH N T  |  N AW  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.03.15, Block: 7, Trial: 41\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  M AY  |  HH EH R AH L IH NG  |  P AA R T  |  IH Z  |  P AA R T  |  AH V  |  M AY  |  HH OW M  |  D IH K AO R  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.03.15, Block: 7, Trial: 42\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  HH AE V  |  Y UW  |  EH V ER  |  HH ER D  |  AH V  |  IH T  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.03.15, Block: 7, Trial: 43\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AY  |  TH IH NG K  |  DH AE T  |  W UH D  |  B IY  |  M AO R  |  F EH R  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.03.15, Block: 7, Trial: 44\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  W IY  |  B AA T  |  S EY K AH N D  |  AH N D  |  V ER N AH S T ER  |  F AO R  |  AW ER  |  L IH V IH NG  |  R UW M  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.03.15, Block: 7, Trial: 45\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AY  |  D OW N T  |  N OW  |  W AY  |  AY  |  N EH V ER  |  R EH S IH S IH N  |  M AY  |  K AA R  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.03.15, Block: 7, Trial: 46\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AH N D  |  N AW  |  DH EY V  |  G AO N  |  AH N D  |  D AH N  |  AH  |  AO R AH B AH L  |  TH IH NG  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.03.15, Block: 7, Trial: 47\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AY  |  D OW N T  |  TH IH NG K  |  AY  |  K EY N D  |  EH N IY  |  W EH N T  |  L AE S T  |  Y IH R  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.03.15, Block: 7, Trial: 48\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AY  |  AE M  |  S AA R IY  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.03.15, Block: 7, Trial: 49\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AY  |  K AH M P L UW T AH D  |  DH AH  |  T R EY N IH NG  |  K AA S  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.03.15, Block: 9, Trial: 24\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  S OW  |  HH IY  |  AE Z  |  AO L  |  AH  |  W EY K  |  P EY S  |  DH AH  |  N EH K S T  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.03.15, Block: 9, Trial: 25\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  B IY P AH Z  |  S EY M  |  T UW  |  AH N JH OY  |  IH T  |  DH AH  |  DH AE T  |  IH Z  |  IH D  |  TH IH NG  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.03.15, Block: 9, Trial: 26\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  W IY V  |  B AE G  |  T AO K IH NG  |  AH  |  L IH T AH L  |  B IH T  |  N AW  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.03.15, Block: 9, Trial: 27\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  IH T S  |  S OW  |  F AA R  |  D AA  |  DH AH  |  R EH D  |  N AA T  |  M EY K  |  IH T  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.03.15, Block: 9, Trial: 28\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  G AA T  |  G EH T  |  K AE L  |  G UH D  |  V EH R IY  |  JH IH M  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.03.15, Block: 9, Trial: 29\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  HH UW  |  IH Z  |  DH AH  |  B EH S T  |  V EH R IY AH L AY N  |  R EY IY  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.03.15, Block: 9, Trial: 30\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  W EH N  |  W AA Z  |  K L AA L  |  D EH L AH V IH ZH AH N  |  IH V AY T AH N T  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.03.15, Block: 9, Trial: 31\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AY M  |  T AO K IH NG  |  AH B AW T  |  N AE SH ZH ER AH L  |  P IH L IH T AH L  |  K AH M EH K T S  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.03.15, Block: 9, Trial: 32\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  DH AH  |  W EY K S  |  M IY  |  Y UW S  |  R AH T  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.03.15, Block: 9, Trial: 33\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  SH IY  |  W AH T  |  R UW  |  TH R IY  |  HH AA L F IH S P ER Z  |  IH Z  |  M AH CH  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.03.15, Block: 9, Trial: 34\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  S AH M  |  AH V  |  DH EH M  |  AO R  |  F IH V AH L  |  T UW  |  Y UW  |  D R EH D IY NG  |  P R OW K ER Z S  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.03.15, Block: 9, Trial: 35\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  DH EH R  |  AA R  |  AH  |  N EH V ER  |  AH V  |  G UH D  |  M UW V IH Z  |  DH AY  |  DH AE T  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.03.15, Block: 9, Trial: 36\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  DH EY  |  SH UH D  |  JH AH S T  |  AO L  |  B IY  |  JH AH S T  |  N AY T  |  N AW  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.03.15, Block: 9, Trial: 38\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  B AH T  |  AH  |  AO L  |  T EY N  |  AO R  |  TH AH M TH  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.03.15, Block: 9, Trial: 39\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  W AH T  |  AE Z  |  DH IH S  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.03.15, Block: 9, Trial: 40\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  W IH L  |  AE K CH UW AH L IY  |  DH EY  |  M AY  |  IH B Z D AH S  |  B EH T S  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.03.15, Block: 9, Trial: 41\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  IH T  |  IH Z  |  F EY V IH NG  |  T UW  |  AE N  |  AA B V IH NG  |  K AH K L UW ZH  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.03.15, Block: 9, Trial: 42\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  IH T S  |  T UW  |  B AE K  |  DH AE T  |  HH AE P AH N  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.03.15, Block: 9, Trial: 43\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AY V  |  B IH K  |  K UH T  |  AH V  |  IH N  |  D R EH F IH  |  T W AY S  |  R EH T ER  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.03.15, Block: 9, Trial: 44\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AY V  |  N EH ER  |  S EH N S T  |  AW T  |  AH  |  Y UH R  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.03.15, Block: 9, Trial: 45\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  W IY  |  W EH R  |  W ER K S  |  IH N  |  W IY N T ER  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.03.15, Block: 9, Trial: 46\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AY  |  W EY K  |  AE T  |  DH AH  |  AH L W AW D  |  K R IH S AH Z  |  EH B AH L IY  |  HH IY R  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.03.15, Block: 9, Trial: 47\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AY  |  HH AE D  |  W AH T  |  K AE T  |  F AO R  |  AH N D IY  |  Y IH R Z  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.03.15, Block: 9, Trial: 48\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  JH AH S T  |  AH N D  |  K AH N CH ER  |  M IH Z IH K  |  AA R  |  M AY  |  F EY V ER AH T S  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.03.15, Block: 9, Trial: 49\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  SH IY  |  W AA Z  |  L IH V IH NG  |  IH N  |  AO R L AH L Z AH DH ER  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.03.17, Block: 6, Trial: 23\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  IH T  |  W AA Z  |  AH  |  D IH S IH ZH AH N  |  DH AE T  |  W UH D  |  P EY  |  AO F  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.03.17, Block: 6, Trial: 24\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  IH T  |  IH Z  |  HH AA R D  |  T UW  |  R IH M EH M B ER  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.03.17, Block: 6, Trial: 26\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AY  |  F IY L  |  S OW  |  S IH L IY  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.03.17, Block: 6, Trial: 28\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  CH EH K  |  DH AH  |  S AO V W EH R  |  V ER ZH AH N  |  B AY  |  T AY P IH NG  |  DH IH S  |  K AH M AE N D  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.03.17, Block: 6, Trial: 29\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AY  |  L AY V  |  IH N  |  AH  |  R IH L IY  |  S M AO L  |  AH P AA R T M AH N T  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.03.17, Block: 6, Trial: 30\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  M EY B IY  |  Y UW  |  L AY V  |  T UW  |  F AO R  |  AH W EY  |  F R AH M  |  Y AO R  |  F AE M AH L IY  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.03.17, Block: 6, Trial: 31\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AY  |  TH IH NG K  |  IH T  |  HH AE P AH N D  |  AH B AW T  |  T EH N  |  AO R  |  F IH F T IY N  |  Y IH R Z  |  AH G OW  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.03.17, Block: 6, Trial: 32\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AY  |  HH OW P  |  Y UW  |  EH N JH OY D  |  R EH D IH NG  |  DH IH S  |  B L AO G  |  P ER S T  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.03.17, Block: 6, Trial: 33\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  W IY  |  G OW  |  AA N  |  V EY K EY SH AH N  |  AE T  |  D IH F ER AH N T  |  P L EY S AH Z  |  EH V ER IY  |  Y IH R  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.03.17, Block: 6, Trial: 35\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AE K T ER  |  DH AE T  |  DH EY  |  W IH L  |  B IY  |  D IH S T R OY D  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.03.17, Block: 6, Trial: 36\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AY  |  L AY K  |  K L AE S IH K AH L  |  M Y UW Z IH K  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.03.17, Block: 6, Trial: 37\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  HH IY  |  IH Z  |  AH  |  TH AW AH P EH N T S  |  M AY  |  T R EY D  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.03.17, Block: 6, Trial: 38\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  L AY K  |  W EH N  |  AY  |  L AY V D  |  IH N  |  W AA SH IH NG T AH N  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.03.17, Block: 6, Trial: 39\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  DH AH  |  P L EY ER Z  |  AA R  |  P R IH T IY  |  IH N F ER K AH S T  |  AE T  |  DH IH S  |  P OY N T  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.03.17, Block: 6, Trial: 40\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AY  |  AO L W EY Z  |  G EH T  |  DH OW Z  |  S P AE M  |  F OW N  |  K AO L Z  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.03.17, Block: 6, Trial: 41\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  DH AE T  |  W AA Z  |  B IH F AO R  |  AY  |  M UW V D  |  AW T  |  HH IY R  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.03.17, Block: 6, Trial: 42\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AY  |  F ER G EH T  |  W EH R  |  SH IY  |  G AA T  |  IH T  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.03.17, Block: 6, Trial: 43\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  DH EY  |  W ER  |  IH L EH K T AH D  |  T UW  |  DH AH  |  K AH M IH T IY  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.03.17, Block: 6, Trial: 44\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AY  |  AO L S OW  |  R IH M EH M B ER  |  AH N D  |  IH L AH S T R IH T AH  |  V ER ZH AH N  |  AH V  |  DH IH S  |  S T AO R IY  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.03.17, Block: 6, Trial: 45\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  M AY  |  HH AH Z B AH N D  |  D IH D AH N T  |  L AY K  |  DH AE T  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.03.17, Block: 6, Trial: 46\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  B OW TH  |  T IY M Z  |  W AO K T  |  AH W EY  |  W IH DH  |  JH AH S T  |  W AH N  |  P OY N T  |  IY CH  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.03.17, Block: 6, Trial: 47\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  DH AH  |  T UW  |  M EY N  |  T AA R Z  |  AH V  |  DH AH  |  SH OW  |  G AA T  |  M EH R IY D  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.03.17, Block: 6, Trial: 48\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  IH T  |  W AA Z  |  AA N  |  DH AH  |  N UW Z  |  DH IH S  |  M AO R N IH NG  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.03.17, Block: 6, Trial: 49\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  HH AE Z  |  HH IY  |  EH V ER  |  B IH N  |  Y AO R  |  F EY V ER IH T  |  P L EY ER  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.03.17, Block: 7, Trial: 25\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  P AH B L IH K  |  CH IH M P AH N T EY SH AH N  |  ER AW N D  |  HH IY R  |  IH Z  |  B IH T IY  |  G UH D  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.03.17, Block: 7, Trial: 26\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  IH T  |  P EH Z AH N T  |  S IY M  |  L AY K  |  DH EY  |  AA R  |  T EH IY  |  M AH K S T  |  W IH DH  |  IH T  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.03.17, Block: 7, Trial: 27\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  DH AE T  |  N AY  |  W AA Z  |  R IH F AA R K AH B L IY  |  IH N EH P AH T AH D  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.03.17, Block: 7, Trial: 28\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AY  |  L AY K  |  T UW  |  HH AE V  |  S AH M B AA D IY  |  K AH M  |  W IH DH  |  M AH  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.03.17, Block: 7, Trial: 29\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AY D  |  L AY K  |  T UW  |  T UW  |  DH AE T  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.03.17, Block: 7, Trial: 30\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AY  |  G R UW  |  AH P  |  IH N  |  AH N L AH HH AH V AH  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.03.17, Block: 7, Trial: 31\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AY D  |  S EY  |  IH T  |  W AA Z  |  AH B AW T  |  T W EH N T IY  |  F AO R  |  IH N T AH R AH D  |  D AA L ER Z  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.03.17, Block: 7, Trial: 32\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AE V IH NG  |  P ER S IH AH B EY T ER D  |  IH N  |  JH UH R IY  |  D UW T IH NG  |  M AE S EH L F  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.03.17, Block: 7, Trial: 33\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  P EY S IH NG  |  DH AE T  |  AA T  |  T UW  |  IY CH  |  AH DH ER  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.03.17, Block: 7, Trial: 34\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  S IY M Z  |  L AY K  |  AY  |  JH AH S T  |  M AA T  |  IH T  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.03.17, Block: 7, Trial: 35\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AY  |  N OW  |  AY  |  HH AE V  |  T UW  |  D UW  |  M AY  |  ER IH B IH N S  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.03.17, Block: 7, Trial: 36\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  CH AE N S AH N  |  IH Z  |  V AW IH NG  |  T UW  |  AH P IY R L  |  DH AH  |  D AH IH S IH ZH AH N  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.03.17, Block: 7, Trial: 37\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  W AY  |  W AA Z  |  DH IH S  |  D IH S IH ZH AH N  |  M AE D  |  IH T  |  W AY  |  N AW  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.03.17, Block: 7, Trial: 38\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AE Z  |  EH N IY  |  S IH T IY  |  K W OW Z  |  IH T  |  G EH T S  |  M AO R  |  T IH CH ER AH N  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.03.17, Block: 7, Trial: 39\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  IH T  |  W AA Z  |  R IH L IY  |  P R IH T IY  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.03.17, Block: 7, Trial: 40\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  IH F  |  Y UW  |  AA R  |  G UH D  |  W IY  |  K AE N  |  G OW  |  G EH T  |  AW S  |  L AY V  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.03.17, Block: 7, Trial: 41\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  IH T  |  AH  |  T AW N  |  AH K IH S AH N T  |  T UW  |  AO L W EY Z  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.03.17, Block: 7, Trial: 42\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  EH V R IY B AA D IY  |  S IY M Z  |  T UW  |  L AY K  |  DH AE T  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.03.17, Block: 7, Trial: 43\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  B IH K AO Z  |  Y UW  |  HH ER N D  |  IH T  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.03.17, Block: 7, Trial: 44\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  W IY R  |  N AA T  |  M AY IH NG  |  EH N IY TH IH NG  |  AH N D  |  DH IH S  |  P EY N  |  IH N  |  T AY M  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.03.17, Block: 7, Trial: 45\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  DH EY  |  K UH D  |  B IY  |  SH AH S T  |  AH B AW T  |  IY K Y AH L  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.03.17, Block: 7, Trial: 46\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  DH EY  |  D IH D AH N T  |  HH AE V  |  EH N IY  |  P R AA B AH M  |  D UW IH NG  |  IH T  |  DH AH  |  W ER S T  |  T AY M  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.03.17, Block: 7, Trial: 47\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  IH T AH L  |  AH P  |  IH N  |  S AH M  |  W EH R  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.03.17, Block: 7, Trial: 48\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  DH IH S  |  V ER V IY  |  IH Z  |  R IH L IY  |  AA N  |  T EH L AH V IH ZH AH N  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.03.17, Block: 7, Trial: 49\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  EH V R IY B AA D IY  |  HH AE Z  |  DH AE T  |  S EY M  |  M AE N D  |  S AH N T  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.05.10, Block: 7, Trial: 25\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  G ER L Z  |  R EH N IH IY NG  |  S IH S T AH Z  |  L AO DH Z  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.05.10, Block: 7, Trial: 26\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  Y UW  |  P R AA B AH B L IY  |  W UH D AH N T  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.05.10, Block: 7, Trial: 27\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  IH T  |  W AA Z  |  AA N  |  DH AH  |  N UW Z  |  EH V ER IY  |  N EY T  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.05.10, Block: 7, Trial: 28\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  IH Z  |  S T AO R IY  |  IH Z  |  N AA T  |  AH K Y UW ZH AH W AH L  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.05.10, Block: 7, Trial: 29\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AH N D  |  D OW K T  |  W IH DH  |  S AH M  |  AO L IH V N Z  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.05.10, Block: 7, Trial: 30\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AY  |  HH AE D  |  F AW L D  |  AE N  |  IH N CH R IY AH  |  P OY N T  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.05.10, Block: 7, Trial: 31\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  DH EY  |  D OW N T  |  K EH L  |  DH EH M  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.05.10, Block: 7, Trial: 32\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  S OW L IH NG  |  DH AH  |  W AO T ER  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.05.10, Block: 7, Trial: 33\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  B IH Z N AH S  |  IH Z  |  R UW ZH AH W AH L  |  F AO R  |  T R EY D ER Z  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.05.10, Block: 7, Trial: 34\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  DH EY  |  G EY V  |  AH S  |  AH  |  M EH S SH AH L  |  D IY L  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.05.10, Block: 7, Trial: 35\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  DH AH  |  R IY AH L AH T IY  |  IH Z  |  IH T S  |  Y UW ZH AH W AH L IY  |  N AA T  |  DH AH  |  G K EY S  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.05.10, Block: 7, Trial: 36\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AY  |  W AO N D ER  |  W EH R  |  DH EY  |  D UW  |  DH AE T  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.05.10, Block: 7, Trial: 37\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  HH IY  |  K EH P T  |  IH Z  |  D OW N  |  L AY K T  |  AH N D  |  K AE SH AH W AH L  |  B AH T  |  F R EY M  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.05.10, Block: 7, Trial: 38\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  P EH R AH N OY T IH D  |  IH N  |  DH AH  |  P AE S T  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.05.10, Block: 7, Trial: 39\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  DH EH R  |  M UW V IY  |  T UW  |  R EH L AH T AH  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.05.10, Block: 7, Trial: 40\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AH N D  |  AY  |  AO L W EY Z  |  DH AE T  |  IH N  |  W AA Z  |  K AY N D  |  AH V  |  AW T  |  AH V  |  M EH ZH AH N  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.05.10, Block: 7, Trial: 41\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  W IY  |  D IH D  |  F AY N D  |  S IH M F AH L  |  K UH D  |  T AA K S AH Z  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.05.10, Block: 7, Trial: 42\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  W AH T  |  G R UW P  |  Y UW  |  HH AE P AH N  |  T UW  |  B IY  |  IH N  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.05.10, Block: 7, Trial: 43\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  DH EH R  |  IH Z  |  AH  |  K AH M P AH N EY SH AH N  |  AO L DH AH  |  DH AA P  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.05.10, Block: 7, Trial: 44\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  DH AE T S  |  W AH T  |  AY  |  D IH D  |  W EH N  |  AY  |  W AA Z  |  T R ER IH NG  |  AH P  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.05.10, Block: 7, Trial: 45\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AY  |  R IH L IY  |  W AO N T IH D  |  T UW  |  G OW  |  AA N  |  DH AH  |  R AE F T IH NG  |  T R AH M  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.05.10, Block: 7, Trial: 46\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  W IY  |  W EH N T  |  W IH DH  |  S AH M  |  F R EH N D Z  |  AH V  |  AW ER Z  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.05.10, Block: 7, Trial: 47\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AY  |  K AE N  |  M EY K  |  M AY  |  P AY Z  |  F R AH M  |  K R AE S  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.05.10, Block: 7, Trial: 48\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  N AA T  |  T OW T AH L  |  B AH T  |  S AH S T  |  F R AH M  |  K AA R Z  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.05.10, Block: 7, Trial: 49\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  DH AH  |  OW L D ER  |  OW L D  |  M IY T IY  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.06.14, Block: 12, Trial: 25\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AY  |  TH IH NG K  |  S UW T ER  |  AA R  |  L EY T ER  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.06.14, Block: 12, Trial: 26\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  S EH N D  |  M IY  |  S AH M  |  M AH N IY  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.06.14, Block: 12, Trial: 27\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  Y UW  |  G EH T  |  AH  |  L AA T  |  AH V  |  R EH F IH K S  |  IH N  |  DH EH R  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.06.14, Block: 12, Trial: 28\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  IH F  |  AY  |  W AA Z  |  S EY T IH NG  |  AH P  |  AH  |  D EY  |  K IH L  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.06.14, Block: 12, Trial: 29\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  HH IY  |  W AA Z  |  F AW N D  |  D EY D  |  AE F T ER  |  AE N  |  IH K S P L OW ZH AH N  |  W AA Z  |  HH ER D  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.06.14, Block: 12, Trial: 30\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  D UW  |  AH  |  Y IH R  |  L AO NG  |  P R AA JH EH N T  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.06.14, Block: 12, Trial: 31\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  W EH N  |  W UH D  |  P IY P AH L  |  T UW  |  IH T  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.06.14, Block: 12, Trial: 32\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AY M  |  N AA T  |  K W AY T  |  AE Z  |  B IH G  |  AH V  |  DH AE T  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.06.14, Block: 12, Trial: 33\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AY  |  AE V  |  N AA T  |  D AO T AH N IY  |  EH N IY  |  R IH K OY S  |  G R EH T  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.06.14, Block: 12, Trial: 34\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  B AE S AH Z  |  DH AE T  |  DH EY  |  Y UW Z  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.06.14, Block: 12, Trial: 35\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AE K CH UW AH L IY  |  DH EY  |  HH AE V  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.06.14, Block: 12, Trial: 36\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  EH N IY TH IH NG  |  R AY  |  DH AE T  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.06.14, Block: 12, Trial: 37\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  IH T  |  W AA Z  |  DH AH  |  R AY T  |  D IH S IH ZH AH N  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.06.14, Block: 12, Trial: 38\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  M OW T ER AH N T S  |  AA R  |  IH V AY S D  |  T UW  |  IH V OY D  |  DH AH  |  EH R IY AH  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.06.14, Block: 12, Trial: 39\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  CH IH K CH IH NG  |  DH AH  |  B L AA G Z  |  AH N D  |  S T AH F  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.06.14, Block: 12, Trial: 40\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  Y UW  |  HH AE V  |  DH AH  |  CH EH N S  |  T UW  |  R IH L IY  |  R IY EH N D  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.06.14, Block: 12, Trial: 41\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  B IY IH NG  |  IH N  |  IH N CH ER IH R  |  N AW  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.06.14, Block: 12, Trial: 42\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  HH IY  |  L AY K S  |  T UW  |  S IY  |  L OW Z  |  IH N  |  CH ER CH JH  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.06.14, Block: 12, Trial: 43\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AE D V AY S  |  AA N  |  S AH N  |  AO R  |  D AO T ER  |  G OW IH NG  |  T UW  |  K AA L IH JH  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.06.14, Block: 12, Trial: 44\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  Y UW  |  D OW N T  |  W UH D  |  T UW  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.06.14, Block: 12, Trial: 45\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AY M  |  IH N  |  DH AH  |  N EY V IH  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.06.14, Block: 12, Trial: 46\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  HH AE V  |  Y UW  |  HH ER D  |  DH AE T  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.06.14, Block: 12, Trial: 47\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  IH T  |  K AH N AA T  |  B IY  |  M EH ZH AH N  |  AH N D  |  Y EH T  |  IH T  |  IH G Z IH S T  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.06.14, Block: 12, Trial: 48\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AY  |  TH IH NG K  |  B IY AE N OW  |  IH Z  |  AO L W EY Z  |  G UH D  |  P OW K R AH N D  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.06.14, Block: 12, Trial: 49\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  T R AY IH NG  |  T UW  |  S T IH K  |  IH N  |  W IH DH  |  DH AE T  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.07.19, Block: 9, Trial: 26\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AH N S F AO R AH N AH T L IY  |  DH EY  |  AA R  |  N AA T  |  G UH D  |  F IH T ER Z  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.07.19, Block: 9, Trial: 27\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AY  |  TH IH NG K  |  AH  |  N AA T  |  AH  |  L AA T  |  AH V  |  P IY P AH L  |  F EH R  |  DH AE T  |  M AY  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.07.19, Block: 9, Trial: 28\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  W IY  |  JH UH N  |  HH AE V  |  AH D M AA R T IH D  |  IH T  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.07.19, Block: 9, Trial: 29\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  JH UW N  |  AO F  |  DH AH  |  T EH L AH V IH ZH AH N  |  AH N D  |  S T EY  |  AH V  |  DH AH  |  K AH M P Y UW T ER  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.07.19, Block: 9, Trial: 30\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  F IH N S  |  T W AO R D Z  |  W AH N  |  AH G EH DH ER  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.07.19, Block: 9, Trial: 31\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AH V  |  K AA R Z  |  Y UW  |  K AE N  |  B AY  |  S T AA K  |  IH N  |  DH AH  |  K AH M P AH N IY  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.07.19, Block: 9, Trial: 32\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  W AA Z  |  DH AH  |  M EY N D  |  N AA T  |  V AA SH AH M B AH L  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.07.19, Block: 9, Trial: 33\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AY  |  N IY D  |  T UW  |  M EY K  |  AH  |  F OW N  |  K AO L  |  AO R  |  T UW  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.07.19, Block: 9, Trial: 34\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AY  |  R IH L IY  |  EH N JH OY D  |  IH T  |  W AY T  |  AH  |  P EY T  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.07.19, Block: 9, Trial: 35\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  IH T  |  W IH L  |  B IY  |  AW ER  |  F ER S  |  CH EY N JH  |  T UW  |  S IY  |  IY CH  |  AH DH ER  |  IH N  |  K W AY T  |  AH W EH L  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.07.19, Block: 9, Trial: 36\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  EH K S P L AO L  |  B IH F AO R  |  Y UW  |  EH K S P L OY D T  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.07.19, Block: 9, Trial: 37\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  Y AO R  |  R EH K AH M  |  T UW  |  K AH M  |  OW V ER  |  EH N IY N AY M  |  W IH TH AW T  |  N UW T ER Z  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.07.19, Block: 9, Trial: 38\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  W AH T  |  G UH D  |  B IY  |  EH N T AH S IH NG  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.07.19, Block: 9, Trial: 39\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AY  |  TH IH NG K  |  DH AE T S  |  DH AH  |  M EY N  |  P R AA B L AH M  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.07.19, Block: 9, Trial: 40\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  W AY  |  W UH D  |  AH  |  W AH N  |  T UW  |  B AY  |  M AO R  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.07.19, Block: 9, Trial: 41\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  HH AW  |  M AH CH  |  P AH S IH ZH AH N  |  T UW  |  Y UW  |  N IY D  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.07.19, Block: 9, Trial: 42\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AY  |  HH AE V  |  N AA T  |  D AY T AH N  |  DH EH M  |  IH N  |  AH  |  L AO NG  |  T AY M  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.07.19, Block: 9, Trial: 43\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  HH IY  |  OW L D  |  IH Z  |  AE N ER S EY SH AH N T  |  JH UW IY  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.07.19, Block: 9, Trial: 44\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AY  |  P EY  |  F AO R  |  DH AH  |  AH N S T AH  |  D IH N AH L  |  IH N UW AH N S  |  P L AA S  |  V IH ZH AH N  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.07.19, Block: 9, Trial: 45\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AY  |  N OW  |  DH AE T  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.07.19, Block: 9, Trial: 46\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AY  |  R IY D  |  DH AH  |  W AY L  |  T R EY D  |  D IH T AH L  |  AH N D  |  DH AH  |  N UW  |  Y UW L  |  T AY M Z  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.07.19, Block: 9, Trial: 47\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  DH EH N  |  AY  |  W AH N T  |  AE K CH R UW  |  W IH DH  |  IH T  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.07.19, Block: 9, Trial: 48\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  W IY  |  G EH T  |  D IH S IH N EY T IH D  |  AA R  |  DH AH  |  T AY M  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.07.19, Block: 9, Trial: 49\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  D UW  |  Y UW  |  V IH L AO Z  |  W AY  |  DH AH  |  Y UW N AY T IH D  |  S T EY N S Z  |  W AA Z  |  IH N  |  DH AH  |  B IH D AH L  |  IH T S  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.07.19, Block: 10, Trial: 25\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  DH AH  |  CH IH L T R IY  |  IH Z  |  IH S P IH R IY AH S IY  |  AE N  |  EH K AH N AA M IH K  |  L OW D EY  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.07.19, Block: 10, Trial: 26\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  HH IY  |  T OW T IH T IH D  |  IH Z  |  R EH R AH L T IY Z  |  T UW  |  DH EH M  |  EH V ER IY  |  T AY M  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.07.19, Block: 10, Trial: 27\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  EH N S ER S T EY T  |  K L OW S ER Z  |  AA R  |  P R IY G EH T IH NG  |  AH  |  L AA T  |  AH V  |  T R AY V IH NG  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.07.19, Block: 10, Trial: 28\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  DH AH  |  P AH L IY S  |  G AA T  |  DH EH M  |  R AY D  |  AE N T ER D  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.07.19, Block: 10, Trial: 29\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  Y UW  |  HH AE V  |  B IH N  |  IH N V AA L V D  |  IH N  |  AE N  |  AH K AH L IH ZH AH N  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.07.19, Block: 10, Trial: 30\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  K L OW Z  |  T UW  |  S IY  |  L EH V AH L  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.07.19, Block: 10, Trial: 31\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  D OW N T  |  Y UW  |  W EY K  |  Y UW  |  AH N D  |  B IH N  |  AE P AH L  |  T UW  |  G OW  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.07.19, Block: 10, Trial: 32\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  IH T  |  T EY P S  |  Y UW  |  IH N  |  G AO N  |  K AH M P AH N IY  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.07.19, Block: 10, Trial: 33\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AY M  |  AH  |  D IH V AY ZH D  |  W AO M AH N T  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.07.19, Block: 10, Trial: 34\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  HH AW  |  M AH CH  |  M AO R  |  L AW D  |  G EH T  |  DH AH  |  G EH T  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.07.19, Block: 10, Trial: 35\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  W IY  |  AA R  |  R AY V AH L  |  F AO R  |  DH AH  |  P L EY ZH ER  |  AH V  |  S ER V IH NG  |  Y UW R  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.07.19, Block: 10, Trial: 36\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  DH EY  |  T EH N D  |  T UW  |  M EY K  |  D IH S IH ZH AH N  |  M EY K S T  |  AA N  |  DH EH R  |  M UW D  |  AE N  |  AH  |  S AA R T AH N  |  T AY M  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.07.19, Block: 10, Trial: 37\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  Y UW  |  AO L  |  G AA T  |  AH  |  P EY  |  W EY Z  |  DH IH S  |  Y IH R  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.07.19, Block: 10, Trial: 38\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  TH IH NG K  |  AH B AW T  |  DH IH S  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.07.19, Block: 10, Trial: 39\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  HH IY  |  P L AE B IH SH T  |  AH  |  P EY P ER  |  AH N  |  DH AH  |  S AA B JH R AH D  |  L AE S T  |  Y IH R  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.07.19, Block: 10, Trial: 40\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  DH AH  |  S AH P R IY M  |  K AO R T  |  W EH R  |  B IH  |  AH  |  D IH S IH ZH AH N  |  D AH D EY  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.07.19, Block: 10, Trial: 41\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AH N D  |  AO L  |  AH V  |  AH  |  S IH T IH D  |  DH EY  |  W ER  |  K G AA R D  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.07.19, Block: 10, Trial: 42\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  DH IH S  |  IH Z  |  DH EH R  |  Y IH R L IY  |  K AH M ER S EY SH AH N  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.07.19, Block: 10, Trial: 43\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  TH AH DH ER N  |  T EH L AH V F AO R JH AH  |  AH N D  |  S T IH L  |  P R IH T IY  |  L AA R JH  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.07.19, Block: 10, Trial: 44\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AY  |  W AA Z  |  IH N  |  AH  |  S IH M AH L AH IY  |  S IH N CH UW M EY SH AH N  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.07.19, Block: 10, Trial: 45\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  DH IH S  |  IH Z  |  DH AH  |  P OY N T  |  W EH R  |  Y UW  |  W AA N T  |  T UW  |  T EY S T  |  IH T  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.07.19, Block: 10, Trial: 46\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  L AE S T  |  IH  |  S AE T ER D T IY  |  W IY  |  AO L  |  W EY T  |  AW T  |  T UW  |  D IH T ER  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.07.19, Block: 10, Trial: 47\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AY  |  W AA Z  |  V EH R IY  |  OW P F AH L  |  EH N IY W EY  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.07.19, Block: 10, Trial: 48\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AY  |  G EH S  |  M AY  |  K AH N S AH N D  |  IH Z  |  AH B AW T  |  DH AH  |  AO R D AH IH NG  |  DH AE T  |  W IY  |  AA R  |  R IH D IH NG  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.07.19, Block: 10, Trial: 49\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  M AY  |  K AH M P Y UW T ER  |  HH AE Z  |  G UH D  |  S T AO R IH JH S IH NG  |  K AH M EY JH IH T IY  |  AH N D  |  IH T  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.07.21, Block: 6, Trial: 24\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AY  |  HH AE V AH N T  |  B IH N  |  B AE K  |  HH OW M  |  IH N  |  F AY V  |  Y IH R Z  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.07.21, Block: 6, Trial: 25\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  W IY V  |  G AA T  |  T UW  |  L IH V IH NG  |  R UW M Z  |  IH N  |  AW ER  |  N UW  |  HH AW S  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.07.21, Block: 6, Trial: 26\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  Y UW  |  W UH D  |  TH IH NG K  |  S OW  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.07.21, Block: 6, Trial: 27\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AY  |  D OW N T  |  W AA N T  |  T UW  |  M AE S  |  EH N IY TH IH NG  |  AH P  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.07.21, Block: 6, Trial: 28\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  B AH T  |  DH AE T S  |  DH AH  |  P OY N T  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.07.21, Block: 6, Trial: 29\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  DH AE T  |  IH Z  |  AH  |  G UH D  |  AH AY D IY AH  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.07.21, Block: 6, Trial: 30\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AY  |  D OW N T  |  F IY L  |  V EH R IY  |  G UH D  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.07.21, Block: 6, Trial: 31\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AY  |  HH AE V  |  AO L R EH D IY  |  P R AA S T AH S T  |  S AH M  |  AH V  |  DH EH M  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.07.21, Block: 6, Trial: 32\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AY  |  V AE L Y IY  |  HH ER  |  AH P IH N Y AH N  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.07.21, Block: 6, Trial: 33\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  T IY K S  |  HH ER  |  T UW  |  R AY T  |  HH ER  |  N EY M  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.07.21, Block: 6, Trial: 34\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  S IY  |  IH F  |  DH EH R  |  IH Z  |  S AH M W AH N  |  AE T  |  DH AH  |  D AO R  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.07.21, Block: 6, Trial: 37\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  IH T S  |  G UH D  |  P R AA P ER EY SH AH N  |  F AO R  |  K AA L IH JH  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.07.21, Block: 6, Trial: 39\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AY  |  L AH V  |  DH IH S  |  T IY M  |  AH N D  |  DH AH  |  N UW  |  K AH CH  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.07.21, Block: 6, Trial: 40\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  DH AH  |  AO R IH K AH N T  |  W IH L  |  IH T  |  S IH N T AH L  |  AH N D  |  S AW TH  |  AH M EH R IH K AH  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.07.21, Block: 6, Trial: 41\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  DH AE T  |  IH Z  |  R AY T  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.07.21, Block: 6, Trial: 42\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  DH EH R  |  IH Z  |  K W AY T  |  AH  |  B IH T  |  AH V  |  K R AY M  |  IH N  |  DH AE T  |  N EH B ER AO D T  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.07.21, Block: 6, Trial: 43\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AY  |  D IH D AH N T  |  M AY N D  |  D UW IH NG  |  DH AE T  |  AE T  |  AO L  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.07.21, Block: 6, Trial: 44\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  D IH D  |  Y UW  |  G EH T  |  T UW  |  T AO K  |  T UW  |  HH IH M  |  B IH F AO R  |  HH IY  |  L EH F T  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.07.21, Block: 6, Trial: 45\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  B IH K AO Z  |  DH EH R  |  D EH N D  |  W AA Z  |  AE T  |  W ER K  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.07.21, Block: 6, Trial: 46\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  DH AH  |  S UW N AE L AH T IY K S  |  AA R  |  ER R EH D IY  |  P EY D  |  F AO R  |  DH IH S  |  B OW TH  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.07.21, Block: 6, Trial: 47\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  W IY  |  Y UW ZH AH W AH L IY  |  D IH S AH S  |  B IH Z N AH S  |  OW V ER  |  L AH N CH  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.07.21, Block: 6, Trial: 48\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  HH IY  |  D AH Z AH N T  |  R IH L IY  |  P EY  |  AH T EH N SH AH N  |  IH N  |  K L AE S  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.07.21, Block: 6, Trial: 49\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  IH T S  |  W EH L  |  W ER TH  |  IH T  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.07.21, Block: 7, Trial: 24\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  W AH T  |  K AY N D  |  AH V  |  W ER K  |  D UW  |  Y UW  |  D UW  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.07.21, Block: 7, Trial: 25\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  W IY  |  W ER N T  |  SH UH R  |  HH AW  |  T UW  |  D UW  |  DH AE T  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.07.21, Block: 7, Trial: 26\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  DH EY  |  HH AE V  |  DH IY Z  |  F AH N  |  L IH T AH L  |  P AA R T IH Z S  |  AE T  |  N AY T  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.07.21, Block: 7, Trial: 27\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  DH EY  |  HH AE V  |  N AA T  |  B IH N  |  M EY D  |  AH W EH R  |  AH V  |  DH IH S  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.07.21, Block: 7, Trial: 28\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AE T  |  DH AE T  |  P OY N T  |  SH IY  |  W AA Z  |  AO L R EH D IY  |  G AO N  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.07.21, Block: 7, Trial: 29\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AY  |  D OW N T  |  W AA N T  |  T UW  |  P EY  |  HH ER  |  T UW  |  B IY  |  AH  |  P EY B IY  |  S IH T ER  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.07.21, Block: 7, Trial: 30\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  W EH N  |  D IH D  |  DH EY  |  M EY K  |  DH AE T  |  B UH K  |  IH N T UW  |  AH  |  M UW V IY  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.07.21, Block: 7, Trial: 32\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AY V  |  S IY N  |  AO L  |  AH V  |  DH IH S  |  B IH F AO R  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.07.21, Block: 7, Trial: 34\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  W IY  |  HH AE D  |  AH N D  |  HH AE P R IY NG  |  AH V  |  DH AH  |  F L UW  |  L AE S T  |  B OW TH  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.07.21, Block: 7, Trial: 35\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AO L W EY Z  |  AH  |  P L EH ZH ER  |  T UW  |  S IY  |  AH N D  |  T AO K  |  T UW  |  DH EH M  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.07.21, Block: 7, Trial: 36\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  DH EH R Z  |  AH  |  P AA N T  |  AH V  |  M IY  |  DH AE T  |  M IH S AH Z  |  DH EH M  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.07.21, Block: 7, Trial: 37\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  D UW  |  W IY  |  HH AE V  |  T UW  |  W EY T  |  AH N T IH L  |  EH V R IY W AH N  |  IH Z  |  W AO T IY  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.07.21, Block: 7, Trial: 38\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  DH EY  |  V IH Z IH T AH N T  |  DH EH R  |  R IH N M AH DH ER  |  AE T  |  DH AH  |  N ER S IH NG  |  HH OW M  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.07.21, Block: 7, Trial: 39\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  IH T S  |  G AA T  |  P IY P AH L  |  S ER M IH NG  |  F AO R  |  JH OY  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.07.21, Block: 7, Trial: 40\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  N AA T  |  EH V R IY B AA D IY  |  HH AE Z  |  AH  |  P IH CH ER  |  P ER F AH N T  |  B AA R IY  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.07.21, Block: 7, Trial: 41\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  Y UW  |  W IH L  |  B IY  |  L ER N IH NG  |  L AA T S  |  AH V  |  N UW  |  S T AH F  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.07.21, Block: 7, Trial: 42\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  DH AH  |  P IY P AH L  |  AA R  |  R IH L IY  |  N AY S  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.07.21, Block: 7, Trial: 43\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  EH V R IY B AA D IY  |  JH AH S T  |  L AH V Z  |  IH T  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.07.21, Block: 7, Trial: 44\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  Y UW  |  M AY T  |  B IY  |  L AY K  |  M IY  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.07.21, Block: 7, Trial: 45\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AY  |  G EH S  |  IH T  |  W AA Z  |  L AE S T  |  Y IH R  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.07.21, Block: 7, Trial: 46\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  IH T  |  JH AH S T  |  HH AE P AH N D  |  W IH DH IH N  |  DH AH  |  L AE S T  |  TH R IY  |  W IY K S  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.07.21, Block: 7, Trial: 47\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  IH T  |  W AA Z AH N T  |  R IH L IY  |  DH AE T  |  IH M P AO R T AH N T  |  T UW  |  M IY  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.07.21, Block: 7, Trial: 48\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AY  |  D OW N T  |  N OW  |  AH V  |  EH N IY  |  AH DH ER  |  S T EY T  |  W IH DH  |  DH IH S  |  P AA L AH S IY  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.07.21, Block: 7, Trial: 49\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AY  |  K UH D  |  HH IY R  |  DH AH  |  T EH R ER  |  IH N  |  IH Z  |  V OY S  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.07.28, Block: 6, Trial: 24\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AH N D  |  AY  |  AO L W EY Z  |  TH AO T  |  IH T  |  W AA Z  |  K AY N D  |  AH V  |  AW T  |  AH V  |  F EH AE SH AH N  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.07.28, Block: 6, Trial: 25\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  W IY  |  D IH D  |  F AY N D  |  S AE M AH L  |  G UH D  |  D AA K T ER Z  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.07.28, Block: 6, Trial: 26\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  IH T  |  D IH P EH N D Z  |  W AH T  |  G R UW P  |  Y UW  |  HH AE P AH N  |  T UW  |  B IY  |  IH N  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.07.28, Block: 6, Trial: 28\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  DH AE T S  |  W AH T  |  AY  |  D IH D  |  F AO R  |  M AH N IY  |  W EH N  |  AY  |  W AA Z  |  G R OW IH NG  |  AH P  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.07.28, Block: 6, Trial: 29\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AY  |  R IH L IY  |  W AO N T IH D  |  T UW  |  G OW  |  AA N  |  DH AH  |  W AY F IH K NG  |  T R IH M P  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.07.28, Block: 6, Trial: 30\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  W IY  |  W EH N T  |  W IH DH  |  S AH M  |  F R EH N D Z  |  AH V  |  AW ER Z  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.07.28, Block: 6, Trial: 31\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AY  |  K AE N  |  M EY K  |  M AY  |  P AY L Z  |  F R AH M  |  S K R EH S  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.07.28, Block: 6, Trial: 32\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  DH AH  |  OW L D ER  |  OW L D  |  P IY P AH L  |  AA R  |  S OW  |  OW L D  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.07.28, Block: 6, Trial: 33\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  Y UW  |  OW N L IY  |  N IY D  |  T UW  |  D UW  |  IH T  |  W AH N S  |  F AO R  |  AH  |  T OW T AH L  |  B IH N  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.07.28, Block: 6, Trial: 34\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  B AH T  |  AE T  |  W ER T  |  P OY N T  |  D IH D  |  DH AH  |  F IY R  |  R IH L IY  |  S EH T  |  IH N  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.07.28, Block: 6, Trial: 35\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AY  |  HH AE V  |  B IH N  |  IH N  |  P ER Z AH N  |  AO L  |  M AY  |  L AY F  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.07.28, Block: 6, Trial: 36\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  DH EY V  |  G AA T  |  AH  |  G UH D  |  TH IH NG  |  G OW IH NG  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.07.28, Block: 6, Trial: 37\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  DH AH  |  W EY  |  Y UW  |  HH AE N D AH L  |  Y ER S EH L F  |  IH Z  |  IH M S P EH N S IH V  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.07.28, Block: 6, Trial: 38\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  M AY  |  W AY F  |  W UH D  |  JH AH S T  |  L AH V  |  DH AE T  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.07.28, Block: 6, Trial: 39\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AW ER  |  V AE L Y ER Z  |  AH V  |  D IH V ER S AH T IY  |  AH N D  |  IH N K L UW SH AH N  |  AA R  |  D R AH G  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.07.28, Block: 6, Trial: 40\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  IH F  |  Y UW  |  P L EY  |  R EH G Y AH L ER  |  D IH F AH K AH N T IY  |  IH T  |  IH Z  |  N AA T  |  S OW  |  B AE D  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.07.28, Block: 6, Trial: 41\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  W EH R  |  L IH V IH NG  |  IH N  |  AH  |  R EH L AH N T AH L F L IY  |  N UW  |  EH R IY AH  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.07.28, Block: 6, Trial: 42\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  D AW N  |  DH EH R  |  AA N  |  DH AH  |  F IH F S IH NG  |  W AY F  |  B AY  |  DH AH  |  P IH L Z  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.07.28, Block: 6, Trial: 43\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  W EH L  |  AY L  |  B IY  |  W IH DH  |  AH DH ER  |  P IY P AH L  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.07.28, Block: 6, Trial: 44\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AY  |  G EH S  |  W IY  |  D UW  |  G EH T  |  IH T  |  F R AH M  |  P IY P AH L  |  T UW  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.07.28, Block: 6, Trial: 45\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  M EY B IY  |  W IY  |  SH UH D  |  M UW V  |  T UW  |  DH AH  |  S AW TH  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.07.28, Block: 6, Trial: 46\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  HH AW  |  M EH N IY  |  AH V  |  DH IY Z  |  K OY N Z  |  W IH L  |  W IY  |  N IY D  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.07.28, Block: 6, Trial: 47\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  IH F  |  Y UW  |  D R IH NG K  |  AH  |  L AA T  |  AH V  |  K AE N F IH N  |  Y UW L  |  S T EY  |  AH W EY  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.07.28, Block: 6, Trial: 48\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  SH OW IH NG  |  D IH T AH  |  IH Z  |  AE N  |  EH K S AH L AH N T  |  W EY  |  T UW  |  P R UW V  |  AH  |  P OY N T  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.07.28, Block: 6, Trial: 49\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  IH T  |  W AA Z  |  AH  |  K AH R D L AH N S  |  F OW N  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.07.28, Block: 7, Trial: 24\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AY  |  D UW  |  N AA T  |  CH AA R JH  |  IH K S EH P T  |  F AO R  |  AH M ER JH AH N IY Z  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.07.28, Block: 7, Trial: 25\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AY L  |  B IY  |  DH EH R  |  IH N  |  DH AH  |  AE F T ER N UW N  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.07.28, Block: 7, Trial: 26\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  DH AE T S  |  G OW  |  V IH Z IH T  |  F AO R  |  L AY K  |  AH  |  SH AO R T  |  W IY K EH N D  |  AO R  |  S AH M TH IH NG  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.07.28, Block: 7, Trial: 27\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AY  |  TH IH NG K  |  DH AE T S  |  DH AH  |  W EY  |  DH IH S  |  IH Z  |  D AH N  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.07.28, Block: 7, Trial: 28\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AH  |  P UH T  |  AH V  |  DH AH  |  S EH K S T AH M  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.07.28, Block: 7, Trial: 29\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  EH V R IY W AH N  |  N OW Z  |  HH AW  |  T UW  |  M EY K  |  AH  |  T UW N AH  |  F IH SH  |  S AW M P L IH N JH  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.07.28, Block: 7, Trial: 30\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AY  |  G EH T  |  R IH M EH M B ER  |  DH AH  |  G AY L Z  |  N EY M  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.07.28, Block: 7, Trial: 31\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  W AH T  |  D UW  |  Y UW  |  TH IH NG K  |  AH B AW T  |  DH IH S  |  R IY S ER CH  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.07.28, Block: 7, Trial: 32\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  W IY  |  L AH V  |  IY T IY  |  F R EH SH  |  V EH JH T AH B AH L Z  |  IH N  |  DH AH  |  S AH M ER  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.07.28, Block: 7, Trial: 33\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  Y UW  |  K AE N  |  S IY  |  W AH T  |  AY  |  M IY N  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.07.28, Block: 7, Trial: 34\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AY  |  AE M  |  AH N D  |  EY ZH AH N  |  W IH M AH N  |  W IH DH  |  AH  |  W AY T  |  B OY F R EH N T  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.07.28, Block: 7, Trial: 36\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  W IY  |  F EH L T  |  G OW N T IY  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.07.28, Block: 7, Trial: 37\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AY  |  R IH L IY  |  L AY K  |  IH T  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.07.28, Block: 7, Trial: 38\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  Y UW  |  K AE N  |  S IH T  |  IH N  |  DH AH  |  S AH N  |  AO L  |  D EY  |  ER AW N D  |  DH AH  |  P OY L  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.07.28, Block: 7, Trial: 39\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AY  |  R IH L IY  |  D OW N T  |  W AA N T  |  T UW  |  S IY  |  DH EH M  |  G OW  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.07.28, Block: 7, Trial: 40\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  DH AH  |  AO L  |  W AH T  |  AH  |  R IH W AO R D  |  AO R  |  W AH T EH V ER  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.07.28, Block: 7, Trial: 41\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AY V  |  K W IH T  |  D UW IH NG  |  DH AE T  |  B AH S EH L F  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.07.28, Block: 7, Trial: 42\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  DH AH  |  R EH S T ER AY T  |  M AH S T  |  B AE G Z  |  DH AH  |  IH K S P EH K SH AH N  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.07.28, Block: 7, Trial: 43\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  W EH R  |  D UW  |  Y UW  |  G OW  |  K AE M P IH NG  |  AE T  |  ER AW N D  |  HH IY R  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.07.28, Block: 7, Trial: 44\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AY  |  T R AY  |  T UW  |  S EY V  |  DH AE T  |  F AO R  |  DH AH  |  W IY K EH N D  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.07.28, Block: 7, Trial: 45\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  W EH N  |  D AH Z  |  S K UW L  |  S P AA R T  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.07.28, Block: 7, Trial: 47\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  DH AE T S  |  JH AH S T  |  DH AH  |  W EY  |  IH T  |  W AA Z  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.07.28, Block: 7, Trial: 48\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  V AE K S T AH B AH L Z  |  G R OW  |  IH N  |  DH AH  |  F IY N D Z  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2024.07.28, Block: 7, Trial: 49\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AY  |  HH AE D  |  EH N D AH D  |  AH P  |  IH T  |  AH  |  V EH R IY  |  T AH M P L IY  |  L UH T  |  EH R IY AH  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2025.01.10, Block: 8, Trial: 25\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  N AW T  |  G EH T  |  M AY  |  R AE D AH  |  AH  |  DH OW Z  |  B EY B ER  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2025.01.10, Block: 8, Trial: 26\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  SH IY  |  W AH D AH N D  |  DH EH M  |  T UW  |  K AO R L D  |  T UW  |  G EH T  |  W AH N  |  F AO R  |  HH ER  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2025.01.10, Block: 8, Trial: 27\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  DH EH N  |  AY  |  TH IH NG K  |  Y UW  |  HH AE V  |  AH  |  M AO R  |  IH P AE D AH B AH L  |  AH P R EH OW S  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2025.01.10, Block: 8, Trial: 28\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AY  |  JH AH S T  |  D OW N T  |  L AY K  |  DH AE T  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2025.01.10, Block: 8, Trial: 29\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  IH T  |  Y UW  |  S IY  |  IH T  |  P R AY IH NG  |  DH AE R Z  |  AH  |  P R EH B L AH M  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2025.01.10, Block: 8, Trial: 31\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  W AH T S  |  DH AH  |  W AH N T  |  AH V  |  DH AH T  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2025.01.10, Block: 8, Trial: 32\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AY  |  W AA Z AH N T  |  IY V IH N  |  K AH IH JH D  |  F AO R  |  IH N  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2025.01.10, Block: 8, Trial: 33\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AH N JH AH N Z  |  AH V  |  AA R T ER  |  AO R  |  P AE L ER Z  |  P AA S IH NG  |  TH R UW  |  DH AH  |  K AH N T AW L  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2025.01.10, Block: 8, Trial: 34\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AY  |  N OW  |  W EH N  |  AH  |  W AA Z  |  W ER K IH NG  |  TH IH NG Z  |  W AH  |  D EH F ER AH  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2025.01.10, Block: 8, Trial: 35\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  JH OY S T  |  TH IH NG Z  |  AH P  |  AH  |  L IH T AH L  |  B AH T  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2025.01.10, Block: 8, Trial: 36\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  IH F  |  AH  |  M OW V ER  |  IH Z  |  P R AA B Y AH L IY  |  IH T  |  N IY Z  |  IH N  |  DH EH R AH N AH Z  |  R IH G ER  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2025.01.10, Block: 8, Trial: 37\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AY  |  D OW N T  |  N OW  |  IH F  |  Y IY L  |  EH V ER  |  S IY  |  AE M  |  AH G EH N  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2025.01.10, Block: 8, Trial: 38\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  IH F  |  AY  |  L AY V D  |  IH N  |  N UW  |  Y UW  |  S IH T IY  |  AA R  |  W AA EH CH AH N AH N  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2025.01.10, Block: 8, Trial: 39\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  D UW  |  Y UW  |  W AA N T  |  T UW  |  HH OW M  |  OW V ER  |  AE F T ER  |  S K Y UW R  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2025.01.10, Block: 8, Trial: 40\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  DH EH R Z  |  R AO IH NG  |  T R AY AW L Z  |  AH N D  |  B OW TH  |  S EH S D  |  AH V  |  DH AH  |  R IH V ER  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2025.01.10, Block: 8, Trial: 41\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  IH T  |  S EY M Z  |  AH  |  P IY P AH L  |  JH AH S T  |  G OW  |  IH N  |  S OW K ER L Z  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2025.01.10, Block: 8, Trial: 42\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  S EY  |  W AH T  |  W IY  |  K AE N  |  T AH M  |  AH T  |  W EH DH  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2025.01.10, Block: 8, Trial: 43\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  K AH M P Y UW L AH ER AH S T  |  D AH S IH N Z  |  AA R  |  V EH R IY  |  K AH N P L AH T IH T AH D  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2025.01.10, Block: 8, Trial: 44\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  W EH R  |  AO L W EY Z  |  B IY  |  T AE K S AH Z  |  M AO R  |  S AH M TH IH NG  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2025.01.10, Block: 8, Trial: 45\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AY  |  TH IH NG K  |  IH Z  |  S AH B  |  K IH Z AH Z  |  N AE T  |  IH Z  |  G ER AY K T  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2025.01.10, Block: 8, Trial: 46\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  DH EY  |  W IH L  |  HH OW M  |  DH AH  |  K AH N T R IY  |  R ER AY M IH NG  |  IH N V EH N T UW AH L IY  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2025.01.10, Block: 8, Trial: 47\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  IH T  |  S AH D AH N  |  B IY  |  DH AE T  |  W EY  |  AY  |  OW N D  |  TH IH NG K  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2025.01.10, Block: 8, Trial: 48\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  HH IY  |  K AA T  |  AH V  |  AE Z  |  F AO L  |  S IH N P UH  |  AH N  |  DH AH  |  P L EY S  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2025.01.10, Block: 8, Trial: 49\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  IH T  |  IH Z  |  AO L  |  AH B AW T  |  EH V IY  |  K AA N T EY SH AH N Z  |  AH N D  |  M EH N IY  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2025.01.12, Block: 6, Trial: 25\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  IH T S  |  P AA T  |  AH V  |  DH AH  |  OW N K W EY ZH AH N  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2025.01.12, Block: 6, Trial: 26\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  DH EH R Z  |  AH N AH DH ER  |  HH AE S P AE N T  |  AH V  |  DH IH S  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2025.01.12, Block: 6, Trial: 28\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  HH IY  |  ER N D  |  AH  |  F UH L  |  V AA L AH JH AH P  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2025.01.12, Block: 6, Trial: 29\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  W IY  |  D AH Z  |  G UH D AH N T  |  S T AE N D  |  IH T  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2025.01.12, Block: 6, Trial: 30\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  DH AH  |  S T AO R IY  |  W AA Z  |  AH  |  V EH R IY  |  D IH P AO R T IH K  |  S T AO R IY  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2025.01.12, Block: 6, Trial: 31\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AH  |  P IH K Y IH K Y AH L ER  |  K AY N D  |  AH V  |  SH UW  |  F AO R  |  HH AE K IH NG  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2025.01.12, Block: 6, Trial: 32\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  D UW  |  Y UW  |  W AA N T  |  T UW  |  M AY  |  S AH M TH IH NG  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2025.01.12, Block: 6, Trial: 33\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  W AH T  |  W UH D  |  Y UW  |  D UW  |  AH B AW T  |  IH T  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2025.01.12, Block: 6, Trial: 34\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  DH IH S  |  IH Z  |  JH AH S T  |  AH  |  D AA R T IY  |  P OY N T  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2025.01.12, Block: 6, Trial: 35\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  W EH N  |  D UW  |  Y UW  |  W AA N T  |  DH AH  |  P EY M AH S IH T ER  |  T UW  |  K EY M  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2025.01.12, Block: 6, Trial: 36\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AY  |  D OW N T  |  N OW  |  W AH T  |  Y AO R  |  M AH T IY  |  P ER S IH D IH K  |  IH Z  |  AA N  |  Y AO R  |  F OW N  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2025.01.12, Block: 6, Trial: 37\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  DH EY  |  D OW N T  |  N IH T IY S  |  EH N IY  |  T AY M  |  D IH F ER AH S  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2025.01.12, Block: 6, Trial: 38\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  IH T  |  W AA Z  |  AH  |  B EH N AH S W IY T  |  JH OY R  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2025.01.12, Block: 6, Trial: 39\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AY  |  TH IH NG K  |  IH T S  |  N EH V ER AH N AH T L IY  |  G AA T AH N  |  B EH T ER  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2025.01.12, Block: 6, Trial: 40\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  DH EY  |  D UW  |  N AA T  |  P R EH V IY Z  |  EH N IY TH IH NG  |  S P AH S IH SH AH L  |  DH IY Z  |  D EY Z  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2025.01.12, Block: 6, Trial: 41\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AY  |  D OW N T  |  HH AE V  |  AH  |  P R AA B L AH M  |  AE T  |  AO L  |  W IH DH  |  EH M P L OY AH Z  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2025.01.12, Block: 6, Trial: 42\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  T EY K  |  AH  |  SH AW AH  |  AH N D  |  G EH T  |  D R EH S T  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2025.01.12, Block: 6, Trial: 43\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  B OW TH  |  AH V  |  M AY  |  K AE T S  |  AO R  |  D IH N K L AO D  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2025.01.12, Block: 6, Trial: 44\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AY  |  JH AH S T  |  L EH T  |  AW T  |  D IH D AH S T  |  S P AY D  |  EH N IY  |  M AH N IY  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2025.01.12, Block: 6, Trial: 45\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  DH EH R  |  K UH D  |  B IY  |  AH  |  L AA T  |  AH V  |  AA P SH AH Z  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2025.01.12, Block: 6, Trial: 46\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AH DH ER  |  DH AE T  |  DH AE T  |  DH EY  |  HH AE V  |  DH AH  |  Y UW ZH AH W AH L  |  S T AH F  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2025.01.12, Block: 6, Trial: 47\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  IH T  |  IH Z  |  R IH L IY  |  S T EH R IY  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2025.01.12, Block: 6, Trial: 48\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  DH EH R Z  |  AE T  |  L IY S T  |  W AH N  |  K AE T  |  IH N  |  DH AH  |  HH AW S  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2025.01.12, Block: 6, Trial: 49\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AY M  |  N AA T  |  SH UH R  |  HH AW  |  DH EH R  |  G OW IH NG  |  T UW  |  F IY L  |  AH B AW T  |  IH T  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2025.01.12, Block: 7, Trial: 26\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  SH IY  |  D IH D  |  V EH R IY  |  W IY L  |  DH EH R  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2025.01.12, Block: 7, Trial: 27\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  SH IY  |  D IH D AH N T  |  L AY V  |  W IH DH  |  AH S  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2025.01.12, Block: 7, Trial: 28\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  DH AE T S  |  R IH L IY  |  W IH N D  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2025.01.12, Block: 7, Trial: 29\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  IH T S  |  AH  |  P L EH ZH ER  |  T UW  |  M EY K  |  Y AO R  |  AH K EY N T IY Z  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2025.01.12, Block: 7, Trial: 30\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  HH OW P  |  Y UW  |  HH AE V  |  EH N JH OY D  |  DH IH S  |  D IH N AO R IY AH L  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2025.01.12, Block: 7, Trial: 31\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  DH AH  |  JH UH R IY  |  S T EH K T AH M  |  IH N S OW L  |  IH Z  |  N AA T  |  P IH P F IH K T  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2025.01.12, Block: 7, Trial: 32\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  M AY  |  P EH R AH N T S  |  AO L W EY Z  |  S EH D  |  IH F  |  W IY  |  W AO N T IH D  |  AH  |  K AA R  |  W IY  |  AE T  |  T UW  |  D EY  |  F AO R  |  IH T  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2025.01.12, Block: 7, Trial: 33\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  W IY  |  P EH N T AH N  |  DH OW Z  |  AE T  |  B AY  |  DH AH  |  S AH M T IH NG  |  T EY K  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2025.01.12, Block: 7, Trial: 34\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  IH T  |  HH AE P AH N Z  |  EH V ER IY  |  S IH NG G AH L  |  M AH N TH  |  W IH TH AW T  |  F IY L  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2025.01.12, Block: 7, Trial: 35\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AE N AH M L AH S  |  AE D  |  S AH M B AW L  |  G AA N T AH N  |  IH N T UW  |  DH AH  |  D R AE SH  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2025.01.12, Block: 7, Trial: 36\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AY V  |  D AH N  |  S AH M  |  AH DH ER  |  TH IH NG Z  |  T UW  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2025.01.12, Block: 7, Trial: 37\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  K AY N D  |  AH V  |  AH  |  P IH K T IH K  |  IH N  |  DH AH  |  W ER N S  |  T AY  |  TH IH NG  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2025.01.12, Block: 7, Trial: 38\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AE K CH UW AH L IY  |  DH IH S  |  F AO L  |  AY  |  AE M  |  G OW IH NG  |  B AE K  |  T UW  |  S K UW L  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2025.01.12, Block: 7, Trial: 39\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AW ER  |  IH N V AH S T R EY SH AH N  |  IH Z T ER IY  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2025.01.12, Block: 7, Trial: 40\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  W IY  |  Y UW Z D  |  T UW  |  AO L W EY Z  |  EH N JH OY  |  W AA N T IH NG  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2025.01.12, Block: 7, Trial: 41\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  Y UW  |  G OW  |  AW T S T AY D  |  AH N D  |  P L EY  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2025.01.12, Block: 7, Trial: 42\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  Y UW D  |  TH IH NG  |  DH AE T  |  IH T  |  W AA Z  |  AH  |  P R AY V AH N T  |  S K UW L  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2025.01.12, Block: 7, Trial: 43\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AY  |  N OW  |  T UW  |  W IH M AH N  |  HH UW  |  W EH N T  |  DH EH R  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2025.01.12, Block: 7, Trial: 44\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  DH EY V  |  D AO R T IH D  |  AH  |  JH R IH G  |  D EH S IH NG  |  P AA L AH S IY  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2025.01.12, Block: 7, Trial: 45\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AY  |  TH IH NG K  |  N EH R Z  |  AH B AW T  |  S EH V AH N T IY  |  AH V  |  DH EH M  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2025.01.12, Block: 7, Trial: 46\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  IH F  |  Y AO R  |  S AH V IH NG  |  AH N AH DH ER  |  T IY K  |  W IH DH  |  IH T  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2025.01.12, Block: 7, Trial: 47\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AY V  |  HH ER D  |  D EH F ER AH N T  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2025.01.12, Block: 7, Trial: 48\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  HH IY  |  D OW N T  |  IH N S EH L F  |  DH EH R  |  S K UW L  |  P R EY S IH K L IY  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2025.03.14, Block: 4, Trial: 12\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  DH EH N  |  AY  |  HH ER  |  AH  |  V EH R IY  |  N AA T  |  IH N S P L OW ZH AH N  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2025.03.14, Block: 4, Trial: 13\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  M AY  |  D AE S  |  IH Z  |  AH  |  P IH T EY T AH  |  F EY V ER IY  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2025.03.14, Block: 4, Trial: 14\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  DH IH S  |  AH  |  G UH N  |  AE F SH AH IH NG  |  T UW  |  K AH N D AH D T IY  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2025.03.14, Block: 4, Trial: 15\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  D UW  |  Y UW  |  W AA T  |  T UW  |  IH T  |  EH N S AY D  |  AO R  |  AO L S AY D  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2025.03.14, Block: 4, Trial: 16\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:   |  S OW  |  W IY  |  K AH L W AH L IY  |  S T EY T  |  IH N S ER T  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2025.03.14, Block: 4, Trial: 17\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  B IH S P W EY Z AH Z  |  R AH M  |  AH DH ER  |  T EH N AH V EH S AH T IY  |  W IH L  |  B IH S EH T  |  DH EH R  |  R IH S IH Z  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2025.03.14, Block: 4, Trial: 18\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  DH EY  |  AA  |  N IY L  |  S P R AA R T IH D  |  T UW  |  M AH N TH  |  DH EH M  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2025.03.14, Block: 4, Trial: 19\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AY  |  AY  |  G OW Z  |  Y EH R  |  AH  |  F Y UW TH  |  DH IH S  |  AH B AW N D  |  S T EH L  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2025.03.14, Block: 4, Trial: 20\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  DH AH  |  AA R  |  S OW  |  F AO L  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2025.03.14, Block: 4, Trial: 21\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  IH T  |  IH Z  |  AH  |  R IH L IY  |  P L AE Z  |  L AH P AH L  |  AE T K S  |  K AA L IH JH Z  |  AH V  |  W IH L  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2025.03.14, Block: 4, Trial: 22\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AE V IY  |  AH  |  JH ER M  |  W IH L  |  T IY CH  |  Y UW  |  AA T  |  AH V  |  R EY V IH  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2025.03.14, Block: 4, Trial: 23\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  IH T  |  W AA Z  |  AH  |  B IH L EY SH AH N  |  DH AH  |  AH  |  P IY  |  HH AE V  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2025.03.14, Block: 4, Trial: 24\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  IH T  |  IH Z  |  K AO N  |  T UW  |  W IH M EH M B ER  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2025.03.14, Block: 6, Trial: 12\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  DH EH N  |  AY  |  HH ER D  |  AH  |  V EH R IY  |  K AE N  |  IH S K L EY S AH N  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2025.03.14, Block: 6, Trial: 13\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  M AY  |  G EH T  |  IH Z  |  AH  |  R IH T EH T AH  |  F AA F M ER  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2025.03.14, Block: 6, Trial: 14\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  DH AE T S  |  AH  |  G UH D  |  AA P SH AH N  |  T UW  |  K AH S IH D IY  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2025.03.14, Block: 6, Trial: 15\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  D UW  |  Y UW  |  W AH N  |  IH T  |  IH N S AY N D  |  AO R  |  AO P S AY D  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2025.03.14, Block: 6, Trial: 16\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AE Z  |  S OW  |  W EY  |  F AE L IY  |  S EH T  |  AW T S T AY T  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2025.03.14, Block: 6, Trial: 17\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  B IH S EY S AH N Z  |  R AA  |  AH DH ER  |  G AH M ER IH SH AH N IY  |  W IH L  |  F ER S EH K T  |  DH EH R  |  L EY S AH JH  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2025.03.14, Block: 6, Trial: 18\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  DH EY  |  AA R  |  D IY L  |  S P EH D IH NG  |  T UW  |  B EY TH  |  DH AH M  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2025.03.14, Block: 6, Trial: 19\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AY  |  G OW Z  |  DH EH R  |  AA R  |  AH  |  F Y UW TH  |  DH IH S  |  AH F EH N D  |  S T IH L  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2025.03.14, Block: 6, Trial: 20\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  DH EY  |  AA R  |  S OW  |  S B L AO G  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2025.03.14, Block: 6, Trial: 21\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  IH T  |  IH Z  |  AH  |  F R EY L IY  |  L AA G Z  |  P L EY P ER  |  AA N S  |  R IH L ER JH  |  AH  |  F EY L  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2025.03.14, Block: 6, Trial: 22\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AE V IY  |  AH  |  D JH AA B  |  DH AA  |  T IY CH  |  Y AO  |  AA T  |  AH V  |  R EY ER  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2025.03.14, Block: 6, Trial: 23\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  IH T  |  W AA Z  |  AH  |  D AH N S IH N  |  DH AH T  |  W EY T  |  P EY  |  HH AO F S  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2025.03.14, Block: 6, Trial: 24\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  IH T  |  AH  |  AW L T  |  T UW  |  R IH M EH M B ER  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2025.03.16, Block: 5, Trial: 25\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  W IY  |  HH AE P AH N D  |  HH AE D  |  AH  |  L AA T  |  AH V  |  P R AA B L AH M Z  |  W IH DH  |  DH AH  |  N UW  |  K AH M P UW T ER  |  AE T  |  AO L  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2025.03.16, Block: 5, Trial: 26\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  D EY K  |  AH  |  S IH T  |  AH N D  |  EH N JH OY  |  DH AH  |  W AY N D  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2025.03.16, Block: 5, Trial: 27\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AY  |  TH IH NG K  |  W IY  |  F AH F EH L D  |  AW ER  |  AA B AH B EY SH AH N  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2025.03.16, Block: 5, Trial: 28\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  DH EY  |  SH UH D  |  S T AH D IY  |  DH IH S  |  N OW  |  S P IY SH AH Z  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2025.03.16, Block: 5, Trial: 29\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  M AH B L IY  |  W IY  |  K AE CH  |  K AA M P  |  AH N D  |  S AH M AH N T  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2025.03.16, Block: 5, Trial: 30\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  P IH K IH NG  |  AE T  |  D OW N T  |  IH N  |  AH  |  R IH L D EH R L  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2025.03.16, Block: 5, Trial: 31\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  S T AA D  |  B AY  |  K AE N CH AH S R EY T IH NG  |  AH N D  |  IH K EH N S IH NG  |  SH UH R  |  V IH M AH L AH L EY SH AH N  |  P AW ER  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2025.03.16, Block: 5, Trial: 33\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AY  |  G EH S  |  W EH R  |  B OW TH  |  P R IH T IY  |  R EH D ER K AH L  |  P IY P AH L  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2025.03.16, Block: 5, Trial: 34\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  IH T  |  W AA Z  |  AA N  |  IH Z  |  W EY  |  DH EH R  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2025.03.16, Block: 5, Trial: 35\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  Y UW  |  AA R  |  P R AA B AH B L IY  |  W AY T  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2025.03.16, Block: 5, Trial: 36\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AY  |  AE M  |  SH AY R D IH NG  |  T UW  |  K AH N P EH K S  |  IH N  |  T UW  |  W AH T  |  AO L  |  DH IH S  |  D AW N  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2025.03.16, Block: 5, Trial: 37\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  IH F  |  DH EY  |  W ER K  |  AE T  |  IH T  |  AH  |  L IH T AH L  |  B IH T  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2025.03.16, Block: 5, Trial: 38\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AY  |  TH IH NG K  |  DH EY  |  D IH D  |  AH  |  W IH L  |  G UH D  |  JH AA B  |  AH V  |  DH AE T  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2025.03.16, Block: 5, Trial: 39\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  DH AE T S  |  W AH T  |  DH EH R  |  D UW IH NG  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2025.03.16, Block: 5, Trial: 40\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  IH T S  |  AH  |  R IH L IY  |  G UH D  |  M UW V IH  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2025.03.16, Block: 5, Trial: 41\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  W AH S T  |  Y AO R  |  S EH S T AH D  |  F EH V ER IH T  |  F UW D  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2025.03.16, Block: 5, Trial: 42\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  P IY P AH L  |  AA R  |  F R EH S IH NG  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2025.03.16, Block: 5, Trial: 43\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  DH EH R  |  N EH V ER  |  W IH L  |  B IY  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2025.03.16, Block: 5, Trial: 44\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  W AH T  |  AH V  |  DH AH  |  L EY NG Z  |  DH AE T  |  IH Z  |  AH  |  P R AA B AH K T  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2025.03.16, Block: 5, Trial: 45\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  DH AE S  |  K AY N D  |  T UW  |  B IY  |  B IY T AH F AH L T  |  T EH R AH N T EH R IY  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2025.03.16, Block: 5, Trial: 46\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  K AE N  |  D UW  |  B AH F EH V ER  |  DH EY  |  W EY N T  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2025.03.16, Block: 5, Trial: 47\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  DH AH  |  OW N L IY  |  K AA S T S  |  AH V  |  TH IH NG Z  |  DH AE T  |  Y UW  |  K AE N  |  Y UW Z  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2025.03.16, Block: 5, Trial: 48\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  DH AE T S  |  K AY N D  |  AH V  |  AH N D ER S T AE N D AH B AH L  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2025.03.16, Block: 5, Trial: 49\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  IH T  |  DH AH  |  B EH D AH L  |  AH V  |  AH  |  R EH G IH D EH N SH AH L  |  EH R IY AH  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2025.03.30, Block: 10, Trial: 7\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AA R  |  Y UW  |  S ER V IH NG  |  AH N AH DH ER  |  D EH S  |  W IH DH  |  IH T  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2025.03.30, Block: 10, Trial: 9\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  HH IY  |  B EH S IH K L IY  |  P UH T  |  IH N S EH L TH  |  TH R UW  |  S K UW L  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2025.03.30, Block: 10, Trial: 10\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  M AY  |  K AA R  |  IH Z  |  AH  |  N AY N T AH N  |  EY T IY  |  S EH N S  |  T AY UW T ER  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2025.03.30, Block: 10, Trial: 12\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  G EH T  |  R EH D  |  AH V  |  DH AH  |  T UW  |  DH AE T  |  W IY  |  HH AE V  |  W AH T  |  N AW  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2025.03.30, Block: 10, Trial: 13\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AY  |  AE M  |  AE N  |  AH M EH R IH K AH N  |  S IH T AH S AH N  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2025.03.30, Block: 10, Trial: 14\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  DH AE T S  |  W AY  |  W IY  |  D IH S AY D IH D  |  T UW  |  B IH L D  |  AE N  |  AH G IH SH AH N  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2025.03.30, Block: 13, Trial: 25\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  W AH T S  |  DH AE T  |  M EH R IY  |  AH B AW T  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2025.03.30, Block: 13, Trial: 26\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  DH AH  |  B EH T AH F AH N T  |  AH V  |  F AE V IH NG  |  V IH Z IH T  |  IH N SH IH R AH N  |  IH Z  |  F AO R  |  DH AH  |  R IH M AH L IY  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2025.03.30, Block: 13, Trial: 27\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  Y UW  |  G EH T  |  F AY N D  |  DH EH M  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2025.03.30, Block: 13, Trial: 28\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  W AH T  |  K AY N  |  AH V  |  F AH S EH B T IH NG  |  T UW  |  Y UW  |  T UW  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2025.03.30, Block: 13, Trial: 29\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AY V  |  B IH N  |  AE T  |  K AE M P AH N AH N T S  |  W EH R  |  D IH P AH L  |  IH L IY  |  W ER NG  |  T UW  |  AA R  |  TH R IY  |  AW Z IH Z  |  AH  |  D EY  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2025.03.30, Block: 13, Trial: 30\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AY  |  W AA Z  |  L IH V IY  |  B EH T ER  |  T ER N  |  Y IH R Z  |  AH G AO L  |  DH AE T  |  AH  |  AE M  |  N AW  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2025.03.30, Block: 13, Trial: 31\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  SH IY  |  K AH M  |  AH  |  G AA T  |  T UW  |  Y UW  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2025.03.30, Block: 13, Trial: 32\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  HH ER  |  AY Z  |  AA L  |  D EY N IH NG  |  K AA L ER  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2025.03.30, Block: 13, Trial: 33\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AW ER  |  AH N OY IH NG  |  P R EH JH IH K T  |  D IH F AH L AH M AH N T  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2025.03.30, Block: 13, Trial: 34\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AY  |  TH IH NG  |  W DH IY  |  HH AE V  |  AH B AW T  |  TH ER T D  |  B EH T S  |  L EH F T  |  AO R  |  AW ER  |  TH L OW D  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2025.03.30, Block: 13, Trial: 35\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AY  |  L AY K  |  W ER S  |  CH UW Z IH K  |  JH ER ZH AH N S  |  AH T S EH P T  |  F AO R  |  K AE N T R IY  |  M Y UW Z IH K  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2025.03.30, Block: 13, Trial: 36\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AY  |  W AA Z  |  M IY N IH NG  |  AA L  |  DH AH  |  AE F  |  AH V  |  M AY  |  DH IH  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2025.03.30, Block: 13, Trial: 37\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  W AH T IY  |  L AE V Z  |  DH AH M  |  DH EH R  |  M AH CH  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2025.03.30, Block: 13, Trial: 38\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  DH IH S  |  DH AH  |  W EY T  |  AH  |  HH AE V  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2025.03.30, Block: 13, Trial: 40\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  DH EY  |  JH AH S T  |  W AH D  |  DH AH  |  W EH T ER  |  P AO R  |  AA N  |  DH AH  |  AE P  |  DH AH P EH T  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2025.03.30, Block: 13, Trial: 41\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  W AH T  |  IH N  |  DH AH  |  M IH D AH L  |  AH V  |  M AY  |  D EH K  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2025.03.30, Block: 13, Trial: 42\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AE T  |  HH AE Z  |  D AE N D  |  T UW  |  W AH T  |  M EH ZH AH Z  |  R EH D  |  AH K AW S T  |  AH G TH EH DH ER Z  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2025.03.30, Block: 13, Trial: 43\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AY  |  AW N S OY D  |  B EH T IY  |  HH AE Z  |  AH  |  G AE G AH N  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2025.03.30, Block: 13, Trial: 44\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  S OW  |  W UH D  |  T UW  |  Y UW  |  TH IH NG K  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2025.03.30, Block: 13, Trial: 45\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AA R  |  W EH N IY  |  Y UW  |  Y UW  |  HH AE V  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2025.03.30, Block: 13, Trial: 46\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  W AY  |  W AY F S  |  B AA DH ER  |  IH Z  |  DH AH  |  OW N L IY  |  R EH R P EH R T AH L  |  L AH V  |  B IH T  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2025.03.30, Block: 13, Trial: 47\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AY  |  W AA Z  |  IH N  |  IH L EH T AH  |  F AO R  |  AY  |  B AE S AH S R AE M  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2025.03.30, Block: 13, Trial: 48\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  DH AH  |  K AA R D  |  D AE L AH SH AH P  |  R EY D  |  B ER  |  AO F  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2025.03.30, Block: 13, Trial: 49\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  W EH N  |  AY  |  W AA Z  |  AH N T IY N  |  Y IH R Z  |  OW L D  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2025.04.13, Block: 8, Trial: 25\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  HH IY  |  W UH D AH N T  |  EH V ER  |  R IH L IY  |  T AO K  |  AH B AW T  |  IH T  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2025.04.13, Block: 8, Trial: 26\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AY  |  HH AE D  |  F AO R  |  B L AE DH ER Z  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2025.04.13, Block: 8, Trial: 27\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AY  |  G UH D  |  S IY  |  DH AE T  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2025.04.13, Block: 8, Trial: 28\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  IH F  |  S AH M W EY  |  K EY M  |  AH N D  |  HH ER D  |  IH T  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2025.04.13, Block: 8, Trial: 29\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AY  |  HH AE V AH N T  |  R IH L IY  |  P R EH S T  |  IH T  |  AW T  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2025.04.13, Block: 8, Trial: 30\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  DH AE T  |  W AA Z  |  V EH R IY  |  D IH S AO R T AH N T IY  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2025.04.13, Block: 8, Trial: 31\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  DH EH R  |  AE K S UW AH S L IY  |  D UW  |  DH IH NG Z  |  L AY K  |  DH IH S  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2025.04.13, Block: 8, Trial: 32\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  M AY  |  AH S B M EH K T  |  G EH T Z  |  P IH N  |  W AH N S  |  AH  |  M AH N TH S  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2025.04.13, Block: 8, Trial: 33\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AY  |  N OW  |  W IY  |  L AY V  |  IH N  |  R IY K AE N IH L  |  F AO R  |  S EH V AH N  |  Y IH R Z  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2025.04.13, Block: 8, Trial: 34\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AY  |  D OW N T  |  N OW  |  W AH T  |  TH AE NG K S  |  AH B AW T  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2025.04.13, Block: 8, Trial: 35\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  DH EH R  |  AA R  |  AO L W EY Z  |  N UW  |  K AH K F EH F ER F IH T S  |  AO R  |  P R AA B L AH M Z  |  AA R  |  R EY Z AH S IY Z  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2025.04.13, Block: 8, Trial: 36\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AY M  |  T AO K IH NG  |  AH B AW T  |  IH N K R IY L AH T L IY  |  L OY Z  |  F AO R K S  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2025.04.13, Block: 8, Trial: 37\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  DH EH R Z  |  AH  |  K AH P AH L  |  N UW  |  T EY N CH AH N Z  |  DH IH S  |  Y IH R  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2025.04.13, Block: 8, Trial: 38\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  DH AH  |  L AE S AH N T S  |  F AO R  |  K AE M W AH T S  |  AA R  |  B EH R IY  |  IH K S P EH S SH IH S  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2025.04.13, Block: 8, Trial: 39\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  W IY  |  EH N JH OY D  |  HH AE V IH NG  |  HH UW  |  HH IY R  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2025.04.13, Block: 8, Trial: 40\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AY  |  W AA Z  |  W AO N T IH NG  |  AA N  |  AH  |  F AA R M  |  L AY N S  |  S AH M IY  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2025.04.13, Block: 8, Trial: 41\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  DH IY Z  |  B OY  |  K AE T S  |  AA R  |  AH P  |  T UW  |  AO L  |  S AO R T S  |  AH V  |  TH IH NG Z  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2025.04.13, Block: 8, Trial: 42\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  DH AH  |  AA K CH SH AH N D AH D  |  IH Z  |  P EH SH AH N  |  B AY  |  IH T S  |  L UW V M AH N  |  W AY T  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2025.04.13, Block: 8, Trial: 43\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  EH N AH  |  R EH S AH N  |  P ER ZH IH N  |  AH V  |  W IH T AH N S  |  SH UH D  |  B IY  |  F AY T  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2025.04.13, Block: 8, Trial: 44\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  N  |  DH AH  |  IH N D T AH N AE T  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2025.04.13, Block: 8, Trial: 45\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  S IH N S  |  DH EY  |  D OW N T  |  HH AE V  |  DH AH  |  R IH L IY  |  F IY  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2025.04.13, Block: 8, Trial: 46\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  DH EH R Z  |  AH  |  L AA T  |  AH V  |  N UW  |  S EH CH AH N  |  IH N  |  DH AH  |  T AA K Y AH M AH N T  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2025.04.13, Block: 8, Trial: 47\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  AH N D  |  AW ER  |  AE N D  |  AH  |  HH AE V  |  AH W EY  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2025.04.13, Block: 8, Trial: 48\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  SH IY  |  B AA S  |  AE T  |  DH AH  |  AH DH ER  |  W AH N  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Session: t15.2025.04.13, Block: 8, Trial: 49\n",
      "\u001b[92mcmd2:\u001b[0m Predicted Sequence:  W EH L  |  B EY B IY  |  DH AE T  |  IH Z  |  AH N T AE S IH  |  F AE F T ER  | \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m \n",
      "\u001b[94mcmd1:\u001b[0m depbase=`echo reverse.lo | sed 's|[^/]*$|.deps/&|;s|\\.lo$||'`;\\\n",
      "\u001b[94mcmd1:\u001b[0m /bin/bash ../../libtool  --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H   -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/../include  -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char  -std=c++11 -MT reverse.lo -MD -MP -MF $depbase.Tpo -c -o reverse.lo /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/reverse.cc &&\\\n",
      "\u001b[94mcmd1:\u001b[0m mv -f $depbase.Tpo $depbase.Plo\n",
      "\u001b[94mcmd1:\u001b[0m libtool: compile:  g++ -DHAVE_CONFIG_H -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/../include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char -std=c++11 -MT reverse.lo -MD -MP -MF .deps/reverse.Tpo -c /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/reverse.cc  -fPIC -DPIC -o .libs/reverse.o\n",
      "\u001b[94mcmd1:\u001b[0m depbase=`echo reweight.lo | sed 's|[^/]*$|.deps/&|;s|\\.lo$||'`;\\\n",
      "\u001b[94mcmd1:\u001b[0m /bin/bash ../../libtool  --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H   -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/../include  -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char  -std=c++11 -MT reweight.lo -MD -MP -MF $depbase.Tpo -c -o reweight.lo /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/reweight.cc &&\\\n",
      "\u001b[94mcmd1:\u001b[0m mv -f $depbase.Tpo $depbase.Plo\n",
      "\u001b[94mcmd1:\u001b[0m libtool: compile:  g++ -DHAVE_CONFIG_H -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/../include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char -std=c++11 -MT reweight.lo -MD -MP -MF .deps/reweight.Tpo -c /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/reweight.cc  -fPIC -DPIC -o .libs/reweight.o\n",
      "\u001b[94mcmd1:\u001b[0m depbase=`echo rmepsilon.lo | sed 's|[^/]*$|.deps/&|;s|\\.lo$||'`;\\\n",
      "\u001b[94mcmd1:\u001b[0m /bin/bash ../../libtool  --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H   -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/../include  -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char  -std=c++11 -MT rmepsilon.lo -MD -MP -MF $depbase.Tpo -c -o rmepsilon.lo /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/rmepsilon.cc &&\\\n",
      "\u001b[94mcmd1:\u001b[0m mv -f $depbase.Tpo $depbase.Plo\n",
      "\u001b[94mcmd1:\u001b[0m libtool: compile:  g++ -DHAVE_CONFIG_H -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/../include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char -std=c++11 -MT rmepsilon.lo -MD -MP -MF .deps/rmepsilon.Tpo -c /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/rmepsilon.cc  -fPIC -DPIC -o .libs/rmepsilon.o\n",
      "\u001b[94mcmd1:\u001b[0m depbase=`echo shortest-distance.lo | sed 's|[^/]*$|.deps/&|;s|\\.lo$||'`;\\\n",
      "\u001b[94mcmd1:\u001b[0m /bin/bash ../../libtool  --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H   -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/../include  -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char  -std=c++11 -MT shortest-distance.lo -MD -MP -MF $depbase.Tpo -c -o shortest-distance.lo /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/shortest-distance.cc &&\\\n",
      "\u001b[94mcmd1:\u001b[0m mv -f $depbase.Tpo $depbase.Plo\n",
      "\u001b[94mcmd1:\u001b[0m libtool: compile:  g++ -DHAVE_CONFIG_H -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/../include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char -std=c++11 -MT shortest-distance.lo -MD -MP -MF .deps/shortest-distance.Tpo -c /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/shortest-distance.cc  -fPIC -DPIC -o .libs/shortest-distance.o\n",
      "\u001b[94mcmd1:\u001b[0m depbase=`echo shortest-path.lo | sed 's|[^/]*$|.deps/&|;s|\\.lo$||'`;\\\n",
      "\u001b[94mcmd1:\u001b[0m /bin/bash ../../libtool  --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H   -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/../include  -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char  -std=c++11 -MT shortest-path.lo -MD -MP -MF $depbase.Tpo -c -o shortest-path.lo /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/shortest-path.cc &&\\\n",
      "\u001b[94mcmd1:\u001b[0m mv -f $depbase.Tpo $depbase.Plo\n",
      "\u001b[94mcmd1:\u001b[0m libtool: compile:  g++ -DHAVE_CONFIG_H -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/../include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char -std=c++11 -MT shortest-path.lo -MD -MP -MF .deps/shortest-path.Tpo -c /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/shortest-path.cc  -fPIC -DPIC -o .libs/shortest-path.o\n",
      "\u001b[92mcmd2:\u001b[0m Running remote language model:   0%|          | 0/1450 [00:00<?, ?trial/s]Still waiting for remote lm reset from ts 1766528432100...\n",
      "\u001b[94mcmd1:\u001b[0m depbase=`echo stateiterator-class.lo | sed 's|[^/]*$|.deps/&|;s|\\.lo$||'`;\\\n",
      "\u001b[94mcmd1:\u001b[0m /bin/bash ../../libtool  --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H   -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/../include  -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char  -std=c++11 -MT stateiterator-class.lo -MD -MP -MF $depbase.Tpo -c -o stateiterator-class.lo /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/stateiterator-class.cc &&\\\n",
      "\u001b[94mcmd1:\u001b[0m mv -f $depbase.Tpo $depbase.Plo\n",
      "\u001b[94mcmd1:\u001b[0m libtool: compile:  g++ -DHAVE_CONFIG_H -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/../include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char -std=c++11 -MT stateiterator-class.lo -MD -MP -MF .deps/stateiterator-class.Tpo -c /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/stateiterator-class.cc  -fPIC -DPIC -o .libs/stateiterator-class.o\n",
      "\u001b[94mcmd1:\u001b[0m depbase=`echo synchronize.lo | sed 's|[^/]*$|.deps/&|;s|\\.lo$||'`;\\\n",
      "\u001b[94mcmd1:\u001b[0m /bin/bash ../../libtool  --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H   -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/../include  -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char  -std=c++11 -MT synchronize.lo -MD -MP -MF $depbase.Tpo -c -o synchronize.lo /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/synchronize.cc &&\\\n",
      "\u001b[94mcmd1:\u001b[0m mv -f $depbase.Tpo $depbase.Plo\n",
      "\u001b[94mcmd1:\u001b[0m libtool: compile:  g++ -DHAVE_CONFIG_H -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/../include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char -std=c++11 -MT synchronize.lo -MD -MP -MF .deps/synchronize.Tpo -c /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/synchronize.cc  -fPIC -DPIC -o .libs/synchronize.o\n",
      "\u001b[94mcmd1:\u001b[0m depbase=`echo text-io.lo | sed 's|[^/]*$|.deps/&|;s|\\.lo$||'`;\\\n",
      "\u001b[94mcmd1:\u001b[0m /bin/bash ../../libtool  --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H   -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/../include  -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char  -std=c++11 -MT text-io.lo -MD -MP -MF $depbase.Tpo -c -o text-io.lo /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/text-io.cc &&\\\n",
      "\u001b[94mcmd1:\u001b[0m mv -f $depbase.Tpo $depbase.Plo\n",
      "\u001b[94mcmd1:\u001b[0m libtool: compile:  g++ -DHAVE_CONFIG_H -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/../include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char -std=c++11 -MT text-io.lo -MD -MP -MF .deps/text-io.Tpo -c /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/text-io.cc  -fPIC -DPIC -o .libs/text-io.o\n",
      "\u001b[94mcmd1:\u001b[0m depbase=`echo topsort.lo | sed 's|[^/]*$|.deps/&|;s|\\.lo$||'`;\\\n",
      "\u001b[94mcmd1:\u001b[0m /bin/bash ../../libtool  --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H   -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/../include  -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char  -std=c++11 -MT topsort.lo -MD -MP -MF $depbase.Tpo -c -o topsort.lo /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/topsort.cc &&\\\n",
      "\u001b[94mcmd1:\u001b[0m mv -f $depbase.Tpo $depbase.Plo\n",
      "\u001b[94mcmd1:\u001b[0m libtool: compile:  g++ -DHAVE_CONFIG_H -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/../include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char -std=c++11 -MT topsort.lo -MD -MP -MF .deps/topsort.Tpo -c /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/topsort.cc  -fPIC -DPIC -o .libs/topsort.o\n",
      "\u001b[94mcmd1:\u001b[0m depbase=`echo union.lo | sed 's|[^/]*$|.deps/&|;s|\\.lo$||'`;\\\n",
      "\u001b[94mcmd1:\u001b[0m /bin/bash ../../libtool  --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H   -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/../include  -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char  -std=c++11 -MT union.lo -MD -MP -MF $depbase.Tpo -c -o union.lo /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/union.cc &&\\\n",
      "\u001b[94mcmd1:\u001b[0m mv -f $depbase.Tpo $depbase.Plo\n",
      "\u001b[94mcmd1:\u001b[0m libtool: compile:  g++ -DHAVE_CONFIG_H -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/../include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char -std=c++11 -MT union.lo -MD -MP -MF .deps/union.Tpo -c /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/union.cc  -fPIC -DPIC -o .libs/union.o\n",
      "\u001b[92mcmd2:\u001b[0m Still waiting for remote lm reset from ts 1766528432100...\n",
      "\u001b[94mcmd1:\u001b[0m depbase=`echo weight-class.lo | sed 's|[^/]*$|.deps/&|;s|\\.lo$||'`;\\\n",
      "\u001b[94mcmd1:\u001b[0m /bin/bash ../../libtool  --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H   -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/../include  -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char  -std=c++11 -MT weight-class.lo -MD -MP -MF $depbase.Tpo -c -o weight-class.lo /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/weight-class.cc &&\\\n",
      "\u001b[94mcmd1:\u001b[0m mv -f $depbase.Tpo $depbase.Plo\n",
      "\u001b[94mcmd1:\u001b[0m libtool: compile:  g++ -DHAVE_CONFIG_H -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/../include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char -std=c++11 -MT weight-class.lo -MD -MP -MF .deps/weight-class.Tpo -c /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/weight-class.cc  -fPIC -DPIC -o .libs/weight-class.o\n",
      "\u001b[94mcmd1:\u001b[0m depbase=`echo verify.lo | sed 's|[^/]*$|.deps/&|;s|\\.lo$||'`;\\\n",
      "\u001b[94mcmd1:\u001b[0m /bin/bash ../../libtool  --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H   -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/../include  -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char  -std=c++11 -MT verify.lo -MD -MP -MF $depbase.Tpo -c -o verify.lo /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/verify.cc &&\\\n",
      "\u001b[94mcmd1:\u001b[0m mv -f $depbase.Tpo $depbase.Plo\n",
      "\u001b[94mcmd1:\u001b[0m libtool: compile:  g++ -DHAVE_CONFIG_H -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/../include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char -std=c++11 -MT verify.lo -MD -MP -MF .deps/verify.Tpo -c /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/script/verify.cc  -fPIC -DPIC -o .libs/verify.o\n",
      "\u001b[94mcmd1:\u001b[0m /bin/bash ../../libtool  --tag=CXX   --mode=link g++  -std=c++11 -version-info 8:0:0 -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -o libfstscript.la -rpath /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-subbuild/openfst-populate-prefix/lib arciterator-class.lo arcsort.lo closure.lo compile.lo compose.lo concat.lo connect.lo convert.lo decode.lo determinize.lo difference.lo disambiguate.lo draw.lo encode.lo encodemapper-class.lo epsnormalize.lo equal.lo equivalent.lo fst-class.lo getters.lo info-impl.lo info.lo intersect.lo invert.lo isomorphic.lo map.lo minimize.lo print.lo project.lo prune.lo push.lo randequivalent.lo randgen.lo relabel.lo replace.lo reverse.lo reweight.lo rmepsilon.lo shortest-distance.lo shortest-path.lo stateiterator-class.lo synchronize.lo text-io.lo topsort.lo union.lo weight-class.lo verify.lo ../lib/libfst.la -lm -ldl -lgflags_nothreads -lglog -lpthread\n",
      "\u001b[94mcmd1:\u001b[0m libtool: link: g++  -fPIC -DPIC -shared -nostdlib /usr/lib/gcc/x86_64-linux-gnu/11/../../../x86_64-linux-gnu/crti.o /usr/lib/gcc/x86_64-linux-gnu/11/crtbeginS.o  .libs/arciterator-class.o .libs/arcsort.o .libs/closure.o .libs/compile.o .libs/compose.o .libs/concat.o .libs/connect.o .libs/convert.o .libs/decode.o .libs/determinize.o .libs/difference.o .libs/disambiguate.o .libs/draw.o .libs/encode.o .libs/encodemapper-class.o .libs/epsnormalize.o .libs/equal.o .libs/equivalent.o .libs/fst-class.o .libs/getters.o .libs/info-impl.o .libs/info.o .libs/intersect.o .libs/invert.o .libs/isomorphic.o .libs/map.o .libs/minimize.o .libs/print.o .libs/project.o .libs/prune.o .libs/push.o .libs/randequivalent.o .libs/randgen.o .libs/relabel.o .libs/replace.o .libs/reverse.o .libs/reweight.o .libs/rmepsilon.o .libs/shortest-distance.o .libs/shortest-path.o .libs/stateiterator-class.o .libs/synchronize.o .libs/text-io.o .libs/topsort.o .libs/union.o .libs/weight-class.o .libs/verify.o   -Wl,-rpath -Wl,/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-build/src/lib/.libs -Wl,-rpath -Wl,/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-subbuild/openfst-populate-prefix/lib -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build ../lib/.libs/libfst.so -ldl -lgflags_nothreads -lglog -lpthread -L/usr/lib/gcc/x86_64-linux-gnu/11 -L/usr/lib/gcc/x86_64-linux-gnu/11/../../../x86_64-linux-gnu -L/usr/lib/gcc/x86_64-linux-gnu/11/../../../../lib -L/lib/x86_64-linux-gnu -L/lib/../lib -L/usr/lib/x86_64-linux-gnu -L/usr/lib/../lib -L/usr/local/cuda/lib64/stubs -L/usr/lib/gcc/x86_64-linux-gnu/11/../../.. -lstdc++ -lm -lc -lgcc_s /usr/lib/gcc/x86_64-linux-gnu/11/crtendS.o /usr/lib/gcc/x86_64-linux-gnu/11/../../../x86_64-linux-gnu/crtn.o    -Wl,-soname -Wl,libfstscript.so.8 -o .libs/libfstscript.so.8.0.0\n",
      "\u001b[92mcmd2:\u001b[0m Still waiting for remote lm reset from ts 1766528432100...\n",
      "\u001b[94mcmd1:\u001b[0m libtool: link: (cd \".libs\" && rm -f \"libfstscript.so.8\" && ln -s \"libfstscript.so.8.0.0\" \"libfstscript.so.8\")\n",
      "\u001b[94mcmd1:\u001b[0m libtool: link: (cd \".libs\" && rm -f \"libfstscript.so\" && ln -s \"libfstscript.so.8.0.0\" \"libfstscript.so\")\n",
      "\u001b[94mcmd1:\u001b[0m libtool: link: ( cd \".libs\" && rm -f \"libfstscript.la\" && ln -s \"../libfstscript.la\" \"libfstscript.la\" )\n",
      "\u001b[94mcmd1:\u001b[0m make[7]: Leaving directory '/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-build/src/script'\n",
      "\u001b[94mcmd1:\u001b[0m Making all in bin\n",
      "\u001b[94mcmd1:\u001b[0m make[7]: Entering directory '/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-build/src/bin'\n",
      "\u001b[94mcmd1:\u001b[0m depbase=`echo fstarcsort.o | sed 's|[^/]*$|.deps/&|;s|\\.o$||'`;\\\n",
      "\u001b[94mcmd1:\u001b[0m g++ -DHAVE_CONFIG_H   -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../script  -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char  -std=c++11 -MT fstarcsort.o -MD -MP -MF $depbase.Tpo -c -o fstarcsort.o /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/fstarcsort.cc &&\\\n",
      "\u001b[94mcmd1:\u001b[0m mv -f $depbase.Tpo $depbase.Po\n",
      "\u001b[94mcmd1:\u001b[0m depbase=`echo fstarcsort-main.o | sed 's|[^/]*$|.deps/&|;s|\\.o$||'`;\\\n",
      "\u001b[94mcmd1:\u001b[0m g++ -DHAVE_CONFIG_H   -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../script  -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char  -std=c++11 -MT fstarcsort-main.o -MD -MP -MF $depbase.Tpo -c -o fstarcsort-main.o /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/fstarcsort-main.cc &&\\\n",
      "\u001b[94mcmd1:\u001b[0m mv -f $depbase.Tpo $depbase.Po\n",
      "\u001b[94mcmd1:\u001b[0m depbase=`echo fstclosure.o | sed 's|[^/]*$|.deps/&|;s|\\.o$||'`;\\\n",
      "\u001b[94mcmd1:\u001b[0m g++ -DHAVE_CONFIG_H   -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../script  -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char  -std=c++11 -MT fstclosure.o -MD -MP -MF $depbase.Tpo -c -o fstclosure.o /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/fstclosure.cc &&\\\n",
      "\u001b[94mcmd1:\u001b[0m mv -f $depbase.Tpo $depbase.Po\n",
      "\u001b[94mcmd1:\u001b[0m depbase=`echo fstclosure-main.o | sed 's|[^/]*$|.deps/&|;s|\\.o$||'`;\\\n",
      "\u001b[94mcmd1:\u001b[0m g++ -DHAVE_CONFIG_H   -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../script  -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char  -std=c++11 -MT fstclosure-main.o -MD -MP -MF $depbase.Tpo -c -o fstclosure-main.o /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/fstclosure-main.cc &&\\\n",
      "\u001b[94mcmd1:\u001b[0m mv -f $depbase.Tpo $depbase.Po\n",
      "\u001b[94mcmd1:\u001b[0m depbase=`echo fstcompile.o | sed 's|[^/]*$|.deps/&|;s|\\.o$||'`;\\\n",
      "\u001b[94mcmd1:\u001b[0m g++ -DHAVE_CONFIG_H   -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../script  -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char  -std=c++11 -MT fstcompile.o -MD -MP -MF $depbase.Tpo -c -o fstcompile.o /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/fstcompile.cc &&\\\n",
      "\u001b[94mcmd1:\u001b[0m mv -f $depbase.Tpo $depbase.Po\n",
      "\u001b[94mcmd1:\u001b[0m depbase=`echo fstcompile-main.o | sed 's|[^/]*$|.deps/&|;s|\\.o$||'`;\\\n",
      "\u001b[94mcmd1:\u001b[0m g++ -DHAVE_CONFIG_H   -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../script  -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char  -std=c++11 -MT fstcompile-main.o -MD -MP -MF $depbase.Tpo -c -o fstcompile-main.o /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/fstcompile-main.cc &&\\\n",
      "\u001b[94mcmd1:\u001b[0m mv -f $depbase.Tpo $depbase.Po\n",
      "\u001b[94mcmd1:\u001b[0m depbase=`echo fstcompose.o | sed 's|[^/]*$|.deps/&|;s|\\.o$||'`;\\\n",
      "\u001b[94mcmd1:\u001b[0m g++ -DHAVE_CONFIG_H   -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../script  -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char  -std=c++11 -MT fstcompose.o -MD -MP -MF $depbase.Tpo -c -o fstcompose.o /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/fstcompose.cc &&\\\n",
      "\u001b[94mcmd1:\u001b[0m mv -f $depbase.Tpo $depbase.Po\n",
      "\u001b[94mcmd1:\u001b[0m depbase=`echo fstcompose-main.o | sed 's|[^/]*$|.deps/&|;s|\\.o$||'`;\\\n",
      "\u001b[94mcmd1:\u001b[0m g++ -DHAVE_CONFIG_H   -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../script  -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char  -std=c++11 -MT fstcompose-main.o -MD -MP -MF $depbase.Tpo -c -o fstcompose-main.o /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/fstcompose-main.cc &&\\\n",
      "\u001b[94mcmd1:\u001b[0m mv -f $depbase.Tpo $depbase.Po\n",
      "\u001b[94mcmd1:\u001b[0m depbase=`echo fstconcat.o | sed 's|[^/]*$|.deps/&|;s|\\.o$||'`;\\\n",
      "\u001b[94mcmd1:\u001b[0m g++ -DHAVE_CONFIG_H   -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../script  -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char  -std=c++11 -MT fstconcat.o -MD -MP -MF $depbase.Tpo -c -o fstconcat.o /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/fstconcat.cc &&\\\n",
      "\u001b[94mcmd1:\u001b[0m mv -f $depbase.Tpo $depbase.Po\n",
      "\u001b[94mcmd1:\u001b[0m depbase=`echo fstconcat-main.o | sed 's|[^/]*$|.deps/&|;s|\\.o$||'`;\\\n",
      "\u001b[94mcmd1:\u001b[0m g++ -DHAVE_CONFIG_H   -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../script  -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char  -std=c++11 -MT fstconcat-main.o -MD -MP -MF $depbase.Tpo -c -o fstconcat-main.o /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/fstconcat-main.cc &&\\\n",
      "\u001b[94mcmd1:\u001b[0m mv -f $depbase.Tpo $depbase.Po\n",
      "\u001b[94mcmd1:\u001b[0m depbase=`echo fstconnect.o | sed 's|[^/]*$|.deps/&|;s|\\.o$||'`;\\\n",
      "\u001b[94mcmd1:\u001b[0m g++ -DHAVE_CONFIG_H   -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../script  -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char  -std=c++11 -MT fstconnect.o -MD -MP -MF $depbase.Tpo -c -o fstconnect.o /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/fstconnect.cc &&\\\n",
      "\u001b[94mcmd1:\u001b[0m mv -f $depbase.Tpo $depbase.Po\n",
      "\u001b[94mcmd1:\u001b[0m depbase=`echo fstconnect-main.o | sed 's|[^/]*$|.deps/&|;s|\\.o$||'`;\\\n",
      "\u001b[94mcmd1:\u001b[0m g++ -DHAVE_CONFIG_H   -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../script  -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char  -std=c++11 -MT fstconnect-main.o -MD -MP -MF $depbase.Tpo -c -o fstconnect-main.o /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/fstconnect-main.cc &&\\\n",
      "\u001b[94mcmd1:\u001b[0m mv -f $depbase.Tpo $depbase.Po\n",
      "\u001b[94mcmd1:\u001b[0m depbase=`echo fstconvert.o | sed 's|[^/]*$|.deps/&|;s|\\.o$||'`;\\\n",
      "\u001b[94mcmd1:\u001b[0m g++ -DHAVE_CONFIG_H   -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../script  -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char  -std=c++11 -MT fstconvert.o -MD -MP -MF $depbase.Tpo -c -o fstconvert.o /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/fstconvert.cc &&\\\n",
      "\u001b[94mcmd1:\u001b[0m mv -f $depbase.Tpo $depbase.Po\n",
      "\u001b[94mcmd1:\u001b[0m depbase=`echo fstconvert-main.o | sed 's|[^/]*$|.deps/&|;s|\\.o$||'`;\\\n",
      "\u001b[94mcmd1:\u001b[0m g++ -DHAVE_CONFIG_H   -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../script  -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char  -std=c++11 -MT fstconvert-main.o -MD -MP -MF $depbase.Tpo -c -o fstconvert-main.o /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/fstconvert-main.cc &&\\\n",
      "\u001b[94mcmd1:\u001b[0m mv -f $depbase.Tpo $depbase.Po\n",
      "\u001b[94mcmd1:\u001b[0m depbase=`echo fstdeterminize.o | sed 's|[^/]*$|.deps/&|;s|\\.o$||'`;\\\n",
      "\u001b[94mcmd1:\u001b[0m g++ -DHAVE_CONFIG_H   -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../script  -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char  -std=c++11 -MT fstdeterminize.o -MD -MP -MF $depbase.Tpo -c -o fstdeterminize.o /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/fstdeterminize.cc &&\\\n",
      "\u001b[94mcmd1:\u001b[0m mv -f $depbase.Tpo $depbase.Po\n",
      "\u001b[94mcmd1:\u001b[0m depbase=`echo fstdeterminize-main.o | sed 's|[^/]*$|.deps/&|;s|\\.o$||'`;\\\n",
      "\u001b[94mcmd1:\u001b[0m g++ -DHAVE_CONFIG_H   -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../script  -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char  -std=c++11 -MT fstdeterminize-main.o -MD -MP -MF $depbase.Tpo -c -o fstdeterminize-main.o /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/fstdeterminize-main.cc &&\\\n",
      "\u001b[94mcmd1:\u001b[0m mv -f $depbase.Tpo $depbase.Po\n",
      "\u001b[94mcmd1:\u001b[0m depbase=`echo fstdifference.o | sed 's|[^/]*$|.deps/&|;s|\\.o$||'`;\\\n",
      "\u001b[94mcmd1:\u001b[0m g++ -DHAVE_CONFIG_H   -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../script  -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char  -std=c++11 -MT fstdifference.o -MD -MP -MF $depbase.Tpo -c -o fstdifference.o /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/fstdifference.cc &&\\\n",
      "\u001b[94mcmd1:\u001b[0m mv -f $depbase.Tpo $depbase.Po\n",
      "\u001b[94mcmd1:\u001b[0m depbase=`echo fstdifference-main.o | sed 's|[^/]*$|.deps/&|;s|\\.o$||'`;\\\n",
      "\u001b[94mcmd1:\u001b[0m g++ -DHAVE_CONFIG_H   -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../script  -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char  -std=c++11 -MT fstdifference-main.o -MD -MP -MF $depbase.Tpo -c -o fstdifference-main.o /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/fstdifference-main.cc &&\\\n",
      "\u001b[94mcmd1:\u001b[0m mv -f $depbase.Tpo $depbase.Po\n",
      "\u001b[94mcmd1:\u001b[0m depbase=`echo fstdisambiguate.o | sed 's|[^/]*$|.deps/&|;s|\\.o$||'`;\\\n",
      "\u001b[94mcmd1:\u001b[0m g++ -DHAVE_CONFIG_H   -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../script  -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char  -std=c++11 -MT fstdisambiguate.o -MD -MP -MF $depbase.Tpo -c -o fstdisambiguate.o /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/fstdisambiguate.cc &&\\\n",
      "\u001b[94mcmd1:\u001b[0m mv -f $depbase.Tpo $depbase.Po\n",
      "\u001b[94mcmd1:\u001b[0m depbase=`echo fstdisambiguate-main.o | sed 's|[^/]*$|.deps/&|;s|\\.o$||'`;\\\n",
      "\u001b[94mcmd1:\u001b[0m g++ -DHAVE_CONFIG_H   -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../script  -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char  -std=c++11 -MT fstdisambiguate-main.o -MD -MP -MF $depbase.Tpo -c -o fstdisambiguate-main.o /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/fstdisambiguate-main.cc &&\\\n",
      "\u001b[94mcmd1:\u001b[0m mv -f $depbase.Tpo $depbase.Po\n",
      "\u001b[94mcmd1:\u001b[0m depbase=`echo fstdraw.o | sed 's|[^/]*$|.deps/&|;s|\\.o$||'`;\\\n",
      "\u001b[94mcmd1:\u001b[0m g++ -DHAVE_CONFIG_H   -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../script  -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char  -std=c++11 -MT fstdraw.o -MD -MP -MF $depbase.Tpo -c -o fstdraw.o /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/fstdraw.cc &&\\\n",
      "\u001b[94mcmd1:\u001b[0m mv -f $depbase.Tpo $depbase.Po\n",
      "\u001b[94mcmd1:\u001b[0m depbase=`echo fstdraw-main.o | sed 's|[^/]*$|.deps/&|;s|\\.o$||'`;\\\n",
      "\u001b[94mcmd1:\u001b[0m g++ -DHAVE_CONFIG_H   -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../script  -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char  -std=c++11 -MT fstdraw-main.o -MD -MP -MF $depbase.Tpo -c -o fstdraw-main.o /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/fstdraw-main.cc &&\\\n",
      "\u001b[94mcmd1:\u001b[0m mv -f $depbase.Tpo $depbase.Po\n",
      "\u001b[94mcmd1:\u001b[0m depbase=`echo fstencode.o | sed 's|[^/]*$|.deps/&|;s|\\.o$||'`;\\\n",
      "\u001b[94mcmd1:\u001b[0m g++ -DHAVE_CONFIG_H   -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../script  -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char  -std=c++11 -MT fstencode.o -MD -MP -MF $depbase.Tpo -c -o fstencode.o /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/fstencode.cc &&\\\n",
      "\u001b[94mcmd1:\u001b[0m mv -f $depbase.Tpo $depbase.Po\n",
      "\u001b[94mcmd1:\u001b[0m depbase=`echo fstencode-main.o | sed 's|[^/]*$|.deps/&|;s|\\.o$||'`;\\\n",
      "\u001b[94mcmd1:\u001b[0m g++ -DHAVE_CONFIG_H   -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../script  -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char  -std=c++11 -MT fstencode-main.o -MD -MP -MF $depbase.Tpo -c -o fstencode-main.o /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/fstencode-main.cc &&\\\n",
      "\u001b[94mcmd1:\u001b[0m mv -f $depbase.Tpo $depbase.Po\n",
      "\u001b[94mcmd1:\u001b[0m depbase=`echo fstepsnormalize.o | sed 's|[^/]*$|.deps/&|;s|\\.o$||'`;\\\n",
      "\u001b[94mcmd1:\u001b[0m g++ -DHAVE_CONFIG_H   -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../script  -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char  -std=c++11 -MT fstepsnormalize.o -MD -MP -MF $depbase.Tpo -c -o fstepsnormalize.o /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/fstepsnormalize.cc &&\\\n",
      "\u001b[94mcmd1:\u001b[0m mv -f $depbase.Tpo $depbase.Po\n",
      "\u001b[94mcmd1:\u001b[0m depbase=`echo fstepsnormalize-main.o | sed 's|[^/]*$|.deps/&|;s|\\.o$||'`;\\\n",
      "\u001b[94mcmd1:\u001b[0m g++ -DHAVE_CONFIG_H   -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../script  -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char  -std=c++11 -MT fstepsnormalize-main.o -MD -MP -MF $depbase.Tpo -c -o fstepsnormalize-main.o /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/fstepsnormalize-main.cc &&\\\n",
      "\u001b[94mcmd1:\u001b[0m mv -f $depbase.Tpo $depbase.Po\n",
      "\u001b[94mcmd1:\u001b[0m depbase=`echo fstequal.o | sed 's|[^/]*$|.deps/&|;s|\\.o$||'`;\\\n",
      "\u001b[94mcmd1:\u001b[0m g++ -DHAVE_CONFIG_H   -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../script  -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char  -std=c++11 -MT fstequal.o -MD -MP -MF $depbase.Tpo -c -o fstequal.o /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/fstequal.cc &&\\\n",
      "\u001b[94mcmd1:\u001b[0m mv -f $depbase.Tpo $depbase.Po\n",
      "\u001b[94mcmd1:\u001b[0m depbase=`echo fstequal-main.o | sed 's|[^/]*$|.deps/&|;s|\\.o$||'`;\\\n",
      "\u001b[94mcmd1:\u001b[0m g++ -DHAVE_CONFIG_H   -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../script  -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char  -std=c++11 -MT fstequal-main.o -MD -MP -MF $depbase.Tpo -c -o fstequal-main.o /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/fstequal-main.cc &&\\\n",
      "\u001b[94mcmd1:\u001b[0m mv -f $depbase.Tpo $depbase.Po\n",
      "\u001b[94mcmd1:\u001b[0m depbase=`echo fstequivalent.o | sed 's|[^/]*$|.deps/&|;s|\\.o$||'`;\\\n",
      "\u001b[94mcmd1:\u001b[0m g++ -DHAVE_CONFIG_H   -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../script  -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char  -std=c++11 -MT fstequivalent.o -MD -MP -MF $depbase.Tpo -c -o fstequivalent.o /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/fstequivalent.cc &&\\\n",
      "\u001b[94mcmd1:\u001b[0m mv -f $depbase.Tpo $depbase.Po\n",
      "\u001b[94mcmd1:\u001b[0m depbase=`echo fstequivalent-main.o | sed 's|[^/]*$|.deps/&|;s|\\.o$||'`;\\\n",
      "\u001b[94mcmd1:\u001b[0m g++ -DHAVE_CONFIG_H   -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../script  -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char  -std=c++11 -MT fstequivalent-main.o -MD -MP -MF $depbase.Tpo -c -o fstequivalent-main.o /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/fstequivalent-main.cc &&\\\n",
      "\u001b[94mcmd1:\u001b[0m mv -f $depbase.Tpo $depbase.Po\n",
      "\u001b[94mcmd1:\u001b[0m depbase=`echo fstinfo.o | sed 's|[^/]*$|.deps/&|;s|\\.o$||'`;\\\n",
      "\u001b[94mcmd1:\u001b[0m g++ -DHAVE_CONFIG_H   -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../script  -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char  -std=c++11 -MT fstinfo.o -MD -MP -MF $depbase.Tpo -c -o fstinfo.o /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/fstinfo.cc &&\\\n",
      "\u001b[94mcmd1:\u001b[0m mv -f $depbase.Tpo $depbase.Po\n",
      "\u001b[94mcmd1:\u001b[0m depbase=`echo fstinfo-main.o | sed 's|[^/]*$|.deps/&|;s|\\.o$||'`;\\\n",
      "\u001b[94mcmd1:\u001b[0m g++ -DHAVE_CONFIG_H   -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../script  -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char  -std=c++11 -MT fstinfo-main.o -MD -MP -MF $depbase.Tpo -c -o fstinfo-main.o /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/fstinfo-main.cc &&\\\n",
      "\u001b[94mcmd1:\u001b[0m mv -f $depbase.Tpo $depbase.Po\n",
      "\u001b[94mcmd1:\u001b[0m depbase=`echo fstintersect.o | sed 's|[^/]*$|.deps/&|;s|\\.o$||'`;\\\n",
      "\u001b[94mcmd1:\u001b[0m g++ -DHAVE_CONFIG_H   -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../script  -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char  -std=c++11 -MT fstintersect.o -MD -MP -MF $depbase.Tpo -c -o fstintersect.o /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/fstintersect.cc &&\\\n",
      "\u001b[94mcmd1:\u001b[0m mv -f $depbase.Tpo $depbase.Po\n",
      "\u001b[94mcmd1:\u001b[0m depbase=`echo fstintersect-main.o | sed 's|[^/]*$|.deps/&|;s|\\.o$||'`;\\\n",
      "\u001b[94mcmd1:\u001b[0m g++ -DHAVE_CONFIG_H   -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../script  -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char  -std=c++11 -MT fstintersect-main.o -MD -MP -MF $depbase.Tpo -c -o fstintersect-main.o /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/fstintersect-main.cc &&\\\n",
      "\u001b[94mcmd1:\u001b[0m mv -f $depbase.Tpo $depbase.Po\n",
      "\u001b[94mcmd1:\u001b[0m depbase=`echo fstinvert.o | sed 's|[^/]*$|.deps/&|;s|\\.o$||'`;\\\n",
      "\u001b[94mcmd1:\u001b[0m g++ -DHAVE_CONFIG_H   -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../script  -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char  -std=c++11 -MT fstinvert.o -MD -MP -MF $depbase.Tpo -c -o fstinvert.o /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/fstinvert.cc &&\\\n",
      "\u001b[94mcmd1:\u001b[0m mv -f $depbase.Tpo $depbase.Po\n",
      "\u001b[94mcmd1:\u001b[0m depbase=`echo fstinvert-main.o | sed 's|[^/]*$|.deps/&|;s|\\.o$||'`;\\\n",
      "\u001b[94mcmd1:\u001b[0m g++ -DHAVE_CONFIG_H   -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../script  -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char  -std=c++11 -MT fstinvert-main.o -MD -MP -MF $depbase.Tpo -c -o fstinvert-main.o /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/fstinvert-main.cc &&\\\n",
      "\u001b[94mcmd1:\u001b[0m mv -f $depbase.Tpo $depbase.Po\n",
      "\u001b[92mcmd2:\u001b[0m Still waiting for remote lm reset from ts 1766528432100...\n",
      "\u001b[94mcmd1:\u001b[0m depbase=`echo fstisomorphic.o | sed 's|[^/]*$|.deps/&|;s|\\.o$||'`;\\\n",
      "\u001b[94mcmd1:\u001b[0m g++ -DHAVE_CONFIG_H   -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../script  -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char  -std=c++11 -MT fstisomorphic.o -MD -MP -MF $depbase.Tpo -c -o fstisomorphic.o /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/fstisomorphic.cc &&\\\n",
      "\u001b[94mcmd1:\u001b[0m mv -f $depbase.Tpo $depbase.Po\n",
      "\u001b[94mcmd1:\u001b[0m depbase=`echo fstisomorphic-main.o | sed 's|[^/]*$|.deps/&|;s|\\.o$||'`;\\\n",
      "\u001b[94mcmd1:\u001b[0m g++ -DHAVE_CONFIG_H   -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../script  -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char  -std=c++11 -MT fstisomorphic-main.o -MD -MP -MF $depbase.Tpo -c -o fstisomorphic-main.o /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/fstisomorphic-main.cc &&\\\n",
      "\u001b[94mcmd1:\u001b[0m mv -f $depbase.Tpo $depbase.Po\n",
      "\u001b[94mcmd1:\u001b[0m depbase=`echo fstmap.o | sed 's|[^/]*$|.deps/&|;s|\\.o$||'`;\\\n",
      "\u001b[94mcmd1:\u001b[0m g++ -DHAVE_CONFIG_H   -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../script  -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char  -std=c++11 -MT fstmap.o -MD -MP -MF $depbase.Tpo -c -o fstmap.o /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/fstmap.cc &&\\\n",
      "\u001b[94mcmd1:\u001b[0m mv -f $depbase.Tpo $depbase.Po\n",
      "\u001b[94mcmd1:\u001b[0m depbase=`echo fstmap-main.o | sed 's|[^/]*$|.deps/&|;s|\\.o$||'`;\\\n",
      "\u001b[94mcmd1:\u001b[0m g++ -DHAVE_CONFIG_H   -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../script  -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char  -std=c++11 -MT fstmap-main.o -MD -MP -MF $depbase.Tpo -c -o fstmap-main.o /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/fstmap-main.cc &&\\\n",
      "\u001b[94mcmd1:\u001b[0m mv -f $depbase.Tpo $depbase.Po\n",
      "\u001b[94mcmd1:\u001b[0m depbase=`echo fstminimize.o | sed 's|[^/]*$|.deps/&|;s|\\.o$||'`;\\\n",
      "\u001b[94mcmd1:\u001b[0m g++ -DHAVE_CONFIG_H   -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../script  -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char  -std=c++11 -MT fstminimize.o -MD -MP -MF $depbase.Tpo -c -o fstminimize.o /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/fstminimize.cc &&\\\n",
      "\u001b[94mcmd1:\u001b[0m mv -f $depbase.Tpo $depbase.Po\n",
      "\u001b[94mcmd1:\u001b[0m depbase=`echo fstminimize-main.o | sed 's|[^/]*$|.deps/&|;s|\\.o$||'`;\\\n",
      "\u001b[94mcmd1:\u001b[0m g++ -DHAVE_CONFIG_H   -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../script  -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char  -std=c++11 -MT fstminimize-main.o -MD -MP -MF $depbase.Tpo -c -o fstminimize-main.o /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/fstminimize-main.cc &&\\\n",
      "\u001b[94mcmd1:\u001b[0m mv -f $depbase.Tpo $depbase.Po\n",
      "\u001b[94mcmd1:\u001b[0m depbase=`echo fstprint.o | sed 's|[^/]*$|.deps/&|;s|\\.o$||'`;\\\n",
      "\u001b[94mcmd1:\u001b[0m g++ -DHAVE_CONFIG_H   -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../script  -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char  -std=c++11 -MT fstprint.o -MD -MP -MF $depbase.Tpo -c -o fstprint.o /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/fstprint.cc &&\\\n",
      "\u001b[94mcmd1:\u001b[0m mv -f $depbase.Tpo $depbase.Po\n",
      "\u001b[94mcmd1:\u001b[0m depbase=`echo fstprint-main.o | sed 's|[^/]*$|.deps/&|;s|\\.o$||'`;\\\n",
      "\u001b[94mcmd1:\u001b[0m g++ -DHAVE_CONFIG_H   -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../script  -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char  -std=c++11 -MT fstprint-main.o -MD -MP -MF $depbase.Tpo -c -o fstprint-main.o /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/fstprint-main.cc &&\\\n",
      "\u001b[94mcmd1:\u001b[0m mv -f $depbase.Tpo $depbase.Po\n",
      "\u001b[94mcmd1:\u001b[0m depbase=`echo fstproject.o | sed 's|[^/]*$|.deps/&|;s|\\.o$||'`;\\\n",
      "\u001b[94mcmd1:\u001b[0m g++ -DHAVE_CONFIG_H   -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../script  -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char  -std=c++11 -MT fstproject.o -MD -MP -MF $depbase.Tpo -c -o fstproject.o /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/fstproject.cc &&\\\n",
      "\u001b[94mcmd1:\u001b[0m mv -f $depbase.Tpo $depbase.Po\n",
      "\u001b[94mcmd1:\u001b[0m depbase=`echo fstproject-main.o | sed 's|[^/]*$|.deps/&|;s|\\.o$||'`;\\\n",
      "\u001b[94mcmd1:\u001b[0m g++ -DHAVE_CONFIG_H   -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../script  -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char  -std=c++11 -MT fstproject-main.o -MD -MP -MF $depbase.Tpo -c -o fstproject-main.o /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/fstproject-main.cc &&\\\n",
      "\u001b[94mcmd1:\u001b[0m mv -f $depbase.Tpo $depbase.Po\n",
      "\u001b[94mcmd1:\u001b[0m depbase=`echo fstprune.o | sed 's|[^/]*$|.deps/&|;s|\\.o$||'`;\\\n",
      "\u001b[94mcmd1:\u001b[0m g++ -DHAVE_CONFIG_H   -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../script  -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char  -std=c++11 -MT fstprune.o -MD -MP -MF $depbase.Tpo -c -o fstprune.o /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/fstprune.cc &&\\\n",
      "\u001b[94mcmd1:\u001b[0m mv -f $depbase.Tpo $depbase.Po\n",
      "\u001b[94mcmd1:\u001b[0m depbase=`echo fstprune-main.o | sed 's|[^/]*$|.deps/&|;s|\\.o$||'`;\\\n",
      "\u001b[94mcmd1:\u001b[0m g++ -DHAVE_CONFIG_H   -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../script  -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char  -std=c++11 -MT fstprune-main.o -MD -MP -MF $depbase.Tpo -c -o fstprune-main.o /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/fstprune-main.cc &&\\\n",
      "\u001b[94mcmd1:\u001b[0m mv -f $depbase.Tpo $depbase.Po\n",
      "\u001b[94mcmd1:\u001b[0m depbase=`echo fstpush.o | sed 's|[^/]*$|.deps/&|;s|\\.o$||'`;\\\n",
      "\u001b[94mcmd1:\u001b[0m g++ -DHAVE_CONFIG_H   -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../script  -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char  -std=c++11 -MT fstpush.o -MD -MP -MF $depbase.Tpo -c -o fstpush.o /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/fstpush.cc &&\\\n",
      "\u001b[94mcmd1:\u001b[0m mv -f $depbase.Tpo $depbase.Po\n",
      "\u001b[94mcmd1:\u001b[0m depbase=`echo fstpush-main.o | sed 's|[^/]*$|.deps/&|;s|\\.o$||'`;\\\n",
      "\u001b[94mcmd1:\u001b[0m g++ -DHAVE_CONFIG_H   -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../script  -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char  -std=c++11 -MT fstpush-main.o -MD -MP -MF $depbase.Tpo -c -o fstpush-main.o /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/fstpush-main.cc &&\\\n",
      "\u001b[94mcmd1:\u001b[0m mv -f $depbase.Tpo $depbase.Po\n",
      "\u001b[94mcmd1:\u001b[0m depbase=`echo fstrandgen.o | sed 's|[^/]*$|.deps/&|;s|\\.o$||'`;\\\n",
      "\u001b[94mcmd1:\u001b[0m g++ -DHAVE_CONFIG_H   -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../script  -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char  -std=c++11 -MT fstrandgen.o -MD -MP -MF $depbase.Tpo -c -o fstrandgen.o /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/fstrandgen.cc &&\\\n",
      "\u001b[94mcmd1:\u001b[0m mv -f $depbase.Tpo $depbase.Po\n",
      "\u001b[94mcmd1:\u001b[0m depbase=`echo fstrandgen-main.o | sed 's|[^/]*$|.deps/&|;s|\\.o$||'`;\\\n",
      "\u001b[94mcmd1:\u001b[0m g++ -DHAVE_CONFIG_H   -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../script  -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char  -std=c++11 -MT fstrandgen-main.o -MD -MP -MF $depbase.Tpo -c -o fstrandgen-main.o /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/fstrandgen-main.cc &&\\\n",
      "\u001b[94mcmd1:\u001b[0m mv -f $depbase.Tpo $depbase.Po\n",
      "\u001b[94mcmd1:\u001b[0m depbase=`echo fstrelabel.o | sed 's|[^/]*$|.deps/&|;s|\\.o$||'`;\\\n",
      "\u001b[94mcmd1:\u001b[0m g++ -DHAVE_CONFIG_H   -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../script  -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char  -std=c++11 -MT fstrelabel.o -MD -MP -MF $depbase.Tpo -c -o fstrelabel.o /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/fstrelabel.cc &&\\\n",
      "\u001b[94mcmd1:\u001b[0m mv -f $depbase.Tpo $depbase.Po\n",
      "\u001b[94mcmd1:\u001b[0m depbase=`echo fstrelabel-main.o | sed 's|[^/]*$|.deps/&|;s|\\.o$||'`;\\\n",
      "\u001b[94mcmd1:\u001b[0m g++ -DHAVE_CONFIG_H   -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../script  -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char  -std=c++11 -MT fstrelabel-main.o -MD -MP -MF $depbase.Tpo -c -o fstrelabel-main.o /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/fstrelabel-main.cc &&\\\n",
      "\u001b[94mcmd1:\u001b[0m mv -f $depbase.Tpo $depbase.Po\n",
      "\u001b[94mcmd1:\u001b[0m depbase=`echo fstreplace.o | sed 's|[^/]*$|.deps/&|;s|\\.o$||'`;\\\n",
      "\u001b[94mcmd1:\u001b[0m g++ -DHAVE_CONFIG_H   -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../script  -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char  -std=c++11 -MT fstreplace.o -MD -MP -MF $depbase.Tpo -c -o fstreplace.o /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/fstreplace.cc &&\\\n",
      "\u001b[94mcmd1:\u001b[0m mv -f $depbase.Tpo $depbase.Po\n",
      "\u001b[94mcmd1:\u001b[0m depbase=`echo fstreplace-main.o | sed 's|[^/]*$|.deps/&|;s|\\.o$||'`;\\\n",
      "\u001b[94mcmd1:\u001b[0m g++ -DHAVE_CONFIG_H   -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../script  -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char  -std=c++11 -MT fstreplace-main.o -MD -MP -MF $depbase.Tpo -c -o fstreplace-main.o /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/fstreplace-main.cc &&\\\n",
      "\u001b[94mcmd1:\u001b[0m mv -f $depbase.Tpo $depbase.Po\n",
      "\u001b[94mcmd1:\u001b[0m depbase=`echo fstreverse.o | sed 's|[^/]*$|.deps/&|;s|\\.o$||'`;\\\n",
      "\u001b[94mcmd1:\u001b[0m g++ -DHAVE_CONFIG_H   -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../script  -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char  -std=c++11 -MT fstreverse.o -MD -MP -MF $depbase.Tpo -c -o fstreverse.o /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/fstreverse.cc &&\\\n",
      "\u001b[94mcmd1:\u001b[0m mv -f $depbase.Tpo $depbase.Po\n",
      "\u001b[94mcmd1:\u001b[0m depbase=`echo fstreverse-main.o | sed 's|[^/]*$|.deps/&|;s|\\.o$||'`;\\\n",
      "\u001b[94mcmd1:\u001b[0m g++ -DHAVE_CONFIG_H   -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../script  -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char  -std=c++11 -MT fstreverse-main.o -MD -MP -MF $depbase.Tpo -c -o fstreverse-main.o /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/fstreverse-main.cc &&\\\n",
      "\u001b[94mcmd1:\u001b[0m mv -f $depbase.Tpo $depbase.Po\n",
      "\u001b[94mcmd1:\u001b[0m depbase=`echo fstreweight.o | sed 's|[^/]*$|.deps/&|;s|\\.o$||'`;\\\n",
      "\u001b[94mcmd1:\u001b[0m g++ -DHAVE_CONFIG_H   -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../script  -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char  -std=c++11 -MT fstreweight.o -MD -MP -MF $depbase.Tpo -c -o fstreweight.o /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/fstreweight.cc &&\\\n",
      "\u001b[94mcmd1:\u001b[0m mv -f $depbase.Tpo $depbase.Po\n",
      "\u001b[94mcmd1:\u001b[0m depbase=`echo fstreweight-main.o | sed 's|[^/]*$|.deps/&|;s|\\.o$||'`;\\\n",
      "\u001b[94mcmd1:\u001b[0m g++ -DHAVE_CONFIG_H   -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../script  -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char  -std=c++11 -MT fstreweight-main.o -MD -MP -MF $depbase.Tpo -c -o fstreweight-main.o /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/fstreweight-main.cc &&\\\n",
      "\u001b[94mcmd1:\u001b[0m mv -f $depbase.Tpo $depbase.Po\n",
      "\u001b[94mcmd1:\u001b[0m depbase=`echo fstrmepsilon.o | sed 's|[^/]*$|.deps/&|;s|\\.o$||'`;\\\n",
      "\u001b[94mcmd1:\u001b[0m g++ -DHAVE_CONFIG_H   -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../script  -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char  -std=c++11 -MT fstrmepsilon.o -MD -MP -MF $depbase.Tpo -c -o fstrmepsilon.o /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/fstrmepsilon.cc &&\\\n",
      "\u001b[94mcmd1:\u001b[0m mv -f $depbase.Tpo $depbase.Po\n",
      "\u001b[94mcmd1:\u001b[0m depbase=`echo fstrmepsilon-main.o | sed 's|[^/]*$|.deps/&|;s|\\.o$||'`;\\\n",
      "\u001b[94mcmd1:\u001b[0m g++ -DHAVE_CONFIG_H   -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../script  -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char  -std=c++11 -MT fstrmepsilon-main.o -MD -MP -MF $depbase.Tpo -c -o fstrmepsilon-main.o /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/fstrmepsilon-main.cc &&\\\n",
      "\u001b[94mcmd1:\u001b[0m mv -f $depbase.Tpo $depbase.Po\n",
      "\u001b[94mcmd1:\u001b[0m depbase=`echo fstshortestdistance.o | sed 's|[^/]*$|.deps/&|;s|\\.o$||'`;\\\n",
      "\u001b[94mcmd1:\u001b[0m g++ -DHAVE_CONFIG_H   -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../script  -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char  -std=c++11 -MT fstshortestdistance.o -MD -MP -MF $depbase.Tpo -c -o fstshortestdistance.o /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/fstshortestdistance.cc &&\\\n",
      "\u001b[94mcmd1:\u001b[0m mv -f $depbase.Tpo $depbase.Po\n",
      "\u001b[94mcmd1:\u001b[0m depbase=`echo fstshortestdistance-main.o | sed 's|[^/]*$|.deps/&|;s|\\.o$||'`;\\\n",
      "\u001b[94mcmd1:\u001b[0m g++ -DHAVE_CONFIG_H   -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../script  -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char  -std=c++11 -MT fstshortestdistance-main.o -MD -MP -MF $depbase.Tpo -c -o fstshortestdistance-main.o /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/fstshortestdistance-main.cc &&\\\n",
      "\u001b[94mcmd1:\u001b[0m mv -f $depbase.Tpo $depbase.Po\n",
      "\u001b[94mcmd1:\u001b[0m depbase=`echo fstshortestpath.o | sed 's|[^/]*$|.deps/&|;s|\\.o$||'`;\\\n",
      "\u001b[94mcmd1:\u001b[0m g++ -DHAVE_CONFIG_H   -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../script  -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char  -std=c++11 -MT fstshortestpath.o -MD -MP -MF $depbase.Tpo -c -o fstshortestpath.o /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/fstshortestpath.cc &&\\\n",
      "\u001b[94mcmd1:\u001b[0m mv -f $depbase.Tpo $depbase.Po\n",
      "\u001b[94mcmd1:\u001b[0m depbase=`echo fstshortestpath-main.o | sed 's|[^/]*$|.deps/&|;s|\\.o$||'`;\\\n",
      "\u001b[94mcmd1:\u001b[0m g++ -DHAVE_CONFIG_H   -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../script  -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char  -std=c++11 -MT fstshortestpath-main.o -MD -MP -MF $depbase.Tpo -c -o fstshortestpath-main.o /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/fstshortestpath-main.cc &&\\\n",
      "\u001b[94mcmd1:\u001b[0m mv -f $depbase.Tpo $depbase.Po\n",
      "\u001b[94mcmd1:\u001b[0m depbase=`echo fstsymbols.o | sed 's|[^/]*$|.deps/&|;s|\\.o$||'`;\\\n",
      "\u001b[94mcmd1:\u001b[0m g++ -DHAVE_CONFIG_H   -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../script  -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char  -std=c++11 -MT fstsymbols.o -MD -MP -MF $depbase.Tpo -c -o fstsymbols.o /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/fstsymbols.cc &&\\\n",
      "\u001b[94mcmd1:\u001b[0m mv -f $depbase.Tpo $depbase.Po\n",
      "\u001b[94mcmd1:\u001b[0m depbase=`echo fstsymbols-main.o | sed 's|[^/]*$|.deps/&|;s|\\.o$||'`;\\\n",
      "\u001b[94mcmd1:\u001b[0m g++ -DHAVE_CONFIG_H   -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../script  -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char  -std=c++11 -MT fstsymbols-main.o -MD -MP -MF $depbase.Tpo -c -o fstsymbols-main.o /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/fstsymbols-main.cc &&\\\n",
      "\u001b[94mcmd1:\u001b[0m mv -f $depbase.Tpo $depbase.Po\n",
      "\u001b[94mcmd1:\u001b[0m depbase=`echo fstsynchronize.o | sed 's|[^/]*$|.deps/&|;s|\\.o$||'`;\\\n",
      "\u001b[94mcmd1:\u001b[0m g++ -DHAVE_CONFIG_H   -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../script  -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char  -std=c++11 -MT fstsynchronize.o -MD -MP -MF $depbase.Tpo -c -o fstsynchronize.o /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/fstsynchronize.cc &&\\\n",
      "\u001b[94mcmd1:\u001b[0m mv -f $depbase.Tpo $depbase.Po\n",
      "\u001b[94mcmd1:\u001b[0m depbase=`echo fstsynchronize-main.o | sed 's|[^/]*$|.deps/&|;s|\\.o$||'`;\\\n",
      "\u001b[94mcmd1:\u001b[0m g++ -DHAVE_CONFIG_H   -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../script  -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char  -std=c++11 -MT fstsynchronize-main.o -MD -MP -MF $depbase.Tpo -c -o fstsynchronize-main.o /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/fstsynchronize-main.cc &&\\\n",
      "\u001b[94mcmd1:\u001b[0m mv -f $depbase.Tpo $depbase.Po\n",
      "\u001b[94mcmd1:\u001b[0m depbase=`echo fsttopsort.o | sed 's|[^/]*$|.deps/&|;s|\\.o$||'`;\\\n",
      "\u001b[94mcmd1:\u001b[0m g++ -DHAVE_CONFIG_H   -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../script  -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char  -std=c++11 -MT fsttopsort.o -MD -MP -MF $depbase.Tpo -c -o fsttopsort.o /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/fsttopsort.cc &&\\\n",
      "\u001b[94mcmd1:\u001b[0m mv -f $depbase.Tpo $depbase.Po\n",
      "\u001b[94mcmd1:\u001b[0m depbase=`echo fsttopsort-main.o | sed 's|[^/]*$|.deps/&|;s|\\.o$||'`;\\\n",
      "\u001b[94mcmd1:\u001b[0m g++ -DHAVE_CONFIG_H   -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../script  -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char  -std=c++11 -MT fsttopsort-main.o -MD -MP -MF $depbase.Tpo -c -o fsttopsort-main.o /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/fsttopsort-main.cc &&\\\n",
      "\u001b[94mcmd1:\u001b[0m mv -f $depbase.Tpo $depbase.Po\n",
      "\u001b[92mcmd2:\u001b[0m Still waiting for remote lm reset from ts 1766528432100...\n",
      "\u001b[94mcmd1:\u001b[0m depbase=`echo fstunion.o | sed 's|[^/]*$|.deps/&|;s|\\.o$||'`;\\\n",
      "\u001b[94mcmd1:\u001b[0m g++ -DHAVE_CONFIG_H   -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../script  -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char  -std=c++11 -MT fstunion.o -MD -MP -MF $depbase.Tpo -c -o fstunion.o /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/fstunion.cc &&\\\n",
      "\u001b[94mcmd1:\u001b[0m mv -f $depbase.Tpo $depbase.Po\n",
      "\u001b[94mcmd1:\u001b[0m depbase=`echo fstunion-main.o | sed 's|[^/]*$|.deps/&|;s|\\.o$||'`;\\\n",
      "\u001b[94mcmd1:\u001b[0m g++ -DHAVE_CONFIG_H   -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/../script  -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -D_GLIBCXX_USE_CXX11_ABI=0 -fno-exceptions -funsigned-char  -std=c++11 -MT fstunion-main.o -MD -MP -MF $depbase.Tpo -c -o fstunion-main.o /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/bin/fstunion-main.cc &&\\\n",
      "\u001b[94mcmd1:\u001b[0m mv -f $depbase.Tpo $depbase.Po\n",
      "\u001b[94mcmd1:\u001b[0m /bin/bash ../../libtool  --tag=CXX   --mode=link g++  -std=c++11  -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -o fstarcsort fstarcsort.o fstarcsort-main.o ../script/libfstscript.la ../lib/libfst.la -lm -ldl -lgflags_nothreads -lglog -lpthread\n",
      "\u001b[94mcmd1:\u001b[0m libtool: link: g++ -std=c++11 -o .libs/fstarcsort fstarcsort.o fstarcsort-main.o  -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build ../script/.libs/libfstscript.so ../lib/.libs/libfst.so -lm -ldl -lgflags_nothreads -lglog -lpthread -Wl,-rpath -Wl,/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-subbuild/openfst-populate-prefix/lib\n",
      "\u001b[94mcmd1:\u001b[0m /bin/bash ../../libtool  --tag=CXX   --mode=link g++  -std=c++11  -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -o fstclosure fstclosure.o fstclosure-main.o ../script/libfstscript.la ../lib/libfst.la -lm -ldl -lgflags_nothreads -lglog -lpthread\n",
      "\u001b[94mcmd1:\u001b[0m /bin/bash ../../libtool  --tag=CXX   --mode=link g++  -std=c++11  -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -o fstcompile fstcompile.o fstcompile-main.o ../script/libfstscript.la ../lib/libfst.la -lm -ldl -lgflags_nothreads -lglog -lpthread\n",
      "\u001b[94mcmd1:\u001b[0m libtool: link: g++ -std=c++11 -o .libs/fstclosure fstclosure.o fstclosure-main.o  -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build ../script/.libs/libfstscript.so ../lib/.libs/libfst.so -lm -ldl -lgflags_nothreads -lglog -lpthread -Wl,-rpath -Wl,/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-subbuild/openfst-populate-prefix/lib\n",
      "\u001b[94mcmd1:\u001b[0m libtool: link: g++ -std=c++11 -o .libs/fstcompile fstcompile.o fstcompile-main.o  -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build ../script/.libs/libfstscript.so ../lib/.libs/libfst.so -lm -ldl -lgflags_nothreads -lglog -lpthread -Wl,-rpath -Wl,/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-subbuild/openfst-populate-prefix/lib\n",
      "\u001b[94mcmd1:\u001b[0m /bin/bash ../../libtool  --tag=CXX   --mode=link g++  -std=c++11  -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -o fstcompose fstcompose.o fstcompose-main.o ../script/libfstscript.la ../lib/libfst.la -lm -ldl -lgflags_nothreads -lglog -lpthread\n",
      "\u001b[94mcmd1:\u001b[0m /bin/bash ../../libtool  --tag=CXX   --mode=link g++  -std=c++11  -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -o fstconcat fstconcat.o fstconcat-main.o ../script/libfstscript.la ../lib/libfst.la -lm -ldl -lgflags_nothreads -lglog -lpthread\n",
      "\u001b[94mcmd1:\u001b[0m libtool: link: g++ -std=c++11 -o .libs/fstcompose fstcompose.o fstcompose-main.o  -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build ../script/.libs/libfstscript.so ../lib/.libs/libfst.so -lm -ldl -lgflags_nothreads -lglog -lpthread -Wl,-rpath -Wl,/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-subbuild/openfst-populate-prefix/lib\n",
      "\u001b[94mcmd1:\u001b[0m libtool: link: g++ -std=c++11 -o .libs/fstconcat fstconcat.o fstconcat-main.o  -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build ../script/.libs/libfstscript.so ../lib/.libs/libfst.so -lm -ldl -lgflags_nothreads -lglog -lpthread -Wl,-rpath -Wl,/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-subbuild/openfst-populate-prefix/lib\n",
      "\u001b[94mcmd1:\u001b[0m /bin/bash ../../libtool  --tag=CXX   --mode=link g++  -std=c++11  -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -o fstconnect fstconnect.o fstconnect-main.o ../script/libfstscript.la ../lib/libfst.la -lm -ldl -lgflags_nothreads -lglog -lpthread\n",
      "\u001b[94mcmd1:\u001b[0m /bin/bash ../../libtool  --tag=CXX   --mode=link g++  -std=c++11  -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -o fstconvert fstconvert.o fstconvert-main.o ../script/libfstscript.la ../lib/libfst.la -lm -ldl -lgflags_nothreads -lglog -lpthread\n",
      "\u001b[94mcmd1:\u001b[0m libtool: link: g++ -std=c++11 -o .libs/fstconnect fstconnect.o fstconnect-main.o  -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build ../script/.libs/libfstscript.so ../lib/.libs/libfst.so -lm -ldl -lgflags_nothreads -lglog -lpthread -Wl,-rpath -Wl,/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-subbuild/openfst-populate-prefix/lib\n",
      "\u001b[94mcmd1:\u001b[0m libtool: link: g++ -std=c++11 -o .libs/fstconvert fstconvert.o fstconvert-main.o  -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build ../script/.libs/libfstscript.so ../lib/.libs/libfst.so -lm -ldl -lgflags_nothreads -lglog -lpthread -Wl,-rpath -Wl,/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-subbuild/openfst-populate-prefix/lib\n",
      "\u001b[94mcmd1:\u001b[0m /bin/bash ../../libtool  --tag=CXX   --mode=link g++  -std=c++11  -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -o fstdeterminize fstdeterminize.o fstdeterminize-main.o ../script/libfstscript.la ../lib/libfst.la -lm -ldl -lgflags_nothreads -lglog -lpthread\n",
      "\u001b[94mcmd1:\u001b[0m /bin/bash ../../libtool  --tag=CXX   --mode=link g++  -std=c++11  -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -o fstdifference fstdifference.o fstdifference-main.o ../script/libfstscript.la ../lib/libfst.la -lm -ldl -lgflags_nothreads -lglog -lpthread\n",
      "\u001b[94mcmd1:\u001b[0m libtool: link: g++ -std=c++11 -o .libs/fstdeterminize fstdeterminize.o fstdeterminize-main.o  -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build ../script/.libs/libfstscript.so ../lib/.libs/libfst.so -lm -ldl -lgflags_nothreads -lglog -lpthread -Wl,-rpath -Wl,/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-subbuild/openfst-populate-prefix/lib\n",
      "\u001b[94mcmd1:\u001b[0m libtool: link: g++ -std=c++11 -o .libs/fstdifference fstdifference.o fstdifference-main.o  -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build ../script/.libs/libfstscript.so ../lib/.libs/libfst.so -lm -ldl -lgflags_nothreads -lglog -lpthread -Wl,-rpath -Wl,/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-subbuild/openfst-populate-prefix/lib\n",
      "\u001b[94mcmd1:\u001b[0m /bin/bash ../../libtool  --tag=CXX   --mode=link g++  -std=c++11  -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -o fstdisambiguate fstdisambiguate.o fstdisambiguate-main.o ../script/libfstscript.la ../lib/libfst.la -lm -ldl -lgflags_nothreads -lglog -lpthread\n",
      "\u001b[94mcmd1:\u001b[0m /bin/bash ../../libtool  --tag=CXX   --mode=link g++  -std=c++11  -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -o fstdraw fstdraw.o fstdraw-main.o ../script/libfstscript.la ../lib/libfst.la -lm -ldl -lgflags_nothreads -lglog -lpthread\n",
      "\u001b[94mcmd1:\u001b[0m libtool: link: g++ -std=c++11 -o .libs/fstdisambiguate fstdisambiguate.o fstdisambiguate-main.o  -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build ../script/.libs/libfstscript.so ../lib/.libs/libfst.so -lm -ldl -lgflags_nothreads -lglog -lpthread -Wl,-rpath -Wl,/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-subbuild/openfst-populate-prefix/lib\n",
      "\u001b[94mcmd1:\u001b[0m libtool: link: g++ -std=c++11 -o .libs/fstdraw fstdraw.o fstdraw-main.o  -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build ../script/.libs/libfstscript.so ../lib/.libs/libfst.so -lm -ldl -lgflags_nothreads -lglog -lpthread -Wl,-rpath -Wl,/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-subbuild/openfst-populate-prefix/lib\n",
      "\u001b[94mcmd1:\u001b[0m /bin/bash ../../libtool  --tag=CXX   --mode=link g++  -std=c++11  -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -o fstencode fstencode.o fstencode-main.o ../script/libfstscript.la ../lib/libfst.la -lm -ldl -lgflags_nothreads -lglog -lpthread\n",
      "\u001b[94mcmd1:\u001b[0m /bin/bash ../../libtool  --tag=CXX   --mode=link g++  -std=c++11  -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -o fstepsnormalize fstepsnormalize.o fstepsnormalize-main.o ../script/libfstscript.la ../lib/libfst.la -lm -ldl -lgflags_nothreads -lglog -lpthread\n",
      "\u001b[94mcmd1:\u001b[0m libtool: link: g++ -std=c++11 -o .libs/fstencode fstencode.o fstencode-main.o  -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build ../script/.libs/libfstscript.so ../lib/.libs/libfst.so -lm -ldl -lgflags_nothreads -lglog -lpthread -Wl,-rpath -Wl,/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-subbuild/openfst-populate-prefix/lib\n",
      "\u001b[94mcmd1:\u001b[0m /bin/bash ../../libtool  --tag=CXX   --mode=link g++  -std=c++11  -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -o fstequal fstequal.o fstequal-main.o ../script/libfstscript.la ../lib/libfst.la -lm -ldl -lgflags_nothreads -lglog -lpthread\n",
      "\u001b[94mcmd1:\u001b[0m /bin/bash ../../libtool  --tag=CXX   --mode=link g++  -std=c++11  -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -o fstequivalent fstequivalent.o fstequivalent-main.o ../script/libfstscript.la ../lib/libfst.la -lm -ldl -lgflags_nothreads -lglog -lpthread\n",
      "\u001b[94mcmd1:\u001b[0m libtool: link: g++ -std=c++11 -o .libs/fstepsnormalize fstepsnormalize.o fstepsnormalize-main.o  -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build ../script/.libs/libfstscript.so ../lib/.libs/libfst.so -lm -ldl -lgflags_nothreads -lglog -lpthread -Wl,-rpath -Wl,/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-subbuild/openfst-populate-prefix/lib\n",
      "\u001b[94mcmd1:\u001b[0m libtool: link: g++ -std=c++11 -o .libs/fstequal fstequal.o fstequal-main.o  -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build ../script/.libs/libfstscript.so ../lib/.libs/libfst.so -lm -ldl -lgflags_nothreads -lglog -lpthread -Wl,-rpath -Wl,/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-subbuild/openfst-populate-prefix/lib\n",
      "\u001b[94mcmd1:\u001b[0m libtool: link: g++ -std=c++11 -o .libs/fstequivalent fstequivalent.o fstequivalent-main.o  -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build ../script/.libs/libfstscript.so ../lib/.libs/libfst.so -lm -ldl -lgflags_nothreads -lglog -lpthread -Wl,-rpath -Wl,/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-subbuild/openfst-populate-prefix/lib\n",
      "\u001b[94mcmd1:\u001b[0m /bin/bash ../../libtool  --tag=CXX   --mode=link g++  -std=c++11  -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -o fstinfo fstinfo.o fstinfo-main.o ../script/libfstscript.la ../lib/libfst.la -lm -ldl -lgflags_nothreads -lglog -lpthread\n",
      "\u001b[94mcmd1:\u001b[0m /bin/bash ../../libtool  --tag=CXX   --mode=link g++  -std=c++11  -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -o fstintersect fstintersect.o fstintersect-main.o ../script/libfstscript.la ../lib/libfst.la -lm -ldl -lgflags_nothreads -lglog -lpthread\n",
      "\u001b[94mcmd1:\u001b[0m libtool: link: g++ -std=c++11 -o .libs/fstinfo fstinfo.o fstinfo-main.o  -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build ../script/.libs/libfstscript.so ../lib/.libs/libfst.so -lm -ldl -lgflags_nothreads -lglog -lpthread -Wl,-rpath -Wl,/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-subbuild/openfst-populate-prefix/lib\n",
      "\u001b[94mcmd1:\u001b[0m /bin/bash ../../libtool  --tag=CXX   --mode=link g++  -std=c++11  -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -o fstinvert fstinvert.o fstinvert-main.o ../script/libfstscript.la ../lib/libfst.la -lm -ldl -lgflags_nothreads -lglog -lpthread\n",
      "\u001b[94mcmd1:\u001b[0m /bin/bash ../../libtool  --tag=CXX   --mode=link g++  -std=c++11  -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -o fstisomorphic fstisomorphic.o fstisomorphic-main.o ../script/libfstscript.la ../lib/libfst.la -lm -ldl -lgflags_nothreads -lglog -lpthread\n",
      "\u001b[94mcmd1:\u001b[0m libtool: link: g++ -std=c++11 -o .libs/fstintersect fstintersect.o fstintersect-main.o  -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build ../script/.libs/libfstscript.so ../lib/.libs/libfst.so -lm -ldl -lgflags_nothreads -lglog -lpthread -Wl,-rpath -Wl,/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-subbuild/openfst-populate-prefix/lib\n",
      "\u001b[94mcmd1:\u001b[0m libtool: link: g++ -std=c++11 -o .libs/fstinvert fstinvert.o fstinvert-main.o  -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build ../script/.libs/libfstscript.so ../lib/.libs/libfst.so -lm -ldl -lgflags_nothreads -lglog -lpthread -Wl,-rpath -Wl,/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-subbuild/openfst-populate-prefix/lib\n",
      "\u001b[94mcmd1:\u001b[0m libtool: link: g++ -std=c++11 -o .libs/fstisomorphic fstisomorphic.o fstisomorphic-main.o  -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build ../script/.libs/libfstscript.so ../lib/.libs/libfst.so -lm -ldl -lgflags_nothreads -lglog -lpthread -Wl,-rpath -Wl,/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-subbuild/openfst-populate-prefix/lib\n",
      "\u001b[94mcmd1:\u001b[0m /bin/bash ../../libtool  --tag=CXX   --mode=link g++  -std=c++11  -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -o fstmap fstmap.o fstmap-main.o ../script/libfstscript.la ../lib/libfst.la -lm -ldl -lgflags_nothreads -lglog -lpthread\n",
      "\u001b[94mcmd1:\u001b[0m /bin/bash ../../libtool  --tag=CXX   --mode=link g++  -std=c++11  -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -o fstminimize fstminimize.o fstminimize-main.o ../script/libfstscript.la ../lib/libfst.la -lm -ldl -lgflags_nothreads -lglog -lpthread\n",
      "\u001b[94mcmd1:\u001b[0m libtool: link: g++ -std=c++11 -o .libs/fstmap fstmap.o fstmap-main.o  -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build ../script/.libs/libfstscript.so ../lib/.libs/libfst.so -lm -ldl -lgflags_nothreads -lglog -lpthread -Wl,-rpath -Wl,/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-subbuild/openfst-populate-prefix/lib\n",
      "\u001b[94mcmd1:\u001b[0m /bin/bash ../../libtool  --tag=CXX   --mode=link g++  -std=c++11  -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -o fstprint fstprint.o fstprint-main.o ../script/libfstscript.la ../lib/libfst.la -lm -ldl -lgflags_nothreads -lglog -lpthread\n",
      "\u001b[94mcmd1:\u001b[0m /bin/bash ../../libtool  --tag=CXX   --mode=link g++  -std=c++11  -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -o fstproject fstproject.o fstproject-main.o ../script/libfstscript.la ../lib/libfst.la -lm -ldl -lgflags_nothreads -lglog -lpthread\n",
      "\u001b[94mcmd1:\u001b[0m libtool: link: g++ -std=c++11 -o .libs/fstminimize fstminimize.o fstminimize-main.o  -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build ../script/.libs/libfstscript.so ../lib/.libs/libfst.so -lm -ldl -lgflags_nothreads -lglog -lpthread -Wl,-rpath -Wl,/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-subbuild/openfst-populate-prefix/lib\n",
      "\u001b[94mcmd1:\u001b[0m libtool: link: g++ -std=c++11 -o .libs/fstprint fstprint.o fstprint-main.o  -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build ../script/.libs/libfstscript.so ../lib/.libs/libfst.so -lm -ldl -lgflags_nothreads -lglog -lpthread -Wl,-rpath -Wl,/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-subbuild/openfst-populate-prefix/lib\n",
      "\u001b[94mcmd1:\u001b[0m libtool: link: g++ -std=c++11 -o .libs/fstproject fstproject.o fstproject-main.o  -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build ../script/.libs/libfstscript.so ../lib/.libs/libfst.so -lm -ldl -lgflags_nothreads -lglog -lpthread -Wl,-rpath -Wl,/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-subbuild/openfst-populate-prefix/lib\n",
      "\u001b[94mcmd1:\u001b[0m /bin/bash ../../libtool  --tag=CXX   --mode=link g++  -std=c++11  -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -o fstprune fstprune.o fstprune-main.o ../script/libfstscript.la ../lib/libfst.la -lm -ldl -lgflags_nothreads -lglog -lpthread\n",
      "\u001b[94mcmd1:\u001b[0m /bin/bash ../../libtool  --tag=CXX   --mode=link g++  -std=c++11  -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -o fstpush fstpush.o fstpush-main.o ../script/libfstscript.la ../lib/libfst.la -lm -ldl -lgflags_nothreads -lglog -lpthread\n",
      "\u001b[94mcmd1:\u001b[0m libtool: link: g++ -std=c++11 -o .libs/fstprune fstprune.o fstprune-main.o  -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build ../script/.libs/libfstscript.so ../lib/.libs/libfst.so -lm -ldl -lgflags_nothreads -lglog -lpthread -Wl,-rpath -Wl,/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-subbuild/openfst-populate-prefix/lib\n",
      "\u001b[94mcmd1:\u001b[0m /bin/bash ../../libtool  --tag=CXX   --mode=link g++  -std=c++11  -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -o fstrandgen fstrandgen.o fstrandgen-main.o ../script/libfstscript.la ../lib/libfst.la -lm -ldl -lgflags_nothreads -lglog -lpthread\n",
      "\u001b[94mcmd1:\u001b[0m /bin/bash ../../libtool  --tag=CXX   --mode=link g++  -std=c++11  -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -o fstrelabel fstrelabel.o fstrelabel-main.o ../script/libfstscript.la ../lib/libfst.la -lm -ldl -lgflags_nothreads -lglog -lpthread\n",
      "\u001b[94mcmd1:\u001b[0m libtool: link: g++ -std=c++11 -o .libs/fstpush fstpush.o fstpush-main.o  -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build ../script/.libs/libfstscript.so ../lib/.libs/libfst.so -lm -ldl -lgflags_nothreads -lglog -lpthread -Wl,-rpath -Wl,/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-subbuild/openfst-populate-prefix/lib\n",
      "\u001b[94mcmd1:\u001b[0m libtool: link: g++ -std=c++11 -o .libs/fstrandgen fstrandgen.o fstrandgen-main.o  -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build ../script/.libs/libfstscript.so ../lib/.libs/libfst.so -lm -ldl -lgflags_nothreads -lglog -lpthread -Wl,-rpath -Wl,/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-subbuild/openfst-populate-prefix/lib\n",
      "\u001b[94mcmd1:\u001b[0m libtool: link: g++ -std=c++11 -o .libs/fstrelabel fstrelabel.o fstrelabel-main.o  -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build ../script/.libs/libfstscript.so ../lib/.libs/libfst.so -lm -ldl -lgflags_nothreads -lglog -lpthread -Wl,-rpath -Wl,/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-subbuild/openfst-populate-prefix/lib\n",
      "\u001b[94mcmd1:\u001b[0m /bin/bash ../../libtool  --tag=CXX   --mode=link g++  -std=c++11  -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -o fstreplace fstreplace.o fstreplace-main.o ../script/libfstscript.la ../lib/libfst.la -lm -ldl -lgflags_nothreads -lglog -lpthread\n",
      "\u001b[94mcmd1:\u001b[0m /bin/bash ../../libtool  --tag=CXX   --mode=link g++  -std=c++11  -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -o fstreverse fstreverse.o fstreverse-main.o ../script/libfstscript.la ../lib/libfst.la -lm -ldl -lgflags_nothreads -lglog -lpthread\n",
      "\u001b[94mcmd1:\u001b[0m /bin/bash ../../libtool  --tag=CXX   --mode=link g++  -std=c++11  -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -o fstreweight fstreweight.o fstreweight-main.o ../script/libfstscript.la ../lib/libfst.la -lm -ldl -lgflags_nothreads -lglog -lpthread\n",
      "\u001b[94mcmd1:\u001b[0m libtool: link: g++ -std=c++11 -o .libs/fstreplace fstreplace.o fstreplace-main.o  -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build ../script/.libs/libfstscript.so ../lib/.libs/libfst.so -lm -ldl -lgflags_nothreads -lglog -lpthread -Wl,-rpath -Wl,/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-subbuild/openfst-populate-prefix/lib\n",
      "\u001b[94mcmd1:\u001b[0m /bin/bash ../../libtool  --tag=CXX   --mode=link g++  -std=c++11  -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -o fstrmepsilon fstrmepsilon.o fstrmepsilon-main.o ../script/libfstscript.la ../lib/libfst.la -lm -ldl -lgflags_nothreads -lglog -lpthread\n",
      "\u001b[94mcmd1:\u001b[0m libtool: link: g++ -std=c++11 -o .libs/fstreverse fstreverse.o fstreverse-main.o  -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build ../script/.libs/libfstscript.so ../lib/.libs/libfst.so -lm -ldl -lgflags_nothreads -lglog -lpthread -Wl,-rpath -Wl,/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-subbuild/openfst-populate-prefix/lib\n",
      "\u001b[94mcmd1:\u001b[0m libtool: link: g++ -std=c++11 -o .libs/fstreweight fstreweight.o fstreweight-main.o  -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build ../script/.libs/libfstscript.so ../lib/.libs/libfst.so -lm -ldl -lgflags_nothreads -lglog -lpthread -Wl,-rpath -Wl,/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-subbuild/openfst-populate-prefix/lib\n",
      "\u001b[94mcmd1:\u001b[0m libtool: link: g++ -std=c++11 -o .libs/fstrmepsilon fstrmepsilon.o fstrmepsilon-main.o  -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build ../script/.libs/libfstscript.so ../lib/.libs/libfst.so -lm -ldl -lgflags_nothreads -lglog -lpthread -Wl,-rpath -Wl,/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-subbuild/openfst-populate-prefix/lib\n",
      "\u001b[94mcmd1:\u001b[0m /bin/bash ../../libtool  --tag=CXX   --mode=link g++  -std=c++11  -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -o fstshortestdistance fstshortestdistance.o fstshortestdistance-main.o ../script/libfstscript.la ../lib/libfst.la -lm -ldl -lgflags_nothreads -lglog -lpthread\n",
      "\u001b[94mcmd1:\u001b[0m /bin/bash ../../libtool  --tag=CXX   --mode=link g++  -std=c++11  -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -o fstshortestpath fstshortestpath.o fstshortestpath-main.o ../script/libfstscript.la ../lib/libfst.la -lm -ldl -lgflags_nothreads -lglog -lpthread\n",
      "\u001b[92mcmd2:\u001b[0m Still waiting for remote lm reset from ts 1766528432100...\n",
      "\u001b[94mcmd1:\u001b[0m /bin/bash ../../libtool  --tag=CXX   --mode=link g++  -std=c++11  -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -o fstsymbols fstsymbols.o fstsymbols-main.o ../script/libfstscript.la ../lib/libfst.la -lm -ldl -lgflags_nothreads -lglog -lpthread\n",
      "\u001b[94mcmd1:\u001b[0m libtool: link: g++ -std=c++11 -o .libs/fstshortestdistance fstshortestdistance.o fstshortestdistance-main.o  -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build ../script/.libs/libfstscript.so ../lib/.libs/libfst.so -lm -ldl -lgflags_nothreads -lglog -lpthread -Wl,-rpath -Wl,/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-subbuild/openfst-populate-prefix/lib\n",
      "\u001b[94mcmd1:\u001b[0m /bin/bash ../../libtool  --tag=CXX   --mode=link g++  -std=c++11  -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -o fstsynchronize fstsynchronize.o fstsynchronize-main.o ../script/libfstscript.la ../lib/libfst.la -lm -ldl -lgflags_nothreads -lglog -lpthread\n",
      "\u001b[94mcmd1:\u001b[0m libtool: link: g++ -std=c++11 -o .libs/fstshortestpath fstshortestpath.o fstshortestpath-main.o  -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build ../script/.libs/libfstscript.so ../lib/.libs/libfst.so -lm -ldl -lgflags_nothreads -lglog -lpthread -Wl,-rpath -Wl,/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-subbuild/openfst-populate-prefix/lib\n",
      "\u001b[94mcmd1:\u001b[0m libtool: link: g++ -std=c++11 -o .libs/fstsymbols fstsymbols.o fstsymbols-main.o  -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build ../script/.libs/libfstscript.so ../lib/.libs/libfst.so -lm -ldl -lgflags_nothreads -lglog -lpthread -Wl,-rpath -Wl,/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-subbuild/openfst-populate-prefix/lib\n",
      "\u001b[94mcmd1:\u001b[0m libtool: link: g++ -std=c++11 -o .libs/fstsynchronize fstsynchronize.o fstsynchronize-main.o  -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build ../script/.libs/libfstscript.so ../lib/.libs/libfst.so -lm -ldl -lgflags_nothreads -lglog -lpthread -Wl,-rpath -Wl,/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-subbuild/openfst-populate-prefix/lib\n",
      "\u001b[94mcmd1:\u001b[0m /bin/bash ../../libtool  --tag=CXX   --mode=link g++  -std=c++11  -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -o fsttopsort fsttopsort.o fsttopsort-main.o ../script/libfstscript.la ../lib/libfst.la -lm -ldl -lgflags_nothreads -lglog -lpthread\n",
      "\u001b[94mcmd1:\u001b[0m /bin/bash ../../libtool  --tag=CXX   --mode=link g++  -std=c++11  -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -o fstunion fstunion.o fstunion-main.o ../script/libfstscript.la ../lib/libfst.la -lm -ldl -lgflags_nothreads -lglog -lpthread\n",
      "\u001b[94mcmd1:\u001b[0m libtool: link: g++ -std=c++11 -o .libs/fsttopsort fsttopsort.o fsttopsort-main.o  -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build ../script/.libs/libfstscript.so ../lib/.libs/libfst.so -lm -ldl -lgflags_nothreads -lglog -lpthread -Wl,-rpath -Wl,/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-subbuild/openfst-populate-prefix/lib\n",
      "\u001b[94mcmd1:\u001b[0m libtool: link: g++ -std=c++11 -o .libs/fstunion fstunion.o fstunion-main.o  -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build ../script/.libs/libfstscript.so ../lib/.libs/libfst.so -lm -ldl -lgflags_nothreads -lglog -lpthread -Wl,-rpath -Wl,/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-subbuild/openfst-populate-prefix/lib\n",
      "\u001b[94mcmd1:\u001b[0m make[7]: Leaving directory '/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-build/src/bin'\n",
      "\u001b[94mcmd1:\u001b[0m Making all in test\n",
      "\u001b[94mcmd1:\u001b[0m make[7]: Entering directory '/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-build/src/test'\n",
      "\u001b[94mcmd1:\u001b[0m make[7]: Nothing to be done for 'all'.\n",
      "\u001b[94mcmd1:\u001b[0m make[7]: Leaving directory '/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-build/src/test'\n",
      "\u001b[94mcmd1:\u001b[0m Making all in extensions\n",
      "\u001b[94mcmd1:\u001b[0m make[7]: Entering directory '/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-build/src/extensions'\n",
      "\u001b[94mcmd1:\u001b[0m make[8]: Entering directory '/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-build/src/extensions'\n",
      "\u001b[94mcmd1:\u001b[0m make[8]: Nothing to be done for 'all-am'.\n",
      "\u001b[94mcmd1:\u001b[0m make[8]: Leaving directory '/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-build/src/extensions'\n",
      "\u001b[94mcmd1:\u001b[0m make[7]: Leaving directory '/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-build/src/extensions'\n",
      "\u001b[94mcmd1:\u001b[0m make[7]: Entering directory '/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-build/src'\n",
      "\u001b[94mcmd1:\u001b[0m make[7]: Nothing to be done for 'all-am'.\n",
      "\u001b[94mcmd1:\u001b[0m make[7]: Leaving directory '/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-build/src'\n",
      "\u001b[94mcmd1:\u001b[0m make[6]: Leaving directory '/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-build/src'\n",
      "\u001b[94mcmd1:\u001b[0m make[6]: Entering directory '/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-build'\n",
      "\u001b[94mcmd1:\u001b[0m make[6]: Leaving directory '/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-build'\n",
      "\u001b[94mcmd1:\u001b[0m make[5]: Leaving directory '/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-build'\n",
      "\u001b[94mcmd1:\u001b[0m make[4]: Leaving directory '/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-build'\n",
      "\u001b[94mcmd1:\u001b[0m cd /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-build && /usr/local/lib/python3.11/dist-packages/cmake/data/bin/cmake -E touch /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/build/temp.linux-x86_64-cpython-39/openfst-prefix/src/openfst-stamp/openfst-build\n",
      "\u001b[94mcmd1:\u001b[0m [ 39%] Performing install step for 'openfst'\n",
      "\u001b[94mcmd1:\u001b[0m cd /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-build && /usr/bin/gmake install\n",
      "\u001b[94mcmd1:\u001b[0m gmake[4]: Entering directory '/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-build'\n",
      "\u001b[94mcmd1:\u001b[0m Making install in src\n",
      "\u001b[94mcmd1:\u001b[0m gmake[5]: Entering directory '/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-build/src'\n",
      "\u001b[94mcmd1:\u001b[0m Making install in include\n",
      "\u001b[94mcmd1:\u001b[0m gmake[6]: Entering directory '/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-build/src/include'\n",
      "\u001b[94mcmd1:\u001b[0m gmake[7]: Entering directory '/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-build/src/include'\n",
      "\u001b[94mcmd1:\u001b[0m gmake[7]: Nothing to be done for 'install-exec-am'.\n",
      "\u001b[94mcmd1:\u001b[0m  /usr/bin/mkdir -p '/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-subbuild/openfst-populate-prefix/include'\n",
      "\u001b[94mcmd1:\u001b[0m  /usr/bin/mkdir -p '/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-subbuild/openfst-populate-prefix/include/fst'\n",
      "\u001b[94mcmd1:\u001b[0m  /usr/bin/install -c -m 644  /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/accumulator.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/add-on.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/arc-arena.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/arc-map.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/arc.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/arcfilter.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/arcsort.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/bi-table.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/cache.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/closure.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/compact-fst.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/compat.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/complement.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/compose-filter.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/compose.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/concat.h fst/config.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/connect.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/const-fst.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/determinize.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/dfs-visit.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/difference.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/disambiguate.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/edit-fst.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/encode.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/epsnormalize.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/equal.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/equivalent.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/expanded-fst.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/expectation-weight.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/factor-weight.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/filter-state.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/flags.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/float-weight.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/fst-decl.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/fst.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/fstlib.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/generic-register.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/heap.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/icu.h '/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-subbuild/openfst-populate-prefix/include/fst'\n",
      "\u001b[94mcmd1:\u001b[0m  /usr/bin/mkdir -p '/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-subbuild/openfst-populate-prefix/include/fst'\n",
      "\u001b[94mcmd1:\u001b[0m  /usr/bin/install -c -m 644  /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/intersect.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/interval-set.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/invert.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/isomorphic.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/label-reachable.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/lexicographic-weight.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/lock.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/log.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/lookahead-filter.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/lookahead-matcher.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/map.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/mapped-file.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/matcher-fst.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/matcher.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/memory.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/minimize.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/mutable-fst.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/pair-weight.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/partition.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/power-weight.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/product-weight.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/project.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/properties.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/prune.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/push.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/queue.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/randequivalent.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/randgen.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/rational.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/register.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/relabel.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/replace-util.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/replace.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/reverse.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/reweight.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/rmepsilon.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/rmfinalepsilon.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/set-weight.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/shortest-distance.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/shortest-path.h '/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-subbuild/openfst-populate-prefix/include/fst'\n",
      "\u001b[94mcmd1:\u001b[0m  /usr/bin/mkdir -p '/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-subbuild/openfst-populate-prefix/include/fst/script'\n",
      "\u001b[94mcmd1:\u001b[0m  /usr/bin/install -c -m 644  /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/script/arc-class.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/script/arciterator-class.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/script/arcsort.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/script/arg-packs.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/script/closure.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/script/compile-impl.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/script/compile.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/script/compose.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/script/concat.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/script/connect.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/script/convert.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/script/decode.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/script/determinize.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/script/difference.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/script/disambiguate.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/script/draw-impl.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/script/draw.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/script/encode.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/script/encodemapper-class.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/script/epsnormalize.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/script/equal.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/script/equivalent.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/script/fst-class.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/script/fstscript.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/script/getters.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/script/info-impl.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/script/info.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/script/intersect.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/script/invert.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/script/isomorphic.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/script/map.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/script/minimize.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/script/print-impl.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/script/print.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/script/project.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/script/prune.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/script/push.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/script/randequivalent.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/script/randgen.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/script/register.h '/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-subbuild/openfst-populate-prefix/include/fst/script'\n",
      "\u001b[94mcmd1:\u001b[0m  /usr/bin/mkdir -p '/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-subbuild/openfst-populate-prefix/include/fst/script'\n",
      "\u001b[94mcmd1:\u001b[0m  /usr/bin/install -c -m 644  /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/script/relabel.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/script/replace.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/script/reverse.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/script/reweight.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/script/rmepsilon.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/script/script-impl.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/script/shortest-distance.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/script/shortest-path.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/script/stateiterator-class.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/script/synchronize.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/script/text-io.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/script/topsort.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/script/union.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/script/weight-class.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/script/fstscript-decl.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/script/verify.h '/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-subbuild/openfst-populate-prefix/include/fst/script'\n",
      "\u001b[94mcmd1:\u001b[0m  /usr/bin/mkdir -p '/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-subbuild/openfst-populate-prefix/include/fst'\n",
      "\u001b[94mcmd1:\u001b[0m  /usr/bin/install -c -m 644  /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/signed-log-weight.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/sparse-power-weight.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/sparse-tuple-weight.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/state-map.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/state-reachable.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/state-table.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/statesort.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/string-weight.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/string.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/symbol-table-ops.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/symbol-table.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/synchronize.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/test-properties.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/topsort.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/tuple-weight.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/types.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/union-find.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/union-weight.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/union.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/util.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/vector-fst.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/verify.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/visit.h /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include/fst/weight.h '/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-subbuild/openfst-populate-prefix/include/fst'\n",
      "\u001b[94mcmd1:\u001b[0m gmake[7]: Leaving directory '/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-build/src/include'\n",
      "\u001b[94mcmd1:\u001b[0m gmake[6]: Leaving directory '/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-build/src/include'\n",
      "\u001b[94mcmd1:\u001b[0m Making install in lib\n",
      "\u001b[94mcmd1:\u001b[0m gmake[6]: Entering directory '/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-build/src/lib'\n",
      "\u001b[94mcmd1:\u001b[0m gmake[7]: Entering directory '/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-build/src/lib'\n",
      "\u001b[94mcmd1:\u001b[0m  /usr/bin/mkdir -p '/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-subbuild/openfst-populate-prefix/lib'\n",
      "\u001b[94mcmd1:\u001b[0m  /bin/bash ../../libtool   --mode=install /usr/bin/install -c   libfst.la '/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-subbuild/openfst-populate-prefix/lib'\n",
      "\u001b[94mcmd1:\u001b[0m libtool: install: /usr/bin/install -c .libs/libfst.so.8.0.0 /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-subbuild/openfst-populate-prefix/lib/libfst.so.8.0.0\n",
      "\u001b[94mcmd1:\u001b[0m libtool: install: (cd /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-subbuild/openfst-populate-prefix/lib && { ln -s -f libfst.so.8.0.0 libfst.so.8 || { rm -f libfst.so.8 && ln -s libfst.so.8.0.0 libfst.so.8; }; })\n",
      "\u001b[94mcmd1:\u001b[0m libtool: install: (cd /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-subbuild/openfst-populate-prefix/lib && { ln -s -f libfst.so.8.0.0 libfst.so || { rm -f libfst.so && ln -s libfst.so.8.0.0 libfst.so; }; })\n",
      "\u001b[94mcmd1:\u001b[0m libtool: install: /usr/bin/install -c .libs/libfst.lai /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-subbuild/openfst-populate-prefix/lib/libfst.la\n",
      "\u001b[94mcmd1:\u001b[0m libtool: finish: PATH=\"/root/miniconda3/envs/b2txt25_lm/bin:/root/miniconda3/condabin:/opt/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/tools/node/bin:/tools/google-cloud-sdk/bin:/sbin\" ldconfig -n /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-subbuild/openfst-populate-prefix/lib\n",
      "\u001b[94mcmd1:\u001b[0m ----------------------------------------------------------------------\n",
      "\u001b[94mcmd1:\u001b[0m Libraries have been installed in:\n",
      "\u001b[94mcmd1:\u001b[0m    /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-subbuild/openfst-populate-prefix/lib\n",
      "\u001b[94mcmd1:\u001b[0m \n",
      "\u001b[94mcmd1:\u001b[0m If you ever happen to want to link against installed libraries\n",
      "\u001b[94mcmd1:\u001b[0m in a given directory, LIBDIR, you must either use libtool, and\n",
      "\u001b[94mcmd1:\u001b[0m specify the full pathname of the library, or use the `-LLIBDIR'\n",
      "\u001b[94mcmd1:\u001b[0m flag during linking and do at least one of the following:\n",
      "\u001b[94mcmd1:\u001b[0m    - add LIBDIR to the `LD_LIBRARY_PATH' environment variable\n",
      "\u001b[94mcmd1:\u001b[0m      during execution\n",
      "\u001b[94mcmd1:\u001b[0m    - add LIBDIR to the `LD_RUN_PATH' environment variable\n",
      "\u001b[94mcmd1:\u001b[0m      during linking\n",
      "\u001b[94mcmd1:\u001b[0m    - use the `-Wl,-rpath -Wl,LIBDIR' linker flag\n",
      "\u001b[94mcmd1:\u001b[0m    - have your system administrator add LIBDIR to `/etc/ld.so.conf'\n",
      "\u001b[94mcmd1:\u001b[0m \n",
      "\u001b[94mcmd1:\u001b[0m See any operating system documentation about shared libraries for\n",
      "\u001b[94mcmd1:\u001b[0m more information, such as the ld(1) and ld.so(8) manual pages.\n",
      "\u001b[94mcmd1:\u001b[0m ----------------------------------------------------------------------\n",
      "\u001b[94mcmd1:\u001b[0m gmake[7]: Nothing to be done for 'install-data-am'.\n",
      "\u001b[94mcmd1:\u001b[0m gmake[7]: Leaving directory '/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-build/src/lib'\n",
      "\u001b[94mcmd1:\u001b[0m gmake[6]: Leaving directory '/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-build/src/lib'\n",
      "\u001b[94mcmd1:\u001b[0m Making install in script\n",
      "\u001b[94mcmd1:\u001b[0m gmake[6]: Entering directory '/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-build/src/script'\n",
      "\u001b[94mcmd1:\u001b[0m gmake[7]: Entering directory '/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-build/src/script'\n",
      "\u001b[94mcmd1:\u001b[0m  /usr/bin/mkdir -p '/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-subbuild/openfst-populate-prefix/lib'\n",
      "\u001b[94mcmd1:\u001b[0m  /bin/bash ../../libtool   --mode=install /usr/bin/install -c   libfstscript.la '/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-subbuild/openfst-populate-prefix/lib'\n",
      "\u001b[94mcmd1:\u001b[0m libtool: install: warning: relinking `libfstscript.la'\n",
      "\u001b[94mcmd1:\u001b[0m libtool: install: (cd /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-build/src/script; /bin/bash /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-build/libtool  --tag CXX --mode=relink g++ -std=c++11 -version-info 8:0:0 -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -o libfstscript.la -rpath /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-subbuild/openfst-populate-prefix/lib arciterator-class.lo arcsort.lo closure.lo compile.lo compose.lo concat.lo connect.lo convert.lo decode.lo determinize.lo difference.lo disambiguate.lo draw.lo encode.lo encodemapper-class.lo epsnormalize.lo equal.lo equivalent.lo fst-class.lo getters.lo info-impl.lo info.lo intersect.lo invert.lo isomorphic.lo map.lo minimize.lo print.lo project.lo prune.lo push.lo randequivalent.lo randgen.lo relabel.lo replace.lo reverse.lo reweight.lo rmepsilon.lo shortest-distance.lo shortest-path.lo stateiterator-class.lo synchronize.lo text-io.lo topsort.lo union.lo weight-class.lo verify.lo ../lib/libfst.la -lm -ldl -lgflags_nothreads -lglog -lpthread )\n",
      "\u001b[94mcmd1:\u001b[0m libtool: relink: g++  -fPIC -DPIC -shared -nostdlib /usr/lib/gcc/x86_64-linux-gnu/11/../../../x86_64-linux-gnu/crti.o /usr/lib/gcc/x86_64-linux-gnu/11/crtbeginS.o  .libs/arciterator-class.o .libs/arcsort.o .libs/closure.o .libs/compile.o .libs/compose.o .libs/concat.o .libs/connect.o .libs/convert.o .libs/decode.o .libs/determinize.o .libs/difference.o .libs/disambiguate.o .libs/draw.o .libs/encode.o .libs/encodemapper-class.o .libs/epsnormalize.o .libs/equal.o .libs/equivalent.o .libs/fst-class.o .libs/getters.o .libs/info-impl.o .libs/info.o .libs/intersect.o .libs/invert.o .libs/isomorphic.o .libs/map.o .libs/minimize.o .libs/print.o .libs/project.o .libs/prune.o .libs/push.o .libs/randequivalent.o .libs/randgen.o .libs/relabel.o .libs/replace.o .libs/reverse.o .libs/reweight.o .libs/rmepsilon.o .libs/shortest-distance.o .libs/shortest-path.o .libs/stateiterator-class.o .libs/synchronize.o .libs/text-io.o .libs/topsort.o .libs/union.o .libs/weight-class.o .libs/verify.o   -Wl,-rpath -Wl,/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-subbuild/openfst-populate-prefix/lib -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-subbuild/openfst-populate-prefix/lib -lfst -ldl -lgflags_nothreads -lglog -lpthread -L/usr/lib/gcc/x86_64-linux-gnu/11 -L/usr/lib/gcc/x86_64-linux-gnu/11/../../../x86_64-linux-gnu -L/usr/lib/gcc/x86_64-linux-gnu/11/../../../../lib -L/lib/x86_64-linux-gnu -L/lib/../lib -L/usr/lib/x86_64-linux-gnu -L/usr/lib/../lib -L/usr/local/cuda/lib64/stubs -L/usr/lib/gcc/x86_64-linux-gnu/11/../../.. -lstdc++ -lm -lc -lgcc_s /usr/lib/gcc/x86_64-linux-gnu/11/crtendS.o /usr/lib/gcc/x86_64-linux-gnu/11/../../../x86_64-linux-gnu/crtn.o    -Wl,-soname -Wl,libfstscript.so.8 -o .libs/libfstscript.so.8.0.0\n",
      "\u001b[94mcmd1:\u001b[0m libtool: install: /usr/bin/install -c .libs/libfstscript.so.8.0.0T /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-subbuild/openfst-populate-prefix/lib/libfstscript.so.8.0.0\n",
      "\u001b[94mcmd1:\u001b[0m libtool: install: (cd /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-subbuild/openfst-populate-prefix/lib && { ln -s -f libfstscript.so.8.0.0 libfstscript.so.8 || { rm -f libfstscript.so.8 && ln -s libfstscript.so.8.0.0 libfstscript.so.8; }; })\n",
      "\u001b[94mcmd1:\u001b[0m libtool: install: (cd /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-subbuild/openfst-populate-prefix/lib && { ln -s -f libfstscript.so.8.0.0 libfstscript.so || { rm -f libfstscript.so && ln -s libfstscript.so.8.0.0 libfstscript.so; }; })\n",
      "\u001b[94mcmd1:\u001b[0m libtool: install: /usr/bin/install -c .libs/libfstscript.lai /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-subbuild/openfst-populate-prefix/lib/libfstscript.la\n",
      "\u001b[94mcmd1:\u001b[0m libtool: finish: PATH=\"/root/miniconda3/envs/b2txt25_lm/bin:/root/miniconda3/condabin:/opt/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/tools/node/bin:/tools/google-cloud-sdk/bin:/sbin\" ldconfig -n /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-subbuild/openfst-populate-prefix/lib\n",
      "\u001b[94mcmd1:\u001b[0m ----------------------------------------------------------------------\n",
      "\u001b[94mcmd1:\u001b[0m Libraries have been installed in:\n",
      "\u001b[94mcmd1:\u001b[0m    /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-subbuild/openfst-populate-prefix/lib\n",
      "\u001b[94mcmd1:\u001b[0m \n",
      "\u001b[94mcmd1:\u001b[0m If you ever happen to want to link against installed libraries\n",
      "\u001b[94mcmd1:\u001b[0m in a given directory, LIBDIR, you must either use libtool, and\n",
      "\u001b[94mcmd1:\u001b[0m specify the full pathname of the library, or use the `-LLIBDIR'\n",
      "\u001b[94mcmd1:\u001b[0m flag during linking and do at least one of the following:\n",
      "\u001b[94mcmd1:\u001b[0m    - add LIBDIR to the `LD_LIBRARY_PATH' environment variable\n",
      "\u001b[94mcmd1:\u001b[0m      during execution\n",
      "\u001b[94mcmd1:\u001b[0m    - add LIBDIR to the `LD_RUN_PATH' environment variable\n",
      "\u001b[94mcmd1:\u001b[0m      during linking\n",
      "\u001b[94mcmd1:\u001b[0m    - use the `-Wl,-rpath -Wl,LIBDIR' linker flag\n",
      "\u001b[94mcmd1:\u001b[0m    - have your system administrator add LIBDIR to `/etc/ld.so.conf'\n",
      "\u001b[94mcmd1:\u001b[0m \n",
      "\u001b[94mcmd1:\u001b[0m See any operating system documentation about shared libraries for\n",
      "\u001b[94mcmd1:\u001b[0m more information, such as the ld(1) and ld.so(8) manual pages.\n",
      "\u001b[94mcmd1:\u001b[0m ----------------------------------------------------------------------\n",
      "\u001b[94mcmd1:\u001b[0m gmake[7]: Nothing to be done for 'install-data-am'.\n",
      "\u001b[94mcmd1:\u001b[0m gmake[7]: Leaving directory '/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-build/src/script'\n",
      "\u001b[94mcmd1:\u001b[0m gmake[6]: Leaving directory '/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-build/src/script'\n",
      "\u001b[94mcmd1:\u001b[0m Making install in bin\n",
      "\u001b[94mcmd1:\u001b[0m gmake[6]: Entering directory '/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-build/src/bin'\n",
      "\u001b[94mcmd1:\u001b[0m gmake[7]: Entering directory '/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-build/src/bin'\n",
      "\u001b[94mcmd1:\u001b[0m  /usr/bin/mkdir -p '/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-subbuild/openfst-populate-prefix/bin'\n",
      "\u001b[94mcmd1:\u001b[0m   /bin/bash ../../libtool   --mode=install /usr/bin/install -c fstarcsort fstclosure fstcompile fstcompose fstconcat fstconnect fstconvert fstdeterminize fstdifference fstdisambiguate fstdraw fstencode fstepsnormalize fstequal fstequivalent fstinfo fstintersect fstinvert fstisomorphic fstmap fstminimize fstprint fstproject fstprune fstpush fstrandgen fstrelabel fstreplace fstreverse fstreweight fstrmepsilon fstshortestdistance fstshortestpath fstsymbols fstsynchronize fsttopsort fstunion '/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-subbuild/openfst-populate-prefix/bin'\n",
      "\u001b[94mcmd1:\u001b[0m libtool: install: /usr/bin/install -c .libs/fstarcsort /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-subbuild/openfst-populate-prefix/bin/fstarcsort\n",
      "\u001b[94mcmd1:\u001b[0m libtool: install: /usr/bin/install -c .libs/fstclosure /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-subbuild/openfst-populate-prefix/bin/fstclosure\n",
      "\u001b[94mcmd1:\u001b[0m libtool: install: /usr/bin/install -c .libs/fstcompile /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-subbuild/openfst-populate-prefix/bin/fstcompile\n",
      "\u001b[94mcmd1:\u001b[0m libtool: install: /usr/bin/install -c .libs/fstcompose /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-subbuild/openfst-populate-prefix/bin/fstcompose\n",
      "\u001b[94mcmd1:\u001b[0m libtool: install: /usr/bin/install -c .libs/fstconcat /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-subbuild/openfst-populate-prefix/bin/fstconcat\n",
      "\u001b[94mcmd1:\u001b[0m libtool: install: /usr/bin/install -c .libs/fstconnect /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-subbuild/openfst-populate-prefix/bin/fstconnect\n",
      "\u001b[94mcmd1:\u001b[0m libtool: install: /usr/bin/install -c .libs/fstconvert /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-subbuild/openfst-populate-prefix/bin/fstconvert\n",
      "\u001b[94mcmd1:\u001b[0m libtool: install: /usr/bin/install -c .libs/fstdeterminize /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-subbuild/openfst-populate-prefix/bin/fstdeterminize\n",
      "\u001b[94mcmd1:\u001b[0m libtool: install: /usr/bin/install -c .libs/fstdifference /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-subbuild/openfst-populate-prefix/bin/fstdifference\n",
      "\u001b[94mcmd1:\u001b[0m libtool: install: /usr/bin/install -c .libs/fstdisambiguate /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-subbuild/openfst-populate-prefix/bin/fstdisambiguate\n",
      "\u001b[94mcmd1:\u001b[0m libtool: install: /usr/bin/install -c .libs/fstdraw /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-subbuild/openfst-populate-prefix/bin/fstdraw\n",
      "\u001b[94mcmd1:\u001b[0m libtool: install: /usr/bin/install -c .libs/fstencode /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-subbuild/openfst-populate-prefix/bin/fstencode\n",
      "\u001b[94mcmd1:\u001b[0m libtool: install: /usr/bin/install -c .libs/fstepsnormalize /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-subbuild/openfst-populate-prefix/bin/fstepsnormalize\n",
      "\u001b[94mcmd1:\u001b[0m libtool: install: /usr/bin/install -c .libs/fstequal /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-subbuild/openfst-populate-prefix/bin/fstequal\n",
      "\u001b[94mcmd1:\u001b[0m libtool: install: /usr/bin/install -c .libs/fstequivalent /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-subbuild/openfst-populate-prefix/bin/fstequivalent\n",
      "\u001b[94mcmd1:\u001b[0m libtool: install: /usr/bin/install -c .libs/fstinfo /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-subbuild/openfst-populate-prefix/bin/fstinfo\n",
      "\u001b[94mcmd1:\u001b[0m libtool: install: /usr/bin/install -c .libs/fstintersect /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-subbuild/openfst-populate-prefix/bin/fstintersect\n",
      "\u001b[94mcmd1:\u001b[0m libtool: install: /usr/bin/install -c .libs/fstinvert /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-subbuild/openfst-populate-prefix/bin/fstinvert\n",
      "\u001b[94mcmd1:\u001b[0m libtool: install: /usr/bin/install -c .libs/fstisomorphic /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-subbuild/openfst-populate-prefix/bin/fstisomorphic\n",
      "\u001b[94mcmd1:\u001b[0m libtool: install: /usr/bin/install -c .libs/fstmap /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-subbuild/openfst-populate-prefix/bin/fstmap\n",
      "\u001b[94mcmd1:\u001b[0m libtool: install: /usr/bin/install -c .libs/fstminimize /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-subbuild/openfst-populate-prefix/bin/fstminimize\n",
      "\u001b[94mcmd1:\u001b[0m libtool: install: /usr/bin/install -c .libs/fstprint /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-subbuild/openfst-populate-prefix/bin/fstprint\n",
      "\u001b[94mcmd1:\u001b[0m libtool: install: /usr/bin/install -c .libs/fstproject /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-subbuild/openfst-populate-prefix/bin/fstproject\n",
      "\u001b[94mcmd1:\u001b[0m libtool: install: /usr/bin/install -c .libs/fstprune /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-subbuild/openfst-populate-prefix/bin/fstprune\n",
      "\u001b[94mcmd1:\u001b[0m libtool: install: /usr/bin/install -c .libs/fstpush /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-subbuild/openfst-populate-prefix/bin/fstpush\n",
      "\u001b[94mcmd1:\u001b[0m libtool: install: /usr/bin/install -c .libs/fstrandgen /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-subbuild/openfst-populate-prefix/bin/fstrandgen\n",
      "\u001b[92mcmd2:\u001b[0m Still waiting for remote lm reset from ts 1766528432100...\n",
      "\u001b[94mcmd1:\u001b[0m libtool: install: /usr/bin/install -c .libs/fstrelabel /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-subbuild/openfst-populate-prefix/bin/fstrelabel\n",
      "\u001b[94mcmd1:\u001b[0m libtool: install: /usr/bin/install -c .libs/fstreplace /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-subbuild/openfst-populate-prefix/bin/fstreplace\n",
      "\u001b[94mcmd1:\u001b[0m libtool: install: /usr/bin/install -c .libs/fstreverse /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-subbuild/openfst-populate-prefix/bin/fstreverse\n",
      "\u001b[94mcmd1:\u001b[0m libtool: install: /usr/bin/install -c .libs/fstreweight /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-subbuild/openfst-populate-prefix/bin/fstreweight\n",
      "\u001b[94mcmd1:\u001b[0m libtool: install: /usr/bin/install -c .libs/fstrmepsilon /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-subbuild/openfst-populate-prefix/bin/fstrmepsilon\n",
      "\u001b[94mcmd1:\u001b[0m libtool: install: /usr/bin/install -c .libs/fstshortestdistance /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-subbuild/openfst-populate-prefix/bin/fstshortestdistance\n",
      "\u001b[94mcmd1:\u001b[0m libtool: install: /usr/bin/install -c .libs/fstshortestpath /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-subbuild/openfst-populate-prefix/bin/fstshortestpath\n",
      "\u001b[94mcmd1:\u001b[0m libtool: install: /usr/bin/install -c .libs/fstsymbols /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-subbuild/openfst-populate-prefix/bin/fstsymbols\n",
      "\u001b[94mcmd1:\u001b[0m libtool: install: /usr/bin/install -c .libs/fstsynchronize /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-subbuild/openfst-populate-prefix/bin/fstsynchronize\n",
      "\u001b[94mcmd1:\u001b[0m libtool: install: /usr/bin/install -c .libs/fsttopsort /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-subbuild/openfst-populate-prefix/bin/fsttopsort\n",
      "\u001b[94mcmd1:\u001b[0m libtool: install: /usr/bin/install -c .libs/fstunion /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-subbuild/openfst-populate-prefix/bin/fstunion\n",
      "\u001b[94mcmd1:\u001b[0m gmake[7]: Nothing to be done for 'install-data-am'.\n",
      "\u001b[94mcmd1:\u001b[0m gmake[7]: Leaving directory '/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-build/src/bin'\n",
      "\u001b[94mcmd1:\u001b[0m gmake[6]: Leaving directory '/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-build/src/bin'\n",
      "\u001b[94mcmd1:\u001b[0m Making install in test\n",
      "\u001b[94mcmd1:\u001b[0m gmake[6]: Entering directory '/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-build/src/test'\n",
      "\u001b[94mcmd1:\u001b[0m gmake[7]: Entering directory '/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-build/src/test'\n",
      "\u001b[94mcmd1:\u001b[0m gmake[7]: Nothing to be done for 'install-exec-am'.\n",
      "\u001b[94mcmd1:\u001b[0m gmake[7]: Nothing to be done for 'install-data-am'.\n",
      "\u001b[94mcmd1:\u001b[0m gmake[7]: Leaving directory '/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-build/src/test'\n",
      "\u001b[94mcmd1:\u001b[0m gmake[6]: Leaving directory '/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-build/src/test'\n",
      "\u001b[94mcmd1:\u001b[0m Making install in extensions\n",
      "\u001b[94mcmd1:\u001b[0m gmake[6]: Entering directory '/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-build/src/extensions'\n",
      "\u001b[94mcmd1:\u001b[0m gmake[7]: Entering directory '/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-build/src/extensions'\n",
      "\u001b[94mcmd1:\u001b[0m gmake[8]: Entering directory '/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-build/src/extensions'\n",
      "\u001b[94mcmd1:\u001b[0m gmake[8]: Nothing to be done for 'install-exec-am'.\n",
      "\u001b[94mcmd1:\u001b[0m gmake[8]: Nothing to be done for 'install-data-am'.\n",
      "\u001b[94mcmd1:\u001b[0m gmake[8]: Leaving directory '/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-build/src/extensions'\n",
      "\u001b[94mcmd1:\u001b[0m gmake[7]: Leaving directory '/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-build/src/extensions'\n",
      "\u001b[94mcmd1:\u001b[0m gmake[6]: Leaving directory '/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-build/src/extensions'\n",
      "\u001b[94mcmd1:\u001b[0m gmake[6]: Entering directory '/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-build/src'\n",
      "\u001b[94mcmd1:\u001b[0m gmake[7]: Entering directory '/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-build/src'\n",
      "\u001b[94mcmd1:\u001b[0m gmake[7]: Nothing to be done for 'install-exec-am'.\n",
      "\u001b[94mcmd1:\u001b[0m gmake[7]: Nothing to be done for 'install-data-am'.\n",
      "\u001b[94mcmd1:\u001b[0m gmake[7]: Leaving directory '/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-build/src'\n",
      "\u001b[94mcmd1:\u001b[0m gmake[6]: Leaving directory '/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-build/src'\n",
      "\u001b[94mcmd1:\u001b[0m gmake[5]: Leaving directory '/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-build/src'\n",
      "\u001b[94mcmd1:\u001b[0m gmake[5]: Entering directory '/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-build'\n",
      "\u001b[94mcmd1:\u001b[0m gmake[6]: Entering directory '/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-build'\n",
      "\u001b[94mcmd1:\u001b[0m gmake[6]: Nothing to be done for 'install-exec-am'.\n",
      "\u001b[94mcmd1:\u001b[0m gmake[6]: Nothing to be done for 'install-data-am'.\n",
      "\u001b[94mcmd1:\u001b[0m gmake[6]: Leaving directory '/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-build'\n",
      "\u001b[94mcmd1:\u001b[0m gmake[5]: Leaving directory '/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-build'\n",
      "\u001b[94mcmd1:\u001b[0m gmake[4]: Leaving directory '/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-build'\n",
      "\u001b[94mcmd1:\u001b[0m cd /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-build && /usr/local/lib/python3.11/dist-packages/cmake/data/bin/cmake -E touch /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/build/temp.linux-x86_64-cpython-39/openfst-prefix/src/openfst-stamp/openfst-install\n",
      "\u001b[94mcmd1:\u001b[0m [ 42%] Completed 'openfst'\n",
      "\u001b[94mcmd1:\u001b[0m /usr/local/lib/python3.11/dist-packages/cmake/data/bin/cmake -E make_directory /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/build/temp.linux-x86_64-cpython-39/CMakeFiles\n",
      "\u001b[94mcmd1:\u001b[0m /usr/local/lib/python3.11/dist-packages/cmake/data/bin/cmake -E touch /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/build/temp.linux-x86_64-cpython-39/CMakeFiles/openfst-complete\n",
      "\u001b[94mcmd1:\u001b[0m /usr/local/lib/python3.11/dist-packages/cmake/data/bin/cmake -E touch /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/build/temp.linux-x86_64-cpython-39/openfst-prefix/src/openfst-stamp/openfst-done\n",
      "\u001b[94mcmd1:\u001b[0m gmake[3]: Leaving directory '/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/build/temp.linux-x86_64-cpython-39'\n",
      "\u001b[94mcmd1:\u001b[0m [ 42%] Built target openfst\n",
      "\u001b[94mcmd1:\u001b[0m /usr/bin/gmake  -f CMakeFiles/utils.dir/build.make CMakeFiles/utils.dir/depend\n",
      "\u001b[94mcmd1:\u001b[0m gmake[3]: Entering directory '/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/build/temp.linux-x86_64-cpython-39'\n",
      "\u001b[94mcmd1:\u001b[0m cd /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/build/temp.linux-x86_64-cpython-39 && /usr/local/lib/python3.11/dist-packages/cmake/data/bin/cmake -E cmake_depends \"Unix Makefiles\" /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86 /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86 /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/build/temp.linux-x86_64-cpython-39 /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/build/temp.linux-x86_64-cpython-39 /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/build/temp.linux-x86_64-cpython-39/CMakeFiles/utils.dir/DependInfo.cmake \"--color=\"\n",
      "\u001b[94mcmd1:\u001b[0m gmake[3]: Leaving directory '/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/build/temp.linux-x86_64-cpython-39'\n",
      "\u001b[94mcmd1:\u001b[0m /usr/bin/gmake  -f CMakeFiles/utils.dir/build.make CMakeFiles/utils.dir/build\n",
      "\u001b[94mcmd1:\u001b[0m gmake[3]: Entering directory '/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/build/temp.linux-x86_64-cpython-39'\n",
      "\u001b[94mcmd1:\u001b[0m [ 45%] Building CXX object CMakeFiles/utils.dir/utils/string.cc.o\n",
      "\u001b[94mcmd1:\u001b[0m /usr/bin/c++ -D_GLIBCXX_USE_CXX11_ABI=0 -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86 -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/kaldi -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/boost-src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/cnpy-src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include -std=c++14 -pthread -fPIC -D_GLIBCXX_USE_CXX11_ABI=0 -DC10_USE_GLOG -O3 -DNDEBUG -MD -MT CMakeFiles/utils.dir/utils/string.cc.o -MF CMakeFiles/utils.dir/utils/string.cc.o.d -o CMakeFiles/utils.dir/utils/string.cc.o -c /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/utils/string.cc\n",
      "\u001b[94mcmd1:\u001b[0m [ 48%] Building CXX object CMakeFiles/utils.dir/utils/utils.cc.o\n",
      "\u001b[94mcmd1:\u001b[0m /usr/bin/c++ -D_GLIBCXX_USE_CXX11_ABI=0 -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86 -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/kaldi -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/boost-src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/cnpy-src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include -std=c++14 -pthread -fPIC -D_GLIBCXX_USE_CXX11_ABI=0 -DC10_USE_GLOG -O3 -DNDEBUG -MD -MT CMakeFiles/utils.dir/utils/utils.cc.o -MF CMakeFiles/utils.dir/utils/utils.cc.o.d -o CMakeFiles/utils.dir/utils/utils.cc.o -c /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/utils/utils.cc\n",
      "\u001b[94mcmd1:\u001b[0m [ 51%] Linking CXX static library libutils.a\n",
      "\u001b[94mcmd1:\u001b[0m /usr/local/lib/python3.11/dist-packages/cmake/data/bin/cmake -P CMakeFiles/utils.dir/cmake_clean_target.cmake\n",
      "\u001b[94mcmd1:\u001b[0m /usr/local/lib/python3.11/dist-packages/cmake/data/bin/cmake -E cmake_link_script CMakeFiles/utils.dir/link.txt --verbose=1\n",
      "\u001b[94mcmd1:\u001b[0m /usr/bin/ar qc libutils.a CMakeFiles/utils.dir/utils/string.cc.o CMakeFiles/utils.dir/utils/utils.cc.o\n",
      "\u001b[94mcmd1:\u001b[0m /usr/bin/ranlib libutils.a\n",
      "\u001b[94mcmd1:\u001b[0m gmake[3]: Leaving directory '/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/build/temp.linux-x86_64-cpython-39'\n",
      "\u001b[94mcmd1:\u001b[0m [ 51%] Built target utils\n",
      "\u001b[94mcmd1:\u001b[0m /usr/bin/gmake  -f kaldi/CMakeFiles/kaldi-base.dir/build.make kaldi/CMakeFiles/kaldi-base.dir/depend\n",
      "\u001b[94mcmd1:\u001b[0m gmake[3]: Entering directory '/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/build/temp.linux-x86_64-cpython-39'\n",
      "\u001b[94mcmd1:\u001b[0m cd /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/build/temp.linux-x86_64-cpython-39 && /usr/local/lib/python3.11/dist-packages/cmake/data/bin/cmake -E cmake_depends \"Unix Makefiles\" /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86 /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/kaldi /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/build/temp.linux-x86_64-cpython-39 /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/build/temp.linux-x86_64-cpython-39/kaldi /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/build/temp.linux-x86_64-cpython-39/kaldi/CMakeFiles/kaldi-base.dir/DependInfo.cmake \"--color=\"\n",
      "\u001b[94mcmd1:\u001b[0m gmake[3]: Leaving directory '/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/build/temp.linux-x86_64-cpython-39'\n",
      "\u001b[94mcmd1:\u001b[0m /usr/bin/gmake  -f kaldi/CMakeFiles/kaldi-base.dir/build.make kaldi/CMakeFiles/kaldi-base.dir/build\n",
      "\u001b[94mcmd1:\u001b[0m gmake[3]: Entering directory '/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/build/temp.linux-x86_64-cpython-39'\n",
      "\u001b[94mcmd1:\u001b[0m [ 54%] Building CXX object kaldi/CMakeFiles/kaldi-base.dir/base/kaldi-error.cc.o\n",
      "\u001b[94mcmd1:\u001b[0m cd /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/build/temp.linux-x86_64-cpython-39/kaldi && /usr/bin/c++ -D_GLIBCXX_USE_CXX11_ABI=0 -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86 -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/kaldi -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/boost-src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/cnpy-src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include -std=c++14 -pthread -fPIC -D_GLIBCXX_USE_CXX11_ABI=0 -DC10_USE_GLOG -O3 -DNDEBUG -MD -MT kaldi/CMakeFiles/kaldi-base.dir/base/kaldi-error.cc.o -MF CMakeFiles/kaldi-base.dir/base/kaldi-error.cc.o.d -o CMakeFiles/kaldi-base.dir/base/kaldi-error.cc.o -c /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/kaldi/base/kaldi-error.cc\n",
      "\u001b[94mcmd1:\u001b[0m [ 57%] Building CXX object kaldi/CMakeFiles/kaldi-base.dir/base/kaldi-math.cc.o\n",
      "\u001b[94mcmd1:\u001b[0m cd /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/build/temp.linux-x86_64-cpython-39/kaldi && /usr/bin/c++ -D_GLIBCXX_USE_CXX11_ABI=0 -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86 -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/kaldi -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/boost-src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/cnpy-src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include -std=c++14 -pthread -fPIC -D_GLIBCXX_USE_CXX11_ABI=0 -DC10_USE_GLOG -O3 -DNDEBUG -MD -MT kaldi/CMakeFiles/kaldi-base.dir/base/kaldi-math.cc.o -MF CMakeFiles/kaldi-base.dir/base/kaldi-math.cc.o.d -o CMakeFiles/kaldi-base.dir/base/kaldi-math.cc.o -c /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/kaldi/base/kaldi-math.cc\n",
      "\u001b[94mcmd1:\u001b[0m [ 57%] Linking CXX static library libkaldi-base.a\n",
      "\u001b[94mcmd1:\u001b[0m cd /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/build/temp.linux-x86_64-cpython-39/kaldi && /usr/local/lib/python3.11/dist-packages/cmake/data/bin/cmake -P CMakeFiles/kaldi-base.dir/cmake_clean_target.cmake\n",
      "\u001b[94mcmd1:\u001b[0m cd /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/build/temp.linux-x86_64-cpython-39/kaldi && /usr/local/lib/python3.11/dist-packages/cmake/data/bin/cmake -E cmake_link_script CMakeFiles/kaldi-base.dir/link.txt --verbose=1\n",
      "\u001b[94mcmd1:\u001b[0m /usr/bin/ar qc libkaldi-base.a \"CMakeFiles/kaldi-base.dir/base/kaldi-error.cc.o\" \"CMakeFiles/kaldi-base.dir/base/kaldi-math.cc.o\"\n",
      "\u001b[94mcmd1:\u001b[0m /usr/bin/ranlib libkaldi-base.a\n",
      "\u001b[94mcmd1:\u001b[0m gmake[3]: Leaving directory '/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/build/temp.linux-x86_64-cpython-39'\n",
      "\u001b[94mcmd1:\u001b[0m [ 57%] Built target kaldi-base\n",
      "\u001b[94mcmd1:\u001b[0m /usr/bin/gmake  -f kaldi/CMakeFiles/kaldi-util.dir/build.make kaldi/CMakeFiles/kaldi-util.dir/depend\n",
      "\u001b[94mcmd1:\u001b[0m gmake[3]: Entering directory '/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/build/temp.linux-x86_64-cpython-39'\n",
      "\u001b[94mcmd1:\u001b[0m cd /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/build/temp.linux-x86_64-cpython-39 && /usr/local/lib/python3.11/dist-packages/cmake/data/bin/cmake -E cmake_depends \"Unix Makefiles\" /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86 /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/kaldi /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/build/temp.linux-x86_64-cpython-39 /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/build/temp.linux-x86_64-cpython-39/kaldi /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/build/temp.linux-x86_64-cpython-39/kaldi/CMakeFiles/kaldi-util.dir/DependInfo.cmake \"--color=\"\n",
      "\u001b[94mcmd1:\u001b[0m gmake[3]: Leaving directory '/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/build/temp.linux-x86_64-cpython-39'\n",
      "\u001b[94mcmd1:\u001b[0m /usr/bin/gmake  -f kaldi/CMakeFiles/kaldi-util.dir/build.make kaldi/CMakeFiles/kaldi-util.dir/build\n",
      "\u001b[94mcmd1:\u001b[0m gmake[3]: Entering directory '/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/build/temp.linux-x86_64-cpython-39'\n",
      "\u001b[94mcmd1:\u001b[0m [ 60%] Building CXX object kaldi/CMakeFiles/kaldi-util.dir/util/kaldi-io.cc.o\n",
      "\u001b[94mcmd1:\u001b[0m cd /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/build/temp.linux-x86_64-cpython-39/kaldi && /usr/bin/c++ -D_GLIBCXX_USE_CXX11_ABI=0 -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86 -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/kaldi -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/boost-src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/cnpy-src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include -std=c++14 -pthread -fPIC -D_GLIBCXX_USE_CXX11_ABI=0 -DC10_USE_GLOG -O3 -DNDEBUG -MD -MT kaldi/CMakeFiles/kaldi-util.dir/util/kaldi-io.cc.o -MF CMakeFiles/kaldi-util.dir/util/kaldi-io.cc.o.d -o CMakeFiles/kaldi-util.dir/util/kaldi-io.cc.o -c /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/kaldi/util/kaldi-io.cc\n",
      "\u001b[94mcmd1:\u001b[0m [ 60%] Building CXX object kaldi/CMakeFiles/kaldi-util.dir/util/parse-options.cc.o\n",
      "\u001b[94mcmd1:\u001b[0m cd /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/build/temp.linux-x86_64-cpython-39/kaldi && /usr/bin/c++ -D_GLIBCXX_USE_CXX11_ABI=0 -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86 -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/kaldi -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/boost-src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/cnpy-src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include -std=c++14 -pthread -fPIC -D_GLIBCXX_USE_CXX11_ABI=0 -DC10_USE_GLOG -O3 -DNDEBUG -MD -MT kaldi/CMakeFiles/kaldi-util.dir/util/parse-options.cc.o -MF CMakeFiles/kaldi-util.dir/util/parse-options.cc.o.d -o CMakeFiles/kaldi-util.dir/util/parse-options.cc.o -c /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/kaldi/util/parse-options.cc\n",
      "\u001b[94mcmd1:\u001b[0m [ 63%] Building CXX object kaldi/CMakeFiles/kaldi-util.dir/util/simple-io-funcs.cc.o\n",
      "\u001b[94mcmd1:\u001b[0m cd /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/build/temp.linux-x86_64-cpython-39/kaldi && /usr/bin/c++ -D_GLIBCXX_USE_CXX11_ABI=0 -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86 -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/kaldi -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/boost-src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/cnpy-src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include -std=c++14 -pthread -fPIC -D_GLIBCXX_USE_CXX11_ABI=0 -DC10_USE_GLOG -O3 -DNDEBUG -MD -MT kaldi/CMakeFiles/kaldi-util.dir/util/simple-io-funcs.cc.o -MF CMakeFiles/kaldi-util.dir/util/simple-io-funcs.cc.o.d -o CMakeFiles/kaldi-util.dir/util/simple-io-funcs.cc.o -c /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/kaldi/util/simple-io-funcs.cc\n",
      "\u001b[94mcmd1:\u001b[0m [ 66%] Building CXX object kaldi/CMakeFiles/kaldi-util.dir/util/text-utils.cc.o\n",
      "\u001b[94mcmd1:\u001b[0m cd /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/build/temp.linux-x86_64-cpython-39/kaldi && /usr/bin/c++ -D_GLIBCXX_USE_CXX11_ABI=0 -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86 -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/kaldi -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/boost-src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/cnpy-src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include -std=c++14 -pthread -fPIC -D_GLIBCXX_USE_CXX11_ABI=0 -DC10_USE_GLOG -O3 -DNDEBUG -MD -MT kaldi/CMakeFiles/kaldi-util.dir/util/text-utils.cc.o -MF CMakeFiles/kaldi-util.dir/util/text-utils.cc.o.d -o CMakeFiles/kaldi-util.dir/util/text-utils.cc.o -c /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/kaldi/util/text-utils.cc\n",
      "\u001b[94mcmd1:\u001b[0m [ 69%] Linking CXX static library libkaldi-util.a\n",
      "\u001b[94mcmd1:\u001b[0m cd /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/build/temp.linux-x86_64-cpython-39/kaldi && /usr/local/lib/python3.11/dist-packages/cmake/data/bin/cmake -P CMakeFiles/kaldi-util.dir/cmake_clean_target.cmake\n",
      "\u001b[94mcmd1:\u001b[0m cd /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/build/temp.linux-x86_64-cpython-39/kaldi && /usr/local/lib/python3.11/dist-packages/cmake/data/bin/cmake -E cmake_link_script CMakeFiles/kaldi-util.dir/link.txt --verbose=1\n",
      "\u001b[94mcmd1:\u001b[0m /usr/bin/ar qc libkaldi-util.a \"CMakeFiles/kaldi-util.dir/util/kaldi-io.cc.o\" \"CMakeFiles/kaldi-util.dir/util/parse-options.cc.o\" \"CMakeFiles/kaldi-util.dir/util/simple-io-funcs.cc.o\" \"CMakeFiles/kaldi-util.dir/util/text-utils.cc.o\"\n",
      "\u001b[94mcmd1:\u001b[0m /usr/bin/ranlib libkaldi-util.a\n",
      "\u001b[94mcmd1:\u001b[0m gmake[3]: Leaving directory '/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/build/temp.linux-x86_64-cpython-39'\n",
      "\u001b[94mcmd1:\u001b[0m [ 69%] Built target kaldi-util\n",
      "\u001b[94mcmd1:\u001b[0m /usr/bin/gmake  -f kaldi/CMakeFiles/kaldi-fstext.dir/build.make kaldi/CMakeFiles/kaldi-fstext.dir/depend\n",
      "\u001b[94mcmd1:\u001b[0m gmake[3]: Entering directory '/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/build/temp.linux-x86_64-cpython-39'\n",
      "\u001b[94mcmd1:\u001b[0m cd /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/build/temp.linux-x86_64-cpython-39 && /usr/local/lib/python3.11/dist-packages/cmake/data/bin/cmake -E cmake_depends \"Unix Makefiles\" /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86 /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/kaldi /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/build/temp.linux-x86_64-cpython-39 /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/build/temp.linux-x86_64-cpython-39/kaldi /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/build/temp.linux-x86_64-cpython-39/kaldi/CMakeFiles/kaldi-fstext.dir/DependInfo.cmake \"--color=\"\n",
      "\u001b[94mcmd1:\u001b[0m gmake[3]: Leaving directory '/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/build/temp.linux-x86_64-cpython-39'\n",
      "\u001b[94mcmd1:\u001b[0m /usr/bin/gmake  -f kaldi/CMakeFiles/kaldi-fstext.dir/build.make kaldi/CMakeFiles/kaldi-fstext.dir/build\n",
      "\u001b[94mcmd1:\u001b[0m gmake[3]: Entering directory '/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/build/temp.linux-x86_64-cpython-39'\n",
      "\u001b[94mcmd1:\u001b[0m [ 69%] Building CXX object kaldi/CMakeFiles/kaldi-fstext.dir/fstext/kaldi-fst-io.cc.o\n",
      "\u001b[94mcmd1:\u001b[0m cd /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/build/temp.linux-x86_64-cpython-39/kaldi && /usr/bin/c++ -D_GLIBCXX_USE_CXX11_ABI=0 -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86 -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/kaldi -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/boost-src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/cnpy-src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include -std=c++14 -pthread -fPIC -D_GLIBCXX_USE_CXX11_ABI=0 -DC10_USE_GLOG -O3 -DNDEBUG -MD -MT kaldi/CMakeFiles/kaldi-fstext.dir/fstext/kaldi-fst-io.cc.o -MF CMakeFiles/kaldi-fstext.dir/fstext/kaldi-fst-io.cc.o.d -o CMakeFiles/kaldi-fstext.dir/fstext/kaldi-fst-io.cc.o -c /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/kaldi/fstext/kaldi-fst-io.cc\n",
      "\u001b[92mcmd2:\u001b[0m Still waiting for remote lm reset from ts 1766528432100...\n",
      "\u001b[94mcmd1:\u001b[0m [ 72%] Linking CXX static library libkaldi-fstext.a\n",
      "\u001b[94mcmd1:\u001b[0m cd /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/build/temp.linux-x86_64-cpython-39/kaldi && /usr/local/lib/python3.11/dist-packages/cmake/data/bin/cmake -P CMakeFiles/kaldi-fstext.dir/cmake_clean_target.cmake\n",
      "\u001b[94mcmd1:\u001b[0m cd /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/build/temp.linux-x86_64-cpython-39/kaldi && /usr/local/lib/python3.11/dist-packages/cmake/data/bin/cmake -E cmake_link_script CMakeFiles/kaldi-fstext.dir/link.txt --verbose=1\n",
      "\u001b[94mcmd1:\u001b[0m /usr/bin/ar qc libkaldi-fstext.a \"CMakeFiles/kaldi-fstext.dir/fstext/kaldi-fst-io.cc.o\"\n",
      "\u001b[94mcmd1:\u001b[0m /usr/bin/ranlib libkaldi-fstext.a\n",
      "\u001b[94mcmd1:\u001b[0m gmake[3]: Leaving directory '/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/build/temp.linux-x86_64-cpython-39'\n",
      "\u001b[94mcmd1:\u001b[0m [ 72%] Built target kaldi-fstext\n",
      "\u001b[94mcmd1:\u001b[0m /usr/bin/gmake  -f kaldi/CMakeFiles/kaldi-lat.dir/build.make kaldi/CMakeFiles/kaldi-lat.dir/depend\n",
      "\u001b[94mcmd1:\u001b[0m gmake[3]: Entering directory '/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/build/temp.linux-x86_64-cpython-39'\n",
      "\u001b[94mcmd1:\u001b[0m cd /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/build/temp.linux-x86_64-cpython-39 && /usr/local/lib/python3.11/dist-packages/cmake/data/bin/cmake -E cmake_depends \"Unix Makefiles\" /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86 /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/kaldi /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/build/temp.linux-x86_64-cpython-39 /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/build/temp.linux-x86_64-cpython-39/kaldi /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/build/temp.linux-x86_64-cpython-39/kaldi/CMakeFiles/kaldi-lat.dir/DependInfo.cmake \"--color=\"\n",
      "\u001b[94mcmd1:\u001b[0m gmake[3]: Leaving directory '/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/build/temp.linux-x86_64-cpython-39'\n",
      "\u001b[94mcmd1:\u001b[0m /usr/bin/gmake  -f kaldi/CMakeFiles/kaldi-lat.dir/build.make kaldi/CMakeFiles/kaldi-lat.dir/build\n",
      "\u001b[94mcmd1:\u001b[0m gmake[3]: Entering directory '/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/build/temp.linux-x86_64-cpython-39'\n",
      "\u001b[94mcmd1:\u001b[0m [ 75%] Building CXX object kaldi/CMakeFiles/kaldi-lat.dir/lat/determinize-lattice-pruned.cc.o\n",
      "\u001b[94mcmd1:\u001b[0m cd /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/build/temp.linux-x86_64-cpython-39/kaldi && /usr/bin/c++ -D_GLIBCXX_USE_CXX11_ABI=0 -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86 -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/kaldi -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/boost-src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/cnpy-src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include -std=c++14 -pthread -fPIC -D_GLIBCXX_USE_CXX11_ABI=0 -DC10_USE_GLOG -O3 -DNDEBUG -MD -MT kaldi/CMakeFiles/kaldi-lat.dir/lat/determinize-lattice-pruned.cc.o -MF CMakeFiles/kaldi-lat.dir/lat/determinize-lattice-pruned.cc.o.d -o CMakeFiles/kaldi-lat.dir/lat/determinize-lattice-pruned.cc.o -c /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/kaldi/lat/determinize-lattice-pruned.cc\n",
      "\u001b[92mcmd2:\u001b[0m Still waiting for remote lm reset from ts 1766528432100...\n",
      "\u001b[94mcmd1:\u001b[0m [ 75%] Building CXX object kaldi/CMakeFiles/kaldi-lat.dir/lat/lattice-functions.cc.o\n",
      "\u001b[94mcmd1:\u001b[0m cd /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/build/temp.linux-x86_64-cpython-39/kaldi && /usr/bin/c++ -D_GLIBCXX_USE_CXX11_ABI=0 -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86 -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/kaldi -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/boost-src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/cnpy-src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include -std=c++14 -pthread -fPIC -D_GLIBCXX_USE_CXX11_ABI=0 -DC10_USE_GLOG -O3 -DNDEBUG -MD -MT kaldi/CMakeFiles/kaldi-lat.dir/lat/lattice-functions.cc.o -MF CMakeFiles/kaldi-lat.dir/lat/lattice-functions.cc.o.d -o CMakeFiles/kaldi-lat.dir/lat/lattice-functions.cc.o -c /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/kaldi/lat/lattice-functions.cc\n",
      "\u001b[92mcmd2:\u001b[0m Still waiting for remote lm reset from ts 1766528432100...\n",
      "\u001b[94mcmd1:\u001b[0m [ 78%] Linking CXX static library libkaldi-lat.a\n",
      "\u001b[94mcmd1:\u001b[0m cd /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/build/temp.linux-x86_64-cpython-39/kaldi && /usr/local/lib/python3.11/dist-packages/cmake/data/bin/cmake -P CMakeFiles/kaldi-lat.dir/cmake_clean_target.cmake\n",
      "\u001b[94mcmd1:\u001b[0m cd /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/build/temp.linux-x86_64-cpython-39/kaldi && /usr/local/lib/python3.11/dist-packages/cmake/data/bin/cmake -E cmake_link_script CMakeFiles/kaldi-lat.dir/link.txt --verbose=1\n",
      "\u001b[94mcmd1:\u001b[0m /usr/bin/ar qc libkaldi-lat.a \"CMakeFiles/kaldi-lat.dir/lat/determinize-lattice-pruned.cc.o\" \"CMakeFiles/kaldi-lat.dir/lat/lattice-functions.cc.o\"\n",
      "\u001b[94mcmd1:\u001b[0m /usr/bin/ranlib libkaldi-lat.a\n",
      "\u001b[94mcmd1:\u001b[0m gmake[3]: Leaving directory '/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/build/temp.linux-x86_64-cpython-39'\n",
      "\u001b[94mcmd1:\u001b[0m [ 78%] Built target kaldi-lat\n",
      "\u001b[94mcmd1:\u001b[0m /usr/bin/gmake  -f kaldi/CMakeFiles/kaldi-decoder.dir/build.make kaldi/CMakeFiles/kaldi-decoder.dir/depend\n",
      "\u001b[94mcmd1:\u001b[0m gmake[3]: Entering directory '/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/build/temp.linux-x86_64-cpython-39'\n",
      "\u001b[94mcmd1:\u001b[0m cd /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/build/temp.linux-x86_64-cpython-39 && /usr/local/lib/python3.11/dist-packages/cmake/data/bin/cmake -E cmake_depends \"Unix Makefiles\" /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86 /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/kaldi /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/build/temp.linux-x86_64-cpython-39 /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/build/temp.linux-x86_64-cpython-39/kaldi /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/build/temp.linux-x86_64-cpython-39/kaldi/CMakeFiles/kaldi-decoder.dir/DependInfo.cmake \"--color=\"\n",
      "\u001b[94mcmd1:\u001b[0m gmake[3]: Leaving directory '/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/build/temp.linux-x86_64-cpython-39'\n",
      "\u001b[94mcmd1:\u001b[0m /usr/bin/gmake  -f kaldi/CMakeFiles/kaldi-decoder.dir/build.make kaldi/CMakeFiles/kaldi-decoder.dir/build\n",
      "\u001b[94mcmd1:\u001b[0m gmake[3]: Entering directory '/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/build/temp.linux-x86_64-cpython-39'\n",
      "\u001b[94mcmd1:\u001b[0m [ 81%] Building CXX object kaldi/CMakeFiles/kaldi-decoder.dir/decoder/lattice-faster-decoder.cc.o\n",
      "\u001b[94mcmd1:\u001b[0m cd /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/build/temp.linux-x86_64-cpython-39/kaldi && /usr/bin/c++ -D_GLIBCXX_USE_CXX11_ABI=0 -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86 -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/kaldi -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/boost-src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/cnpy-src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include -std=c++14 -pthread -fPIC -D_GLIBCXX_USE_CXX11_ABI=0 -DC10_USE_GLOG -O3 -DNDEBUG -MD -MT kaldi/CMakeFiles/kaldi-decoder.dir/decoder/lattice-faster-decoder.cc.o -MF CMakeFiles/kaldi-decoder.dir/decoder/lattice-faster-decoder.cc.o.d -o CMakeFiles/kaldi-decoder.dir/decoder/lattice-faster-decoder.cc.o -c /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/kaldi/decoder/lattice-faster-decoder.cc\n",
      "\u001b[92mcmd2:\u001b[0m Still waiting for remote lm reset from ts 1766528432100...\n",
      "\u001b[92mcmd2:\u001b[0m Still waiting for remote lm reset from ts 1766528432100...\n",
      "\u001b[92mcmd2:\u001b[0m Still waiting for remote lm reset from ts 1766528432100...\n",
      "\u001b[94mcmd1:\u001b[0m [ 84%] Building CXX object kaldi/CMakeFiles/kaldi-decoder.dir/decoder/lattice-faster-online-decoder.cc.o\n",
      "\u001b[94mcmd1:\u001b[0m cd /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/build/temp.linux-x86_64-cpython-39/kaldi && /usr/bin/c++ -D_GLIBCXX_USE_CXX11_ABI=0 -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86 -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/kaldi -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/boost-src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/cnpy-src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include -std=c++14 -pthread -fPIC -D_GLIBCXX_USE_CXX11_ABI=0 -DC10_USE_GLOG -O3 -DNDEBUG -MD -MT kaldi/CMakeFiles/kaldi-decoder.dir/decoder/lattice-faster-online-decoder.cc.o -MF CMakeFiles/kaldi-decoder.dir/decoder/lattice-faster-online-decoder.cc.o.d -o CMakeFiles/kaldi-decoder.dir/decoder/lattice-faster-online-decoder.cc.o -c /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/kaldi/decoder/lattice-faster-online-decoder.cc\n",
      "\u001b[92mcmd2:\u001b[0m Still waiting for remote lm reset from ts 1766528432100...\n",
      "\u001b[92mcmd2:\u001b[0m Still waiting for remote lm reset from ts 1766528432100...\n",
      "\u001b[94mcmd1:\u001b[0m [ 87%] Linking CXX static library libkaldi-decoder.a\n",
      "\u001b[94mcmd1:\u001b[0m cd /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/build/temp.linux-x86_64-cpython-39/kaldi && /usr/local/lib/python3.11/dist-packages/cmake/data/bin/cmake -P CMakeFiles/kaldi-decoder.dir/cmake_clean_target.cmake\n",
      "\u001b[94mcmd1:\u001b[0m cd /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/build/temp.linux-x86_64-cpython-39/kaldi && /usr/local/lib/python3.11/dist-packages/cmake/data/bin/cmake -E cmake_link_script CMakeFiles/kaldi-decoder.dir/link.txt --verbose=1\n",
      "\u001b[94mcmd1:\u001b[0m /usr/bin/ar qc libkaldi-decoder.a \"CMakeFiles/kaldi-decoder.dir/decoder/lattice-faster-decoder.cc.o\" \"CMakeFiles/kaldi-decoder.dir/decoder/lattice-faster-online-decoder.cc.o\"\n",
      "\u001b[94mcmd1:\u001b[0m /usr/bin/ranlib libkaldi-decoder.a\n",
      "\u001b[94mcmd1:\u001b[0m gmake[3]: Leaving directory '/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/build/temp.linux-x86_64-cpython-39'\n",
      "\u001b[94mcmd1:\u001b[0m [ 87%] Built target kaldi-decoder\n",
      "\u001b[94mcmd1:\u001b[0m /usr/bin/gmake  -f CMakeFiles/decoder.dir/build.make CMakeFiles/decoder.dir/depend\n",
      "\u001b[94mcmd1:\u001b[0m gmake[3]: Entering directory '/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/build/temp.linux-x86_64-cpython-39'\n",
      "\u001b[94mcmd1:\u001b[0m cd /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/build/temp.linux-x86_64-cpython-39 && /usr/local/lib/python3.11/dist-packages/cmake/data/bin/cmake -E cmake_depends \"Unix Makefiles\" /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86 /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86 /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/build/temp.linux-x86_64-cpython-39 /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/build/temp.linux-x86_64-cpython-39 /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/build/temp.linux-x86_64-cpython-39/CMakeFiles/decoder.dir/DependInfo.cmake \"--color=\"\n",
      "\u001b[94mcmd1:\u001b[0m gmake[3]: Leaving directory '/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/build/temp.linux-x86_64-cpython-39'\n",
      "\u001b[94mcmd1:\u001b[0m /usr/bin/gmake  -f CMakeFiles/decoder.dir/build.make CMakeFiles/decoder.dir/build\n",
      "\u001b[94mcmd1:\u001b[0m gmake[3]: Entering directory '/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/build/temp.linux-x86_64-cpython-39'\n",
      "\u001b[94mcmd1:\u001b[0m [ 90%] Building CXX object CMakeFiles/decoder.dir/decoder/ctc_prefix_beam_search.cc.o\n",
      "\u001b[94mcmd1:\u001b[0m /usr/bin/c++ -DUSE_C10D_GLOO -DUSE_DISTRIBUTED -DUSE_RPC -DUSE_TENSORPIPE -D_GLIBCXX_USE_CXX11_ABI=0 -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86 -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/kaldi -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/boost-src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/cnpy-src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include -isystem /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/libtorch-src/include -isystem /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/libtorch-src/include/torch/csrc/api/include -std=c++14 -pthread -fPIC -D_GLIBCXX_USE_CXX11_ABI=0 -DC10_USE_GLOG -O3 -DNDEBUG -D_GLIBCXX_USE_CXX11_ABI=0 -MD -MT CMakeFiles/decoder.dir/decoder/ctc_prefix_beam_search.cc.o -MF CMakeFiles/decoder.dir/decoder/ctc_prefix_beam_search.cc.o.d -o CMakeFiles/decoder.dir/decoder/ctc_prefix_beam_search.cc.o -c /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/decoder/ctc_prefix_beam_search.cc\n",
      "\u001b[92mcmd2:\u001b[0m Still waiting for remote lm reset from ts 1766528432100...\n",
      "\u001b[92mcmd2:\u001b[0m Still waiting for remote lm reset from ts 1766528432100...\n",
      "\u001b[92mcmd2:\u001b[0m Still waiting for remote lm reset from ts 1766528432100...\n",
      "\u001b[94mcmd1:\u001b[0m [ 90%] Building CXX object CMakeFiles/decoder.dir/decoder/ctc_wfst_beam_search.cc.o\n",
      "\u001b[94mcmd1:\u001b[0m /usr/bin/c++ -DUSE_C10D_GLOO -DUSE_DISTRIBUTED -DUSE_RPC -DUSE_TENSORPIPE -D_GLIBCXX_USE_CXX11_ABI=0 -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86 -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/kaldi -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/boost-src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/cnpy-src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include -isystem /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/libtorch-src/include -isystem /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/libtorch-src/include/torch/csrc/api/include -std=c++14 -pthread -fPIC -D_GLIBCXX_USE_CXX11_ABI=0 -DC10_USE_GLOG -O3 -DNDEBUG -D_GLIBCXX_USE_CXX11_ABI=0 -MD -MT CMakeFiles/decoder.dir/decoder/ctc_wfst_beam_search.cc.o -MF CMakeFiles/decoder.dir/decoder/ctc_wfst_beam_search.cc.o.d -o CMakeFiles/decoder.dir/decoder/ctc_wfst_beam_search.cc.o -c /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/decoder/ctc_wfst_beam_search.cc\n",
      "\u001b[92mcmd2:\u001b[0m Still waiting for remote lm reset from ts 1766528432100...\n",
      "\u001b[92mcmd2:\u001b[0m Still waiting for remote lm reset from ts 1766528432100...\n",
      "\u001b[92mcmd2:\u001b[0m Still waiting for remote lm reset from ts 1766528432100...\n",
      "\u001b[94mcmd1:\u001b[0m [ 93%] Building CXX object CMakeFiles/decoder.dir/decoder/brain_speech_decoder.cc.o\n",
      "\u001b[94mcmd1:\u001b[0m /usr/bin/c++ -DUSE_C10D_GLOO -DUSE_DISTRIBUTED -DUSE_RPC -DUSE_TENSORPIPE -D_GLIBCXX_USE_CXX11_ABI=0 -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86 -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/kaldi -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/boost-src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/cnpy-src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include -isystem /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/libtorch-src/include -isystem /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/libtorch-src/include/torch/csrc/api/include -std=c++14 -pthread -fPIC -D_GLIBCXX_USE_CXX11_ABI=0 -DC10_USE_GLOG -O3 -DNDEBUG -D_GLIBCXX_USE_CXX11_ABI=0 -MD -MT CMakeFiles/decoder.dir/decoder/brain_speech_decoder.cc.o -MF CMakeFiles/decoder.dir/decoder/brain_speech_decoder.cc.o.d -o CMakeFiles/decoder.dir/decoder/brain_speech_decoder.cc.o -c /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/decoder/brain_speech_decoder.cc\n",
      "\u001b[92mcmd2:\u001b[0m Still waiting for remote lm reset from ts 1766528432100...\n",
      "\u001b[92mcmd2:\u001b[0m Still waiting for remote lm reset from ts 1766528432100...\n",
      "\u001b[92mcmd2:\u001b[0m Still waiting for remote lm reset from ts 1766528432100...\n",
      "\u001b[92mcmd2:\u001b[0m Still waiting for remote lm reset from ts 1766528432100...\n",
      "\u001b[92mcmd2:\u001b[0m Still waiting for remote lm reset from ts 1766528432100...\n",
      "\u001b[94mcmd1:\u001b[0m [ 96%] Linking CXX static library libdecoder.a\n",
      "\u001b[94mcmd1:\u001b[0m /usr/local/lib/python3.11/dist-packages/cmake/data/bin/cmake -P CMakeFiles/decoder.dir/cmake_clean_target.cmake\n",
      "\u001b[94mcmd1:\u001b[0m /usr/local/lib/python3.11/dist-packages/cmake/data/bin/cmake -E cmake_link_script CMakeFiles/decoder.dir/link.txt --verbose=1\n",
      "\u001b[94mcmd1:\u001b[0m /usr/bin/ar qc libdecoder.a CMakeFiles/decoder.dir/decoder/ctc_prefix_beam_search.cc.o CMakeFiles/decoder.dir/decoder/ctc_wfst_beam_search.cc.o CMakeFiles/decoder.dir/decoder/brain_speech_decoder.cc.o\n",
      "\u001b[94mcmd1:\u001b[0m /usr/bin/ranlib libdecoder.a\n",
      "\u001b[94mcmd1:\u001b[0m gmake[3]: Leaving directory '/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/build/temp.linux-x86_64-cpython-39'\n",
      "\u001b[94mcmd1:\u001b[0m [ 96%] Built target decoder\n",
      "\u001b[94mcmd1:\u001b[0m /usr/bin/gmake  -f CMakeFiles/lm_decoder.dir/build.make CMakeFiles/lm_decoder.dir/depend\n",
      "\u001b[94mcmd1:\u001b[0m gmake[3]: Entering directory '/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/build/temp.linux-x86_64-cpython-39'\n",
      "\u001b[94mcmd1:\u001b[0m cd /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/build/temp.linux-x86_64-cpython-39 && /usr/local/lib/python3.11/dist-packages/cmake/data/bin/cmake -E cmake_depends \"Unix Makefiles\" /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86 /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86 /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/build/temp.linux-x86_64-cpython-39 /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/build/temp.linux-x86_64-cpython-39 /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/build/temp.linux-x86_64-cpython-39/CMakeFiles/lm_decoder.dir/DependInfo.cmake \"--color=\"\n",
      "\u001b[94mcmd1:\u001b[0m gmake[3]: Leaving directory '/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/build/temp.linux-x86_64-cpython-39'\n",
      "\u001b[94mcmd1:\u001b[0m /usr/bin/gmake  -f CMakeFiles/lm_decoder.dir/build.make CMakeFiles/lm_decoder.dir/build\n",
      "\u001b[94mcmd1:\u001b[0m gmake[3]: Entering directory '/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/build/temp.linux-x86_64-cpython-39'\n",
      "\u001b[94mcmd1:\u001b[0m [ 96%] Building CXX object CMakeFiles/lm_decoder.dir/python/lm_decoder.cc.o\n",
      "\u001b[94mcmd1:\u001b[0m /usr/bin/c++ -DUSE_C10D_GLOO -DUSE_DISTRIBUTED -DUSE_RPC -DUSE_TENSORPIPE -D_GLIBCXX_USE_CXX11_ABI=0 -Dlm_decoder_EXPORTS -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86 -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/kaldi -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/gflags-build/include -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-src/src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/glog-build -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/boost-src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/cnpy-src -I/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-src/src/include -isystem /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/pybind11/include -isystem /root/miniconda3/envs/b2txt25_lm/include/python3.9 -isystem /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/libtorch-src/include -isystem /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/libtorch-src/include/torch/csrc/api/include -std=c++14 -pthread -fPIC -D_GLIBCXX_USE_CXX11_ABI=0 -DC10_USE_GLOG -O3 -DNDEBUG -fPIC -fvisibility=hidden -flto -fno-fat-lto-objects -D_GLIBCXX_USE_CXX11_ABI=0 -MD -MT CMakeFiles/lm_decoder.dir/python/lm_decoder.cc.o -MF CMakeFiles/lm_decoder.dir/python/lm_decoder.cc.o.d -o CMakeFiles/lm_decoder.dir/python/lm_decoder.cc.o -c /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/python/lm_decoder.cc\n",
      "\u001b[92mcmd2:\u001b[0m Still waiting for remote lm reset from ts 1766528432100...\n",
      "\u001b[92mcmd2:\u001b[0m Still waiting for remote lm reset from ts 1766528432100...\n",
      "\u001b[92mcmd2:\u001b[0m Still waiting for remote lm reset from ts 1766528432100...\n",
      "\u001b[94mcmd1:\u001b[0m [100%] Linking CXX shared module /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/build/lib.linux-x86_64-cpython-39/lm_decoder.cpython-39-x86_64-linux-gnu.so\n",
      "\u001b[94mcmd1:\u001b[0m /usr/local/lib/python3.11/dist-packages/cmake/data/bin/cmake -E cmake_link_script CMakeFiles/lm_decoder.dir/link.txt --verbose=1\n",
      "\u001b[94mcmd1:\u001b[0m lto-wrapper: warning: using serial compilation of 5 LTRANS jobs\n",
      "\u001b[94mcmd1:\u001b[0m /usr/bin/c++ -fPIC  -std=c++14 -pthread -fPIC -D_GLIBCXX_USE_CXX11_ABI=0 -DC10_USE_GLOG -O3 -DNDEBUG -flto -shared  -o /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/build/lib.linux-x86_64-cpython-39/lm_decoder.cpython-39-x86_64-linux-gnu.so CMakeFiles/lm_decoder.dir/python/lm_decoder.cc.o   -L/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-subbuild/openfst-populate-prefix/lib  -Wl,-rpath,/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/openfst-subbuild/openfst-populate-prefix/lib:/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/libtorch-src/lib libdecoder.a /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/libtorch-src/lib/libtorch.so -Wl,--no-as-needed,\"/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/libtorch-src/lib/libtorch_cpu.so\" -Wl,--as-needed /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/libtorch-src/lib/libc10.so -Wl,--no-as-needed,\"/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/libtorch-src/lib/libtorch.so\" -Wl,--as-needed /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/libtorch-src/lib/libc10.so /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/fc_base/libtorch-src/lib/libkineto.a kaldi/libkaldi-decoder.a kaldi/libkaldi-lat.a kaldi/libkaldi-fstext.a kaldi/libkaldi-util.a kaldi/libkaldi-base.a libutils.a -lfst -ldl\n",
      "\u001b[94mcmd1:\u001b[0m /usr/bin/strip /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/build/lib.linux-x86_64-cpython-39/lm_decoder.cpython-39-x86_64-linux-gnu.so\n",
      "\u001b[94mcmd1:\u001b[0m gmake[3]: Leaving directory '/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/build/temp.linux-x86_64-cpython-39'\n",
      "\u001b[94mcmd1:\u001b[0m [100%] Built target lm_decoder\n",
      "\u001b[94mcmd1:\u001b[0m gmake[2]: Leaving directory '/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/build/temp.linux-x86_64-cpython-39'\n",
      "\u001b[94mcmd1:\u001b[0m /usr/local/lib/python3.11/dist-packages/cmake/data/bin/cmake -E cmake_progress_start /kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/build/temp.linux-x86_64-cpython-39/CMakeFiles 0\n",
      "\u001b[94mcmd1:\u001b[0m gmake[1]: Leaving directory '/kaggle/working/Brain-To-Text-MOA/language_model/runtime/server/x86/build/temp.linux-x86_64-cpython-39'\n",
      "\u001b[94mcmd1:\u001b[0m running install_lib\n",
      "\u001b[92mcmd2:\u001b[0m Still waiting for remote lm reset from ts 1766528432100...\n",
      "\u001b[94mcmd1:\u001b[0m copying build/lib.linux-x86_64-cpython-39/lm_decoder.cpython-39-x86_64-linux-gnu.so -> /root/miniconda3/envs/b2txt25_lm/lib/python3.9/site-packages\n",
      "\u001b[94mcmd1:\u001b[0m running install_egg_info\n",
      "\u001b[94mcmd1:\u001b[0m running egg_info\n",
      "\u001b[94mcmd1:\u001b[0m creating lm_decoder.egg-info\n",
      "\u001b[94mcmd1:\u001b[0m writing lm_decoder.egg-info/PKG-INFO\n",
      "\u001b[94mcmd1:\u001b[0m writing dependency_links to lm_decoder.egg-info/dependency_links.txt\n",
      "\u001b[94mcmd1:\u001b[0m writing top-level names to lm_decoder.egg-info/top_level.txt\n",
      "\u001b[94mcmd1:\u001b[0m writing manifest file 'lm_decoder.egg-info/SOURCES.txt'\n",
      "\u001b[94mcmd1:\u001b[0m reading manifest file 'lm_decoder.egg-info/SOURCES.txt'\n",
      "\u001b[94mcmd1:\u001b[0m writing manifest file 'lm_decoder.egg-info/SOURCES.txt'\n",
      "\u001b[94mcmd1:\u001b[0m Copying lm_decoder.egg-info to /root/miniconda3/envs/b2txt25_lm/lib/python3.9/site-packages/lm_decoder-0.0.1-py3.9.egg-info\n",
      "\u001b[94mcmd1:\u001b[0m running install_scripts\n",
      "\u001b[94mcmd1:\u001b[0m \n",
      "\u001b[94mcmd1:\u001b[0m Setup complete! Verify it worked by activating the conda environment with the command 'conda activate b2txt25_lm'.\n",
      "\u001b[94mcmd1:\u001b[0m \n",
      "\u001b[94mcmd1:\u001b[0m 2025-12-23 22:25:35,247 INFO: Using device: cuda:1\n",
      "\u001b[94mcmd1:\u001b[0m 2025-12-23 22:25:35,247 INFO: Building opt model from None...\n",
      "\u001b[94mcmd1:\u001b[0m /root/miniconda3/envs/b2txt25_lm/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "\u001b[94mcmd1:\u001b[0m   warnings.warn(\n",
      "\u001b[94mcmd1:\u001b[0m /root/miniconda3/envs/b2txt25_lm/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "\u001b[94mcmd1:\u001b[0m   warnings.warn(\n",
      "\u001b[94mcmd1:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Still waiting for remote lm reset from ts 1766528432100...\n",
      "\u001b[92mcmd2:\u001b[0m Still waiting for remote lm reset from ts 1766528432100...\n",
      "\u001b[92mcmd2:\u001b[0m Still waiting for remote lm reset from ts 1766528432100...\n",
      "\u001b[92mcmd2:\u001b[0m Still waiting for remote lm reset from ts 1766528432100...\n",
      "\u001b[92mcmd2:\u001b[0m Still waiting for remote lm reset from ts 1766528432100...\n",
      "\u001b[94mcmd1:\u001b[0m Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "\u001b[92mcmd2:\u001b[0m Still waiting for remote lm reset from ts 1766528432100...\n",
      "\u001b[92mcmd2:\u001b[0m Still waiting for remote lm reset from ts 1766528432100...\n",
      "\u001b[94mcmd1:\u001b[0m Downloading shards:  50%|█████     | 1/2 [00:52<00:52, 52.46s/it]\n",
      "\u001b[94mcmd1:\u001b[0m Downloading shards: 100%|██████████| 2/2 [01:10<00:00, 32.10s/it]\n",
      "\u001b[94mcmd1:\u001b[0m Downloading shards: 100%|██████████| 2/2 [01:10<00:00, 35.15s/it]\n",
      "\u001b[94mcmd1:\u001b[0m \n",
      "\u001b[92mcmd2:\u001b[0m Still waiting for remote lm reset from ts 1766528432100...\n",
      "\u001b[92mcmd2:\u001b[0m Still waiting for remote lm reset from ts 1766528432100...\n",
      "\u001b[92mcmd2:\u001b[0m Still waiting for remote lm reset from ts 1766528432100...\n",
      "\u001b[92mcmd2:\u001b[0m Still waiting for remote lm reset from ts 1766528432100...\n",
      "\u001b[94mcmd1:\u001b[0m Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "\u001b[92mcmd2:\u001b[0m Still waiting for remote lm reset from ts 1766528432100...\n",
      "\u001b[94mcmd1:\u001b[0m Loading checkpoint shards:  50%|█████     | 1/2 [00:41<00:41, 41.28s/it]\n",
      "\u001b[94mcmd1:\u001b[0m Loading checkpoint shards: 100%|██████████| 2/2 [00:54<00:00, 24.57s/it]\n",
      "\u001b[94mcmd1:\u001b[0m Loading checkpoint shards: 100%|██████████| 2/2 [00:54<00:00, 27.08s/it]\n",
      "\u001b[92mcmd2:\u001b[0m Still waiting for remote lm reset from ts 1766528432100...\n",
      "\u001b[94mcmd1:\u001b[0m 2025-12-23 22:27:51,251 INFO: OPT model successfully built in 136.0038 seconds.\n",
      "\u001b[94mcmd1:\u001b[0m 2025-12-23 22:27:51,251 INFO: Initializing language model decoder from language_model/pretrained_language_models/openwebtext_1gram_lm_sil...\n",
      "\u001b[94mcmd1:\u001b[0m WARNING: Logging before InitGoogleLogging() is written to STDERR\n",
      "\u001b[94mcmd1:\u001b[0m I1223 22:27:51.255093  1846 brain_speech_decoder.h:52] Reading fst language_model/pretrained_language_models/openwebtext_1gram_lm_sil/TLG.fst\n",
      "\u001b[94mcmd1:\u001b[0m I1223 22:27:51.356495  1846 brain_speech_decoder.h:81] Reading symbol table language_model/pretrained_language_models/openwebtext_1gram_lm_sil/words.txt\n",
      "\u001b[94mcmd1:\u001b[0m 2025-12-23 22:27:51,518 INFO: Language model successfully initialized in 0.2673 seconds.\n",
      "\u001b[94mcmd1:\u001b[0m 2025-12-23 22:27:51,518 INFO: Attempting to connect to redis at localhost:6379...\n",
      "\u001b[94mcmd1:\u001b[0m 2025-12-23 22:27:51,520 INFO: Connected to redis.\n",
      "\u001b[94mcmd1:\u001b[0m 2025-12-23 22:27:51,520 INFO: Successfully connected to redis server at localhost:6379.\n",
      "\u001b[94mcmd1:\u001b[0m 2025-12-23 22:27:51,520 INFO: Entering main loop...\n",
      "\u001b[94mcmd1:\u001b[0m 2025-12-23 22:27:51,520 INFO: Successfully connected to the redis server.\n",
      "\u001b[92mcmd2:\u001b[0m Still waiting for remote lm reset from ts 1766528432100...\n",
      "\u001b[92mcmd2:\u001b[0m Still waiting for remote lm reset from ts 1766528432100...\n",
      "\u001b[92mcmd2:\u001b[0m Still waiting for remote lm reset from ts 1766528432100...\n",
      "\u001b[92mcmd2:\u001b[0m Still waiting for remote lm reset from ts 1766528432100...\n",
      "\u001b[92mcmd2:\u001b[0m Still waiting for remote lm reset from ts 1766528432100...\n",
      "\u001b[92mcmd2:\u001b[0m Still waiting for remote lm reset from ts 1766528432100...\n",
      "\u001b[92mcmd2:\u001b[0m Still waiting for remote lm reset from ts 1766528432100...\n",
      "\u001b[92mcmd2:\u001b[0m Still waiting for remote lm reset from ts 1766528432100...\n",
      "\u001b[92mcmd2:\u001b[0m Still waiting for remote lm reset from ts 1766528432100...\n",
      "\u001b[92mcmd2:\u001b[0m Still waiting for remote lm reset from ts 1766528432100...\n",
      "\u001b[92mcmd2:\u001b[0m Still waiting for remote lm reset from ts 1766528432100...\n",
      "\u001b[92mcmd2:\u001b[0m Still waiting for remote lm reset from ts 1766528432100...\n",
      "\u001b[92mcmd2:\u001b[0m Still waiting for remote lm reset from ts 1766528432100...\n",
      "\u001b[92mcmd2:\u001b[0m Still waiting for remote lm reset from ts 1766528432100...\n",
      "\u001b[92mcmd2:\u001b[0m Still waiting for remote lm reset from ts 1766528432100...\n",
      "\u001b[92mcmd2:\u001b[0m Still waiting for remote lm reset from ts 1766528432100...\n",
      "\u001b[92mcmd2:\u001b[0m Still waiting for remote lm reset from ts 1766528432100...\n",
      "\u001b[92mcmd2:\u001b[0m Still waiting for remote lm reset from ts 1766528432100...\n",
      "\u001b[92mcmd2:\u001b[0m Still waiting for remote lm reset from ts 1766528432100...\n",
      "\u001b[92mcmd2:\u001b[0m Still waiting for remote lm reset from ts 1766528432100...\n",
      "\u001b[92mcmd2:\u001b[0m Still waiting for remote lm reset from ts 1766528432100...\n",
      "\u001b[92mcmd2:\u001b[0m Still waiting for remote lm reset from ts 1766528432100...\n",
      "\u001b[92mcmd2:\u001b[0m Still waiting for remote lm reset from ts 1766528432100...\n",
      "\u001b[92mcmd2:\u001b[0m Still waiting for remote lm reset from ts 1766528432100...\n",
      "\u001b[92mcmd2:\u001b[0m Still waiting for remote lm reset from ts 1766528432100...\n",
      "\u001b[92mcmd2:\u001b[0m Still waiting for remote lm reset from ts 1766528432100...\n",
      "\u001b[92mcmd2:\u001b[0m Still waiting for remote lm reset from ts 1766528432100...\n",
      "\u001b[92mcmd2:\u001b[0m Still waiting for remote lm reset from ts 1766528432100...\n",
      "\u001b[92mcmd2:\u001b[0m Still waiting for remote lm reset from ts 1766528432100...\n",
      "\u001b[92mcmd2:\u001b[0m Still waiting for remote lm reset from ts 1766528432100...\n",
      "\u001b[92mcmd2:\u001b[0m Still waiting for remote lm reset from ts 1766528432100...\n",
      "\u001b[92mcmd2:\u001b[0m Still waiting for remote lm reset from ts 1766528432100...\n",
      "\u001b[92mcmd2:\u001b[0m Still waiting for remote lm reset from ts 1766528432100...\n",
      "\u001b[92mcmd2:\u001b[0m Still waiting for remote lm reset from ts 1766528432100...\n",
      "\u001b[92mcmd2:\u001b[0m Still waiting for remote lm reset from ts 1766528432100...\n",
      "\u001b[92mcmd2:\u001b[0m Still waiting for remote lm reset from ts 1766528432100...\n",
      "\u001b[92mcmd2:\u001b[0m Still waiting for remote lm reset from ts 1766528432100...\n",
      "\u001b[92mcmd2:\u001b[0m Still waiting for remote lm reset from ts 1766528432100...\n",
      "\u001b[92mcmd2:\u001b[0m Still waiting for remote lm reset from ts 1766528432100...\n",
      "\u001b[92mcmd2:\u001b[0m Still waiting for remote lm reset from ts 1766528432100...\n",
      "\u001b[92mcmd2:\u001b[0m Still waiting for remote lm reset from ts 1766528432100...\n",
      "\u001b[92mcmd2:\u001b[0m Still waiting for remote lm reset from ts 1766528432100...\n",
      "\u001b[92mcmd2:\u001b[0m Still waiting for remote lm reset from ts 1766528432100...\n",
      "\u001b[92mcmd2:\u001b[0m Still waiting for remote lm reset from ts 1766528432100...\n",
      "\u001b[92mcmd2:\u001b[0m Still waiting for remote lm reset from ts 1766528432100...\n",
      "\u001b[92mcmd2:\u001b[0m Still waiting for remote lm reset from ts 1766528432100...\n",
      "\u001b[92mcmd2:\u001b[0m Still waiting for remote lm reset from ts 1766528432100...\n",
      "\u001b[92mcmd2:\u001b[0m Still waiting for remote lm reset from ts 1766528432100...\n",
      "\u001b[92mcmd2:\u001b[0m Still waiting for remote lm reset from ts 1766528432100...\n",
      "\u001b[92mcmd2:\u001b[0m Still waiting for remote lm reset from ts 1766528432100...\n",
      "\u001b[92mcmd2:\u001b[0m Still waiting for remote lm reset from ts 1766528432100...\n",
      "\u001b[92mcmd2:\u001b[0m Still waiting for remote lm reset from ts 1766528432100...\n",
      "\u001b[92mcmd2:\u001b[0m Still waiting for remote lm reset from ts 1766528432100...\n",
      "\u001b[92mcmd2:\u001b[0m Still waiting for remote lm reset from ts 1766528432100...\n",
      "\u001b[92mcmd2:\u001b[0m Still waiting for remote lm reset from ts 1766528432100...\n",
      "\u001b[92mcmd2:\u001b[0m Still waiting for remote lm reset from ts 1766528432100...\n",
      "\u001b[92mcmd2:\u001b[0m Still waiting for remote lm reset from ts 1766528432100...\n",
      "\u001b[92mcmd2:\u001b[0m Still waiting for remote lm reset from ts 1766528432100...\n",
      "\u001b[92mcmd2:\u001b[0m Still waiting for remote lm reset from ts 1766528432100...\n",
      "\u001b[92mcmd2:\u001b[0m Still waiting for remote lm reset from ts 1766528432100...\n",
      "\u001b[92mcmd2:\u001b[0m Still waiting for remote lm reset from ts 1766528432100...\n",
      "\u001b[92mcmd2:\u001b[0m Still waiting for remote lm reset from ts 1766528432100...\n",
      "\u001b[92mcmd2:\u001b[0m Still waiting for remote lm reset from ts 1766528432100...\n",
      "\u001b[92mcmd2:\u001b[0m Still waiting for remote lm reset from ts 1766528432100...\n",
      "\u001b[92mcmd2:\u001b[0m Still waiting for remote lm reset from ts 1766528432100...\n",
      "\u001b[92mcmd2:\u001b[0m Still waiting for remote lm reset from ts 1766528432100...\n",
      "\u001b[92mcmd2:\u001b[0m Still waiting for remote lm reset from ts 1766528432100...\n",
      "\u001b[92mcmd2:\u001b[0m Still waiting for remote lm reset from ts 1766528432100...\n",
      "\u001b[92mcmd2:\u001b[0m Still waiting for remote lm reset from ts 1766528432100...\n",
      "\u001b[92mcmd2:\u001b[0m Still waiting for remote lm reset from ts 1766528432100...\n",
      "\u001b[92mcmd2:\u001b[0m Still waiting for remote lm reset from ts 1766528432100...\n",
      "\u001b[92mcmd2:\u001b[0m Still waiting for remote lm reset from ts 1766528432100...\n",
      "\u001b[92mcmd2:\u001b[0m Still waiting for remote lm reset from ts 1766528432100...\n",
      "\u001b[92mcmd2:\u001b[0m Still waiting for remote lm reset from ts 1766528432100...\n",
      "\u001b[92mcmd2:\u001b[0m Still waiting for remote lm reset from ts 1766528432100...\n",
      "\u001b[92mcmd2:\u001b[0m Still waiting for remote lm reset from ts 1766528432100...\n",
      "\u001b[92mcmd2:\u001b[0m Still waiting for remote lm reset from ts 1766528432100...\n",
      "\u001b[92mcmd2:\u001b[0m Still waiting for remote lm reset from ts 1766528432100...\n",
      "\u001b[92mcmd2:\u001b[0m Still waiting for remote lm reset from ts 1766528432100...\n",
      "\u001b[92mcmd2:\u001b[0m Still waiting for remote lm reset from ts 1766528432100...\n",
      "\u001b[92mcmd2:\u001b[0m Still waiting for remote lm reset from ts 1766528432100...\n",
      "\u001b[92mcmd2:\u001b[0m Still waiting for remote lm reset from ts 1766528432100...\n",
      "\u001b[92mcmd2:\u001b[0m Still waiting for remote lm reset from ts 1766528432100...\n",
      "\u001b[92mcmd2:\u001b[0m Still waiting for remote lm reset from ts 1766528432100...\n",
      "\u001b[92mcmd2:\u001b[0m Still waiting for remote lm reset from ts 1766528432100...\n",
      "\u001b[92mcmd2:\u001b[0m Still waiting for remote lm reset from ts 1766528432100...\n",
      "\u001b[92mcmd2:\u001b[0m Still waiting for remote lm reset from ts 1766528432100...\n",
      "\u001b[92mcmd2:\u001b[0m Still waiting for remote lm reset from ts 1766528432100...\n",
      "\u001b[92mcmd2:\u001b[0m Still waiting for remote lm reset from ts 1766528432100...\n",
      "\u001b[92mcmd2:\u001b[0m Still waiting for remote lm reset from ts 1766528432100...\n",
      "\u001b[92mcmd2:\u001b[0m Still waiting for remote lm reset from ts 1766528432100...\n",
      "\u001b[92mcmd2:\u001b[0m Still waiting for remote lm reset from ts 1766528432100...\n",
      "\u001b[92mcmd2:\u001b[0m Still waiting for remote lm reset from ts 1766528432100...\n",
      "\u001b[92mcmd2:\u001b[0m Still waiting for remote lm reset from ts 1766528432100...\n",
      "\u001b[92mcmd2:\u001b[0m Still waiting for remote lm reset from ts 1766528432100...\n",
      "\u001b[92mcmd2:\u001b[0m Still waiting for remote lm reset from ts 1766528432100...\n",
      "\u001b[92mcmd2:\u001b[0m Still waiting for remote lm reset from ts 1766528432100...\n",
      "\u001b[92mcmd2:\u001b[0m Still waiting for remote lm reset from ts 1766528432100...\n",
      "\u001b[92mcmd2:\u001b[0m Still waiting for remote lm reset from ts 1766528432100...\n",
      "\u001b[92mcmd2:\u001b[0m Still waiting for remote lm reset from ts 1766528432100...\n",
      "\u001b[92mcmd2:\u001b[0m Still waiting for remote lm reset from ts 1766528432100...\n",
      "\u001b[92mcmd2:\u001b[0m Still waiting for remote lm reset from ts 1766528432100...\n",
      "\u001b[92mcmd2:\u001b[0m Still waiting for remote lm reset from ts 1766528432100...\n",
      "\u001b[92mcmd2:\u001b[0m Still waiting for remote lm reset from ts 1766528432100...\n",
      "\u001b[92mcmd2:\u001b[0m Still waiting for remote lm reset from ts 1766528432100...\n",
      "\u001b[92mcmd2:\u001b[0m Still waiting for remote lm reset from ts 1766528432100...\n",
      "\u001b[92mcmd2:\u001b[0m Still waiting for remote lm reset from ts 1766528432100...\n",
      "\u001b[92mcmd2:\u001b[0m Still waiting for remote lm reset from ts 1766528432100...\n",
      "\u001b[92mcmd2:\u001b[0m Still waiting for remote lm reset from ts 1766528432100...\n",
      "\u001b[92mcmd2:\u001b[0m Still waiting for remote lm reset from ts 1766528432100...\n",
      "\u001b[92mcmd2:\u001b[0m Still waiting for remote lm reset from ts 1766528432100...\n",
      "\u001b[92mcmd2:\u001b[0m Still waiting for remote lm reset from ts 1766528432100...\n",
      "\u001b[92mcmd2:\u001b[0m Still waiting for remote lm reset from ts 1766528432100...\n",
      "\u001b[92mcmd2:\u001b[0m Still waiting for remote lm reset from ts 1766528432100...\n",
      "\u001b[92mcmd2:\u001b[0m Still waiting for remote lm reset from ts 1766528432100...\n",
      "\u001b[92mcmd2:\u001b[0m Still waiting for remote lm reset from ts 1766528432100...\n",
      "\u001b[92mcmd2:\u001b[0m Still waiting for remote lm reset from ts 1766528432100...\n",
      "\u001b[92mcmd2:\u001b[0m Still waiting for remote lm reset from ts 1766528432100...\n",
      "\u001b[92mcmd2:\u001b[0m Still waiting for remote lm reset from ts 1766528432100...\n",
      "\u001b[92mcmd2:\u001b[0m Still waiting for remote lm reset from ts 1766528432100...\n",
      "\u001b[92mcmd2:\u001b[0m Still waiting for remote lm reset from ts 1766528432100...\n",
      "\u001b[92mcmd2:\u001b[0m Still waiting for remote lm reset from ts 1766528432100...\n",
      "\u001b[92mcmd2:\u001b[0m Still waiting for remote lm reset from ts 1766528432100...\n",
      "\u001b[92mcmd2:\u001b[0m Still waiting for remote lm reset from ts 1766528432100...\n",
      "\u001b[92mcmd2:\u001b[0m Still waiting for remote lm reset from ts 1766528432100...\n",
      "\u001b[92mcmd2:\u001b[0m Still waiting for remote lm reset from ts 1766528432100...\n",
      "\u001b[92mcmd2:\u001b[0m Still waiting for remote lm reset from ts 1766528432100...\n",
      "\u001b[92mcmd2:\u001b[0m Still waiting for remote lm reset from ts 1766528432100...\n",
      "\u001b[92mcmd2:\u001b[0m Still waiting for remote lm reset from ts 1766528432100...\n",
      "\u001b[92mcmd2:\u001b[0m Still waiting for remote lm reset from ts 1766528432100...\n",
      "\u001b[92mcmd2:\u001b[0m Still waiting for remote lm reset from ts 1766528432100...\n",
      "\u001b[92mcmd2:\u001b[0m Still waiting for remote lm reset from ts 1766528432100...\n",
      "\u001b[92mcmd2:\u001b[0m Still waiting for remote lm reset from ts 1766528432100...\n",
      "\u001b[92mcmd2:\u001b[0m Still waiting for remote lm reset from ts 1766528432100...\n",
      "\u001b[92mcmd2:\u001b[0m Still waiting for remote lm reset from ts 1766528432100...\n",
      "\u001b[92mcmd2:\u001b[0m Still waiting for remote lm reset from ts 1766528432100...\n",
      "\u001b[92mcmd2:\u001b[0m Still waiting for remote lm reset from ts 1766528432100...\n",
      "\u001b[92mcmd2:\u001b[0m Still waiting for remote lm reset from ts 1766528432100...\n",
      "\u001b[92mcmd2:\u001b[0m Still waiting for remote lm reset from ts 1766528432100...\n",
      "\u001b[92mcmd2:\u001b[0m Still waiting for remote lm reset from ts 1766528432100...\n",
      "\u001b[92mcmd2:\u001b[0m Still waiting for remote lm reset from ts 1766528432100...\n",
      "\u001b[92mcmd2:\u001b[0m Still waiting for remote lm reset from ts 1766528432100...\n",
      "\u001b[92mcmd2:\u001b[0m Still waiting for remote lm reset from ts 1766528432100...\n",
      "\u001b[92mcmd2:\u001b[0m Still waiting for remote lm reset from ts 1766528432100...\n",
      "\u001b[92mcmd2:\u001b[0m Still waiting for remote lm reset from ts 1766528432100...\n",
      "\u001b[92mcmd2:\u001b[0m Still waiting for remote lm reset from ts 1766528432100...\n",
      "\u001b[92mcmd2:\u001b[0m Still waiting for remote lm reset from ts 1766528432100...\n",
      "\u001b[92mcmd2:\u001b[0m Still waiting for remote lm reset from ts 1766528432100...\n",
      "\u001b[92mcmd2:\u001b[0m Still waiting for remote lm reset from ts 1766528432100...\n",
      "\u001b[92mcmd2:\u001b[0m Still waiting for remote lm reset from ts 1766528432100...\n",
      "\u001b[92mcmd2:\u001b[0m Still waiting for remote lm reset from ts 1766528432100...\n",
      "\u001b[92mcmd2:\u001b[0m Still waiting for remote lm reset from ts 1766528432100...\n",
      "\u001b[92mcmd2:\u001b[0m Still waiting for remote lm reset from ts 1766528432100...\n",
      "\u001b[92mcmd2:\u001b[0m Still waiting for remote lm reset from ts 1766528432100...\n",
      "\u001b[92mcmd2:\u001b[0m Still waiting for remote lm reset from ts 1766528432100...\n",
      "\u001b[92mcmd2:\u001b[0m Still waiting for remote lm reset from ts 1766528432100...\n",
      "\u001b[92mcmd2:\u001b[0m Still waiting for remote lm reset from ts 1766528432100...\n",
      "\u001b[92mcmd2:\u001b[0m Still waiting for remote lm reset from ts 1766528432100...\n",
      "\u001b[92mcmd2:\u001b[0m Still waiting for remote lm reset from ts 1766528432100...\n",
      "\u001b[92mcmd2:\u001b[0m Still waiting for remote lm reset from ts 1766528432100...\n",
      "\u001b[92mcmd2:\u001b[0m Still waiting for remote lm reset from ts 1766528432100...\n",
      "\u001b[92mcmd2:\u001b[0m Still waiting for remote lm reset from ts 1766528432100...\n",
      "\u001b[92mcmd2:\u001b[0m Still waiting for remote lm reset from ts 1766528432100...\n",
      "\u001b[92mcmd2:\u001b[0m Still waiting for remote lm reset from ts 1766528432100...\n",
      "\u001b[92mcmd2:\u001b[0m Still waiting for remote lm reset from ts 1766528432100...\n",
      "\u001b[92mcmd2:\u001b[0m Still waiting for remote lm reset from ts 1766528432100...\n",
      "\u001b[92mcmd2:\u001b[0m Still waiting for remote lm reset from ts 1766528432100...\n",
      "\u001b[92mcmd2:\u001b[0m Still waiting for remote lm reset from ts 1766528432100...\n",
      "\u001b[92mcmd2:\u001b[0m Still waiting for remote lm reset from ts 1766528432100...\n",
      "\u001b[92mcmd2:\u001b[0m Still waiting for remote lm reset from ts 1766528432100...\n",
      "\u001b[92mcmd2:\u001b[0m Still waiting for remote lm reset from ts 1766528432100...\n",
      "\u001b[92mcmd2:\u001b[0m Still waiting for remote lm reset from ts 1766528432100...\n",
      "\u001b[92mcmd2:\u001b[0m Still waiting for remote lm reset from ts 1766528432100...\n",
      "\u001b[92mcmd2:\u001b[0m Still waiting for remote lm reset from ts 1766528432100...\n",
      "\u001b[92mcmd2:\u001b[0m Still waiting for remote lm reset from ts 1766528432100...\n",
      "\u001b[92mcmd2:\u001b[0m Still waiting for remote lm reset from ts 1766528432100...\n",
      "\u001b[92mcmd2:\u001b[0m Still waiting for remote lm reset from ts 1766528432100...\n",
      "\u001b[92mcmd2:\u001b[0m Still waiting for remote lm reset from ts 1766528432100...\n",
      "\u001b[92mcmd2:\u001b[0m Still waiting for remote lm reset from ts 1766528432100...\n",
      "\u001b[92mcmd2:\u001b[0m Still waiting for remote lm reset from ts 1766528432100...\n",
      "\u001b[92mcmd2:\u001b[0m Still waiting for remote lm reset from ts 1766528432100...\n",
      "\u001b[92mcmd2:\u001b[0m Still waiting for remote lm reset from ts 1766528432100...\n",
      "\u001b[92mcmd2:\u001b[0m Still waiting for remote lm reset from ts 1766528432100...\n",
      "\u001b[92mcmd2:\u001b[0m Still waiting for remote lm reset from ts 1766528432100...\n",
      "\u001b[92mcmd2:\u001b[0m Still waiting for remote lm reset from ts 1766528432100...\n",
      "\u001b[92mcmd2:\u001b[0m Still waiting for remote lm reset from ts 1766528432100...\n",
      "\u001b[92mcmd2:\u001b[0m Still waiting for remote lm reset from ts 1766528432100...\n",
      "\u001b[92mcmd2:\u001b[0m Still waiting for remote lm reset from ts 1766528432100...\n",
      "\u001b[92mcmd2:\u001b[0m Still waiting for remote lm reset from ts 1766528432100...\n",
      "\u001b[92mcmd2:\u001b[0m Still waiting for remote lm reset from ts 1766528432100...\n",
      "\u001b[92mcmd2:\u001b[0m Still waiting for remote lm reset from ts 1766528432100...\n",
      "\u001b[92mcmd2:\u001b[0m Still waiting for remote lm reset from ts 1766528432100...\n",
      "\u001b[92mcmd2:\u001b[0m Still waiting for remote lm reset from ts 1766528432100...\n",
      "\u001b[92mcmd2:\u001b[0m Still waiting for remote lm reset from ts 1766528432100...\n",
      "\u001b[92mcmd2:\u001b[0m Still waiting for remote lm reset from ts 1766528432100...\n",
      "\u001b[92mcmd2:\u001b[0m Still waiting for remote lm reset from ts 1766528432100...\n",
      "\u001b[92mcmd2:\u001b[0m Still waiting for remote lm reset from ts 1766528432100...\n",
      "\u001b[92mcmd2:\u001b[0m Still waiting for remote lm reset from ts 1766528432100...\n",
      "\u001b[92mcmd2:\u001b[0m Still waiting for remote lm reset from ts 1766528432100...\n",
      "\u001b[92mcmd2:\u001b[0m Still waiting for remote lm reset from ts 1766528432100...\n",
      "\u001b[92mcmd2:\u001b[0m Still waiting for remote lm reset from ts 1766528432100...\n",
      "\u001b[92mcmd2:\u001b[0m Still waiting for remote lm reset from ts 1766528432100...\n",
      "\u001b[92mcmd2:\u001b[0m Still waiting for remote lm reset from ts 1766528432100...\n",
      "\u001b[92mcmd2:\u001b[0m Still waiting for remote lm reset from ts 1766528432100...\n",
      "\u001b[92mcmd2:\u001b[0m Still waiting for remote lm reset from ts 1766528432100...\n",
      "\u001b[92mcmd2:\u001b[0m Still waiting for remote lm reset from ts 1766528432100...\n",
      "\u001b[92mcmd2:\u001b[0m Still waiting for remote lm reset from ts 1766528432100...\n",
      "\u001b[92mcmd2:\u001b[0m Still waiting for remote lm reset from ts 1766528432100...\n",
      "\u001b[92mcmd2:\u001b[0m Still waiting for remote lm reset from ts 1766528432100...\n",
      "\u001b[92mcmd2:\u001b[0m Still waiting for remote lm reset from ts 1766528432100...\n",
      "\u001b[92mcmd2:\u001b[0m Still waiting for remote lm reset from ts 1766528432100...\n",
      "\u001b[92mcmd2:\u001b[0m Still waiting for remote lm reset from ts 1766528432100...\n",
      "\u001b[92mcmd2:\u001b[0m Still waiting for remote lm reset from ts 1766528432100...\n",
      "\u001b[92mcmd2:\u001b[0m Still waiting for remote lm reset from ts 1766528432100...\n",
      "\u001b[92mcmd2:\u001b[0m Still waiting for remote lm reset from ts 1766528432100...\n"
     ]
    }
   ],
   "source": [
    "# Install Redis server using apt (system package manager)\n",
    "!apt-get update\n",
    "!apt-get install -y redis-server\n",
    "\n",
    "# Start Redis server in the background\n",
    "!redis-server --daemonize yes\n",
    "\n",
    "!mkdir -p ~/miniconda3\n",
    "!wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh -O ~/miniconda3/miniconda.sh\n",
    "!bash ~/miniconda3/miniconda.sh -b -u -p ~/miniconda3\n",
    "!rm ~/miniconda3/miniconda.sh\n",
    "!source ~/miniconda3/bin/activate\n",
    "\n",
    "!~/miniconda3/bin/conda tos accept --override-channels --channel https://repo.anaconda.com/pkgs/main\n",
    "!~/miniconda3/bin/conda tos accept --override-channels --channel https://repo.anaconda.com/pkgs/r\n",
    "\n",
    "!rm -r ./Brain-To-Text-MOA || true\n",
    "!git clone \"https://github.com/vuvanqh/Brain-To-Text-MOA\"\n",
    "\n",
    "!cd ./Brain-To-Text-MOA\n",
    "\n",
    "%cd /kaggle/working/Brain-To-Text-MOA/\n",
    "\n",
    "!rm -rf language_model/runtime/server/x86/build || true\n",
    "!rm -rf language_model/runtime/server/x86/fc_base || true\n",
    "\n",
    "import subprocess\n",
    "import threading\n",
    "\n",
    "class Colors:\n",
    "    CMD1 = '\\033[95m'  # Pink\n",
    "    CMD2 = '\\033[35m'  # Purple\n",
    "    RESET = '\\033[0m'\n",
    "\n",
    "def run_command(command, prefix, color=\"\"):\n",
    "    \"\"\"Run a shell command and print output in real-time with colored prefix\"\"\"\n",
    "    process = subprocess.Popen(\n",
    "        command,\n",
    "        shell=True,\n",
    "        stdout=subprocess.PIPE,\n",
    "        stderr=subprocess.STDOUT,\n",
    "        text=True,\n",
    "        bufsize=1,\n",
    "        executable='/bin/bash'\n",
    "    )\n",
    "    \n",
    "    # Print output in real-time with colored prefix\n",
    "    for line in process.stdout:\n",
    "        print(f\"{color}{prefix}:{Colors.RESET} {line}\", end='')\n",
    "    \n",
    "    process.wait()\n",
    "    return process.returncode\n",
    "\n",
    "# Define your commands\n",
    "cmd1 = \"alias conda='~/miniconda3/bin/conda' && source ~/miniconda3/bin/activate && bash setup_lm.sh && conda activate b2txt25_lm && python language_model/language-model-standalone.py --lm_path language_model/pretrained_language_models/openwebtext_1gram_lm_sil --do_opt --nbest 100 --acoustic_scale 0.325 --blank_penalty 90 --alpha 0.55 --redis_ip localhost --gpu_number 0\"\n",
    "cmd2 = \"echo 'Sleeping for 15 minutes...' && sleep 900 && alias conda='~/miniconda3/bin/conda' && source ~/miniconda3/bin/activate && bash setup.sh && conda activate b2txt25 && python model_training/evaluate_model.py --gpu_number 1 --model_path /kaggle/input/brain-to-text-25/t15_pretrained_rnn_baseline/t15_pretrained_rnn_baseline/ --data_dir /kaggle/input/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final --csv_path ./data/t15_copyTaskData_description.csv --eval_type val\"\n",
    "\n",
    "# Create threads with colored prefixes\n",
    "thread1 = threading.Thread(target=run_command, args=(cmd1, \"cmd1\", Colors.CMD1))\n",
    "thread2 = threading.Thread(target=run_command, args=(cmd2, \"cmd2\", Colors.CMD2))\n",
    "\n",
    "# Start both threads\n",
    "thread1.start()\n",
    "thread2.start()\n",
    "\n",
    "# Wait for both to complete\n",
    "thread1.join()\n",
    "thread2.join()\n",
    "\n",
    "print(\"Both commands completed!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
